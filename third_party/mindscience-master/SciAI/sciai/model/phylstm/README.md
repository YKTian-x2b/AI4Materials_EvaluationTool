ENGLISH | [简体中文](README_CN.md)

# Contents

- [Physics-informed double-LSTM Network](#physics-informed-double-lstm-network)
    - [Network Introduction](#network-introduction)
    - [Implement Case](#implement-case)
- [Dataset](#dataset)
- [Environment Requirements](#environment-requirements)
- [Quick Start](#quick-start)
- [Script Description](#script-description)
    - [Script and Sample Code](#script-and-sample-code)
    - [Script Parameters](#script-parameters)
    - [Training Process](#training-process)
    - [Evaluation Process](#evaluation-process)

## [Physics-informed double-LSTM Network](#contents)

### [Network Introduction](#contents)

This work introduces an innovative physics-informed deep learning framework for metamodeling of nonlinear structural systems with scarce data. The basic concept is to incorporate available, yet incomplete, physics knowledge (e.g., laws of physics, scientific principles) into deep long short-term memory (LSTM) networks, which constrains and boosts the learning within a feasible solution space. Meanwhile, the physics constraints are embedded in the loss function to enforce the model training. Specifically for dynamic structures, physical laws of equation of motion, state dependency and hysteretic constitutive relationship are considered to construct the physics loss.

> [Paper](https://www.sciencedirect.com/science/article/pii/S0045782520304114): Zhang R, Liu Y, Sun H. Physics-informed multi-LSTM networks for metamodeling of nonlinear structures[J]. Computer Methods in Applied Mechanics and Engineering, 2020, 369: 113226.

### [Implement Case](#contents)

The paper utilizes two LSTM networks to input raw data loaded from the dataset into the network to obtain predictive output. Specifically, both training data and auxiliary data are fed into the network, and after obtaining corresponding outputs at different stages, MSE loss is applied to calculate the difference between the predicted value and the true value to guide network training.

For graph based tensor differentiators, the intermediate variable $\phi$ obtained from raw data processing is multiplied by the corresponding output.

![PhyLSTM2 Network](docs/PhyLSTM2_Network.png)

## [Dataset](#contents)

The dataset adopts the SDOF Bouc Wen hysteresis model. The Bouc Wen hysteresis model is a nonlinear system with rate dependent hysteresis (e.g. dependent on $\dot r$).

The [raw data](./data/data_boucwen.mat) consists of 100 samples (such as independent earthquake sequences), and is generated by numerical simulation of a single degree of freedom nonlinear system excited by random band-limited white noise (BLWN) ground motion to generate synthetic databases of different amplitudes. All datasets are formatted as the required 3D array for $PhyLSTM^2$.

The paper adopts a fully supervised training and validation approach, and the dataset is generated in real-time during operation. The training and testing data [generation method](./src/process.py) is as follows:

- Training data: Randomly select 10 BLWN input datasets and corresponding structural displacement and velocity responses, which are considered as "known" datasets for training or validation (with a segmentation ratio of 0.8:0.2). In addition, 50 additional auxiliary samples (such as only BLWN input records) are used to guide model training with physical constraints.

- Test data: The remaining datasets are considered as "unknown" datasets to test the predictive performance of the training meta-model.

## [Environment Requirements](#contents)

- Hardware(Ascend)
    - Prepare hardware environment with Ascend or GPU processor.
- Framework
    - [MindSpore](https://www.mindspore.cn/install/en)
- For more information, please check the resources below:
    - [MindSpore Tutorials](https://www.mindspore.cn/tutorials/en/master/index.html)
    - [MindSpore Python API](https://www.mindspore.cn/docs/en/master/index.html)

## [Quick Start](#contents)

After installing MindSpore via the official website and the required [dataset](#dataset) above, you can start training
and evaluation as follows:

- running on Ascend

Default:

```bash
python train.py
```

Full command:

```bash
python train.py \
    --print_interval 1 \
    --ckpt_interval 1 \
    --save_fig true \
    --save_ckpt true \
    --load_ckpt false \
    --save_ckpt_path ./checkpoints \
    --load_ckpt_path ./checkpoints/your_file.ckpt \
    --figures_path ./figures \
    --load_data_path ./data/data_boucwen.mat \
    --log_path ./logs \
    --epochs 8000 \
    --lr 1e-4 \
    --mode train
```

## [Script Description](#contents)

### [Script and Sample Code](#contents)

```text
├── auq_pinns
│   ├── checkpoints                                    # checkpoints files
│   ├── data                                           # data files
│   │   └── data_boucwen.mat                           # SDOF Bouc Wen dataset
|   ├── docs
│   │   └──Physics-informed double-LSTM Network.png    # PHYLSTM2 network structure diagram
│   ├── figures                                        # plot figures
│   ├── logs                                           # log files
│   ├── src                                            # source codes
│   │   ├── network.py                                 # network architecture
│   │   ├── plot.py                                    # plotting results
│   │   └── process.py                                 # data process
│   ├── config.json                                    # hyper-parameters configuration
│   ├── README.md                                      # English model descriptions
│   ├── README_CN.md                                   # Chinese model description
│   ├── test.py                                        # test python script
│   └── train.py                                       # training python script
```

### [Script Parameters](#contents)

Important parameters in `train.py` are as follows:

| parameter       | description                                    | default value                |
|-----------------|------------------------------------------------|------------------------------|
| print_interval  | interval for loss printing                     | 1                            |
| ckpt_interval   | interval for saving checkpoint file            | 1                            |
| save_fig        | whether save and plot figures or not           | true                         |
| save_ckpt       | whether save checkpoint or not                 | true                         |
| load_ckpt       | whether load checkpoint or not                 | false                        |
| save_ckpt_path  | checkpoint saving path                         | ./checkpoints                |
| load_ckpt_path  | checkpoint loading path                        | ./checkpoints/your_file.ckpt |
| figures_path    | figures saving path                            | ./figures                    |
| load_data_path  | path to load validation data                   | ./data                       |
| log_path        | log saving path                                | ./logs                       |
| epochs          | number of training epochs                      | 8000                         |
| lr              | learning rate                                  | 1e-4                         |
| mode            | run mode                                       | train                        |

### [Training Process](#contents)

- running on Ascend

  ```bash
  python train.py
  ```

  The loss values during training will be printed in the console.

  ```bash
  [Adam]Epoch:0,Train_Loss:2.2092102,Eval_Loss:2.170113,bestLoss:2.209210157394409,bestEpoch:0
  [Adam]Epoch:1,Train_Loss:2.1713018,Eval_Loss:2.127627,bestLoss:2.17130184173584,bestEpoch:1
  [Adam]Epoch:2,Train_Loss:2.1313734,Eval_Loss:2.1100757,bestLoss:2.131373405456543,bestEpoch:2
  [Adam]Epoch:3,Train_Loss:2.102894,Eval_Loss:2.065416,bestLoss:2.1028940677642822,bestEpoch:3
  [Adam]Epoch:4,Train_Loss:2.0730639,Eval_Loss:2.0375416,bestLoss:2.073063850402832,bestEpoch:4
  [Adam]Epoch:5,Train_Loss:2.043288,Eval_Loss:2.019644,bestLoss:2.043287992477417,bestEpoch:5
  [Adam]Epoch:6,Train_Loss:2.013958,Eval_Loss:2.0036902,bestLoss:2.013957977294922,bestEpoch:6
  [Adam]Epoch:7,Train_Loss:1.9865956,Eval_Loss:1.9802157,bestLoss:1.986595630645752,bestEpoch:7
  [Adam]Epoch:8,Train_Loss:1.9615813,Eval_Loss:1.945712,bestLoss:1.9615813493728638,bestEpoch:8
  [Adam]Epoch:9,Train_Loss:1.9371263,Eval_Loss:1.9073497,bestLoss:1.9371262788772583,bestEpoch:9
  ...
  ```

- After training, you can still review loss function in training through the log file saved in `log_path`, `./logs` directory
  by default.

- The model checkpoint will be saved in `save_ckpt_path`, `./checkpoint` directory by default.

### [Evaluation Process](#contents)

Before running the command below, please check the checkpoint loading path `load_ckpt_path` specified
in `config.json` for evaluation.

- running on Ascend

  ```bash
  python eval.py
  ```

  You can view the process and results through the terminal.
  The result pictures are saved in `figures_path`, `./figures` by default.