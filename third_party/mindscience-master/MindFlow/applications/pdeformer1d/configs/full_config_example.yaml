# An example configuration file containing all possible options.
# This file is provided for the convenience to the users, and will not be used.
model_type: pdeformer  # {pdeformer, fno, deeponet, u-net}
deeponet:
    trunk_dim_in: 2
    trunk_dim_hidden: 256
    trunk_num_layers: 6
    branch_dim_in: 256  # 258 if data.single_pde.input_pde_param
    branch_dim_hidden: 256
    branch_num_layers: 6
    dim_out: 2048
    num_pos_enc: 0  # 0 means no position encoding
fno:
    in_channels: 1  # 3 if data.single_pde.input_pde_param
    out_channels: 1
    resolution: 256
    modes: 12
    channels: 20
    depths: 4
    mlp_ratio: 4
unet:
    in_channels: 1  # 3 if data.single_pde.input_pde_param
    out_channels: 1
model:
    graphormer:
        num_node_type: 128
        num_edge_type: 8
        num_in_degree: 32
        num_out_degree: 32
        num_spatial: 16
        num_encoder_layers: 9
        embed_dim: 512
        ffn_embed_dim: 512
        num_heads: 32
        pre_layernorm: True
    scalar_encoder:
        dim_hidden: 256
        num_layers: 3
    function_encoder:
        type: weighted_deepset  # {deepset, weighted_deepset, patched}
        deepset_point_fn: poly_inr  # {mlp, poly_inr, siren, mfn}
        num_branches: 4
        dim_hidden: 512
        num_layers: 6
    inr:
        type: poly_inr  # {siren, mfn, poly_inr}
        num_layers: 9
        dim_hidden: 256
        dim_in: 2
        dim_out: 1
        siren:
            enable_scale: True
            num_pos_enc: 0  # 0 means no position encoding
        mfn:
            filter_type: dino_fourier  # {original_fourier, dino_fourier, gabor}
            enable_scale: False
            input_scale: 256.0  # 256 for dino_fourier, 64 for original_fourier, ? for gabor
            gabor_alpha: 6.0
            gabor_beta: 1.0
        poly_inr:
            enable_affine: False
            enable_shift: True
            enable_scale: True
    hypernet:
        hyper_dim_hidden: 256
        hyper_num_layers: 3
        share_hypernet: False  # whether the parameters of all INR layers are generated by the same hypernet
    load_ckpt: none
data:
    path: ../data_download
    type: multi_pde  # {single_pde, multi_pde}
    load_to_ram: False
    num_workers: 4
    augment: False  # parallel transport along x-axis for periodic PDEs
    num_samples_per_file:
        train: 9000
        regularize: 9000
        test: 1000
    pde_dag:
        max_n_scalar_nodes: 52
        max_n_function_nodes: 5
        disconn_attn_bias: -inf
    single_pde:
        param_name: burgers_nu2  # {burgers_nu2, adv_beta, reacdiff_nu_rho}
        input_pde_param: False
        regularize_ratio: 0.0  # for pdeformer, introduce multi_pde data for regularization
        train: [0.1]
        test: [0.1]
    multi_pde:
        train:
            sinus0_c:
                - custom_v4.23_sinus0_circ_cU3_k1e-03_1_seed2
            sinus0_r:
                - custom_v4.23_sinus0_robin_cU3_k1e-03_1_seed2
        test:
            sinus0_c:
                - custom_v4.23_sinus0_circ_cU3_k1e-03_1_seed1
            sinus0_r:
                - custom_v4.23_sinus0_robin_cU3_k1e-03_1_seed1
train:
    total_batch_size: 10  # we use 10 per NPU/GPU device in our experiments
    num_tx_samp_pts: 8192
    lr_init: 1.e-4
    epochs: 10
    loss:
        type: RMSE  # {MSE, RMSE, MAE}
        normalize: True
        normalize_eps: 0.05
    optimizer: Adam  # {Adam, AdamW}
    weight_decay: 0.0
    lr_scheduler:
        type: cos  # {mstep, cos}
        milestones: [0.6, 0.8, 1]  # mstep only
        decay: 0.5  # mstep only
        enable_warmup: True
        warmup_epochs: 10
    grad_clip_value: 1  # -1 means no gradient clipping
inverse:
    data_file: custom_v4.23_inv_sinus0_circ_fS_cU3_k1e-03_1_seed1
    system_identification: False
    pde_samples: 4  # int or list of ints
    num_ic_per_pde: 40
    observation:
        ic_noise:
            type: uniform  # {none, uniform, normal}
            level: 0.01
        noise:
            type: uniform  # {none, uniform, normal}
            level: 0.01
        x_location:
            type: random  # {all, equispaced, last, random}
            num_pts: 20
        t_location:
            type: all_random  # {all, equispaced, last, t_random, all_random}
            num_pts: 20
    coef_scale: 3.0
    enable_nu: False
    num_coef: 10
    pso:
        pop_size: 5
        max_gen: 10
    plot_num_per_cls: 2
    function_node_id: 1  # 1 for s(x) of sinus0_fS/fSK, 2 for c(x) or c(x)^2 of wave
    function_regularize:
        type: squareL2  # {L1, L2, squareL2}
        weight: 1.e-5
    epochs: 1000
    learning_rate: 0.1
    weight_decay: 0.0
    loss:
        type: RMSE  # {MSE, RMSE, MAE}
        normalize: True
        normalize_eps: 0.05
test:
    total_batch_size: 10  # we use 10 per NPU/GPU device in our experiments
    interval: 25
    plot_num_per_cls: 2
record_dir: "exp/debug"
