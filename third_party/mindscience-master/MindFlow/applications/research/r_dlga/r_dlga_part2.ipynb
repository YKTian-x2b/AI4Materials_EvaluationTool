{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R_DLGA algorithm _part2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The performance of data-driven partial differential equations lacks stability when dealing with complex situations such as sparse data with high noise, so the robust deep learning Genetic algorithm (R-DLGA) is proposed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical path\n",
    "\n",
    "The specific process of R-DLGA to solve this problem is as follows:\n",
    "\n",
    "1. Run train.py to train the neural network, generate metadata and compute derivatives and obtain potential terms through genetic algorithms\n",
    "2. Modify candidates in the train_pinn.py dict directory based on Step 1\n",
    "3. Run train_pinn.py to get the final result\n",
    "\n",
    "This part2 implements the functional code of the third step. After modifying the term calculation under src/util.py and the dict in part2 according to the result of the genetic algorithm in step 1, run the notebook to obtain the final result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import code packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from mindspore import nn, context, ops, set_seed\n",
    "from mindspore import value_and_grad, jit, save_checkpoint\n",
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "from mindspore.amp import DynamicLossScaler, auto_mixed_precision\n",
    "\n",
    "from mindflow.utils import load_yaml_config\n",
    "from mindflow.cell import MultiScaleFCSequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following `src` packages can be downloaded in [research/r_dlga/src] (https://gitee.com/mindspore/mindscience/tree/master/MindFlow/applications/research/r_dlga/src)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import create_pinn_dataset, evaluate, cal_grads, cal_terms, pinn_loss_func\n",
    "from src import get_dict_name, get_dicts, update_lib, calculate_coef, get_lefts\n",
    "\n",
    "set_seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters are configured, where --case has three choices, \"burgers\" means training on burgers equation, \"cylinder_flow\" means training on cylinder_flow dataset of navier_stokes2D equation, \"periodic_hill\" indicates training on a mountain flow dataset for the Reynolds mean Navier-Stokes equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"train r_glda\")\n",
    "parser.add_argument(\"--case\", type=str, default=\"burgers\", choices=[\"burgers\", \"cylinder_flow\", \"periodic_hill\"],\n",
    "                    help=\"choose burgers, cylinder_flow or periodic_hill\")\n",
    "parser.add_argument(\"--mode\", type=str, default=\"GRAPH\", choices=[\"GRAPH\", \"PYNATIVE\"],\n",
    "                    help=\"Running in GRAPH_MODE OR PYNATIVE_MODE\")\n",
    "parser.add_argument(\"--device_target\", type=str, default=\"Ascend\", choices=[\"GPU\", \"Ascend\"],\n",
    "                    help=\"The target device to run, support 'Ascend', 'GPU'\")\n",
    "parser.add_argument(\"--device_id\", type=int, default=0,\n",
    "                    help=\"ID of the target device\")\n",
    "parser.add_argument(\"--config_file_path\", type=str,\n",
    "                    default=\"./configs/burgers.yaml\")\n",
    "input_args = parser.parse_args()\n",
    "\n",
    "context.set_context(mode=context.GRAPH_MODE if input_args.mode.upper().startswith(\"GRAPH\")\n",
    "                    else context.PYNATIVE_MODE,\n",
    "                    device_target=input_args.device_target,\n",
    "                    device_id=input_args.device_id)\n",
    "print(\n",
    "    f\"Running in {input_args.mode.upper()} mode, using device id: {input_args.device_id}.\")\n",
    "use_ascend = context.get_context(attr_key='device_target') == \"Ascend\"\n",
    "print(use_ascend)\n",
    "print(\"pid:\", os.getpid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the equation to be trained and load the yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get case name\n",
    "case_name = input_args.case\n",
    "\n",
    "# load configurations\n",
    "config = load_yaml_config(input_args.config_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataset\n",
    "\n",
    "Unlike part1, this section creates datasets with a noise percentage of 0 percent, where database_choose and h_data_choose are used for training, and database_validate and h_data_validate are used for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinn_config = config[\"pinn\"]\n",
    "pinn_dataset_config = pinn_config[\"dataset\"]\n",
    "model_config = config[\"model\"]\n",
    "summary_config = config[\"summary\"]\n",
    "optimizer_config = config[\"optimizer\"]\n",
    "epochs = optimizer_config[\"epochs\"]\n",
    "\n",
    "\n",
    "# create dataset for training and validating\n",
    "pinn_dataset = create_pinn_dataset(\n",
    "    case_name, pinn_dataset_config)\n",
    "database_choose, h_data_choose, database_validate, h_data_validate = pinn_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model\n",
    "\n",
    "What structural model is used in part1, where you need to use the model of the corresponding structure and load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiScaleFCSequential(in_channels=model_config[\"in_channels\"],\n",
    "                               out_channels=model_config[\"out_channels\"],\n",
    "                               layers=model_config[\"layers\"],\n",
    "                               neurons=model_config[\"neurons\"],\n",
    "                               residual=model_config[\"residual\"],\n",
    "                               act=model_config[\"activation\"],\n",
    "                               num_scales=1)\n",
    "# load checkpoint\n",
    "ckpt_name = f\"{case_name}_nn-{epochs + 1}.ckpt\"\n",
    "ckpt_path = summary_config[\"save_checkpoint_epochs\"]\n",
    "model_dict = load_checkpoint(os.path.join(\n",
    "    ckpt_path, ckpt_name))\n",
    "load_param_into_net(model, model_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build potential terms\n",
    "\n",
    "After obtaining the result of genetic algorithm in part1, the candidate items of the equation are obtained, and the corresponding Dict_name, Dict_n, Dict are modified, and the code of term calculation in util.py in src directory is modified according to its calculation requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result from ga\n",
    "# need to be change by hand\n",
    "dict_name = get_dict_name(case_name)\n",
    "\n",
    "optimizer = nn.Adam(model.trainable_params(),\n",
    "                    optimizer_config[\"initial_lr\"])\n",
    "# set ascend\n",
    "if use_ascend:\n",
    "    loss_scaler = DynamicLossScaler(1024, 2, 100)\n",
    "    auto_mixed_precision(model, model_config[\"amp_level\"])\n",
    "else:\n",
    "    loss_scaler = None\n",
    "\n",
    "\n",
    "def forward_fn(dataset, lefts, coef_list, dict_name, terms_dict):\n",
    "    database_choose, h_data_choose = dataset\n",
    "    prediction = model(database_choose)\n",
    "    f1 = nn.MSELoss(reduction='mean')(prediction, h_data_choose)\n",
    "    loss = pinn_loss_func(f1, lefts, coef_list,\n",
    "                          dict_name, terms_dict)\n",
    "\n",
    "    if use_ascend:\n",
    "        loss = loss_scaler.scale(loss)\n",
    "    return loss\n",
    "\n",
    "\n",
    "grad_fn = value_and_grad(\n",
    "    forward_fn, None, optimizer.parameters, has_aux=False)\n",
    "\n",
    "\n",
    "@jit\n",
    "def train_step(dataset, lefts, coef_list, dict_name, terms_dict):\n",
    "    loss, grads = grad_fn(dataset, lefts, coef_list, dict_name, terms_dict)\n",
    "    if use_ascend:\n",
    "        loss = loss_scaler.unscale(loss)\n",
    "    loss = ops.depend(loss, optimizer(grads))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training\n",
    "\n",
    "Define the trainer and start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "Theta:[-1.0167898e-10 -3.5906428e-01  3.8740728e-03  6.8805676e-08-2.0166181e-05 -6.6712929e-04]Dict_Name [1, 2, 3, 4, 5, 6]epoch: 100 train loss: 0.16274601 epoch time: 7609.529ms\n",
      "    predict total time: 2.933502197265625 ms\n",
      "    l2_error:  0.03319109569478303\n",
      "=================================================================================================\n",
      "Theta:[-6.1833136e-11 -3.9782286e-01  3.7144462e-03  4.6671396e-08-1.5555745e-05 -9.6872513e-04]Dict_Name [1, 2, 3, 4, 5, 6]epoch: 200 train loss: 0.12895139  epoch time: 8463.217ms\n",
      "    predict total time: 2.847433090209961 ms\n",
      "    l2_error:  0.3844950973176981\n",
      "=================================================================================================\n",
      "...\n",
      "Theta:[[-0.4369226 ][ 0.00145796][ 0.00145796]]Dict_Name [2, 3, 6]epoch: 2390 train loss: 0.08259561 epoch time: 14893.079ms\n",
      "    predict total time: 1.985311508178711 ms\n",
      "    l2_error:  0.0062716909767681125\n",
      "=================================================================================================\n",
      "Theta:[[-0.4367841 ][ 0.00145637][ 0.00145637]]Dict_Name [2, 3, 6]epoch: 2400 train loss: 0.08224905 epoch time: 15054.685ms\n",
      "    predict total time:  3.087759017944336 ms\n",
      "    l2_error:  0.006187851509927684\n",
      "=================================================================================================\n",
      "Theta:[[-0.43811008][ 0.00146007][ 0.00146007]]Dict_Name [2, 3, 6]epoch: 2410 train loss: 0.0810892 epoch time: 14595.442ms\n",
      "    predict total time: 3.632783889770508 ms\n",
      "    l2_error:  0.0062226032090417\n",
      "=================================================================================================\n",
      "End-to-End total time: 12074.045341385 s\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    time_beg = time.time()\n",
    "    prediction = model(database_choose)\n",
    "    grads, libraries = cal_grads(case_name, model, database_choose,\n",
    "                                 pinn_dataset_config[\"choose_train\"])\n",
    "\n",
    "    terms = cal_terms(case_name, prediction, grads)\n",
    "\n",
    "    # terms in numpy\n",
    "    terms_dict, dict_n = get_dicts(terms)\n",
    "\n",
    "    libraries = update_lib(case_name, dict_name, libraries, dict_n)\n",
    "\n",
    "    # Lasso\n",
    "    lefts = get_lefts(case_name, grads, prediction, False)\n",
    "    coef_list, lst_list = calculate_coef(lefts, libraries, epoch, config)\n",
    "\n",
    "    model.set_train(True)\n",
    "\n",
    "    # train step\n",
    "    lefts = get_lefts(case_name, grads, True)\n",
    "\n",
    "    step_train_loss = train_step((database_choose, h_data_choose),\n",
    "                                 lefts, coef_list, dict_name, terms_dict)\n",
    "    # set model to eval mode\n",
    "    model.set_train(False)\n",
    "\n",
    "    # put zeros\n",
    "    if epoch >= 1000:\n",
    "        for lst in lst_list:\n",
    "            for i in range(lst.shape[0]):\n",
    "                if np.abs(lst[i]) < pinn_config[\"kesi\"]:\n",
    "                    dict_name.pop(i)\n",
    "                    break\n",
    "\n",
    "    if epoch % summary_config[\"validate_interval_epochs\"] == 0:\n",
    "        print(\"Dict_Name %s\", dict_name)\n",
    "        # current epoch loss\n",
    "        print(\"epoch: %s train loss: %s epoch time: %.3fms\",\n",
    "              epoch, step_train_loss, (time.time() - time_beg) * 1000)\n",
    "        evaluate(model, database_validate, h_data_validate, config)\n",
    "\n",
    "    # save checkpoint\n",
    "    if epoch % summary_config[\"save_checkpoint_epochs\"] == 0:\n",
    "        ckpt_name = f\"{case_name}_pinn-{epoch + 1}.ckpt\"\n",
    "        save_checkpoint(model, os.path.join(\n",
    "            ckpt_path, ckpt_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![visual_burgers](./images/burgers.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
