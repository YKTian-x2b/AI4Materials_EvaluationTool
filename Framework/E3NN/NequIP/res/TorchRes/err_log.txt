Torch device: cuda
Successfully loaded the data set of type NpzDataset(100000)...
Replace string dataset_forces_rms to 28.83867073059082
Replace string dataset_per_atom_total_energy_mean to -11335.7763671875
Atomic outputs are scaled by: [H, C: 28.838671], shifted by [H, C: -11335.776367].
Replace string dataset_forces_rms to 28.83867073059082
Initially outputs are globally scaled by: 28.83867073059082, total_energy are globally shifted by None.
Successfully built the network...
Number of weights: 1495720
Number of trainable weights: 1495720
! Starting training ...

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      0     5         1.07         1.07      0.00132         21.3         29.9         14.2         29.5         21.8         19.5         38.4           29           15        0.998


  Initialization     #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Initial Validation          0    3.444    0.005        0.959       0.0015         0.96         20.7         28.2         14.3           28         21.1           19           36         27.5           16         1.07
Wall time: 3.4448442310003884
! Best model        0    0.960

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      1    10        0.503        0.481        0.022         14.7           20         9.22           21         15.1         11.9         26.3         19.1         64.2         4.28
      1    20         0.26        0.205       0.0549         9.98         13.1         6.36         14.1         10.2         7.64         17.3         12.5          101         6.75
      1    30        0.118         0.11      0.00739         7.22         9.57         4.74           10         7.39         5.77         12.6         9.17         37.1         2.47
      1    40        0.105        0.103      0.00197            7         9.27         4.55         9.79         7.17         5.56         12.2         8.88         18.8         1.25
      1    50       0.0792       0.0771      0.00209         5.88         8.01         3.33         8.78         6.06         4.36         10.8         7.56         19.7         1.31
      1    60       0.0545       0.0542     0.000217         4.93         6.72         2.98         7.17         5.07         3.82         8.94         6.38         6.25        0.417
      1    70       0.0585       0.0584     5.36e-06         5.34         6.97         3.68         7.23         5.46         4.69         8.89         6.79        0.878       0.0585
      1    80       0.0407       0.0407     6.11e-05         4.29         5.81         3.05          5.7         4.38         3.83         7.46         5.65         3.28        0.219
      1    90       0.0225       0.0224     7.84e-05         3.29         4.32         2.38         4.33         3.35         3.23          5.3         4.26         3.21        0.214
      1   100       0.0368       0.0368     3.27e-05            4         5.53         2.62         5.57         4.09         3.24         7.32         5.28         2.37        0.158
      1   110       0.0143       0.0142     1.81e-05         2.64         3.44         1.88         3.52          2.7         2.64         4.17         3.41         1.72        0.115
      1   120       0.0169       0.0168     0.000106         2.88         3.74         2.93         2.83         2.88         3.83         3.63         3.73         4.39        0.293
      1   130       0.0142       0.0139     0.000329         2.64         3.39         2.08         3.28         2.68         2.55         4.15         3.35          7.8         0.52
      1   140       0.0141       0.0141     1.03e-05         2.57         3.43          2.1         3.11          2.6         2.74         4.08         3.41         1.32       0.0879
      1   150       0.0087      0.00869     1.15e-05         2.06         2.69         1.58         2.62          2.1         2.12         3.22         2.67         1.03        0.069
      1   160      0.00717      0.00712     5.36e-05         1.93         2.43         1.75         2.13         1.94          2.2         2.67         2.44         3.14         0.21
      1   170       0.0125       0.0123     0.000167         2.42          3.2         1.83          3.1         2.47         2.34         3.96         3.15          5.4         0.36
      1   180      0.00736       0.0073     5.82e-05         1.87         2.46         1.65         2.13         1.89         2.03         2.88         2.46         3.24        0.216
      1   190      0.00724      0.00723     6.09e-06         1.82         2.45         1.25         2.46         1.86         1.67         3.11         2.39         1.05         0.07

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      1     5      0.00934      0.00933     1.06e-05         2.01         2.79         1.62         2.46         2.04         2.48          3.1         2.79        0.909       0.0606


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train               1   27.001    0.005       0.0954        0.003       0.0984         5.12         8.91         3.58         6.89         5.23         5.63         11.6          8.6         13.2        0.882
! Validation          1   27.001    0.005      0.00724      6.2e-06      0.00725         1.83         2.45         1.58         2.12         1.85         2.15         2.76         2.45        0.808       0.0539
Wall time: 27.00218857300024
! Best model        1    0.007

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      2    10       0.0117       0.0116     4.41e-05         2.21         3.11         1.75         2.73         2.24         2.43         3.73         3.08         2.53        0.169
      2    20      0.00551       0.0055      1.2e-05         1.64         2.14         1.35         1.96         1.66         1.87         2.41         2.14         1.37        0.091
      2    30      0.00434      0.00418     0.000151         1.47         1.87         1.11         1.89          1.5         1.39         2.29         1.84         5.28        0.352
      2    40      0.00463      0.00457     5.81e-05          1.5         1.95         1.13         1.92         1.53         1.51         2.35         1.93         3.15         0.21
      2    50      0.00464      0.00464     3.18e-06         1.49         1.96         1.29         1.71          1.5         1.71         2.22         1.96        0.731       0.0487
      2    60      0.00947      0.00944      2.8e-05         1.84          2.8          1.4         2.35         1.87         2.28          3.3         2.79         2.06        0.137
      2    70      0.00531      0.00527     3.63e-05         1.54         2.09         1.27         1.85         1.56         1.69         2.47         2.08         2.59        0.173
      2    80      0.00553       0.0055     2.44e-05         1.67         2.14         1.49         1.87         1.68         1.91         2.37         2.14         2.09        0.139
      2    90      0.00451      0.00451     2.34e-06         1.34         1.94        0.992         1.74         1.37         1.41          2.4         1.91        0.569       0.0379
      2   100      0.00503      0.00499     4.03e-05         1.56         2.04         1.15         2.03         1.59         1.49         2.52         2.01          2.7         0.18
      2   110      0.00422      0.00422        1e-06         1.38         1.87         1.03         1.79         1.41         1.45         2.26         1.86        0.359        0.024
      2   120      0.00325      0.00323     1.14e-05         1.33         1.64         1.14         1.56         1.35         1.34         1.93         1.63         1.45       0.0967
      2   130       0.0054       0.0054     5.23e-07          1.5         2.12        0.976          2.1         1.54         1.25          2.8         2.02        0.284        0.019
      2   140      0.00462       0.0046     2.24e-05         1.39         1.96        0.955         1.89         1.42         1.26         2.52         1.89         1.93        0.129
      2   150      0.00403      0.00403     8.11e-06         1.33         1.83        0.807         1.94         1.37          1.1         2.41         1.75         1.18        0.079
      2   160      0.00322      0.00322     5.56e-07         1.14         1.64        0.775         1.55         1.16         1.03         2.13         1.58        0.294       0.0196
      2   170      0.00346      0.00337     9.09e-05         1.24         1.67        0.973         1.54         1.26         1.33         1.99         1.66         4.07        0.272
      2   180       0.0024      0.00238     2.79e-05         1.03         1.41        0.777         1.33         1.05            1         1.76         1.38         2.28        0.152
      2   190      0.00268      0.00268     9.61e-07         1.12         1.49        0.808         1.49         1.15         1.11         1.84         1.47        0.384       0.0256

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      2     5      0.00274      0.00274     1.06e-06         1.03         1.51         0.79         1.31         1.05         1.31         1.71         1.51        0.345        0.023


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train               2   49.294    0.005      0.00465     7.22e-05      0.00472         1.43         1.97         1.09         1.83         1.46         1.48         2.41         1.94         2.98        0.199
! Validation          2   49.294    0.005       0.0021     9.31e-07       0.0021         0.94         1.32        0.709          1.2        0.956         1.03         1.59         1.31        0.315        0.021
Wall time: 49.29444024099939
! Best model        2    0.002

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      3    10      0.00521      0.00517      4.1e-05         1.36         2.07        0.722         2.08          1.4        0.946         2.86          1.9         2.72        0.181
      3    20      0.00388      0.00382     6.08e-05         1.29         1.78         1.05         1.56          1.3         1.29         2.21         1.75         3.36        0.224
      3    30      0.00201        0.002     5.39e-06        0.965         1.29         0.77         1.19        0.979         1.03         1.54         1.28        0.956       0.0638
      3    40      0.00287      0.00287     9.35e-07          1.1         1.55        0.828         1.42         1.12         1.27         1.81         1.54        0.375        0.025
      3    50      0.00186      0.00186     6.02e-06        0.925         1.24        0.659         1.23        0.944        0.864         1.57         1.22         1.03       0.0685
      3    60      0.00237      0.00235     1.96e-05         1.04          1.4        0.683         1.45         1.07        0.918         1.79         1.36         1.87        0.125
      3    70      0.00203        0.002     3.51e-05        0.935         1.29        0.617          1.3        0.958         0.73         1.72         1.22         2.56        0.171
      3    80      0.00158      0.00156     1.92e-05        0.859         1.14        0.519         1.25        0.883        0.642         1.52         1.08         1.88        0.126
      3    90      0.00281      0.00276     4.31e-05        0.969         1.52        0.638         1.35        0.993        0.828         2.04         1.43         2.83        0.189
      3   100      0.00235      0.00228     7.35e-05        0.978         1.38        0.732         1.26        0.996         0.98         1.72         1.35         3.69        0.246
      3   110      0.00198      0.00189     9.81e-05         0.96         1.25         0.88         1.05        0.966         1.08         1.42         1.25         4.28        0.285
      3   120      0.00115      0.00114     1.26e-05        0.708        0.974        0.466        0.986        0.726        0.574         1.29         0.93         1.52        0.102
      3   130      0.00189      0.00186     3.14e-05        0.948         1.24        0.775         1.14         0.96        0.956         1.51         1.23         2.42        0.161
      3   140      0.00208      0.00193     0.000146        0.898         1.27        0.639         1.19        0.917        0.831         1.63         1.23         5.21        0.347
      3   150      0.00154      0.00135     0.000186        0.838         1.06        0.753        0.935        0.844        0.933         1.19         1.06         5.89        0.393
      3   160      0.00156      0.00152     3.42e-05        0.817         1.12        0.561         1.11        0.836        0.749         1.44         1.09         2.52        0.168
      3   170      0.00244      0.00242     2.76e-05         1.03         1.42        0.732         1.37         1.05        0.991         1.78         1.39         2.26        0.151
      3   180      0.00122      0.00119     2.32e-05        0.723        0.996        0.512        0.965        0.738        0.663         1.27        0.969         2.06        0.138
      3   190      0.00423      0.00422     9.96e-06         1.48         1.87         1.11          1.9          1.5         1.42         2.29         1.85         1.36       0.0904

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      3     5      0.00152      0.00152     3.63e-07        0.757         1.12         0.55        0.993        0.772        0.915         1.32         1.12        0.214       0.0143


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train               3   70.424    0.005      0.00223     5.17e-05      0.00228        0.974         1.36        0.704         1.28        0.994        0.947         1.71         1.33         2.59        0.173
! Validation          3   70.424    0.005      0.00122     4.78e-07      0.00122        0.702         1.01        0.506        0.926        0.716         0.73         1.25         0.99        0.222       0.0148
Wall time: 70.42415901899949
! Best model        3    0.001

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      4    10      0.00302      0.00297     5.14e-05         1.11         1.57        0.623         1.66         1.14        0.851         2.11         1.48          3.1        0.206
      4    20      0.00114      0.00114     7.58e-06        0.663        0.972        0.402        0.962        0.682         0.52         1.31        0.915         1.18       0.0787
      4    30      0.00151       0.0015     3.91e-06        0.823         1.12        0.562         1.12        0.842        0.774         1.41         1.09        0.825        0.055
      4    40       0.0017      0.00169     9.32e-06        0.829         1.19        0.538         1.16         0.85         0.66         1.59         1.12         1.29        0.086
      4    50      0.00122      0.00122     5.86e-07        0.742         1.01        0.548        0.964        0.756        0.725         1.26        0.991        0.225        0.015
      4    60      0.00147      0.00142     4.92e-05         0.78         1.09        0.492         1.11          0.8        0.636         1.44         1.04         3.02        0.201
      4    70      0.00109      0.00109     3.83e-06        0.692        0.951        0.463        0.954        0.709         0.63         1.22        0.924        0.837       0.0558
      4    80      0.00185      0.00184     5.46e-06        0.902         1.24        0.638          1.2        0.921        0.843         1.57         1.21        0.906       0.0604
      4    90      0.00163      0.00159     4.26e-05        0.782         1.15        0.502          1.1        0.802        0.673         1.52          1.1         2.82        0.188
      4   100      0.00149      0.00148     1.27e-06        0.798         1.11        0.527         1.11        0.818        0.694         1.45         1.07        0.391        0.026
      4   110      0.00136      0.00135     1.23e-05        0.804         1.06        0.557         1.09        0.822        0.703         1.36         1.03          1.5       0.0998
      4   120      0.00179      0.00178     1.17e-05        0.844         1.22        0.509         1.23        0.868        0.673         1.63         1.15         1.45       0.0969
      4   130     0.000926     0.000909     1.72e-05        0.654         0.87        0.544        0.781        0.662        0.709         1.02        0.866         1.78        0.119
      4   140      0.00182       0.0018     1.19e-05        0.849         1.22        0.603         1.13        0.867        0.849         1.55          1.2         1.46       0.0973
      4   150      0.00179      0.00179     5.61e-06        0.947         1.22         0.78         1.14        0.959         0.98         1.44         1.21        0.969       0.0646
      4   160      0.00147      0.00147     1.76e-06        0.751          1.1        0.527         1.01        0.767        0.721         1.42         1.07        0.506       0.0338
      4   170      0.00141      0.00139     2.29e-05        0.784         1.08        0.537         1.07        0.801        0.691         1.39         1.04         2.05        0.137
      4   180      0.00104      0.00102     2.05e-05        0.671        0.921        0.487        0.881        0.684        0.639         1.16        0.901         1.95         0.13
      4   190      0.00137      0.00137     1.36e-06        0.764         1.07        0.567        0.988        0.778        0.829         1.29         1.06        0.463       0.0308

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      4     5      0.00112      0.00112     2.49e-07         0.65        0.967        0.458        0.868        0.663        0.762         1.16         0.96        0.172       0.0115


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train               4   91.557    0.005      0.00145     1.39e-05      0.00146        0.784          1.1        0.551         1.05        0.801         0.74          1.4         1.07         1.26       0.0842
! Validation          4   91.557    0.005      0.00091     3.49e-07     0.000911        0.598         0.87        0.425        0.796         0.61        0.615         1.09        0.853        0.192       0.0128
Wall time: 91.55793023899969
! Best model        4    0.001

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      5    10       0.0017      0.00169     5.84e-06         0.77         1.19        0.459         1.13        0.793        0.564         1.63          1.1         1.03       0.0688
      5    20      0.00152      0.00152     3.66e-06        0.886         1.12        0.759         1.03        0.895        0.913         1.33         1.12        0.822       0.0548
      5    30      0.00115      0.00111     4.54e-05        0.697         0.96        0.498        0.924        0.711        0.661         1.21        0.938         2.92        0.194
      5    40     0.000682     0.000682     9.11e-08        0.572        0.753        0.501        0.653        0.577        0.642        0.863        0.752          0.1      0.00667
      5    50      0.00149      0.00145     4.57e-05        0.835          1.1        0.708         0.98        0.844        0.986         1.21          1.1         2.92        0.195
      5    60      0.00178      0.00178     1.89e-06        0.897         1.22        0.502         1.35        0.925         0.63         1.65         1.14        0.528       0.0352
      5    70      0.00146      0.00145     1.09e-05        0.843          1.1        0.611         1.11        0.859         0.74          1.4         1.07         1.41       0.0942
      5    80     0.000945     0.000937     7.67e-06        0.606        0.883        0.386        0.856        0.621        0.543         1.15        0.849         1.18        0.079
      5    90       0.0012      0.00119     1.49e-05        0.741        0.994        0.509         1.01        0.757        0.646         1.28        0.963         1.63        0.109
      5   100      0.00275      0.00273     1.99e-05        0.995         1.51        0.628         1.42         1.02        0.892         1.99         1.44         1.87        0.125
      5   110     0.000882     0.000882     1.34e-07        0.648        0.856        0.524         0.79        0.657        0.687         1.02        0.851        0.119      0.00792
      5   120     0.000874     0.000865     9.04e-06        0.592        0.848        0.423        0.786        0.604        0.573         1.08        0.826         1.29       0.0862
      5   130     0.000912     0.000901     1.08e-05        0.623        0.866        0.464        0.805        0.635        0.587          1.1        0.844         1.42       0.0948
      5   140      0.00103      0.00103     3.72e-07        0.672        0.925        0.426        0.954         0.69        0.555         1.22        0.886        0.234       0.0156
      5   150      0.00182       0.0018     1.61e-05         0.93         1.22        0.737         1.15        0.944         0.94         1.48         1.21         1.69        0.113
      5   160     0.000975     0.000956     1.91e-05        0.667        0.892        0.437        0.929        0.683        0.546         1.17        0.857         1.89        0.126
      5   170      0.00098      0.00093     4.99e-05        0.629         0.88        0.496        0.781        0.638        0.634         1.09        0.864         3.05        0.204
      5   180      0.00128      0.00126     1.43e-05        0.729         1.02        0.529        0.958        0.743        0.696          1.3            1         1.62        0.108
      5   190      0.00134      0.00133     3.21e-07         0.78         1.05        0.486         1.12        0.801        0.654         1.37         1.01        0.194       0.0129

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      5     5      0.00091      0.00091     1.85e-07        0.581         0.87        0.416         0.77        0.593        0.688         1.04        0.864        0.158       0.0105


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train               5  112.569    0.005      0.00134     1.61e-05      0.00136         0.76         1.06        0.539         1.01        0.776        0.716         1.35         1.03         1.38       0.0921
! Validation          5  112.569    0.005     0.000705     2.77e-07     0.000705        0.522        0.766        0.372        0.695        0.533        0.541         0.96         0.75        0.176       0.0117
Wall time: 112.5699067530004
! Best model        5    0.001

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      6    10      0.00139      0.00138     1.16e-06        0.763         1.07        0.443         1.13        0.786        0.588         1.44         1.01        0.419       0.0279
      6    20     0.000746     0.000745     1.09e-06        0.563        0.787        0.397        0.753        0.575         0.54        0.997        0.769        0.425       0.0283
      6    30     0.000718     0.000712     6.38e-06        0.588        0.769        0.459        0.735        0.597        0.568        0.948        0.758         1.08       0.0717
      6    40     0.000694     0.000687     7.27e-06        0.571        0.756        0.447        0.712         0.58        0.562         0.93        0.746         1.14       0.0762
      6    50      0.00147      0.00147      7.4e-07        0.809         1.11        0.536         1.12        0.828        0.695         1.44         1.07        0.334       0.0223
      6    60      0.00129      0.00128     8.41e-06        0.757         1.03         0.48         1.07        0.777        0.611         1.36        0.987         1.24       0.0829
      6    70     0.000673     0.000669     3.87e-06        0.531        0.746        0.361        0.725        0.543        0.497        0.954        0.726        0.844       0.0562
      6    80     0.000794     0.000784     9.18e-06        0.582        0.808        0.382        0.811        0.596        0.522         1.04        0.782          1.3       0.0867
      6    90     0.000506     0.000496     9.29e-06        0.496        0.643        0.419        0.583        0.501        0.529        0.751         0.64         1.29       0.0862
      6   100     0.000849     0.000847     2.17e-06        0.618        0.839        0.516        0.734        0.625        0.703        0.972        0.837        0.566       0.0377
      6   110     0.000982     0.000977     5.35e-06        0.606        0.901        0.499        0.729        0.614        0.747         1.05        0.899        0.988       0.0658
      6   120      0.00103        0.001      2.1e-05         0.67        0.914        0.473        0.895        0.684        0.646         1.15        0.896         1.98        0.132
      6   130      0.00109      0.00109     5.24e-07        0.734        0.953        0.487         1.02        0.751        0.613         1.23        0.922        0.278       0.0185
      6   140      0.00107      0.00106     1.39e-06        0.679        0.941        0.423        0.971        0.697        0.601         1.22         0.91        0.434        0.029
      6   150      0.00053      0.00053     2.99e-07        0.477        0.664        0.303        0.677         0.49        0.402        0.871        0.637        0.222       0.0148
      6   160      0.00257      0.00257     1.02e-06         1.01         1.46        0.688         1.37         1.03        0.856         1.93         1.39        0.341       0.0227
      6   170      0.00151      0.00151     3.73e-07        0.831         1.12        0.644         1.04        0.844        0.794          1.4          1.1        0.228       0.0152
      6   180      0.00101      0.00101     3.31e-07        0.675        0.917        0.425         0.96        0.692        0.536         1.21        0.875        0.222       0.0148
      6   190      0.00103      0.00103     2.35e-06        0.666        0.925        0.482        0.877        0.679         0.67         1.15        0.909        0.616        0.041

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      6     5     0.000686     0.000686     1.53e-07        0.516        0.755         0.36        0.694        0.527        0.558        0.931        0.745         0.12      0.00802


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train               6  133.976    0.005     0.000946     4.53e-06      0.00095        0.633        0.887        0.439        0.855        0.647        0.586         1.14        0.862         0.73       0.0487
! Validation          6  133.976    0.005     0.000551     1.86e-07     0.000551        0.464        0.677        0.326        0.623        0.474         0.46         0.86         0.66        0.138      0.00923
Wall time: 133.976800127999
! Best model        6    0.001

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      7    10      0.00108      0.00108     1.43e-06        0.681        0.946         0.44        0.957        0.698        0.619         1.22        0.918        0.438       0.0292
      7    20     0.000451     0.000448      3.4e-06        0.458         0.61         0.37        0.557        0.464        0.478        0.733        0.605        0.784       0.0523
      7    30     0.000739     0.000739     5.48e-07        0.563        0.784        0.409        0.739        0.574        0.562        0.977         0.77        0.291       0.0194
      7    40     0.000398     0.000393     5.53e-06        0.439        0.571        0.344        0.546        0.445         0.44        0.692        0.566         1.01       0.0675
      7    50     0.000586     0.000585     2.36e-07        0.505        0.698        0.326        0.709        0.518        0.421        0.917        0.669        0.184       0.0123
      7    60     0.000706     0.000703     2.83e-06        0.525        0.765         0.27        0.817        0.544        0.354         1.05        0.704        0.712       0.0475
      7    70      0.00111       0.0011     2.81e-06        0.685        0.958        0.535        0.856        0.695         0.68          1.2         0.94        0.663       0.0442
      7    80     0.000809       0.0008     9.43e-06        0.587        0.816         0.33        0.881        0.605        0.424          1.1        0.764          1.3       0.0867
      7    90      0.00126      0.00125     7.17e-06        0.705         1.02        0.398         1.06        0.727        0.522         1.39        0.955         1.15       0.0767
      7   100     0.000994     0.000974     2.03e-05        0.659          0.9        0.402        0.954        0.678        0.576         1.16         0.87         1.93        0.129
      7   110     0.000645     0.000641     3.23e-06        0.498         0.73        0.378        0.634        0.506        0.661        0.802        0.732        0.759       0.0506
      7   120     0.000673     0.000669     4.13e-06        0.508        0.746        0.385        0.648        0.516        0.542        0.925        0.734         0.85       0.0567
      7   130       0.0008     0.000796     3.67e-06         0.64        0.814        0.539        0.756        0.647        0.674        0.948        0.811        0.766        0.051
      7   140     0.000835     0.000828     6.76e-06        0.614         0.83        0.455        0.796        0.626        0.595         1.03        0.815         1.11        0.074
      7   150      0.00139      0.00138     4.48e-06         0.77         1.07        0.504         1.07        0.789        0.685         1.39         1.04        0.906       0.0604
      7   160      0.00114      0.00114     2.11e-07        0.748        0.975        0.573        0.948         0.76        0.696         1.22        0.957        0.175       0.0117
      7   170      0.00148      0.00148     5.22e-06        0.833         1.11        0.611         1.09        0.849        0.737         1.42         1.08        0.988       0.0658
      7   180      0.00113      0.00113     2.95e-07        0.744         0.97        0.595        0.915        0.755        0.761         1.16        0.963        0.225        0.015
      7   190     0.000429     0.000402     2.65e-05        0.418        0.579        0.267        0.591        0.429        0.344        0.763        0.554         2.22        0.148

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      7     5     0.000555     0.000555     1.17e-07        0.455        0.679        0.321        0.608        0.465          0.5        0.838        0.669        0.102      0.00677


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train               7  155.531    0.005     0.000877     5.21e-06     0.000882        0.604        0.854        0.414        0.821        0.618         0.56          1.1        0.829        0.796        0.053
! Validation          7  155.531    0.005     0.000446     1.21e-07     0.000446        0.417        0.609        0.289        0.564        0.426        0.408        0.778        0.593        0.113      0.00752
Wall time: 155.5319089959994
! Best model        7    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      8    10     0.000409     0.000395     1.37e-05        0.427        0.573        0.321        0.548        0.434        0.439        0.696        0.567          1.6        0.107
      8    20     0.000634     0.000629     4.64e-06          0.5        0.723        0.361         0.66         0.51        0.472        0.931        0.702        0.925       0.0617
      8    30     0.000991     0.000991     4.23e-07        0.679        0.908        0.578        0.794        0.686        0.757         1.05        0.905        0.247       0.0165
      8    40      0.00128      0.00128     1.23e-06        0.759         1.03        0.504         1.05        0.777         0.63         1.35         0.99        0.469       0.0312
      8    50     0.000532     0.000532     3.33e-07        0.481        0.665         0.34        0.643        0.491        0.483        0.825        0.654        0.209        0.014
      8    60      0.00059     0.000588     1.86e-06        0.526        0.699        0.407        0.663        0.535        0.525        0.856         0.69        0.569       0.0379
      8    70     0.000615     0.000615     1.78e-07        0.521        0.715        0.367        0.697        0.532        0.482        0.911        0.697        0.162       0.0108
      8    80      0.00107      0.00107     6.82e-06        0.672        0.941        0.443        0.934        0.688        0.651         1.19         0.92         1.12       0.0748
      8    90     0.000728     0.000721     7.48e-06        0.586        0.774        0.359        0.846        0.602        0.462         1.02        0.741         1.17       0.0783
      8   100     0.000521      0.00052     1.08e-06        0.485        0.658        0.379        0.606        0.493        0.496        0.803         0.65        0.431       0.0288
      8   110     0.000776     0.000775     1.66e-07        0.537        0.803        0.309        0.797        0.553        0.386          1.1        0.743        0.166        0.011
      8   120     0.000609     0.000606     2.58e-06        0.521         0.71        0.415        0.643        0.529        0.558        0.851        0.705        0.684       0.0456
      8   130      0.00054     0.000525     1.53e-05        0.482        0.661        0.294        0.696        0.495        0.388        0.873        0.631         1.69        0.113
      8   140     0.000627     0.000627     6.75e-07        0.532        0.722        0.411        0.669         0.54        0.549        0.879        0.714        0.319       0.0213
      8   150     0.000548     0.000546     1.39e-06        0.481        0.674        0.351        0.629         0.49         0.44        0.868        0.654        0.491       0.0327
      8   160     0.000445     0.000435     9.46e-06        0.453        0.602         0.33        0.594        0.462        0.457        0.733        0.595         1.33       0.0885
      8   170     0.000698     0.000698     3.43e-07        0.613        0.762        0.542        0.694        0.618        0.664         0.86        0.762        0.234       0.0156
      8   180      0.00047     0.000467     2.47e-06         0.48        0.623        0.371        0.605        0.488         0.45        0.775        0.613        0.659        0.044
      8   190     0.000731     0.000728     2.92e-06        0.576        0.778        0.368        0.814        0.591        0.447         1.03         0.74        0.731       0.0487

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      8     5     0.000475     0.000475      6.2e-08        0.419        0.628        0.298        0.557        0.428        0.458        0.779        0.618       0.0844      0.00562


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train               8  176.773    0.005     0.000665     4.41e-06      0.00067        0.533        0.744        0.369        0.719        0.544        0.495        0.952        0.723        0.716       0.0477
! Validation          8  176.773    0.005     0.000368     1.02e-07     0.000368         0.38        0.553        0.263        0.513        0.388        0.372        0.706        0.539        0.108      0.00719
Wall time: 176.77407082100035
! Best model        8    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      9    10      0.00119      0.00116     2.92e-05        0.729        0.983        0.515        0.974        0.745        0.682         1.24        0.961         2.32        0.155
      9    20     0.000689     0.000679     9.82e-06        0.563        0.752         0.45        0.692        0.571        0.575        0.912        0.744         1.35       0.0898
      9    30     0.000736     0.000727      8.3e-06        0.588        0.778        0.435        0.763        0.599        0.553        0.973        0.763         1.24       0.0827
      9    40     0.000848     0.000847     1.46e-06        0.631        0.839        0.475         0.81        0.642        0.594         1.05        0.823          0.5       0.0333
      9    50     0.000701     0.000698     2.91e-06         0.55        0.762        0.413        0.706        0.559        0.552        0.946        0.749        0.731       0.0488
      9    60     0.000389     0.000388     6.38e-07        0.406        0.568        0.276        0.554        0.415         0.37        0.732        0.551        0.334       0.0223
      9    70     0.000428     0.000425     2.44e-06        0.432        0.595        0.262        0.628        0.445        0.331        0.796        0.563        0.663       0.0442
      9    80     0.000634     0.000634     3.83e-07        0.477        0.726        0.308         0.67        0.489        0.393        0.976        0.685        0.225        0.015
      9    90     0.000447     0.000447     6.17e-08        0.465        0.609        0.354        0.591        0.472        0.449        0.752          0.6          0.1      0.00667
      9   100     0.000436     0.000421     1.51e-05        0.432        0.591        0.328         0.55        0.439        0.452        0.719        0.585         1.67        0.111
      9   110     0.000559     0.000558     6.39e-07        0.462        0.681        0.313        0.633        0.473        0.378        0.912        0.645        0.338       0.0225
      9   120      0.00113      0.00113     1.59e-06        0.671        0.969        0.403        0.978         0.69        0.499         1.31        0.907        0.506       0.0338
      9   130      0.00116      0.00115     1.05e-05        0.711        0.979        0.476        0.979        0.728        0.612         1.28        0.944          1.4       0.0933
      9   140      0.00118      0.00117     2.86e-06        0.737        0.988        0.539        0.964        0.751        0.676         1.25        0.965        0.725       0.0483
      9   150      0.00124      0.00123     1.17e-05        0.728         1.01        0.481         1.01        0.746        0.634         1.32        0.976         1.48       0.0983
      9   160     0.000479     0.000476      3.7e-06        0.441        0.629        0.249        0.661        0.455        0.311        0.858        0.585        0.828       0.0552
      9   170     0.000278     0.000277     4.61e-07        0.348         0.48        0.223        0.491        0.357        0.287        0.632         0.46        0.253       0.0169
      9   180     0.000548     0.000546     2.48e-06        0.513        0.674        0.386        0.659        0.523          0.5        0.829        0.664        0.672       0.0448
      9   190     0.000544      0.00054      4.2e-06        0.467         0.67        0.285        0.675         0.48        0.356        0.904         0.63        0.881       0.0587

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
      9     5     0.000422     0.000422     5.31e-08        0.392        0.592        0.281        0.518        0.399         0.45        0.721        0.586        0.075        0.005


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train               9  198.059    0.005     0.000707     4.79e-06     0.000712        0.543        0.767        0.373        0.738        0.556        0.504        0.985        0.744        0.715       0.0477
! Validation          9  198.059    0.005     0.000316     8.23e-08     0.000316        0.353        0.512        0.246        0.474         0.36        0.353        0.648        0.501       0.0913      0.00608
Wall time: 198.05981854600032
! Best model        9    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     10    10     0.000662     0.000659     2.28e-06        0.515        0.741        0.343        0.712        0.527        0.415        0.989        0.702        0.634       0.0423
     10    20     0.000615     0.000615     5.98e-08        0.486        0.715        0.277        0.725        0.501         0.37        0.969         0.67       0.0844      0.00563
     10    30     0.000531     0.000527     3.61e-06        0.468        0.662        0.323        0.634        0.479         0.41        0.865        0.637        0.819       0.0546
     10    40     0.000489     0.000489     4.79e-08        0.451        0.638        0.264        0.663        0.464        0.348        0.856        0.602       0.0875      0.00583
     10    50     0.000705     0.000705     4.13e-07        0.553        0.766        0.369        0.762        0.566        0.478        0.998        0.738        0.259       0.0173
     10    60      0.00039     0.000376     1.37e-05        0.391        0.559        0.301        0.493        0.397        0.403        0.696         0.55          1.6        0.106
     10    70     0.000491     0.000486     4.65e-06        0.433        0.636        0.235        0.659        0.447        0.327        0.863        0.595        0.928       0.0619
     10    80     0.000494     0.000492     1.59e-06        0.482         0.64        0.327        0.659        0.493         0.41        0.827        0.619        0.531       0.0354
     10    90     0.000772     0.000761     1.12e-05         0.52        0.795        0.332        0.736        0.534        0.441         1.06        0.753         1.43       0.0956
     10   100     0.000908     0.000908     1.41e-07        0.659        0.869        0.496        0.845         0.67        0.604          1.1         0.85        0.138      0.00917
     10   110     0.000559     0.000557     2.58e-06        0.511         0.68        0.336        0.711        0.523        0.423        0.887        0.655        0.684       0.0456
     10   120     0.000489     0.000488     1.54e-06        0.467        0.637        0.306        0.651        0.478        0.399        0.829        0.614        0.531       0.0354
     10   130      0.00035     0.000344     5.87e-06        0.386        0.535        0.285        0.501        0.393        0.355        0.685         0.52         1.04       0.0692
     10   140     0.000364     0.000361     2.17e-06        0.399        0.548        0.277        0.539        0.408        0.342        0.715        0.528        0.634       0.0423
     10   150     0.000401     0.000396     4.13e-06        0.395        0.574        0.268         0.54        0.404        0.352        0.751        0.552        0.869       0.0579
     10   160     0.000376     0.000372     3.66e-06        0.382        0.556        0.262        0.519         0.39        0.391        0.699        0.545        0.825        0.055
     10   170     0.000405     0.000399     6.15e-06        0.421        0.576        0.256         0.61        0.433        0.327        0.768        0.547         1.07        0.071
     10   180     0.000306     0.000304      2.2e-06         0.38        0.503        0.258         0.52        0.389        0.323         0.65        0.486        0.628       0.0419
     10   190     0.000289     0.000286     2.44e-06        0.366        0.488        0.238        0.513        0.375          0.3        0.638        0.469        0.669       0.0446

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     10     5     0.000358     0.000358     4.76e-08        0.366        0.546        0.263        0.484        0.373        0.419        0.662         0.54        0.075        0.005


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              10  219.250    0.005     0.000572      3.7e-06     0.000576        0.488         0.69        0.328        0.671          0.5        0.438        0.894        0.666          0.7       0.0467
! Validation         10  219.250    0.005     0.000269     5.94e-08     0.000269        0.327        0.473         0.23        0.438        0.334        0.328        0.596        0.462         0.08      0.00533
Wall time: 219.25025444099992
! Best model       10    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     11    10     0.000302     0.000301     8.13e-07        0.346          0.5        0.238        0.469        0.353        0.327        0.643        0.485        0.366       0.0244
     11    20      0.00034      0.00034     8.65e-07        0.391        0.531        0.313        0.481        0.397        0.446        0.615         0.53        0.391        0.026
     11    30     0.000398     0.000395     3.45e-06        0.401        0.573        0.241        0.583        0.412        0.311         0.77        0.541        0.797       0.0531
     11    40     0.000283     0.000278     4.69e-06        0.358        0.481        0.236        0.497        0.367        0.333        0.607         0.47        0.938       0.0625
     11    50     0.000401     0.000401     1.26e-07        0.388        0.578        0.237        0.561        0.399        0.311        0.777        0.544        0.112       0.0075
     11    60     0.000491     0.000485     5.76e-06        0.445        0.635         0.29        0.622        0.456        0.378        0.837        0.608         1.04       0.0692
     11    70     0.000457     0.000454     3.26e-06        0.415        0.615        0.279         0.57        0.424        0.372        0.807         0.59        0.775       0.0517
     11    80     0.000552     0.000546     6.59e-06        0.491        0.674        0.318        0.688        0.503        0.404        0.887        0.645         1.11       0.0738
     11    90      0.00061     0.000601     8.69e-06        0.509        0.707        0.328        0.716        0.522        0.411        0.937        0.674         1.27       0.0844
     11   100     0.000408     0.000407     2.87e-07        0.415        0.582        0.285        0.564        0.424        0.353        0.764        0.558        0.194       0.0129
     11   110     0.000491     0.000491     5.82e-07         0.47        0.639        0.322        0.639         0.48        0.399        0.832        0.616        0.322       0.0215
     11   120     0.000783     0.000783     1.07e-07        0.577        0.807        0.335        0.853        0.594        0.426         1.09        0.758        0.128      0.00854
     11   130     0.000425     0.000423     2.71e-06        0.434        0.593        0.321        0.563        0.442        0.399        0.756        0.577        0.712       0.0475
     11   140     0.000873     0.000856     1.61e-05        0.616        0.844        0.391        0.872        0.632         0.49         1.12        0.804         1.73        0.115
     11   150     0.000666     0.000635     3.08e-05        0.483        0.727        0.308        0.682        0.495        0.397        0.975        0.686         2.39        0.159
     11   160     0.000589     0.000586     3.43e-06        0.443        0.698        0.245        0.669        0.457        0.312        0.966        0.639        0.775       0.0517
     11   170     0.000656     0.000655     1.53e-06        0.524        0.738        0.335         0.74        0.538        0.445         0.97        0.707        0.519       0.0346
     11   180     0.000404     0.000398     5.32e-06        0.376        0.576        0.244        0.526        0.385        0.321        0.769        0.545        0.991        0.066
     11   190      0.00037      0.00037     6.25e-08        0.409        0.555        0.283        0.553        0.418         0.39        0.697        0.543        0.103      0.00687

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     11     5     0.000312     0.000312     3.56e-08         0.34         0.51        0.244         0.45        0.347        0.389        0.619        0.504       0.0625      0.00417


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              11  240.362    0.005     0.000524      3.8e-06     0.000528        0.464         0.66        0.311         0.64        0.475        0.417        0.858        0.637        0.694       0.0463
! Validation         11  240.362    0.005     0.000239     4.73e-08     0.000239        0.308        0.445        0.216        0.414        0.315        0.308        0.563        0.435         0.07      0.00467
Wall time: 240.3630442499998
! Best model       11    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     12    10     0.000292     0.000292     7.33e-08         0.37        0.493        0.237        0.523         0.38        0.302        0.645        0.473        0.112       0.0075
     12    20     0.000323     0.000321     1.72e-06        0.402        0.517        0.316        0.501        0.408        0.422        0.608        0.515        0.553       0.0369
     12    30     0.000559     0.000554     4.15e-06        0.507        0.679        0.387        0.643        0.515        0.501        0.837        0.669        0.853       0.0569
     12    40     0.000654     0.000643     1.12e-05        0.528        0.731        0.268        0.825        0.546        0.344            1        0.674         1.44       0.0958
     12    50     0.000473     0.000472     9.46e-07        0.492        0.627         0.38        0.619          0.5        0.473        0.766        0.619        0.406       0.0271
     12    60     0.000837     0.000837     2.12e-07         0.67        0.834        0.534        0.825        0.679        0.651            1        0.827        0.144      0.00958
     12    70     0.000374     0.000374     1.28e-07        0.413        0.558        0.293         0.55        0.421        0.407        0.691        0.549        0.112       0.0075
     12    80     0.000471     0.000461     9.78e-06        0.446        0.619        0.266        0.652        0.459        0.354        0.823        0.589         1.34       0.0896
     12    90     0.000409     0.000405     3.89e-06        0.407        0.581        0.288        0.544        0.416        0.378        0.747        0.563         0.85       0.0567
     12   100     0.000385     0.000385     1.03e-07        0.365        0.566        0.222        0.528        0.375         0.32        0.754        0.537        0.109      0.00729
     12   110     0.000974     0.000973      6.5e-07        0.599          0.9        0.272        0.973        0.622        0.332         1.27          0.8        0.319       0.0213
     12   120     0.000687     0.000686     1.37e-06        0.477        0.755        0.263        0.721        0.492        0.345         1.04        0.694        0.503       0.0335
     12   130     0.000384     0.000381     2.76e-06        0.438        0.563         0.31        0.584        0.447        0.378        0.718        0.548        0.709       0.0473
     12   140     0.000355     0.000353     1.59e-06        0.416        0.542         0.38        0.458        0.419        0.486          0.6        0.543        0.538       0.0358
     12   150     0.000384     0.000384     1.93e-08        0.405        0.565        0.266        0.564        0.415        0.338        0.744        0.541       0.0562      0.00375
     12   160      0.00051      0.00051      1.1e-07        0.459        0.651        0.294        0.648        0.471        0.391        0.857        0.624        0.128      0.00854
     12   170      0.00048     0.000478     1.61e-06        0.442        0.631        0.256        0.654        0.455        0.353        0.842        0.598        0.528       0.0352
     12   180      0.00036     0.000358      1.4e-06        0.376        0.546        0.205        0.571        0.388         0.27        0.745        0.508        0.512       0.0342
     12   190     0.000363     0.000363     1.44e-07        0.405         0.55        0.338        0.481        0.409        0.456         0.64        0.548        0.147      0.00979

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     12     5      0.00028      0.00028     3.72e-08        0.326        0.483        0.232        0.433        0.333        0.361        0.592        0.477       0.0641      0.00427


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              12  261.899    0.005     0.000549     3.77e-06     0.000553        0.477        0.676        0.323        0.653        0.488        0.435        0.874        0.654        0.692       0.0461
! Validation         12  261.899    0.005      0.00022     4.62e-08      0.00022        0.295        0.427        0.205        0.398        0.302        0.291        0.543        0.417       0.0706      0.00471
Wall time: 261.8990918669988
! Best model       12    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     13    10     0.000411      0.00041     1.09e-06         0.43        0.584        0.299        0.579        0.439        0.421        0.726        0.574        0.419       0.0279
     13    20     0.000341     0.000339     2.11e-06        0.407        0.531        0.317        0.509        0.413          0.4         0.65        0.525        0.619       0.0412
     13    30      0.00059      0.00059     9.81e-08         0.52          0.7        0.378        0.683         0.53        0.503        0.873        0.688        0.112       0.0075
     13    40     0.000422     0.000422     1.63e-07        0.454        0.592        0.367        0.554        0.461        0.455        0.718        0.587         0.15         0.01
     13    50     0.000393     0.000392     5.95e-07        0.419        0.571        0.303        0.552        0.428        0.395        0.722        0.558        0.297       0.0198
     13    60       0.0007     0.000697     2.55e-06        0.525        0.762        0.348        0.727        0.538        0.507        0.974        0.741        0.669       0.0446
     13    70     0.000486     0.000483     3.14e-06        0.418        0.634        0.256        0.603        0.429        0.402        0.822        0.612         0.75         0.05
     13    80     0.000578     0.000578      2.5e-07        0.471        0.693        0.331         0.63        0.481        0.484        0.873        0.679        0.203       0.0135
     13    90      0.00027     0.000267     2.35e-06        0.342        0.472        0.184        0.523        0.353        0.224        0.647        0.436        0.656       0.0437
     13   100     0.000297     0.000295     1.53e-06        0.365        0.496         0.27        0.473        0.371        0.329        0.635        0.482        0.534       0.0356
     13   110     0.000189     0.000187     1.94e-06        0.294        0.394        0.215        0.384          0.3         0.29        0.487        0.388          0.6         0.04
     13   120     0.000242     0.000241     1.02e-06        0.289        0.448        0.171        0.423        0.297        0.235        0.606         0.42        0.438       0.0292
     13   130     0.000238     0.000231     7.46e-06        0.305        0.438        0.212         0.41        0.311         0.27        0.573        0.421         1.18       0.0787
     13   140     0.000153     0.000152      1.2e-06        0.255        0.355        0.174        0.348        0.261        0.228        0.459        0.344        0.469       0.0312
     13   150     0.000257     0.000256     7.39e-07        0.317        0.461        0.192         0.46        0.326        0.268        0.612         0.44        0.347       0.0231
     13   160     0.000206     0.000203      3.5e-06        0.312        0.411        0.184        0.458        0.321        0.232        0.547         0.39        0.812       0.0542
     13   170     0.000388     0.000386     2.07e-06        0.412        0.567        0.306        0.533         0.42        0.407        0.706        0.556          0.6         0.04
     13   180     0.000202       0.0002     1.54e-06        0.295        0.408        0.191        0.414        0.302        0.247        0.536        0.391        0.538       0.0358
     13   190     0.000579     0.000578     1.54e-06        0.508        0.693        0.309        0.735        0.522        0.407        0.916        0.662        0.525        0.035

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     13     5     0.000248     0.000248     3.09e-08        0.307        0.454        0.225        0.401        0.313        0.356        0.546        0.451       0.0531      0.00354


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              13  283.027    0.005     0.000364     2.28e-06     0.000366        0.395         0.55        0.277        0.529        0.403        0.374        0.699        0.536        0.533       0.0355
! Validation         13  283.027    0.005     0.000198     4.49e-08     0.000198        0.282        0.406        0.199        0.377        0.288        0.285         0.51        0.397       0.0694      0.00463
Wall time: 283.02762710299976
! Best model       13    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     14    10     0.000446      0.00044     6.16e-06        0.429        0.605        0.253         0.63        0.442        0.319        0.817        0.568         1.07       0.0712
     14    20     0.000401     0.000401     4.85e-08        0.443        0.578        0.319        0.585        0.452        0.402        0.728        0.565       0.0812      0.00542
     14    30     0.000581     0.000576     4.78e-06        0.498        0.692        0.356        0.661        0.509        0.473        0.878        0.676        0.919       0.0613
     14    40     0.000242     0.000238     3.94e-06        0.319        0.445        0.229        0.422        0.326        0.311        0.559        0.435        0.853       0.0569
     14    50     0.000329     0.000327     2.26e-06        0.376        0.521        0.246        0.526        0.386        0.317        0.684        0.501        0.641       0.0427
     14    60     0.000309     0.000309     2.37e-07        0.334        0.507         0.19        0.498        0.344        0.247        0.694         0.47        0.206       0.0137
     14    70     0.000292     0.000274     1.78e-05        0.358        0.477          0.3        0.424        0.362        0.385        0.565        0.475         1.83        0.122
     14    80      0.00045     0.000441     8.57e-06        0.445        0.606        0.298        0.613        0.456        0.378        0.789        0.584         1.26       0.0842
     14    90      0.00051     0.000506     4.28e-06        0.464        0.649        0.372         0.57        0.471        0.542        0.752        0.647        0.897       0.0598
     14   100     0.000557     0.000551      6.1e-06        0.468        0.677        0.272        0.692        0.482        0.385        0.901        0.643         1.06       0.0706
     14   110       0.0009     0.000898     2.14e-06        0.611        0.864        0.478        0.764        0.621        0.693         1.03        0.859        0.619       0.0413
     14   120     0.000348     0.000347     1.71e-06        0.376        0.537        0.247        0.524        0.385        0.309        0.713        0.511        0.562       0.0375
     14   130     0.000313     0.000311     1.99e-06        0.369        0.509        0.233        0.525        0.379        0.305         0.67        0.487        0.597       0.0398
     14   140     0.000252     0.000251     7.91e-07        0.333        0.457        0.241        0.438         0.34        0.305        0.584        0.445        0.381       0.0254
     14   150     0.000288     0.000288     3.42e-07        0.353        0.489        0.223        0.502        0.363        0.268        0.656        0.462        0.247       0.0165
     14   160      0.00022      0.00022     1.19e-07        0.327        0.428        0.254        0.411        0.332        0.309        0.532        0.421        0.122      0.00813
     14   170     0.000394     0.000391     3.01e-06        0.396         0.57        0.244        0.571        0.407        0.308        0.767        0.537        0.744       0.0496
     14   180     0.000239     0.000239     5.66e-08        0.344        0.446        0.297        0.397        0.347        0.378        0.512        0.445          0.1      0.00667
     14   190     0.000174     0.000167     7.52e-06        0.277        0.372        0.225        0.335         0.28        0.299        0.441         0.37         1.19       0.0792

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     14     5     0.000223     0.000223     2.74e-08         0.29        0.431         0.21        0.382        0.296        0.325        0.526        0.426       0.0594      0.00396


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              14  304.147    0.005      0.00041     2.64e-06     0.000413        0.416        0.584        0.288        0.561        0.425         0.39        0.747        0.568        0.568       0.0379
! Validation         14  304.147    0.005     0.000183     4.34e-08     0.000183        0.272         0.39        0.191        0.364        0.278        0.271        0.492        0.382         0.07      0.00467
Wall time: 304.1478900580005
! Best model       14    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     15    10     0.000222     0.000221     7.86e-07        0.298        0.429        0.212        0.396        0.304        0.283         0.55        0.417        0.366       0.0244
     15    20      0.00028     0.000277      3.2e-06        0.322         0.48        0.177        0.487        0.332        0.223        0.661        0.442        0.766        0.051
     15    30      0.00029      0.00029     2.33e-07        0.332        0.491        0.205        0.477        0.341        0.259        0.663        0.461        0.184       0.0123
     15    40     0.000341     0.000341     6.23e-08        0.387        0.532        0.239        0.556        0.398        0.294        0.713        0.503          0.1      0.00667
     15    50     0.000333     0.000329     3.65e-06        0.372        0.523        0.232        0.532        0.382        0.326        0.682        0.504        0.803       0.0535
     15    60     0.000266     0.000265     6.69e-07        0.347         0.47        0.291         0.41         0.35        0.385        0.551        0.468        0.328       0.0219
     15    70     0.000321     0.000317     3.18e-06        0.358        0.514        0.211        0.525        0.368        0.275        0.692        0.484        0.766        0.051
     15    80     0.000281      0.00028     1.75e-06        0.361        0.482        0.279        0.455        0.367        0.377        0.579        0.478        0.562       0.0375
     15    90     0.000347     0.000347     7.43e-07        0.428        0.537        0.338         0.53        0.434        0.431        0.636        0.534        0.341       0.0227
     15   100     0.000239     0.000239      3.6e-07        0.316        0.446        0.209        0.439        0.324         0.27        0.585        0.427         0.25       0.0167
     15   110     0.000247     0.000247     6.07e-07        0.337        0.453        0.281        0.402        0.342         0.35        0.547        0.449        0.338       0.0225
     15   120     0.000438     0.000438     3.41e-08        0.442        0.603        0.265        0.643        0.454        0.338        0.806        0.572       0.0656      0.00438
     15   130     0.000311     0.000309     1.47e-06        0.368        0.507        0.312        0.433        0.372        0.435        0.578        0.507        0.516       0.0344
     15   140     0.000698      0.00069     8.59e-06        0.621        0.757        0.553        0.698        0.626        0.646        0.867        0.757         1.26        0.084
     15   150     0.000432     0.000432     6.29e-08        0.444        0.599        0.272        0.641        0.457         0.35        0.794        0.572       0.0875      0.00583
     15   160     0.000293     0.000284     8.82e-06        0.351        0.486        0.191        0.533        0.362        0.254        0.658        0.456         1.28       0.0854
     15   170     0.000234     0.000232        2e-06         0.33        0.439         0.23        0.445        0.337        0.286        0.565        0.425        0.606       0.0404
     15   180     0.000258     0.000256     2.71e-06        0.311        0.461         0.18         0.46         0.32        0.228         0.63        0.429        0.703       0.0469
     15   190     0.000263     0.000263     4.58e-07        0.349        0.467        0.213        0.504        0.359        0.276        0.617        0.447        0.275       0.0183

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     15     5     0.000194     0.000194     1.79e-08        0.273        0.402        0.198        0.359        0.278        0.308        0.487        0.397       0.0453      0.00302


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              15  325.330    0.005     0.000332     2.14e-06     0.000334        0.376        0.525        0.259        0.509        0.384        0.351        0.671        0.511        0.506       0.0337
! Validation         15  325.330    0.005     0.000166     3.34e-08     0.000166         0.26        0.371        0.183        0.347        0.265        0.261        0.467        0.364       0.0616       0.0041
Wall time: 325.3309304659997
! Best model       15    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     16    10     0.000231      0.00023     5.84e-07        0.295        0.438        0.185         0.42        0.302        0.253        0.581        0.417          0.3         0.02
     16    20     0.000246     0.000245     1.19e-06        0.336        0.451        0.206        0.485        0.345        0.269        0.594        0.432        0.463       0.0308
     16    30     0.000269     0.000268      7.3e-07        0.354        0.472        0.272        0.448         0.36        0.344        0.585        0.464        0.344       0.0229
     16    40     0.000275     0.000269     5.62e-06        0.362        0.473        0.289        0.445        0.367        0.362        0.574        0.468         1.02       0.0681
     16    50     0.000251      0.00024      1.1e-05        0.327        0.447        0.271        0.392        0.331        0.403        0.492        0.448         1.44       0.0958
     16    60     0.000361     0.000361     8.79e-08        0.392        0.548        0.224        0.586        0.405        0.296        0.737        0.516       0.0969      0.00646
     16    70     0.000366     0.000364     1.66e-06        0.445         0.55        0.378        0.522         0.45        0.468        0.632         0.55         0.55       0.0367
     16    80     0.000272      0.00026     1.12e-05        0.342        0.465         0.27        0.424        0.347        0.343        0.574        0.459         1.45       0.0965
     16    90      0.00031     0.000309     2.12e-07        0.362        0.507        0.232        0.509        0.371        0.292        0.674        0.483        0.178       0.0119
     16   100     0.000297      0.00029     6.39e-06        0.362        0.491        0.271        0.466        0.368        0.347        0.616        0.482         1.09       0.0727
     16   110     0.000386     0.000384     1.65e-06        0.437        0.565        0.282        0.615        0.449        0.342        0.743        0.542        0.547       0.0365
     16   120     0.000279     0.000278     7.46e-07        0.333        0.481        0.199        0.487        0.343        0.261        0.646        0.454        0.353       0.0235
     16   130     0.000325      0.00032     5.79e-06         0.38        0.516        0.265        0.512        0.388        0.358        0.651        0.504         1.04       0.0692
     16   140     0.000363      0.00036     2.31e-06        0.421        0.547        0.341        0.512        0.426        0.411         0.67        0.541        0.656       0.0437
     16   150     0.000334      0.00033     3.59e-06        0.395        0.524        0.312         0.49        0.401        0.385        0.647        0.516        0.809        0.054
     16   160     0.000345     0.000343     2.15e-06        0.401        0.534        0.268        0.554        0.411        0.338        0.693        0.516        0.628       0.0419
     16   170     0.000398     0.000391     6.64e-06        0.452         0.57        0.389        0.525        0.457        0.485        0.655         0.57         1.11        0.074
     16   180     0.000461     0.000461     7.74e-08        0.463        0.619        0.312        0.635        0.474        0.431         0.78        0.606        0.106      0.00708
     16   190     0.000589     0.000587     2.08e-06        0.496        0.699         0.29         0.73         0.51        0.354         0.95        0.652        0.619       0.0412

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     16     5     0.000176     0.000176     2.32e-08        0.262        0.383        0.189        0.345        0.267        0.295        0.464        0.379       0.0547      0.00365


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              16  346.849    0.005     0.000343     2.44e-06     0.000346        0.385        0.534        0.267         0.52        0.394        0.357        0.683         0.52        0.564       0.0376
! Validation         16  346.849    0.005     0.000156      3.9e-08     0.000156        0.252        0.361        0.178        0.337        0.257        0.253        0.453        0.353       0.0659       0.0044
Wall time: 346.8497541609995
! Best model       16    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     17    10     0.000799     0.000796     2.61e-06        0.613        0.814        0.348        0.915        0.631        0.424          1.1        0.763        0.688       0.0458
     17    20     0.000255     0.000255     2.89e-07        0.338        0.461        0.237        0.454        0.345         0.29        0.599        0.444        0.225        0.015
     17    30      0.00025     0.000242     8.15e-06        0.343        0.449        0.273        0.422        0.348        0.333        0.552        0.442         1.24       0.0825
     17    40     0.000469     0.000462     6.78e-06        0.452         0.62        0.273        0.656        0.465        0.366        0.819        0.592         1.12        0.075
     17    50     0.000938     0.000938     5.73e-07         0.63        0.883        0.427        0.861        0.644        0.591         1.13         0.86        0.225        0.015
     17    60     0.000702       0.0007     1.37e-06        0.565        0.763        0.369        0.789        0.579        0.463            1        0.732          0.5       0.0333
     17    70     0.000232     0.000231     8.24e-07        0.332        0.439        0.212         0.47        0.341        0.281        0.567        0.424        0.391        0.026
     17    80     0.000303     0.000303     1.47e-07        0.345        0.502        0.209        0.501        0.355        0.261        0.679         0.47        0.144      0.00958
     17    90     0.000205     0.000205     6.15e-08        0.303        0.413        0.177        0.448        0.312        0.233        0.551        0.392       0.0906      0.00604
     17   100      0.00028      0.00028     5.55e-08        0.315        0.482        0.207        0.439        0.323         0.27        0.645        0.457        0.103      0.00687
     17   110     0.000448     0.000447     3.83e-07         0.42         0.61        0.287        0.573         0.43        0.431        0.765        0.598        0.237       0.0158
     17   120     0.000265     0.000265     1.83e-07        0.311        0.469        0.182        0.459        0.321        0.234         0.64        0.437        0.172       0.0115
     17   130     0.000225     0.000225     1.95e-07        0.322        0.432        0.237        0.419        0.328        0.309        0.539        0.424        0.181       0.0121
     17   140      0.00033     0.000328     2.21e-06        0.371        0.522        0.275        0.481        0.378         0.35        0.667        0.508        0.637       0.0425
     17   150     0.000229     0.000229     7.54e-07        0.316        0.436        0.228        0.417        0.322        0.275        0.567        0.421        0.353       0.0235
     17   160      0.00075     0.000748     1.51e-06        0.572        0.789        0.385        0.785        0.585        0.487         1.03        0.759        0.522       0.0348
     17   170     0.000914     0.000908     6.31e-06        0.662        0.869        0.405        0.955         0.68        0.516         1.15        0.831         1.08       0.0717
     17   180     0.000378     0.000373     4.83e-06        0.373        0.557        0.201        0.569        0.385        0.277         0.76        0.518        0.947       0.0631
     17   190     0.000386     0.000386     1.49e-07        0.405        0.567        0.269        0.561        0.415        0.365        0.732        0.549         0.15         0.01

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     17     5     0.000155     0.000155     2.32e-08        0.251         0.36         0.18        0.332        0.256         0.28        0.433        0.356       0.0484      0.00323


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              17  368.151    0.005     0.000383     2.23e-06     0.000386        0.405        0.565        0.278         0.55        0.414        0.373        0.724        0.548        0.491       0.0327
! Validation         17  368.151    0.005     0.000147     3.23e-08     0.000147        0.245         0.35        0.173        0.328        0.251        0.245         0.44        0.343       0.0597      0.00398
Wall time: 368.15196435299913
! Best model       17    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     18    10     0.000165     0.000163     2.29e-06        0.277        0.368        0.217        0.346        0.282        0.271        0.454        0.362         0.65       0.0433
     18    20     0.000179     0.000179     3.29e-07         0.26        0.386        0.175        0.357        0.266        0.237        0.505        0.371        0.213       0.0142
     18    30     0.000291     0.000288     2.57e-06        0.345         0.49          0.2         0.51        0.355        0.263        0.659        0.461        0.681       0.0454
     18    40     0.000394     0.000385     8.92e-06        0.418        0.566        0.255        0.604        0.429        0.316        0.756        0.536         1.29        0.086
     18    50     0.000381     0.000381     1.04e-07        0.421        0.563        0.319        0.539        0.429        0.396        0.706        0.551        0.119      0.00792
     18    60     0.000341     0.000338      2.9e-06        0.389         0.53        0.254        0.544        0.399        0.351         0.68        0.515        0.734        0.049
     18    70     0.000454     0.000454     4.17e-07        0.423        0.614        0.228        0.646        0.437        0.282        0.847        0.565        0.241        0.016
     18    80      0.00028      0.00028     9.62e-08        0.324        0.483        0.199        0.466        0.333        0.287        0.637        0.462        0.116      0.00771
     18    90     0.000307     0.000307     1.35e-07        0.369        0.505        0.218        0.542         0.38        0.268        0.682        0.475        0.144      0.00958
     18   100     0.000219     0.000217     1.38e-06         0.31        0.425        0.206        0.429        0.317        0.277        0.547        0.412        0.494       0.0329
     18   110     0.000171      0.00017     2.67e-07        0.268        0.377        0.198        0.348        0.273        0.259        0.477        0.368        0.219       0.0146
     18   120     0.000273     0.000272     1.77e-06        0.341        0.475        0.227        0.472        0.349          0.3        0.617        0.459        0.569       0.0379
     18   130     0.000316     0.000315     1.26e-06        0.362        0.512        0.225        0.518        0.371        0.329        0.662        0.495        0.481       0.0321
     18   140     0.000361      0.00036     1.02e-06        0.403        0.547        0.273        0.552        0.412        0.365        0.699        0.532        0.419       0.0279
     18   150      0.00013     0.000129     9.62e-07        0.237        0.327        0.164        0.321        0.243        0.229        0.411         0.32        0.425       0.0283
     18   160     0.000258     0.000256     1.41e-06        0.337        0.462        0.243        0.445        0.344        0.313        0.588         0.45        0.509        0.034
     18   170     0.000271      0.00027     8.94e-07        0.359        0.474         0.23        0.506        0.368        0.293        0.619        0.456        0.394       0.0262
     18   180     0.000258     0.000258     2.96e-07        0.337        0.463        0.235        0.454        0.345        0.294        0.601        0.447        0.209        0.014
     18   190     0.000182     0.000182     6.04e-08        0.289        0.389        0.213        0.375        0.294        0.273        0.489        0.381       0.0781      0.00521

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     18     5     0.000148     0.000148     1.73e-08        0.244        0.351        0.177        0.321        0.249        0.271        0.425        0.348       0.0437      0.00292


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              18  389.401    0.005      0.00028     1.43e-06     0.000281        0.348        0.482        0.243        0.469        0.356        0.324        0.615         0.47        0.395       0.0264
! Validation         18  389.401    0.005     0.000142     3.36e-08     0.000142         0.24        0.343        0.169        0.321        0.245        0.239        0.433        0.336       0.0594      0.00396
Wall time: 389.4020971819991
! Best model       18    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     19    10      0.00034      0.00034     4.22e-07          0.4        0.532        0.243         0.58        0.412        0.309        0.704        0.507        0.272       0.0181
     19    20     0.000149     0.000149     4.05e-08        0.259        0.352        0.207        0.319        0.263        0.269        0.428        0.349        0.075        0.005
     19    30     0.000194     0.000194     4.09e-07        0.288        0.402        0.192        0.397        0.294        0.243        0.527        0.385        0.272       0.0181
     19    40     0.000171     0.000171     3.71e-07        0.279        0.377        0.192        0.378        0.285        0.258        0.478        0.368        0.259       0.0173
     19    50     0.000501       0.0005     3.64e-07         0.47        0.645        0.324        0.637         0.48        0.415        0.834        0.624        0.256       0.0171
     19    60      0.00048     0.000476     3.57e-06        0.463        0.629        0.305        0.642        0.474        0.396        0.818        0.607          0.8       0.0533
     19    70     0.000288     0.000288     2.32e-07         0.36        0.489        0.235        0.503        0.369        0.303        0.639        0.471        0.181       0.0121
     19    80     0.000176     0.000176     4.41e-07        0.293        0.383        0.198        0.402          0.3        0.247        0.494         0.37        0.272       0.0181
     19    90     0.000209     0.000204     5.18e-06        0.315        0.412        0.276         0.36        0.318        0.358        0.466        0.412        0.988       0.0658
     19   100     0.000224     0.000219     5.52e-06        0.321        0.427        0.197        0.462         0.33        0.262        0.558         0.41         1.01       0.0673
     19   110     0.000202     0.000201     9.17e-07        0.304        0.409        0.198        0.426        0.312        0.257        0.533        0.395        0.409       0.0273
     19   120     0.000336     0.000333     2.66e-06        0.366        0.526        0.219        0.534        0.377        0.288        0.706        0.497        0.706       0.0471
     19   130      0.00012      0.00012     6.34e-08        0.218        0.316        0.143        0.304        0.224        0.196        0.412        0.304       0.0969      0.00646
     19   140     0.000215     0.000215     1.71e-07        0.317        0.423        0.216        0.433        0.325        0.267         0.55        0.408        0.159       0.0106
     19   150     0.000257     0.000254     2.73e-06        0.341         0.46        0.242        0.453        0.348        0.336         0.57        0.453        0.716       0.0477
     19   160     0.000189     0.000188     1.34e-07         0.28        0.396        0.165        0.411        0.288        0.247        0.516        0.381        0.138      0.00917
     19   170     0.000217     0.000217      2.1e-08        0.326        0.425        0.244        0.419        0.332        0.317        0.522        0.419       0.0406      0.00271
     19   180     0.000146     0.000146     1.93e-08        0.246        0.348        0.165        0.338        0.251        0.216        0.454        0.335       0.0469      0.00313
     19   190     0.000229     0.000227     1.77e-06        0.323        0.434        0.226        0.433         0.33        0.309        0.543        0.426        0.569       0.0379

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     19     5     0.000141     0.000141     1.76e-08        0.239        0.342        0.173        0.314        0.243        0.266        0.413        0.339         0.05      0.00333


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              19  410.992    0.005     0.000252     1.42e-06     0.000253        0.327        0.458        0.222        0.447        0.334        0.298        0.589        0.444        0.411       0.0274
! Validation         19  410.992    0.005     0.000135     3.34e-08     0.000135        0.233        0.335        0.164        0.312        0.238        0.233        0.422        0.327       0.0631      0.00421
Wall time: 410.9932690049991
! Best model       19    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     20    10     0.000417     0.000417     3.15e-07        0.424        0.589        0.307        0.557        0.432        0.429         0.73         0.58        0.231       0.0154
     20    20     0.000286     0.000285     3.41e-07        0.329        0.487        0.175        0.504         0.34         0.23        0.669         0.45        0.237       0.0158
     20    30     0.000135     0.000135     3.94e-07         0.25        0.335        0.174        0.337        0.256         0.23        0.424        0.327        0.262       0.0175
     20    40     7.91e-05     7.91e-05     3.71e-08        0.196        0.256        0.142        0.258          0.2        0.174        0.326         0.25       0.0656      0.00438
     20    50     0.000169     0.000169     1.28e-07        0.272        0.375        0.192        0.363        0.278        0.262        0.472        0.367        0.144      0.00958
     20    60     0.000117     0.000116     7.45e-07        0.235        0.311        0.171        0.307        0.239        0.224        0.386        0.305        0.366       0.0244
     20    70     0.000215     0.000213     1.24e-06        0.308        0.421        0.202        0.428        0.315        0.253        0.554        0.404        0.481       0.0321
     20    80     0.000231      0.00023     2.78e-07        0.308        0.438        0.204        0.427        0.316        0.305        0.552        0.428        0.209        0.014
     20    90     0.000152     0.000152     2.35e-07        0.246        0.356        0.131        0.377        0.254        0.172        0.487         0.33          0.2       0.0133
     20   100     0.000212     0.000212     2.28e-07        0.286         0.42        0.177         0.41        0.294         0.23        0.563        0.397        0.188       0.0125
     20   110     0.000206     0.000205     9.55e-07        0.282        0.413        0.186        0.392        0.289        0.278        0.527        0.402        0.419       0.0279
     20   120     0.000334     0.000333     5.11e-07        0.377        0.526         0.28        0.488        0.384         0.36        0.667        0.514        0.278       0.0185
     20   130     0.000208     0.000207     5.78e-07        0.296        0.415        0.217        0.386        0.302        0.287        0.524        0.406        0.309       0.0206
     20   140     0.000305     0.000305     7.92e-07        0.341        0.503        0.203        0.499        0.351        0.271        0.677        0.474        0.381       0.0254
     20   150     0.000191      0.00018     1.02e-05        0.258        0.387        0.168         0.36        0.264         0.22        0.516        0.368         1.38       0.0923
     20   160     0.000388     0.000388     1.29e-08        0.408        0.568        0.236        0.603         0.42        0.287        0.773         0.53       0.0344      0.00229
     20   170     0.000446      0.00042     2.54e-05        0.442        0.591        0.302        0.601        0.452        0.374        0.768        0.571         2.18        0.145
     20   180      0.00043     0.000426     4.09e-06        0.388        0.595        0.235        0.562        0.398        0.311        0.805        0.558        0.872       0.0581
     20   190     0.000295     0.000281     1.43e-05        0.317        0.484        0.206        0.443        0.325        0.264        0.649        0.457         1.63        0.109

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     20     5     0.000131     0.000131     1.73e-08        0.231         0.33        0.164        0.308        0.236        0.252        0.401        0.326       0.0453      0.00302


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              20  432.079    0.005     0.000254     2.08e-06     0.000256        0.323        0.459        0.214        0.449        0.331        0.287        0.598        0.443        0.477       0.0318
! Validation         20  432.079    0.005     0.000128     3.24e-08     0.000128        0.227        0.326        0.159        0.305        0.232        0.226        0.412        0.319         0.06        0.004
Wall time: 432.08024929599924
! Best model       20    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     21    10     0.000203     0.000203     9.41e-08        0.287         0.41        0.169        0.422        0.295        0.225         0.55        0.388       0.0969      0.00646
     21    20     0.000221     0.000221     1.43e-07         0.31        0.429        0.229        0.404        0.316        0.321        0.525        0.423        0.144      0.00958
     21    30     0.000134     0.000133     6.14e-07        0.235        0.333         0.15        0.332        0.241        0.206        0.435        0.321        0.334       0.0223
     21    40     0.000381     0.000379     2.14e-06        0.404        0.562         0.34        0.477        0.408        0.466        0.654         0.56        0.616        0.041
     21    50     0.000232      0.00022     1.19e-05        0.284        0.428        0.167        0.417        0.292        0.204        0.587        0.396         1.49       0.0994
     21    60     0.000284      0.00028     3.61e-06        0.348        0.483        0.272        0.434        0.353        0.378         0.58        0.479        0.816       0.0544
     21    70     0.000204     0.000202     1.89e-06        0.306         0.41        0.212        0.413        0.312        0.275        0.524        0.399        0.591       0.0394
     21    80     0.000145     0.000144     5.61e-07        0.255        0.346        0.164        0.359        0.261        0.209        0.455        0.332          0.3         0.02
     21    90      0.00021      0.00021      8.6e-08        0.327        0.418        0.257        0.407        0.332         0.32        0.507        0.414        0.112       0.0075
     21   100     0.000211     0.000201     1.05e-05        0.299        0.409        0.185        0.429        0.307        0.238        0.541         0.39          1.4       0.0935
     21   110     0.000191     0.000191     1.09e-07        0.292        0.398        0.201        0.396        0.298        0.259        0.513        0.386        0.112       0.0075
     21   120     0.000257     0.000253     3.63e-06        0.297        0.459        0.187        0.423        0.305        0.294        0.594        0.444        0.809        0.054
     21   130     0.000207     0.000204     3.21e-06        0.295        0.412         0.22         0.38          0.3        0.306        0.506        0.406        0.769       0.0512
     21   140     0.000183     0.000181     1.95e-06         0.27        0.388        0.147         0.41        0.278         0.21        0.522        0.366        0.603       0.0402
     21   150      0.00034     0.000334     6.16e-06        0.398        0.527        0.326        0.479        0.403        0.423        0.626        0.524         1.07       0.0715
     21   160     0.000396     0.000395     1.21e-06        0.402        0.573        0.286        0.533         0.41        0.406        0.718        0.562        0.469       0.0312
     21   170     0.000183     0.000182     2.58e-07        0.292        0.389        0.196        0.402        0.299        0.244        0.507        0.375        0.197       0.0131
     21   180     0.000201       0.0002     1.27e-06        0.299        0.408        0.207        0.404        0.305        0.274         0.52        0.397        0.488       0.0325
     21   190     0.000341      0.00034      9.5e-07        0.297        0.532        0.183        0.428        0.306        0.284        0.717          0.5        0.416       0.0277

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     21     5     0.000125     0.000125     1.85e-08        0.225        0.322         0.16        0.299        0.229        0.248         0.39        0.319       0.0484      0.00323


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              21  453.093    0.005     0.000226     2.68e-06     0.000229        0.309        0.434        0.207        0.425        0.316        0.279         0.56         0.42        0.585        0.039
! Validation         21  453.093    0.005     0.000121     2.77e-08     0.000121        0.221        0.318        0.156        0.297        0.226        0.222          0.4        0.311       0.0572      0.00381
Wall time: 453.09385224499965
! Best model       21    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     22    10     0.000175     0.000173     1.49e-06        0.301         0.38         0.25         0.36        0.305        0.315        0.442        0.379        0.525        0.035
     22    20     0.000162     0.000162     3.86e-08        0.268        0.367        0.163        0.388        0.276        0.208        0.489        0.349       0.0688      0.00458
     22    30     0.000145     0.000143     2.38e-06        0.265        0.345        0.194        0.345         0.27        0.243        0.433        0.338        0.659        0.044
     22    40     0.000155     0.000155     2.29e-07        0.258        0.359        0.152        0.379        0.266        0.198        0.481        0.339        0.206       0.0137
     22    50     0.000318     0.000318     1.12e-07        0.362        0.514        0.192        0.556        0.374        0.274        0.693        0.484        0.119      0.00792
     22    60     0.000157     0.000154     3.03e-06        0.269        0.358        0.186        0.364        0.275        0.251        0.451        0.351        0.753       0.0502
     22    70     0.000167     0.000166     6.68e-07        0.284        0.371        0.218        0.359        0.289         0.27        0.461        0.365        0.353       0.0235
     22    80     0.000138     0.000137     2.77e-07        0.244        0.338        0.161        0.338         0.25        0.218        0.436        0.327        0.219       0.0146
     22    90     0.000167     0.000167      4.5e-07        0.271        0.373        0.151        0.409         0.28         0.19        0.506        0.348        0.284        0.019
     22   100     0.000156     0.000156     2.92e-08        0.267         0.36        0.179        0.367        0.273         0.22        0.472        0.346       0.0531      0.00354
     22   110     0.000226     0.000226     2.08e-08        0.306        0.433        0.202        0.425        0.314         0.27        0.564        0.417         0.05      0.00333
     22   120     0.000123     0.000122     8.23e-07        0.242        0.319        0.164        0.331        0.248        0.206        0.411        0.309        0.394       0.0262
     22   130     9.23e-05     9.22e-05     1.75e-07        0.205        0.277        0.155        0.262        0.208        0.204        0.342        0.273        0.172       0.0115
     22   140     0.000302     0.000301     4.98e-08        0.327        0.501        0.187        0.488        0.337        0.269        0.674        0.472       0.0875      0.00583
     22   150     0.000245     0.000243     2.39e-06         0.33         0.45        0.251         0.42        0.336        0.329        0.556        0.443        0.659        0.044
     22   160      0.00032     0.000311     9.81e-06        0.361        0.508        0.301         0.43        0.366        0.396        0.612        0.504         1.36       0.0904
     22   170     0.000229     0.000229     4.86e-07        0.284        0.436        0.195        0.385         0.29        0.283        0.562        0.423        0.291       0.0194
     22   180     0.000187     0.000186     1.72e-06        0.291        0.393        0.209        0.385        0.297        0.281         0.49        0.386        0.562       0.0375
     22   190     0.000204     0.000202     1.92e-06        0.283        0.409        0.148        0.438        0.293        0.193        0.563        0.378        0.591       0.0394

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     22     5     0.000109     0.000109     2.03e-08        0.215        0.302        0.159        0.278        0.219        0.243        0.357          0.3       0.0453      0.00302


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              22  474.340    0.005      0.00021     1.49e-06     0.000212        0.299        0.418        0.205        0.407        0.306        0.275        0.537        0.406        0.424       0.0282
! Validation         22  474.340    0.005     0.000114     2.92e-08     0.000114        0.214        0.307        0.153        0.284        0.219        0.218        0.385        0.302       0.0559      0.00373
Wall time: 474.3405519480002
! Best model       22    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     23    10     0.000264     0.000263     1.78e-06         0.35        0.467        0.262        0.451        0.357        0.342        0.578         0.46        0.575       0.0383
     23    20      0.00034     0.000334      5.8e-06        0.383        0.527        0.264        0.518        0.391        0.356        0.671        0.514         1.03        0.069
     23    30     0.000155      0.00015     5.66e-06        0.251        0.353        0.162        0.354        0.258        0.197        0.472        0.334         1.02       0.0683
     23    40     9.72e-05     9.72e-05     1.23e-08        0.214        0.284        0.146        0.292        0.219         0.18        0.369        0.274       0.0406      0.00271
     23    50       0.0003     0.000299     7.97e-07         0.36        0.499        0.241        0.496        0.368        0.322        0.643        0.483        0.369       0.0246
     23    60      0.00022      0.00022      2.8e-08        0.294        0.428        0.181        0.423        0.302        0.241        0.571        0.406       0.0594      0.00396
     23    70     0.000308     0.000302     5.95e-06        0.359        0.501        0.207        0.533         0.37        0.264        0.677        0.471         1.05       0.0702
     23    80     0.000164     0.000162     2.69e-06        0.275        0.366        0.206        0.353         0.28        0.271        0.452        0.361        0.709       0.0473
     23    90     0.000161     0.000154     7.24e-06        0.251        0.358        0.163        0.351        0.257        0.216         0.47        0.343         1.16       0.0775
     23   100     0.000211      0.00021     1.11e-06        0.292        0.417        0.218        0.376        0.297        0.285         0.53        0.407        0.453       0.0302
     23   110     0.000123     0.000119     4.08e-06        0.252        0.315        0.247        0.257        0.252        0.306        0.324        0.315        0.872       0.0581
     23   120     0.000238     0.000238     2.09e-07        0.308        0.445        0.221        0.407        0.314        0.334        0.545        0.439        0.188       0.0125
     23   130     0.000284     0.000282     1.87e-06        0.351        0.485        0.239        0.478        0.359          0.3        0.633        0.466        0.575       0.0383
     23   140     0.000167     0.000165     1.64e-06        0.279        0.371        0.243         0.32        0.281        0.303        0.436        0.369         0.55       0.0367
     23   150     0.000105     0.000104     2.41e-07        0.213        0.295        0.143        0.293        0.218        0.189        0.381        0.285        0.209        0.014
     23   160     0.000176     0.000174     2.08e-06        0.263        0.381        0.153        0.389        0.271        0.215        0.508        0.361        0.625       0.0417
     23   170     0.000214     0.000214     2.12e-08        0.289        0.422        0.165         0.43        0.297        0.212        0.574        0.393       0.0469      0.00313
     23   180     0.000182     0.000182     4.81e-07        0.272        0.389        0.137        0.425        0.281        0.193        0.531        0.362        0.294       0.0196
     23   190     0.000201     0.000198     3.03e-06        0.302        0.406        0.247        0.365        0.306         0.33        0.478        0.404        0.744       0.0496

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     23     5     0.000103     0.000103     2.29e-08        0.209        0.293        0.154        0.272        0.213        0.235        0.348        0.291       0.0531      0.00354


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              23  495.645    0.005     0.000222     2.52e-06     0.000224        0.304         0.43        0.207        0.416        0.311        0.278        0.554        0.416        0.551       0.0368
! Validation         23  495.645    0.005      0.00011     2.59e-08      0.00011        0.211        0.303        0.149        0.281        0.215        0.213         0.38        0.297       0.0541       0.0036
Wall time: 495.64515910499904
! Best model       23    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     24    10     0.000222     0.000214     7.74e-06        0.304        0.422         0.25        0.366        0.308        0.324        0.512        0.418          1.2       0.0802
     24    20      0.00015     0.000149     7.03e-07        0.258        0.352        0.193        0.333        0.263        0.268        0.429        0.348        0.359        0.024
     24    30     0.000233     0.000231     2.08e-06        0.349        0.439        0.321         0.38        0.351        0.405        0.474         0.44        0.622       0.0415
     24    40     0.000222     0.000222     5.91e-07        0.325        0.429        0.241        0.422        0.331        0.299        0.541         0.42        0.325       0.0217
     24    50     0.000184     0.000183     4.27e-07        0.291         0.39         0.22        0.373        0.297        0.276        0.489        0.383        0.259       0.0173
     24    60     0.000147     0.000147     3.01e-07        0.253         0.35        0.176        0.342        0.259        0.218        0.456        0.337        0.225        0.015
     24    70     0.000253     0.000252      9.6e-07        0.323        0.458        0.192        0.473        0.333        0.258         0.61        0.434        0.416       0.0277
     24    80     0.000254     0.000251     3.52e-06        0.318        0.457        0.187        0.468        0.328        0.241        0.617        0.429        0.803       0.0535
     24    90     0.000152     0.000152     1.02e-07        0.264        0.356        0.188         0.35        0.269        0.235        0.456        0.346        0.131      0.00875
     24   100     0.000212     0.000208     4.22e-06        0.314        0.416        0.238          0.4        0.319        0.297         0.52        0.408        0.887       0.0592
     24   110     0.000153     0.000153     2.48e-07        0.263        0.357         0.16        0.381        0.271        0.209        0.472         0.34        0.197       0.0131
     24   120     0.000266     0.000265     6.32e-07        0.301        0.469        0.232        0.379        0.306        0.345         0.58        0.462        0.322       0.0215
     24   130     0.000165     0.000162     3.16e-06        0.265        0.367          0.2         0.34         0.27        0.266        0.456        0.361        0.769       0.0513
     24   140     0.000261     0.000261     3.34e-07        0.351        0.466        0.217        0.504         0.36        0.292        0.607        0.449         0.25       0.0167
     24   150     0.000206     0.000203      3.4e-06        0.303        0.411        0.186        0.437        0.312        0.227         0.55        0.389        0.794       0.0529
     24   160      0.00023      0.00023     6.81e-07        0.314        0.437        0.192        0.454        0.323        0.252         0.58        0.416        0.347       0.0231
     24   170     0.000323     0.000321     2.38e-06        0.337        0.516        0.175        0.523        0.349        0.226        0.716        0.471        0.659        0.044
     24   180     0.000381     0.000381      1.7e-07        0.416        0.563        0.262        0.593        0.427         0.32         0.75        0.535        0.162       0.0108
     24   190     0.000291      0.00029     1.77e-07        0.337        0.491        0.221        0.471        0.346        0.324        0.631        0.477        0.128      0.00854

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     24     5     9.86e-05     9.86e-05     2.83e-08        0.205        0.286        0.151        0.267        0.209        0.231        0.338        0.285       0.0625      0.00417


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              24  516.941    0.005      0.00023     1.76e-06     0.000231        0.308        0.437        0.207        0.424        0.315        0.277        0.567        0.422        0.471       0.0314
! Validation         24  516.941    0.005     0.000105      2.3e-08     0.000105        0.206        0.296        0.145        0.275         0.21        0.208        0.371         0.29       0.0519      0.00346
Wall time: 516.9421356429993
! Best model       24    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     25    10     0.000157     0.000157     1.07e-07        0.261        0.361          0.2         0.33        0.265         0.26         0.45        0.355        0.138      0.00917
     25    20     0.000431     0.000428     3.26e-06        0.414        0.596        0.261        0.588        0.425        0.307        0.809        0.558        0.762       0.0508
     25    30     0.000198     0.000194     3.72e-06        0.302        0.401        0.173        0.448        0.311         0.22        0.538        0.379        0.834       0.0556
     25    40     0.000214     0.000214     1.79e-07        0.321        0.422        0.232        0.424        0.328        0.285        0.537        0.411        0.178       0.0119
     25    50     0.000171      0.00017     6.73e-07        0.279        0.376        0.189        0.382        0.285        0.257        0.478        0.367         0.35       0.0233
     25    60     0.000318     0.000317     1.47e-06        0.388        0.513         0.31        0.476        0.393        0.408        0.611         0.51        0.509        0.034
     25    70      0.00013     0.000128      2.1e-06        0.244        0.326        0.186         0.31        0.248        0.239        0.403        0.321        0.625       0.0417
     25    80     0.000114     0.000114     4.02e-07        0.236        0.307        0.179        0.301         0.24        0.228        0.378        0.303        0.269       0.0179
     25    90     0.000143     0.000142     9.88e-07        0.239        0.343         0.15        0.342        0.246        0.192        0.459        0.325        0.425       0.0283
     25   100     0.000139     0.000138     1.86e-07        0.247        0.339        0.179        0.324        0.252        0.251        0.418        0.335        0.178       0.0119
     25   110     0.000317     0.000315      1.7e-06        0.331        0.512        0.243        0.431        0.337        0.371        0.636        0.504        0.544       0.0363
     25   120     0.000216     0.000216     8.29e-08        0.305        0.424        0.201        0.424        0.312         0.27        0.549        0.409       0.0938      0.00625
     25   130     0.000196     0.000193     2.43e-06        0.274        0.401        0.133        0.436        0.284        0.182        0.554        0.368        0.675        0.045
     25   140     0.000231     0.000231     4.31e-07        0.295        0.438        0.176        0.432        0.304        0.231        0.592        0.411        0.256       0.0171
     25   150     0.000269     0.000268     1.34e-06        0.351        0.472        0.253        0.463        0.358        0.333        0.593        0.463        0.488       0.0325
     25   160     0.000131      0.00013     6.28e-07         0.25        0.329        0.189        0.319        0.254         0.24        0.408        0.324        0.338       0.0225
     25   170     0.000186     0.000185     1.48e-06        0.288        0.392        0.181        0.411        0.296        0.237        0.514        0.376        0.516       0.0344
     25   180     0.000114      0.00011     3.77e-06        0.208        0.302        0.148        0.276        0.212        0.185        0.396        0.291        0.837       0.0558
     25   190     0.000151     0.000147     3.68e-06        0.261         0.35          0.2         0.33        0.265        0.262        0.429        0.346        0.825        0.055

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     25     5     9.48e-05     9.47e-05     2.42e-08        0.201        0.281        0.151        0.259        0.205        0.229         0.33         0.28       0.0547      0.00365


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              25  538.274    0.005     0.000196     1.22e-06     0.000197        0.288        0.404        0.199         0.39        0.294        0.267        0.518        0.392        0.373       0.0249
! Validation         25  538.274    0.005     0.000102     2.45e-08     0.000102        0.203        0.291        0.144         0.27        0.207        0.205        0.366        0.285       0.0519      0.00346
Wall time: 538.2747821659996
! Best model       25    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     26    10     9.67e-05     9.63e-05     3.26e-07        0.218        0.283        0.151        0.295        0.223        0.193        0.359        0.276        0.244       0.0162
     26    20     7.14e-05     7.13e-05     9.24e-08        0.173        0.244         0.12        0.234        0.177        0.155        0.316        0.235        0.109      0.00729
     26    30     0.000196     0.000194     1.97e-06        0.293        0.402         0.17        0.434        0.302        0.234        0.533        0.383          0.6         0.04
     26    40     0.000184     0.000183     1.13e-06        0.283         0.39        0.208         0.37        0.289        0.272        0.492        0.382        0.447       0.0298
     26    50     9.32e-05     9.25e-05     6.74e-07        0.194        0.277        0.107        0.294        0.201        0.149        0.373        0.261        0.347       0.0231
     26    60      0.00015     0.000149     4.39e-07        0.262        0.352        0.194         0.34        0.267        0.265        0.431        0.348        0.266       0.0177
     26    70     0.000268     0.000268     4.66e-08        0.329        0.472        0.188        0.491        0.339        0.243         0.64        0.441       0.0812      0.00542
     26    80     0.000328     0.000327     5.64e-07        0.367        0.522        0.232        0.522        0.377        0.307        0.689        0.498          0.3         0.02
     26    90     0.000324     0.000323     1.26e-07         0.39        0.519        0.289        0.506        0.398        0.373        0.646         0.51        0.131      0.00875
     26   100     0.000168     0.000164     3.21e-06        0.279         0.37        0.208         0.36        0.284        0.277        0.453        0.365        0.775       0.0517
     26   110     0.000188     0.000187     9.77e-07        0.245        0.394        0.123        0.385        0.254        0.165        0.549        0.357        0.419       0.0279
     26   120     0.000231     0.000231      2.6e-07        0.325        0.438        0.238        0.424        0.331        0.311        0.549         0.43          0.2       0.0133
     26   130     0.000218     0.000218     8.22e-08        0.294        0.425        0.184         0.42        0.302         0.25        0.563        0.406       0.0781      0.00521
     26   140     0.000228     0.000228     2.18e-07        0.314        0.435         0.21        0.433        0.322        0.271        0.568        0.419        0.203       0.0135
     26   150     0.000472     0.000472     4.82e-07        0.474        0.626        0.378        0.584        0.481        0.455        0.777        0.616        0.287       0.0192
     26   160      0.00033     0.000328     1.64e-06        0.348        0.523        0.192        0.527         0.36        0.275        0.706        0.491        0.547       0.0365
     26   170     0.000171     0.000168     3.32e-06        0.291        0.374        0.247        0.341        0.294        0.311        0.435        0.373        0.772       0.0515
     26   180     0.000175     0.000171     3.17e-06        0.264        0.378        0.192        0.345        0.269        0.241        0.489        0.365        0.756       0.0504
     26   190     0.000196     0.000196     6.68e-08        0.285        0.404        0.185          0.4        0.292        0.235        0.535        0.385        0.103      0.00687

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     26     5     9.87e-05     9.87e-05     1.76e-08        0.203        0.286        0.151        0.262        0.207        0.233        0.337        0.285       0.0484      0.00323


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              26  559.062    0.005     0.000212     1.36e-06     0.000213        0.299         0.42        0.203        0.408        0.305        0.275         0.54        0.408        0.401       0.0267
! Validation         26  559.062    0.005       0.0001      2.1e-08       0.0001        0.201        0.289        0.143        0.268        0.205        0.205        0.361        0.283       0.0487      0.00325
Wall time: 559.0633619969994
! Best model       26    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     27    10     0.000209     0.000208     1.65e-06        0.289        0.416        0.154        0.445        0.299        0.204        0.568        0.386         0.55       0.0367
     27    20     0.000131     0.000131     1.84e-07        0.253         0.33        0.178        0.338        0.258        0.224         0.42        0.322        0.153       0.0102
     27    30     9.46e-05     9.46e-05     2.82e-08        0.208         0.28        0.139        0.286        0.213        0.182        0.362        0.272       0.0594      0.00396
     27    40     8.43e-05     8.42e-05     1.16e-07        0.192        0.265        0.129        0.263        0.196        0.182        0.335        0.258        0.138      0.00917
     27    50     0.000234     0.000233     1.95e-07        0.307        0.441        0.192        0.438        0.315        0.247        0.588        0.418        0.166        0.011
     27    60     0.000241     0.000241     7.21e-08        0.337        0.447        0.255        0.431        0.343        0.325        0.555         0.44       0.0875      0.00583
     27    70     0.000253     0.000251     2.31e-06        0.353        0.457        0.253        0.468         0.36        0.309        0.581        0.445        0.653       0.0435
     27    80      0.00017      0.00017      3.9e-08        0.274        0.376        0.185        0.376        0.281        0.247        0.482        0.365       0.0688      0.00458
     27    90     0.000244     0.000243     1.47e-07        0.342         0.45        0.254        0.442        0.348         0.32        0.563        0.441        0.144      0.00958
     27   100     0.000175     0.000171     3.45e-06        0.277        0.377        0.206        0.359        0.282        0.274        0.469        0.371        0.803       0.0535
     27   110     0.000238     0.000238     1.82e-08        0.343        0.445        0.243        0.458         0.35        0.288        0.573        0.431       0.0531      0.00354
     27   120     0.000108     0.000108     5.93e-07        0.221        0.299        0.185        0.261        0.223        0.241        0.354        0.298        0.331       0.0221
     27   130     0.000287     0.000286     1.29e-06        0.344        0.488        0.222        0.484        0.353        0.311        0.632        0.471        0.478       0.0319
     27   140     0.000399     0.000398     8.25e-07        0.411        0.576        0.225        0.624        0.425        0.297         0.78        0.539        0.391        0.026
     27   150     8.21e-05      8.2e-05     5.72e-08          0.2        0.261        0.137        0.271        0.204        0.171        0.336        0.253       0.0938      0.00625
     27   160     0.000206     0.000203     3.41e-06        0.285         0.41        0.165        0.422        0.293        0.234        0.546         0.39        0.797       0.0531
     27   170     0.000163     0.000163     1.14e-07        0.256        0.368        0.144        0.383        0.264        0.192        0.498        0.345        0.131      0.00875
     27   180     0.000279     0.000277     1.41e-06        0.328         0.48         0.27        0.394        0.332        0.413        0.547         0.48          0.5       0.0333
     27   190      0.00016      0.00016     5.96e-08         0.27        0.364        0.214        0.333        0.274        0.288        0.436        0.362       0.0938      0.00625

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     27     5     8.72e-05     8.72e-05     1.83e-08        0.193        0.269        0.142         0.25        0.196        0.214        0.321        0.267       0.0453      0.00302


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              27  580.446    0.005     0.000185     6.92e-07     0.000186        0.283        0.393        0.197        0.382         0.29        0.262        0.502        0.382        0.285        0.019
! Validation         27  580.446    0.005     9.57e-05      2.1e-08     9.57e-05        0.197        0.282        0.139        0.262        0.201        0.199        0.354        0.276       0.0478      0.00319
Wall time: 580.4467784909993
! Best model       27    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     28    10     0.000146     0.000145     6.78e-07        0.261        0.348        0.167        0.369        0.268        0.207        0.458        0.332        0.353       0.0235
     28    20     0.000121     0.000121     9.92e-08        0.227        0.317        0.201        0.257        0.229        0.267        0.366        0.317        0.112       0.0075
     28    30     8.86e-05     8.85e-05     5.66e-08        0.195        0.271        0.136        0.263          0.2        0.188        0.342        0.265        0.103      0.00688
     28    40     0.000152     0.000152      5.4e-08         0.24        0.356        0.179        0.309        0.244        0.246        0.449        0.348       0.0781      0.00521
     28    50     0.000124     0.000123     1.08e-06        0.227         0.32        0.129        0.339        0.234        0.175        0.429        0.302        0.447       0.0298
     28    60     0.000187     0.000187     1.98e-07        0.271        0.395         0.19        0.364        0.277        0.249        0.513        0.381        0.169       0.0113
     28    70     0.000202       0.0002     1.62e-06        0.294        0.408        0.202          0.4        0.301         0.27        0.523        0.397        0.538       0.0358
     28    80     0.000313     0.000305     7.99e-06        0.336        0.504        0.216        0.472        0.344        0.274        0.677        0.476         1.22        0.081
     28    90     0.000221     0.000221     6.04e-08        0.316        0.429        0.208        0.439        0.324        0.262        0.562        0.412       0.0844      0.00563
     28   100     0.000122     0.000121     3.82e-07        0.244        0.317        0.186        0.311        0.249        0.238        0.389        0.313        0.241        0.016
     28   110     0.000127     0.000127     4.41e-08        0.231        0.325        0.171        0.298        0.235        0.252        0.392        0.322       0.0656      0.00438
     28   120     0.000127     0.000127     2.65e-07        0.238        0.325        0.175        0.311        0.243        0.228        0.409        0.318        0.216       0.0144
     28   130     0.000119     0.000118      3.7e-07        0.233        0.314        0.186        0.287        0.237        0.244        0.377        0.311        0.253       0.0169
     28   140     0.000149     0.000149     4.62e-08        0.261        0.352         0.18        0.352        0.266        0.243        0.445        0.344       0.0781      0.00521
     28   150     8.45e-05     8.45e-05     5.09e-09        0.198        0.265        0.148        0.254        0.201        0.201        0.323        0.262       0.0281      0.00188
     28   160     0.000101     9.97e-05     1.34e-06        0.209        0.288        0.131        0.299        0.215        0.166        0.382        0.274        0.497       0.0331
     28   170     0.000111      0.00011     8.88e-08        0.225        0.303        0.193        0.262        0.227        0.268        0.339        0.303        0.112       0.0075
     28   180     7.86e-05     7.85e-05     1.14e-07        0.191        0.255        0.121        0.271        0.196        0.159        0.333        0.246        0.125      0.00833
     28   190     0.000108     0.000108     1.18e-07        0.226          0.3        0.152         0.31        0.231        0.192        0.387         0.29        0.134      0.00896

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     28     5     8.38e-05     8.38e-05     1.53e-08        0.187        0.264         0.14         0.24         0.19        0.215         0.31        0.263       0.0469      0.00313


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              28  601.543    0.005     0.000148     1.08e-06     0.000149        0.251         0.35        0.176        0.337        0.257        0.238        0.445        0.342        0.341       0.0227
! Validation         28  601.543    0.005     9.19e-05     1.82e-08      9.2e-05        0.192        0.277        0.136        0.256        0.196        0.195        0.347        0.271       0.0447      0.00298
Wall time: 601.5437058030002
! Best model       28    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     29    10     0.000189     0.000187     1.95e-06        0.292        0.395         0.22        0.374        0.297        0.295        0.484        0.389        0.597       0.0398
     29    20     0.000111     0.000111     4.34e-07        0.223        0.303        0.163        0.292        0.228        0.209        0.384        0.296        0.272       0.0181
     29    30     0.000143     0.000142     1.26e-06        0.253        0.344        0.149        0.372        0.261        0.192         0.46        0.326        0.484       0.0323
     29    40     0.000103     0.000102     6.35e-07        0.215        0.292        0.149        0.291         0.22        0.194        0.373        0.284        0.344       0.0229
     29    50     0.000111     0.000111     2.92e-08        0.209        0.303        0.138        0.289        0.214        0.195        0.392        0.294       0.0656      0.00438
     29    60     0.000164     0.000164     9.11e-09        0.277        0.369        0.189        0.377        0.283        0.233         0.48        0.356       0.0344      0.00229
     29    70      0.00012      0.00012     5.07e-08        0.235        0.315        0.163        0.316         0.24         0.21        0.404        0.307       0.0844      0.00562
     29    80     0.000151     0.000151     4.09e-08        0.239        0.354        0.172        0.315        0.244        0.245        0.447        0.346       0.0625      0.00417
     29    90     0.000202     0.000201     8.42e-07        0.293        0.409        0.191        0.409          0.3        0.257        0.532        0.395        0.391        0.026
     29   100     0.000107     0.000107     8.01e-07        0.222        0.298        0.138        0.319        0.228        0.181        0.391        0.286        0.384       0.0256
     29   110     0.000124     0.000122     2.14e-06         0.23        0.318        0.147        0.325        0.236        0.182        0.424        0.303        0.625       0.0417
     29   120      0.00012      0.00012     6.01e-07        0.235        0.315        0.181        0.297        0.239        0.244        0.381        0.312        0.325       0.0217
     29   130     0.000159     0.000159     6.49e-07        0.255        0.363        0.185        0.335         0.26        0.261        0.453        0.357        0.341       0.0227
     29   140     0.000178     0.000174     3.72e-06        0.266         0.38        0.157        0.391        0.274          0.2        0.514        0.357        0.831       0.0554
     29   150     0.000184     0.000184     7.95e-08        0.286        0.391        0.203        0.381        0.292        0.273        0.492        0.383       0.0938      0.00625
     29   160     8.49e-05     8.48e-05     9.24e-08        0.196        0.266        0.146        0.252        0.199        0.193         0.33        0.261        0.122      0.00812
     29   170     0.000133     0.000133     1.33e-07        0.245        0.333        0.168        0.332         0.25        0.232        0.419        0.326        0.153       0.0102
     29   180     0.000129     0.000128     3.55e-07        0.236        0.327        0.164        0.319        0.241        0.203        0.426        0.315        0.247       0.0165
     29   190     8.63e-05     8.48e-05     1.51e-06        0.196        0.266        0.147        0.253          0.2        0.183        0.336        0.259        0.525        0.035

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     29     5     7.82e-05     7.82e-05     1.53e-08        0.182        0.255        0.136        0.235        0.185        0.205        0.302        0.254       0.0437      0.00292


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              29  623.446    0.005     0.000125     6.93e-07     0.000126        0.231        0.322        0.159        0.313        0.236        0.214        0.413        0.313        0.286       0.0191
! Validation         29  623.446    0.005     8.85e-05     1.93e-08     8.85e-05        0.188        0.271        0.133        0.252        0.192         0.19        0.341        0.266       0.0456      0.00304
Wall time: 623.4473821669999
! Best model       29    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     30    10     0.000103     0.000103     1.27e-07         0.21        0.293        0.147        0.282        0.215        0.197        0.373        0.285        0.134      0.00896
     30    20     0.000123     0.000122     1.46e-06        0.238        0.318        0.159        0.328        0.244        0.199        0.415        0.307        0.522       0.0348
     30    30     0.000105     0.000105     1.17e-07        0.211        0.296        0.152        0.279        0.215        0.196        0.379        0.287        0.128      0.00854
     30    40     0.000144     0.000144     1.72e-07        0.251        0.346        0.183        0.328        0.256        0.237        0.439        0.338        0.169       0.0113
     30    50      0.00025     0.000249     1.39e-06        0.303        0.455        0.169        0.455        0.312        0.208        0.628        0.418        0.497       0.0331
     30    60       0.0002     0.000198     1.02e-06        0.292        0.406        0.169        0.434        0.301        0.207        0.552         0.38        0.431       0.0287
     30    70     0.000109     0.000108     5.97e-07        0.225          0.3        0.196        0.257        0.227        0.259        0.341          0.3        0.331       0.0221
     30    80     0.000171      0.00017     3.44e-07        0.292        0.376        0.212        0.385        0.298        0.259        0.477        0.368        0.237       0.0158
     30    90     8.95e-05     8.93e-05     2.38e-07        0.197        0.273        0.139        0.263        0.201        0.185        0.346        0.266        0.206       0.0137
     30   100     0.000117     0.000117     8.35e-08        0.228        0.312        0.165        0.301        0.233        0.209        0.398        0.304        0.122      0.00813
     30   110     0.000226     0.000224     2.96e-06        0.307        0.431        0.266        0.355         0.31        0.397        0.467        0.432        0.734        0.049
     30   120     0.000116     0.000116     3.54e-08        0.245         0.31        0.186        0.313        0.249        0.235        0.378        0.307       0.0625      0.00417
     30   130     0.000106     0.000105     1.61e-06        0.228        0.295        0.158        0.308        0.233        0.192         0.38        0.286        0.547       0.0365
     30   140     9.04e-05     9.03e-05     7.69e-08          0.2        0.274        0.138        0.271        0.205        0.184         0.35        0.267        0.109      0.00729
     30   150      0.00019     0.000189     1.46e-06        0.253        0.396        0.175        0.342        0.259        0.298        0.485        0.391        0.512       0.0342
     30   160     9.28e-05     9.27e-05      1.1e-07        0.205        0.278        0.142        0.276        0.209        0.196        0.348        0.272        0.128      0.00854
     30   170     0.000167     0.000167     3.71e-08        0.262        0.373        0.215        0.316        0.266        0.276        0.459        0.368       0.0625      0.00417
     30   180     0.000146      0.00014     6.55e-06         0.23        0.341        0.155        0.315        0.235        0.207        0.447        0.327         1.11       0.0737
     30   190     0.000162     0.000162     1.36e-07        0.273        0.367        0.216        0.338        0.277        0.291        0.437        0.364        0.131      0.00875

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     30     5     7.47e-05     7.47e-05     1.99e-08        0.177        0.249        0.131        0.229         0.18          0.2        0.296        0.248       0.0516      0.00344


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              30  644.790    0.005     0.000151     9.37e-07     0.000152        0.254        0.354        0.175        0.344         0.26        0.235        0.454        0.344        0.336       0.0224
! Validation         30  644.790    0.005     8.49e-05     2.04e-08     8.49e-05        0.185        0.266         0.13        0.247        0.189        0.186        0.334         0.26       0.0484      0.00323
Wall time: 644.7911930480004
! Best model       30    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     31    10      9.8e-05     9.79e-05     4.22e-08        0.211        0.285        0.144        0.288        0.216        0.178        0.372        0.275       0.0594      0.00396
     31    20     0.000154     0.000151     2.68e-06        0.267        0.355        0.172        0.375        0.274        0.219        0.464        0.341        0.703       0.0469
     31    30     0.000135     0.000135     4.12e-07        0.235        0.335        0.135        0.349        0.242        0.181        0.451        0.316        0.272       0.0181
     31    40     8.07e-05     7.87e-05     2.03e-06         0.19        0.256        0.131        0.257        0.194        0.165         0.33        0.248        0.616        0.041
     31    50     0.000108     0.000108     6.42e-08        0.222        0.299        0.141        0.314        0.228        0.182        0.392        0.287          0.1      0.00667
     31    60     0.000146     0.000146     3.29e-07        0.259        0.348        0.148        0.385        0.267        0.195        0.466         0.33        0.241        0.016
     31    70     9.71e-05     9.58e-05     1.25e-06        0.206        0.282        0.132         0.29        0.211        0.173         0.37        0.271        0.475       0.0317
     31    80     0.000117     0.000115     2.52e-06        0.225        0.309        0.138        0.325        0.232        0.185        0.406        0.296        0.684       0.0456
     31    90     0.000115     0.000114     1.55e-06        0.239        0.307        0.178        0.308        0.243        0.225         0.38        0.303        0.534       0.0356
     31   100     0.000112     0.000111     5.41e-07        0.213        0.304        0.123        0.316        0.219        0.168        0.407        0.288        0.316        0.021
     31   110     9.92e-05      9.9e-05     2.45e-07        0.196        0.287        0.114        0.289        0.202        0.148        0.389        0.269        0.206       0.0137
     31   120     0.000189     0.000188     8.81e-07        0.248        0.395        0.147        0.364        0.255        0.273        0.499        0.386        0.397       0.0265
     31   130     0.000132     0.000132     5.32e-08        0.221        0.331        0.135        0.319        0.227        0.171        0.449         0.31       0.0969      0.00646
     31   140     9.74e-05     9.32e-05     4.21e-06        0.207        0.278        0.142        0.281        0.212        0.186        0.356        0.271        0.887       0.0592
     31   150     0.000104     0.000104     5.28e-08        0.205        0.294        0.126        0.294         0.21        0.171        0.389         0.28       0.0969      0.00646
     31   160     0.000231     0.000231     1.95e-07        0.285        0.438        0.192        0.392        0.292        0.269        0.574        0.421        0.172       0.0115
     31   170     0.000152     0.000147     4.93e-06        0.273         0.35        0.237        0.314        0.276        0.298        0.401        0.349        0.956       0.0637
     31   180     0.000296     0.000295     5.28e-07        0.368        0.495        0.213        0.545        0.379        0.274        0.663        0.469          0.3         0.02
     31   190     0.000133     0.000129     3.73e-06         0.25        0.328        0.205        0.302        0.253        0.258        0.393        0.325        0.831       0.0554

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     31     5     7.03e-05     7.03e-05     1.31e-08        0.172        0.242        0.131         0.22        0.175          0.2        0.282        0.241       0.0422      0.00281


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              31  666.038    0.005     0.000128     1.14e-06     0.000129        0.236        0.327        0.164        0.317        0.241        0.221        0.416        0.318        0.375        0.025
! Validation         31  666.038    0.005     8.29e-05     1.61e-08     8.29e-05        0.182        0.263        0.128        0.243        0.186        0.184         0.33        0.257       0.0416      0.00277
Wall time: 666.038323376999
! Best model       31    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     32    10      0.00012      0.00012     5.17e-08        0.241        0.316        0.196        0.293        0.244         0.26        0.369        0.314       0.0812      0.00542
     32    20     0.000163     0.000162     1.45e-07        0.255        0.368        0.175        0.347        0.261        0.236        0.475        0.356         0.15         0.01
     32    30     0.000104     0.000102     1.57e-06        0.213        0.292        0.159        0.276        0.217        0.208        0.365        0.286        0.541        0.036
     32    40     0.000131      0.00013     6.62e-07        0.224        0.329        0.139        0.322         0.23        0.186        0.439        0.312        0.347       0.0231
     32    50     0.000162     0.000154     7.27e-06        0.264        0.358        0.185        0.354         0.27        0.232        0.462        0.347         1.17       0.0779
     32    60     7.11e-05     7.11e-05     4.01e-08        0.173        0.243        0.121        0.233        0.177        0.167        0.308        0.238        0.075        0.005
     32    70     0.000219     0.000215     4.23e-06        0.289        0.423        0.178        0.416        0.297        0.242        0.562        0.402        0.884        0.059
     32    80     0.000139     0.000136     2.92e-06        0.255        0.336        0.197        0.322         0.26        0.261        0.406        0.333        0.738       0.0492
     32    90     7.27e-05     7.26e-05     7.63e-08        0.183        0.246        0.138        0.234        0.186         0.18        0.304        0.242        0.109      0.00729
     32   100     0.000103      9.8e-05     4.88e-06        0.216        0.285        0.147        0.295        0.221        0.194        0.363        0.278        0.959        0.064
     32   110     0.000105     0.000104     8.06e-07        0.223        0.295        0.174         0.28        0.227        0.215        0.365         0.29        0.378       0.0252
     32   120     0.000104     0.000104     4.15e-08        0.224        0.294        0.172        0.283        0.228        0.214        0.365        0.289       0.0625      0.00417
     32   130     0.000106     0.000104     2.01e-06        0.215        0.294        0.184         0.25        0.217        0.259        0.329        0.294        0.606       0.0404
     32   140     0.000106     0.000105     8.61e-07        0.214        0.295        0.126        0.315        0.221         0.16        0.396        0.278          0.4       0.0267
     32   150       0.0001     9.88e-05     1.25e-06          0.2        0.287        0.158        0.248        0.203         0.24        0.332        0.286        0.472       0.0315
     32   160     0.000162     0.000157     4.47e-06        0.223        0.362        0.158        0.297        0.227        0.261         0.45        0.356        0.909       0.0606
     32   170     6.78e-05     6.77e-05     1.78e-07        0.174        0.237       0.0968        0.262        0.179        0.119        0.323        0.221        0.178       0.0119
     32   180     0.000127     0.000127     1.11e-07        0.234        0.325        0.149        0.332        0.241        0.203        0.424        0.313        0.138      0.00917
     32   190     0.000238     0.000237     9.12e-07        0.318        0.444        0.207        0.445        0.326        0.274         0.58        0.427          0.4       0.0267

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     32     5     6.92e-05     6.92e-05     1.25e-08        0.171         0.24         0.13        0.218        0.174        0.199        0.279        0.239       0.0391       0.0026


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              32  687.424    0.005     0.000127     1.43e-06     0.000128        0.233        0.325         0.16        0.316        0.238        0.215        0.416        0.316        0.435        0.029
! Validation         32  687.424    0.005     8.05e-05     1.77e-08     8.06e-05        0.179        0.259        0.126        0.239        0.182        0.181        0.326        0.253       0.0422      0.00281
Wall time: 687.4245841190004
! Best model       32    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     33    10     0.000121     0.000121     2.06e-07        0.231        0.317         0.15        0.324        0.237        0.205         0.41        0.307        0.188       0.0125
     33    20     0.000119     0.000119     2.68e-07        0.231        0.315        0.137        0.339        0.238        0.171        0.423        0.297        0.222       0.0148
     33    30     0.000171     0.000169      1.7e-06        0.252        0.375        0.177        0.337        0.257        0.241        0.485        0.363        0.562       0.0375
     33    40     0.000195     0.000191     4.37e-06        0.287        0.398        0.178        0.412        0.295        0.237        0.525        0.381        0.903       0.0602
     33    50     0.000119     0.000115     3.48e-06        0.227        0.309        0.124        0.346        0.235        0.171        0.414        0.293        0.809        0.054
     33    60     8.05e-05     8.04e-05     2.37e-08        0.197        0.259         0.15         0.25          0.2        0.189         0.32        0.255       0.0562      0.00375
     33    70     0.000127     0.000127      1.8e-07        0.221        0.324        0.135        0.319        0.227         0.17        0.439        0.304        0.178       0.0119
     33    80     0.000138     0.000136     1.48e-06        0.254        0.336        0.179         0.34        0.259         0.23        0.427        0.328        0.519       0.0346
     33    90     0.000182     0.000182     7.07e-07        0.267        0.389        0.162        0.386        0.274        0.209        0.523        0.366        0.353       0.0235
     33   100      0.00011     0.000109     1.98e-07        0.218        0.302        0.149        0.297        0.223        0.194         0.39        0.292        0.181       0.0121
     33   110     0.000116     0.000114     1.75e-06        0.228        0.308        0.146        0.321        0.234        0.207        0.393          0.3        0.569       0.0379
     33   120     9.19e-05     9.17e-05     1.63e-07        0.185        0.276        0.138        0.238        0.188        0.246        0.307        0.277        0.162       0.0108
     33   130      0.00012      0.00012     1.07e-07        0.232        0.315        0.162        0.312        0.237        0.206        0.406        0.306        0.134      0.00896
     33   140     0.000108     0.000105     3.29e-06        0.198        0.295        0.121        0.286        0.203         0.16        0.396        0.278        0.784       0.0523
     33   150     0.000202       0.0002     1.98e-06        0.279        0.408        0.166        0.408        0.287        0.229        0.544        0.387        0.613       0.0408
     33   160     8.65e-05     8.62e-05     2.27e-07          0.2        0.268        0.131        0.278        0.204        0.168        0.348        0.258        0.194       0.0129
     33   170     0.000147     0.000147     6.13e-07        0.265        0.349        0.184        0.357         0.27        0.239        0.443        0.341        0.325       0.0217
     33   180     7.28e-05     7.27e-05     1.38e-07        0.184        0.246        0.121        0.256        0.188        0.159        0.317        0.238        0.141      0.00938
     33   190     9.66e-05     9.65e-05     1.01e-07          0.2        0.283        0.126        0.285        0.206        0.168        0.374        0.271        0.138      0.00917

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     33     5     6.57e-05     6.57e-05     1.21e-08        0.167        0.234        0.129        0.211         0.17        0.195        0.271        0.233       0.0406      0.00271


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              33  708.572    0.005     0.000125      9.3e-07     0.000126        0.232        0.323        0.158        0.316        0.237        0.211        0.415        0.313        0.337       0.0225
! Validation         33  708.572    0.005     7.76e-05     1.66e-08     7.77e-05        0.176        0.254        0.124        0.235         0.18        0.177         0.32        0.249       0.0406      0.00271
Wall time: 708.5726452210001
! Best model       33    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     34    10     0.000168     0.000168      8.9e-09        0.263        0.374        0.158        0.383        0.271        0.199        0.505        0.352       0.0344      0.00229
     34    20     0.000104     0.000104     9.01e-08        0.217        0.293        0.148        0.296        0.222        0.182        0.383        0.282        0.122      0.00813
     34    30     0.000236     0.000231      5.6e-06        0.311        0.438        0.202        0.436        0.319        0.266        0.575         0.42         1.02       0.0683
     34    40     0.000158     0.000158     7.61e-08        0.275        0.362          0.2        0.361        0.281        0.252        0.457        0.354        0.106      0.00708
     34    50     0.000114     0.000114     5.96e-08        0.235        0.308        0.174        0.305        0.239         0.23        0.379        0.304       0.0875      0.00583
     34    60     0.000112     0.000111     1.11e-06        0.223        0.304        0.138        0.321         0.23        0.181          0.4        0.291         0.45         0.03
     34    70     0.000153      0.00015     2.79e-06         0.25        0.353        0.146        0.369        0.257        0.185        0.478        0.332        0.719       0.0479
     34    80     0.000164     0.000164     6.94e-07        0.269        0.369        0.183        0.368        0.276        0.229        0.481        0.355        0.359        0.024
     34    90     0.000131      0.00013     8.05e-07        0.236        0.329        0.147        0.338        0.242        0.207        0.428        0.317        0.381       0.0254
     34   100     8.74e-05     8.56e-05     1.81e-06        0.192        0.267        0.134        0.258        0.196        0.166        0.348        0.257        0.575       0.0383
     34   110     0.000107     0.000106     1.24e-06         0.21        0.297        0.145        0.285        0.215        0.189        0.385        0.287        0.478       0.0319
     34   120     6.48e-05     6.46e-05     2.17e-07        0.168        0.232        0.124        0.219        0.171        0.165         0.29        0.227        0.191       0.0127
     34   130     0.000118     0.000118     5.47e-08        0.234        0.313        0.168        0.309        0.239        0.212        0.399        0.305       0.0906      0.00604
     34   140     0.000118     0.000116     1.92e-06        0.222         0.31        0.132        0.324        0.228        0.172        0.415        0.294        0.597       0.0398
     34   150     9.21e-05     8.85e-05     3.55e-06        0.198        0.271        0.151        0.252        0.201        0.205        0.331        0.268        0.812       0.0542
     34   160     0.000108     0.000108     2.03e-07        0.229          0.3        0.173        0.293        0.233        0.223        0.368        0.296        0.178       0.0119
     34   170     0.000124     0.000122     2.31e-06        0.236        0.318        0.174        0.306         0.24        0.231        0.395        0.313        0.653       0.0435
     34   180      0.00013      0.00013     1.62e-07         0.23        0.329        0.131        0.342        0.237         0.17        0.446        0.308        0.178       0.0119
     34   190     0.000159     0.000159     3.88e-08        0.279        0.364        0.209         0.36        0.285        0.269        0.449        0.359        0.075        0.005

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     34     5     6.32e-05     6.32e-05     1.12e-08        0.162        0.229        0.122        0.207        0.165        0.186        0.271        0.228       0.0375       0.0025


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              34  729.861    0.005     0.000126     1.04e-06     0.000127        0.232        0.324         0.16        0.314        0.237        0.215        0.415        0.315        0.356       0.0238
! Validation         34  729.861    0.005     7.44e-05     1.64e-08     7.44e-05        0.172        0.249        0.121        0.231        0.176        0.173        0.313        0.243         0.04      0.00267
Wall time: 729.8615045259994
! Best model       34    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     35    10      0.00016      0.00016     1.14e-07        0.268        0.365         0.17         0.38        0.275        0.221        0.479         0.35        0.147      0.00979
     35    20     0.000122     0.000122     3.52e-08        0.237        0.319        0.182        0.299        0.241        0.248        0.384        0.316        0.075        0.005
     35    30     0.000194     0.000193     1.06e-06        0.294        0.401        0.194        0.409        0.301        0.238        0.528        0.383        0.444       0.0296
     35    40     6.97e-05     6.97e-05     5.34e-08        0.172        0.241        0.107        0.247        0.177        0.141        0.318         0.23       0.0938      0.00625
     35    50     8.75e-05     8.74e-05     6.27e-08        0.186         0.27        0.105        0.279        0.192        0.138        0.366        0.252       0.0938      0.00625
     35    60     7.83e-05     7.79e-05     3.87e-07        0.191        0.255        0.132        0.259        0.195         0.17        0.326        0.248        0.269       0.0179
     35    70     8.67e-05     8.63e-05     4.07e-07        0.206        0.268        0.147        0.273         0.21        0.186        0.338        0.262        0.269       0.0179
     35    80     7.98e-05     7.98e-05     2.27e-08         0.19        0.258        0.133        0.256        0.194        0.187         0.32        0.253       0.0562      0.00375
     35    90     0.000144     0.000144     3.71e-08        0.241        0.347        0.162        0.332        0.247        0.237         0.44        0.338        0.075        0.005
     35   100     0.000116     0.000113     2.78e-06        0.226        0.306        0.146        0.316        0.231        0.192        0.399        0.295        0.722       0.0481
     35   110     0.000124     0.000123     6.73e-07        0.213         0.32        0.134        0.304        0.219        0.177        0.429        0.303        0.347       0.0231
     35   120     0.000101      9.9e-05     1.97e-06        0.198        0.287         0.14        0.264        0.202        0.185        0.371        0.278        0.609       0.0406
     35   130       0.0001     9.98e-05     2.37e-07        0.214        0.288        0.152        0.285        0.219        0.201        0.363        0.282        0.197       0.0131
     35   140     0.000122     0.000121     1.28e-06         0.22        0.317        0.154        0.295        0.225        0.199        0.413        0.306        0.488       0.0325
     35   150     9.71e-05     9.71e-05     1.08e-08        0.203        0.284        0.138        0.277        0.207        0.183        0.367        0.275       0.0281      0.00188
     35   160     6.98e-05     6.58e-05        4e-06        0.179        0.234        0.128        0.237        0.183        0.162        0.296        0.229        0.863       0.0575
     35   170     0.000111     0.000107     4.76e-06        0.223        0.298        0.155          0.3        0.227        0.199        0.381         0.29        0.947       0.0631
     35   180     0.000116     0.000115     1.04e-06        0.237        0.309        0.203        0.276         0.24        0.256         0.36        0.308        0.441       0.0294
     35   190     0.000114     0.000113     1.42e-06        0.219        0.306        0.155        0.293        0.224          0.2        0.394        0.297        0.512       0.0342

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     35     5     6.17e-05     6.17e-05     1.68e-08        0.161        0.227        0.124        0.203        0.163        0.186        0.265        0.226       0.0469      0.00313


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              35  751.156    0.005     0.000113     8.92e-07     0.000114         0.22        0.306        0.151        0.298        0.225        0.204        0.392        0.298        0.328       0.0219
! Validation         35  751.156    0.005     7.31e-05     1.75e-08     7.31e-05         0.17        0.247         0.12        0.227        0.174        0.172        0.311        0.241       0.0437      0.00292
Wall time: 751.1568644549989
! Best model       35    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     36    10     0.000147     0.000146     1.48e-06        0.256        0.348          0.2         0.32         0.26        0.277        0.415        0.346        0.522       0.0348
     36    20     7.58e-05     7.55e-05     3.38e-07        0.194        0.251        0.162        0.232        0.197        0.208        0.291         0.25         0.25       0.0167
     36    30     0.000113     0.000113      2.3e-07        0.204        0.306        0.135        0.283        0.209        0.196        0.396        0.296        0.203       0.0135
     36    40     9.04e-05        9e-05      4.3e-07         0.21        0.274        0.145        0.284        0.214        0.188        0.347        0.267        0.281       0.0188
     36    50     0.000249     0.000247     2.23e-06        0.316        0.453        0.192        0.457        0.324        0.281        0.591        0.436        0.641       0.0427
     36    60      8.5e-05     8.49e-05     5.91e-08        0.203        0.266        0.128         0.29        0.209        0.156        0.352        0.254        0.103      0.00687
     36    70     6.91e-05     6.83e-05     8.69e-07        0.176        0.238        0.108        0.254        0.181        0.147        0.311        0.229          0.4       0.0267
     36    80     0.000104     0.000104     2.44e-07        0.229        0.294        0.176         0.29        0.233         0.21        0.367        0.289        0.209        0.014
     36    90     6.97e-05     6.96e-05     4.28e-08        0.174        0.241        0.128        0.227        0.177        0.178        0.297        0.237       0.0781      0.00521
     36   100      0.00012      0.00012      6.8e-08        0.238        0.315        0.171        0.316        0.243        0.233        0.388        0.311        0.106      0.00708
     36   110     9.22e-05     8.94e-05     2.79e-06        0.206        0.273        0.145        0.276         0.21         0.19        0.344        0.267        0.719       0.0479
     36   120     9.05e-05        9e-05     4.22e-07        0.208        0.274        0.188        0.231         0.21        0.255        0.293        0.274        0.262       0.0175
     36   130      9.8e-05     9.78e-05     2.33e-07        0.209        0.285        0.166        0.258        0.212        0.222        0.343        0.283        0.206       0.0137
     36   140     9.45e-05     9.28e-05     1.64e-06        0.203        0.278        0.154        0.258        0.206        0.196        0.348        0.272         0.55       0.0367
     36   150     8.36e-05     8.19e-05     1.74e-06        0.193        0.261         0.13        0.265        0.198        0.183        0.328        0.256        0.566       0.0377
     36   160     9.64e-05     9.64e-05     2.35e-08        0.217        0.283        0.183        0.256         0.22        0.231        0.333        0.282       0.0688      0.00458
     36   170     0.000162     0.000158     3.61e-06        0.244        0.363        0.139        0.364        0.252        0.179        0.495        0.337        0.822       0.0548
     36   180     0.000203     0.000201      1.5e-06        0.315        0.409        0.226        0.416        0.321        0.285        0.515          0.4        0.528       0.0352
     36   190     0.000107     0.000106     3.91e-07        0.215        0.297        0.151        0.289         0.22        0.199         0.38        0.289        0.269       0.0179

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     36     5     5.95e-05     5.95e-05      1.3e-08        0.159        0.222        0.122        0.202        0.162        0.182        0.261        0.222       0.0422      0.00281


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              36  772.466    0.005     0.000114     1.05e-06     0.000115        0.224        0.308        0.158        0.298        0.228        0.211        0.391        0.301        0.365       0.0243
! Validation         36  772.466    0.005     7.14e-05     1.54e-08     7.14e-05        0.169        0.244        0.119        0.226        0.172        0.169        0.307        0.238       0.0403      0.00269
Wall time: 772.4667697989989
! Best model       36    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     37    10     0.000124     0.000124     1.74e-07        0.242        0.321        0.161        0.336        0.248        0.194        0.422        0.308        0.172       0.0115
     37    20     9.26e-05     9.24e-05     1.22e-07        0.206        0.277        0.157        0.262        0.209         0.21        0.338        0.274        0.116      0.00771
     37    30     0.000192     0.000192     3.12e-07        0.285        0.399        0.186        0.398        0.292        0.232        0.529        0.381        0.225        0.015
     37    40     8.67e-05     8.67e-05     2.67e-08        0.173        0.269        0.104        0.251        0.178         0.14        0.363        0.252       0.0562      0.00375
     37    50     0.000103     0.000103     6.32e-08        0.222        0.292        0.169        0.282        0.226        0.221        0.357        0.289       0.0938      0.00625
     37    60     0.000113     0.000112     9.76e-07        0.208        0.305        0.124        0.305        0.214        0.159        0.413        0.286        0.422       0.0281
     37    70     0.000231      0.00023     1.02e-06        0.306        0.437        0.188        0.439        0.314        0.271        0.571        0.421        0.416       0.0277
     37    80     0.000135     0.000133     2.45e-06        0.247        0.332        0.169        0.336        0.253        0.226        0.422        0.324        0.675        0.045
     37    90     0.000116     0.000116     2.43e-07        0.241         0.31        0.181         0.31        0.245        0.221        0.387        0.304          0.2       0.0133
     37   100     8.61e-05     8.58e-05     2.49e-07        0.206        0.267        0.157        0.261        0.209        0.202        0.326        0.264        0.203       0.0135
     37   110     6.53e-05     6.52e-05     8.37e-08         0.18        0.233         0.12        0.249        0.184        0.151          0.3        0.226        0.119      0.00792
     37   120     0.000147     0.000144      2.7e-06        0.234        0.346        0.142         0.34        0.241        0.203        0.457         0.33        0.703       0.0469
     37   130     0.000133      0.00013     2.53e-06        0.229        0.329        0.156        0.311        0.234        0.225        0.418        0.321        0.688       0.0458
     37   140     0.000159     0.000159     6.85e-08        0.266        0.364        0.177        0.369        0.273         0.23        0.472        0.351       0.0781      0.00521
     37   150     5.56e-05     5.55e-05     1.04e-07        0.158        0.215         0.11        0.213        0.162        0.148        0.272         0.21        0.131      0.00875
     37   160     0.000133     0.000133     1.52e-07        0.258        0.332         0.18        0.347        0.264        0.216        0.428        0.322        0.156       0.0104
     37   170     0.000123     0.000123     4.79e-07         0.23         0.32        0.148        0.324        0.236        0.202        0.415        0.308        0.294       0.0196
     37   180     0.000109     0.000108     1.17e-06         0.21        0.299        0.168        0.259        0.213        0.244        0.352        0.298        0.463       0.0308
     37   190     0.000186     0.000186      3.6e-07        0.272        0.393        0.145        0.417        0.281        0.186         0.54        0.363         0.25       0.0167

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     37     5     5.88e-05     5.88e-05     1.32e-08        0.158        0.221        0.123        0.197         0.16        0.187        0.255        0.221       0.0422      0.00281


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              37  793.304    0.005      0.00012     6.66e-07      0.00012        0.226        0.316        0.155        0.307        0.231        0.207        0.406        0.306        0.291       0.0194
! Validation         37  793.304    0.005     6.97e-05     1.46e-08     6.97e-05        0.166        0.241        0.118        0.222         0.17        0.168        0.303        0.236       0.0409      0.00273
Wall time: 793.304790057
! Best model       37    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     38    10     0.000148     0.000148     4.47e-07        0.251         0.35        0.171        0.342        0.257        0.222        0.455        0.338        0.287       0.0192
     38    20     0.000172     0.000168     3.32e-06        0.285        0.374        0.201         0.38        0.291        0.249        0.479        0.364        0.781       0.0521
     38    30     0.000194     0.000189     4.52e-06        0.282        0.397        0.179        0.399        0.289         0.24        0.521         0.38        0.913       0.0608
     38    40     0.000135     0.000135     1.54e-07        0.247        0.335        0.161        0.347        0.254        0.207        0.437        0.322        0.159       0.0106
     38    50     0.000246     0.000244     1.16e-06        0.349        0.451        0.309        0.395        0.352          0.4        0.503        0.451        0.444       0.0296
     38    60     0.000132     0.000132      2.5e-07        0.234        0.331        0.166        0.312        0.239        0.204        0.432        0.318        0.206       0.0137
     38    70     0.000238     0.000238      3.8e-07        0.347        0.445        0.274         0.43        0.352        0.323        0.552        0.438        0.262       0.0175
     38    80     0.000162      0.00016     1.97e-06        0.291        0.365        0.282        0.301        0.292        0.343        0.388        0.366        0.603       0.0402
     38    90     8.08e-05     7.99e-05     9.21e-07        0.175        0.258        0.116        0.241        0.179        0.164        0.334        0.249        0.412       0.0275
     38   100     0.000159     0.000158     6.17e-07        0.282        0.363        0.243        0.325        0.284        0.304        0.421        0.362        0.325       0.0217
     38   110     0.000144     0.000143     1.21e-06        0.233        0.345         0.15        0.328        0.239        0.185        0.464        0.324        0.472       0.0315
     38   120      0.00018      0.00018     2.65e-08        0.297        0.387        0.195        0.412        0.304        0.242        0.503        0.373       0.0688      0.00458
     38   130     0.000307     0.000306     6.94e-07        0.337        0.505        0.194        0.502        0.348        0.292        0.669        0.481        0.356       0.0238
     38   140     0.000333     0.000332     8.53e-07         0.38        0.526        0.231        0.549         0.39        0.289        0.705        0.497        0.387       0.0258
     38   150     0.000102     0.000102     4.25e-07        0.221        0.291         0.14        0.313        0.226        0.181        0.379         0.28        0.281       0.0188
     38   160     9.08e-05     9.08e-05     2.35e-08          0.2        0.275        0.131        0.278        0.205        0.174        0.357        0.265       0.0531      0.00354
     38   170     7.42e-05     7.42e-05     2.76e-08        0.179        0.248        0.109        0.259        0.184        0.144        0.329        0.237       0.0562      0.00375
     38   180     0.000129     0.000126     3.04e-06        0.229        0.324         0.14        0.331        0.236        0.181        0.433        0.307        0.753       0.0502
     38   190     0.000103     0.000103     6.68e-08        0.212        0.292        0.155        0.277        0.216        0.229        0.351         0.29       0.0969      0.00646

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     38     5     5.84e-05     5.84e-05     9.32e-09        0.156         0.22        0.121        0.196        0.158        0.183        0.257         0.22       0.0344      0.00229


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              38  814.382    0.005     0.000146     8.15e-07     0.000147        0.249        0.348        0.171        0.339        0.255         0.23        0.447        0.338        0.304       0.0203
! Validation         38  814.382    0.005     7.09e-05     1.26e-08     7.09e-05        0.167        0.243        0.117        0.224        0.171        0.167        0.307        0.237       0.0359       0.0024
Wall time: 814.3831102559998

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     39    10     8.74e-05     8.73e-05     1.61e-07        0.192        0.269        0.115         0.28        0.198        0.153        0.359        0.256        0.156       0.0104
     39    20      0.00016      0.00016     9.47e-08         0.28        0.365        0.199        0.374        0.286         0.25        0.463        0.356        0.131      0.00875
     39    30     9.65e-05     9.64e-05     2.84e-08        0.216        0.283        0.155        0.285         0.22        0.196        0.358        0.277       0.0562      0.00375
     39    40     0.000221     0.000219     1.34e-06        0.299        0.427        0.153        0.465        0.309        0.191        0.591        0.391        0.497       0.0331
     39    50      6.5e-05      6.5e-05     9.03e-08        0.173        0.232        0.126        0.227        0.177         0.17        0.288        0.229        0.128      0.00854
     39    60     8.11e-05     8.07e-05     3.89e-07        0.187        0.259        0.126        0.257        0.192        0.176         0.33        0.253        0.262       0.0175
     39    70     0.000115     0.000114     1.36e-06         0.22        0.308        0.152        0.296        0.224        0.202        0.395        0.299        0.503       0.0335
     39    80     9.74e-05     9.74e-05     1.08e-08        0.194        0.285        0.123        0.276        0.199         0.16         0.38         0.27       0.0406      0.00271
     39    90      0.00012      0.00012     1.07e-07         0.22        0.316        0.146        0.303        0.225        0.195        0.412        0.304        0.138      0.00917
     39   100     0.000223     0.000223     1.99e-07        0.293         0.43         0.19        0.411        0.301        0.291        0.548        0.419        0.175       0.0117
     39   110     7.46e-05     7.32e-05     1.42e-06        0.179        0.247        0.128        0.238        0.183        0.174        0.309        0.242        0.512       0.0342
     39   120     0.000137     0.000137     2.06e-08        0.266        0.337        0.207        0.333         0.27        0.252        0.414        0.333         0.05      0.00333
     39   130     0.000117     0.000117     2.73e-08        0.219        0.312        0.159        0.288        0.224         0.24        0.377        0.309       0.0625      0.00417
     39   140     0.000215     0.000215     4.44e-07        0.294        0.422        0.205        0.395          0.3        0.272        0.546        0.409        0.287       0.0192
     39   150     7.62e-05     7.53e-05     8.45e-07        0.188         0.25        0.142        0.242        0.192        0.176        0.315        0.245        0.397       0.0265
     39   160     0.000153     0.000152      6.4e-07        0.261        0.356        0.187        0.344        0.266        0.238        0.455        0.346        0.344       0.0229
     39   170      7.9e-05     7.68e-05     2.11e-06        0.185        0.253         0.13        0.248        0.189        0.172        0.321        0.247        0.625       0.0417
     39   180     7.91e-05     7.87e-05     4.02e-07        0.196        0.256         0.14        0.259          0.2        0.181         0.32        0.251        0.272       0.0181
     39   190     9.03e-05     9.03e-05     1.38e-08        0.211        0.274        0.173        0.255        0.214        0.229        0.318        0.273       0.0531      0.00354

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     39     5      5.5e-05      5.5e-05     1.27e-08        0.152        0.214        0.118        0.191        0.154        0.176        0.251        0.213       0.0422      0.00281


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              39  835.783    0.005     0.000121     7.52e-07     0.000121        0.229        0.317        0.159        0.309        0.234        0.213        0.404        0.308        0.292       0.0194
! Validation         39  835.783    0.005     6.82e-05      1.6e-08     6.82e-05        0.164        0.238        0.115        0.219        0.167        0.163        0.302        0.232       0.0431      0.00288
Wall time: 835.7837193759988
! Best model       39    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     40    10     7.32e-05     7.32e-05     1.36e-08        0.177        0.247        0.116        0.248        0.182         0.15        0.323        0.237       0.0437      0.00292
     40    20     4.67e-05     4.63e-05     4.14e-07        0.133        0.196       0.0829         0.19        0.136        0.113        0.261        0.187        0.272       0.0181
     40    30     7.75e-05      7.7e-05     4.69e-07        0.188        0.253        0.131        0.253        0.192        0.182        0.315        0.249        0.284        0.019
     40    40     9.05e-05     8.93e-05     1.13e-06        0.205        0.273        0.163        0.254        0.208        0.205        0.333        0.269        0.453       0.0302
     40    50     0.000136     0.000136     4.18e-07        0.247        0.336        0.135        0.373        0.254        0.175        0.455        0.315        0.272       0.0181
     40    60     0.000132     0.000131     1.43e-06        0.248         0.33        0.166        0.342        0.254        0.215        0.425         0.32        0.512       0.0342
     40    70     0.000106     0.000106     6.57e-07        0.219        0.297        0.149        0.299        0.224        0.189        0.384        0.287        0.334       0.0223
     40    80     0.000114     0.000113     7.74e-07         0.23        0.307         0.14        0.333        0.236        0.173        0.409        0.291        0.372       0.0248
     40    90     0.000103     0.000103     1.42e-07        0.211        0.293        0.129        0.304        0.217         0.18        0.383        0.281        0.159       0.0106
     40   100      8.3e-05     8.25e-05     4.92e-07        0.181        0.262        0.117        0.256        0.186        0.159        0.344        0.251        0.294       0.0196
     40   110     8.44e-05     8.37e-05      7.4e-07        0.183        0.264       0.0981        0.281         0.19        0.135        0.358        0.247        0.372       0.0248
     40   120     7.54e-05     7.47e-05     6.94e-07        0.189        0.249        0.115        0.273        0.194        0.144        0.331        0.237        0.356       0.0237
     40   130     5.98e-05     5.92e-05     6.44e-07        0.161        0.222        0.116        0.213        0.164        0.164        0.273        0.219        0.338       0.0225
     40   140     0.000108     0.000108     2.52e-07        0.229          0.3        0.136        0.336        0.236         0.17          0.4        0.285        0.197       0.0131
     40   150     8.06e-05     7.88e-05     1.72e-06        0.191        0.256         0.14         0.25        0.195        0.186        0.318        0.252        0.562       0.0375
     40   160     8.08e-05     8.07e-05     5.91e-08        0.186        0.259        0.114        0.268        0.191        0.147        0.345        0.246       0.0906      0.00604
     40   170     0.000103     0.000102     8.16e-07        0.205        0.291        0.136        0.284         0.21        0.191        0.375        0.283        0.387       0.0258
     40   180     0.000144     0.000143     1.37e-06        0.239        0.344        0.176        0.311        0.244        0.256        0.423         0.34        0.506       0.0338
     40   190      0.00014      0.00014     4.28e-08        0.235        0.342        0.124        0.362        0.243        0.157        0.471        0.314        0.075        0.005

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     40     5      5.5e-05      5.5e-05     1.03e-08        0.152        0.214        0.119        0.191        0.155        0.179        0.248        0.213       0.0375       0.0025


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              40  857.083    0.005     9.22e-05     6.57e-07     9.29e-05        0.199        0.277        0.138         0.27        0.204        0.185        0.354        0.269        0.293       0.0195
! Validation         40  857.083    0.005     6.61e-05     1.47e-08     6.61e-05        0.162        0.234        0.113        0.217        0.165        0.161        0.297        0.229       0.0403      0.00269
Wall time: 857.084040271
! Best model       40    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     41    10     8.08e-05     8.07e-05     1.07e-07        0.198        0.259        0.143        0.261        0.202        0.173        0.331        0.252        0.128      0.00854
     41    20     5.35e-05     5.34e-05     6.91e-08        0.147        0.211       0.0895        0.212        0.151        0.114        0.283        0.199          0.1      0.00667
     41    30     0.000145     0.000144     6.41e-07        0.251        0.346        0.144        0.372        0.258        0.185        0.466        0.326        0.341       0.0227
     41    40     9.16e-05     9.15e-05     1.75e-07        0.199        0.276        0.139        0.267        0.203          0.2        0.342        0.271        0.169       0.0112
     41    50     8.76e-05      8.7e-05      6.1e-07        0.196        0.269        0.156        0.241        0.198         0.22        0.316        0.268        0.334       0.0223
     41    60     0.000165     0.000165     1.13e-07         0.26         0.37        0.182        0.349        0.265        0.247        0.473         0.36        0.122      0.00812
     41    70     0.000159     0.000159     5.15e-07        0.235        0.363        0.146        0.336        0.241         0.28         0.44         0.36          0.3         0.02
     41    80     0.000156     0.000155     2.23e-07        0.277        0.359         0.21        0.354        0.282        0.252        0.452        0.352        0.188       0.0125
     41    90     9.08e-05     9.07e-05     4.85e-08        0.206        0.275        0.171        0.247        0.209        0.231        0.317        0.274       0.0875      0.00583
     41   100     0.000114     0.000114     1.33e-07        0.251        0.308        0.227        0.278        0.253        0.272        0.345        0.309        0.138      0.00917
     41   110     6.22e-05     6.15e-05     7.01e-07         0.16        0.226        0.108        0.219        0.163        0.141        0.295        0.218        0.359        0.024
     41   120     6.98e-05     6.96e-05     1.51e-07        0.175        0.241        0.121        0.236        0.178        0.163        0.306        0.235        0.156       0.0104
     41   130     9.91e-05      9.9e-05     1.35e-07        0.193        0.287        0.111        0.286        0.198        0.144        0.391        0.267        0.156       0.0104
     41   140     0.000169     0.000168     1.14e-06        0.258        0.374        0.153        0.377        0.265          0.2        0.504        0.352         0.45         0.03
     41   150     0.000109     0.000109     2.62e-07         0.23        0.301        0.208        0.255        0.231        0.249        0.351          0.3        0.219       0.0146
     41   160     0.000113     0.000113     3.89e-07        0.247        0.306        0.236        0.259        0.248        0.285        0.329        0.307        0.253       0.0169
     41   170     8.32e-05     8.27e-05     4.74e-07        0.181        0.262        0.103         0.27        0.187        0.146        0.351        0.248        0.294       0.0196
     41   180     7.51e-05      7.5e-05     7.23e-08        0.181         0.25        0.137        0.232        0.184        0.182        0.309        0.246        0.112       0.0075
     41   190     0.000137     0.000137     2.26e-07         0.25        0.337         0.19        0.318        0.254        0.241        0.421        0.331        0.194       0.0129

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     41     5     5.35e-05     5.35e-05     1.34e-08        0.149        0.211        0.116        0.187        0.152        0.174        0.246         0.21       0.0453      0.00302


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              41  878.203    0.005     0.000106     6.09e-07     0.000106        0.214        0.296        0.148        0.289        0.218        0.198        0.379        0.288        0.254       0.0169
! Validation         41  878.203    0.005     6.47e-05     1.54e-08     6.47e-05        0.159        0.232        0.111        0.215        0.163        0.159        0.294        0.226       0.0391       0.0026
Wall time: 878.2034435789992
! Best model       41    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     42    10     8.43e-05     8.42e-05     3.18e-08        0.199        0.265        0.126        0.282        0.204        0.168        0.343        0.256       0.0688      0.00458
     42    20     6.28e-05     6.27e-05     1.16e-07        0.172        0.228         0.13        0.221        0.175        0.168        0.282        0.225        0.138      0.00917
     42    30     0.000102     9.82e-05     4.18e-06         0.22        0.286        0.148        0.302        0.225        0.192        0.365        0.278        0.884        0.059
     42    40     9.24e-05     9.13e-05     1.13e-06        0.212        0.276        0.164        0.268        0.216        0.214        0.332        0.273        0.459       0.0306
     42    50     0.000108     0.000108     5.32e-07        0.231        0.299         0.19        0.277        0.233        0.235        0.359        0.297        0.306       0.0204
     42    60     0.000161     0.000159     1.57e-06        0.257        0.364        0.161        0.367        0.264        0.199        0.489        0.344        0.541        0.036
     42    70     7.46e-05     7.46e-05     1.99e-08        0.182        0.249        0.122        0.249        0.186         0.16        0.322        0.241       0.0531      0.00354
     42    80     0.000103     0.000103     2.06e-08        0.209        0.292        0.124        0.306        0.215        0.165        0.389        0.277         0.05      0.00333
     42    90     0.000104     0.000104     8.69e-08        0.213        0.294        0.127        0.312        0.219        0.157        0.397        0.277        0.122      0.00812
     42   100     0.000106     0.000106      3.4e-07        0.211        0.297        0.158        0.272        0.215        0.207        0.374         0.29         0.25       0.0167
     42   110     8.85e-05     8.83e-05     2.15e-07        0.208        0.271        0.164        0.257        0.211        0.213        0.325        0.269          0.2       0.0133
     42   120     0.000108     0.000108     1.33e-07         0.21          0.3        0.133        0.297        0.215        0.188        0.391        0.289         0.15         0.01
     42   130     9.05e-05     9.05e-05     1.97e-08        0.194        0.274        0.124        0.275        0.199        0.158        0.364        0.261       0.0594      0.00396
     42   140     7.15e-05     7.15e-05     4.03e-09        0.164        0.244        0.126        0.208        0.167         0.18        0.301         0.24        0.025      0.00167
     42   150      6.7e-05     6.69e-05     1.29e-07        0.172        0.236         0.11        0.244        0.177         0.14        0.311        0.226        0.147      0.00979
     42   160     5.09e-05     5.09e-05     1.61e-08        0.154        0.206       0.0949        0.222        0.158         0.13        0.267        0.199       0.0344      0.00229
     42   170     0.000116     0.000115     8.35e-07        0.216        0.309        0.147        0.295        0.221        0.193        0.403        0.298        0.387       0.0258
     42   180     0.000111     0.000111     2.12e-08        0.222        0.303        0.141        0.314        0.228        0.179        0.401         0.29       0.0531      0.00354
     42   190     8.96e-05     8.95e-05     6.85e-08        0.198        0.273        0.131        0.274        0.202        0.182        0.349        0.265        0.106      0.00708

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     42     5     5.31e-05     5.31e-05     9.54e-09        0.148         0.21        0.116        0.185        0.151        0.176        0.243         0.21       0.0359       0.0024


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              42  899.737    0.005     9.57e-05     5.44e-07     9.62e-05        0.201        0.282        0.135        0.276        0.206        0.182        0.364        0.273        0.246       0.0164
! Validation         42  899.737    0.005     6.37e-05     1.35e-08     6.37e-05        0.158         0.23         0.11        0.212        0.161        0.158        0.292        0.225       0.0369      0.00246
Wall time: 899.7384285480002
! Best model       42    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     43    10     8.58e-05     8.38e-05     1.95e-06        0.183        0.264        0.128        0.245        0.187        0.172         0.34        0.256        0.603       0.0402
     43    20     0.000174     0.000173     7.31e-07         0.29        0.379        0.216        0.375        0.296        0.277        0.469        0.373        0.363       0.0242
     43    30     0.000189     0.000189     6.85e-07          0.3        0.396         0.23        0.381        0.305         0.31        0.476        0.393        0.353       0.0235
     43    40     0.000179     0.000179     5.63e-07        0.275        0.385        0.165        0.402        0.283        0.234        0.505         0.37        0.316        0.021
     43    50     0.000191      0.00019     5.79e-07        0.283        0.398        0.166        0.418        0.292        0.225         0.53        0.378        0.303       0.0202
     43    60     0.000112     0.000111     1.64e-06        0.222        0.303        0.193        0.254        0.224        0.263        0.344        0.303         0.55       0.0367
     43    70     7.06e-05     6.73e-05     3.31e-06        0.171        0.237        0.117        0.234        0.175        0.148        0.308        0.228        0.788       0.0525
     43    80     7.51e-05     7.47e-05     4.02e-07         0.18        0.249        0.122        0.247        0.184        0.166        0.319        0.242        0.262       0.0175
     43    90     0.000141     0.000139     1.38e-06        0.219         0.34        0.126        0.324        0.225        0.227        0.435        0.331          0.5       0.0333
     43   100     0.000141     0.000141     1.02e-07        0.237        0.342        0.135        0.355        0.245        0.187        0.459        0.323        0.122      0.00812
     43   110     8.64e-05     8.63e-05     3.26e-08        0.198        0.268        0.143        0.261        0.202        0.184        0.339        0.262       0.0688      0.00458
     43   120     8.41e-05     8.34e-05     7.15e-07        0.193        0.263        0.131        0.263        0.197        0.166        0.342        0.254        0.359        0.024
     43   130     7.78e-05     7.76e-05     2.14e-07        0.181        0.254        0.124        0.246        0.185        0.167        0.326        0.247        0.184       0.0123
     43   140     7.51e-05     7.39e-05     1.22e-06        0.173        0.248         0.12        0.233        0.177        0.153        0.324        0.239        0.472       0.0315
     43   150     7.28e-05     7.13e-05      1.5e-06        0.189        0.243        0.151        0.233        0.192        0.201        0.284        0.243        0.525        0.035
     43   160     0.000169     0.000169     1.07e-07        0.264        0.375        0.177        0.363         0.27        0.253        0.477        0.365        0.103      0.00687
     43   170     6.28e-05     6.23e-05     5.09e-07        0.174        0.228        0.136        0.218        0.177        0.186        0.267        0.227        0.303       0.0202
     43   180     7.03e-05     6.96e-05     7.19e-07        0.181        0.241        0.137        0.232        0.184        0.184        0.292        0.238        0.363       0.0242
     43   190     7.28e-05     7.27e-05     9.49e-08        0.172        0.246        0.107        0.248        0.177        0.138        0.329        0.233        0.125      0.00833

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     43     5      4.9e-05      4.9e-05     9.43e-09        0.144        0.202        0.114        0.179        0.146         0.17        0.233        0.202       0.0359       0.0024


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              43  922.042    0.005     0.000106     9.37e-07     0.000107        0.212        0.297        0.144        0.289        0.216        0.195        0.382        0.289        0.347       0.0231
! Validation         43  922.042    0.005     6.16e-05     1.57e-08     6.16e-05        0.156        0.226        0.111        0.209         0.16        0.156        0.286        0.221       0.0378      0.00252
Wall time: 922.0427134139991
! Best model       43    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     44    10     0.000106     0.000105     1.58e-06        0.182        0.295        0.101        0.274        0.187        0.134        0.408        0.271        0.547       0.0365
     44    20     0.000214     0.000211     2.49e-06        0.297        0.419         0.18        0.431        0.306        0.245        0.555          0.4        0.684       0.0456
     44    30     5.68e-05     5.59e-05     8.47e-07        0.153        0.216        0.102        0.211        0.157        0.133        0.282        0.207        0.394       0.0262
     44    40      0.00018     0.000179     1.13e-06        0.288        0.386        0.188        0.403        0.295        0.231        0.508        0.369        0.453       0.0302
     44    50     0.000115     0.000115     1.45e-07        0.217         0.31        0.116        0.333        0.225        0.148        0.425        0.286        0.162       0.0108
     44    60     6.46e-05     6.43e-05     3.48e-07        0.169        0.231        0.102        0.245        0.173        0.138        0.305        0.221         0.25       0.0167
     44    70     0.000157     0.000157     5.66e-08        0.286        0.361        0.212        0.371        0.291        0.257        0.452        0.354       0.0719      0.00479
     44    80     7.62e-05     7.51e-05      1.1e-06        0.172         0.25        0.108        0.245        0.176        0.155        0.326        0.241        0.444       0.0296
     44    90     0.000264     0.000264     1.72e-07        0.336        0.469        0.218         0.47        0.344        0.305        0.603        0.454        0.169       0.0112
     44   100     0.000105     0.000105     1.42e-08        0.215        0.295        0.138        0.303        0.221        0.183        0.385        0.284       0.0344      0.00229
     44   110     8.06e-05     8.04e-05     2.28e-07        0.181        0.259        0.103        0.269        0.186        0.132        0.351        0.242          0.2       0.0133
     44   120     8.52e-05      8.3e-05     2.21e-06        0.193        0.263        0.131        0.265        0.198        0.167         0.34        0.254        0.637       0.0425
     44   130     9.56e-05     9.52e-05        4e-07        0.194        0.281        0.115        0.284          0.2        0.145        0.382        0.263        0.266       0.0177
     44   140     0.000128     0.000128     1.54e-07        0.222        0.326        0.127        0.329        0.228         0.17        0.441        0.306        0.134      0.00896
     44   150     9.41e-05     9.25e-05     1.55e-06        0.188        0.277        0.111        0.275        0.193         0.15        0.373        0.261        0.534       0.0356
     44   160     8.53e-05     8.43e-05     9.89e-07        0.203        0.265         0.15        0.263        0.207         0.19         0.33         0.26        0.428       0.0285
     44   170     0.000131     0.000131     1.36e-08        0.248         0.33        0.175        0.331        0.253         0.22        0.422        0.321       0.0406      0.00271
     44   180      0.00012      0.00012     1.68e-07        0.237        0.316        0.198        0.282         0.24        0.274        0.358        0.316        0.156       0.0104
     44   190     8.32e-05     8.32e-05     7.63e-09        0.188        0.263        0.143         0.24        0.191        0.186         0.33        0.258       0.0375       0.0025

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     44     5     5.17e-05     5.17e-05     9.43e-09        0.146        0.207        0.113        0.184        0.149        0.172        0.242        0.207       0.0359       0.0024


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              44  943.193    0.005     0.000108     6.85e-07     0.000108        0.214        0.299        0.145        0.294        0.219        0.193        0.386         0.29        0.294       0.0196
! Validation         44  943.193    0.005     6.13e-05     1.34e-08     6.13e-05        0.155        0.226        0.109        0.207        0.158        0.156        0.285        0.221       0.0369      0.00246
Wall time: 943.1938440319991
! Best model       44    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     45    10     7.26e-05     7.26e-05     6.99e-09         0.19        0.246        0.151        0.235        0.193         0.19        0.297        0.243       0.0312      0.00208
     45    20     0.000101     0.000101     1.07e-07        0.215        0.289        0.142        0.298         0.22        0.181        0.377        0.279        0.122      0.00812
     45    30     6.99e-05     6.98e-05     7.14e-08        0.174        0.241        0.125         0.23        0.178        0.166        0.305        0.235        0.103      0.00688
     45    40     5.51e-05     5.41e-05     9.47e-07        0.158        0.212        0.112         0.21        0.161        0.138        0.273        0.206        0.419       0.0279
     45    50     0.000124     0.000123     2.73e-07        0.215         0.32        0.121        0.322        0.222        0.157        0.438        0.298        0.219       0.0146
     45    60     7.18e-05     7.13e-05     4.71e-07        0.181        0.244        0.139        0.228        0.184        0.174        0.304        0.239        0.287       0.0192
     45    70     4.78e-05     4.77e-05     1.01e-07         0.15        0.199        0.104        0.202        0.153        0.136        0.253        0.194        0.131      0.00875
     45    80     8.49e-05     8.45e-05      3.6e-07        0.191        0.265        0.144        0.244        0.194        0.193        0.329        0.261        0.256       0.0171
     45    90     7.52e-05     7.51e-05     1.28e-07         0.19         0.25        0.137        0.251        0.194        0.178        0.312        0.245        0.144      0.00958
     45   100     5.18e-05     5.15e-05     2.06e-07        0.156        0.207        0.109        0.209        0.159        0.139        0.264        0.202        0.197       0.0131
     45   110     0.000159     0.000159     9.43e-08        0.283        0.364        0.219        0.355        0.287        0.286        0.436        0.361        0.112       0.0075
     45   120     0.000108     0.000108     1.11e-07        0.241        0.299        0.208        0.278        0.243        0.252        0.345        0.299        0.141      0.00938
     45   130      6.2e-05     6.15e-05     4.49e-07        0.174        0.226        0.129        0.226        0.177        0.162        0.282        0.222        0.287       0.0192
     45   140     6.63e-05     6.63e-05      2.1e-08        0.173        0.235        0.114         0.24        0.177        0.151        0.303        0.227         0.05      0.00333
     45   150     0.000174     0.000174     5.47e-08        0.274         0.38        0.178        0.383        0.281        0.254        0.486         0.37       0.0906      0.00604
     45   160     0.000115     0.000115      3.2e-07        0.228        0.309        0.151        0.315        0.233        0.197        0.401        0.299        0.237       0.0158
     45   170     0.000174     0.000173     1.04e-06         0.29         0.38         0.23        0.358        0.294        0.272        0.474        0.373        0.425       0.0283
     45   180     7.93e-05     7.92e-05     1.07e-07        0.196        0.257        0.108        0.297        0.202        0.133        0.348         0.24        0.134      0.00896
     45   190     8.25e-05     8.21e-05     4.88e-07        0.183        0.261        0.128        0.247        0.187         0.17        0.337        0.253        0.294       0.0196

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     45     5     5.04e-05     5.04e-05     1.27e-08        0.145        0.205        0.112        0.183        0.147        0.169        0.239        0.204       0.0437      0.00292


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              45  964.633    0.005     8.94e-05     4.02e-07     8.98e-05        0.197        0.273        0.137        0.266        0.201        0.182        0.348        0.265        0.218       0.0145
! Validation         45  964.633    0.005        6e-05     1.44e-08        6e-05        0.153        0.223        0.108        0.205        0.156        0.154        0.283        0.218       0.0381      0.00254
Wall time: 964.6342743249988
! Best model       45    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     46    10     0.000102     0.000101     9.43e-08        0.225        0.291        0.175        0.283        0.229         0.22        0.354        0.287        0.116      0.00771
     46    20     7.56e-05     7.53e-05     2.49e-07        0.183         0.25        0.127        0.248        0.187         0.17        0.318        0.244          0.2       0.0133
     46    30     8.03e-05     8.02e-05      1.5e-07        0.187        0.258        0.146        0.233         0.19        0.202        0.311        0.256        0.166        0.011
     46    40     0.000139     0.000138     7.36e-07         0.24        0.339        0.175        0.316        0.245        0.221        0.436        0.329        0.347       0.0231
     46    50     7.31e-05      7.3e-05      5.4e-08          0.2        0.246        0.179        0.223        0.201        0.216        0.277        0.247       0.0938      0.00625
     46    60     5.42e-05     5.42e-05     2.52e-08        0.159        0.212        0.109        0.216        0.162        0.148        0.268        0.208       0.0562      0.00375
     46    70     9.37e-05     9.35e-05     2.53e-07        0.209        0.279        0.169        0.254        0.211        0.217        0.336        0.276        0.213       0.0142
     46    80     0.000115     0.000114     4.35e-07        0.214        0.308        0.118        0.324        0.221        0.154         0.42        0.287        0.287       0.0192
     46    90     0.000105     0.000105     1.88e-07        0.206        0.296        0.124        0.299        0.212        0.159        0.398        0.279        0.181       0.0121
     46   100     0.000118     0.000118     8.16e-07        0.235        0.313        0.154        0.328        0.241        0.195        0.407        0.301        0.387       0.0258
     46   110     5.18e-05     4.88e-05     3.04e-06        0.163        0.201        0.146        0.183        0.164        0.178        0.226        0.202        0.753       0.0502
     46   120     6.57e-05     6.56e-05     1.02e-07        0.176        0.234        0.126        0.233         0.18        0.158        0.297        0.228        0.131      0.00875
     46   130     7.96e-05     7.89e-05     7.11e-07        0.183        0.256        0.111        0.265        0.188        0.153        0.338        0.245        0.356       0.0237
     46   140     8.03e-05     8.03e-05     6.99e-08         0.18        0.258        0.115        0.254        0.184         0.15        0.342        0.246        0.109      0.00729
     46   150     6.89e-05     6.88e-05     4.83e-08        0.176        0.239        0.139        0.218        0.178        0.194        0.283        0.238       0.0812      0.00542
     46   160     5.76e-05     5.74e-05     2.56e-07        0.163        0.218        0.105        0.229        0.167        0.136        0.285         0.21        0.216       0.0144
     46   170     7.29e-05     7.29e-05     2.46e-08        0.185        0.246        0.141        0.235        0.188        0.182        0.304        0.243       0.0562      0.00375
     46   180     8.33e-05     8.33e-05     1.23e-08        0.191        0.263         0.13         0.26        0.195         0.16        0.345        0.252       0.0281      0.00188
     46   190     5.83e-05     5.83e-05     2.01e-08        0.152         0.22       0.0975        0.214        0.156        0.126        0.293        0.209       0.0469      0.00313

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     46     5     4.99e-05     4.99e-05     1.18e-08        0.144        0.204        0.112        0.179        0.146         0.17        0.236        0.203       0.0391       0.0026


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              46  985.852    0.005     8.28e-05     3.54e-07     8.31e-05        0.189        0.262         0.13        0.255        0.193        0.174        0.336        0.255        0.199       0.0133
! Validation         46  985.852    0.005     5.95e-05     1.26e-08     5.95e-05        0.153        0.222        0.107        0.204        0.156        0.153        0.281        0.217       0.0347      0.00231
Wall time: 985.8527937529998
! Best model       46    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     47    10     0.000101     9.99e-05     9.62e-07        0.218        0.288        0.159        0.286        0.222        0.199        0.365        0.282        0.419       0.0279
     47    20     0.000101     0.000101     7.86e-08         0.22         0.29        0.186        0.259        0.223        0.229        0.347        0.288        0.103      0.00687
     47    30     6.23e-05      6.2e-05     2.89e-07        0.157        0.227       0.0998        0.222        0.161         0.13        0.302        0.216        0.231       0.0154
     47    40     7.75e-05     7.74e-05     4.54e-08        0.197        0.254        0.173        0.224        0.198        0.216        0.291        0.253       0.0688      0.00458
     47    50     5.88e-05     5.86e-05     2.07e-07        0.165        0.221        0.116        0.222        0.169        0.155        0.278        0.216        0.197       0.0131
     47    60     6.92e-05     6.83e-05     8.53e-07        0.168        0.238        0.113         0.23        0.172        0.156        0.307        0.231        0.391        0.026
     47    70     0.000176     0.000173     2.44e-06        0.258         0.38         0.18        0.346        0.263        0.263        0.479        0.371        0.675        0.045
     47    80     7.93e-05     7.92e-05     3.33e-08        0.174        0.257        0.102        0.255        0.179        0.125        0.351        0.238       0.0812      0.00542
     47    90     6.39e-05     6.39e-05     2.86e-08        0.159        0.231       0.0971         0.23        0.164        0.127        0.309        0.218       0.0656      0.00438
     47   100     0.000157     0.000157     1.01e-07        0.263        0.361        0.171        0.368        0.269        0.235        0.465         0.35        0.106      0.00708
     47   110     0.000106     0.000106     7.21e-09        0.217        0.297        0.144        0.301        0.223        0.188        0.386        0.287       0.0375       0.0025
     47   120     0.000132     0.000132     4.19e-07        0.228        0.331         0.14         0.33        0.235        0.173        0.448         0.31        0.272       0.0181
     47   130     9.51e-05     9.49e-05     1.36e-07        0.224        0.281        0.187        0.265        0.226        0.232        0.328         0.28        0.153       0.0102
     47   140     8.11e-05     8.11e-05     7.42e-09        0.203         0.26        0.154         0.26        0.207        0.195        0.318        0.256       0.0344      0.00229
     47   150     5.18e-05     5.18e-05     6.78e-09        0.161        0.208        0.125        0.203        0.164        0.167        0.246        0.207        0.025      0.00167
     47   160     4.82e-05     4.79e-05     3.01e-07        0.146          0.2        0.111        0.186        0.149        0.143        0.249        0.196        0.228       0.0152
     47   170     5.07e-05     5.06e-05     1.61e-08        0.151        0.205        0.121        0.185        0.153        0.179        0.232        0.205       0.0406      0.00271
     47   180     5.16e-05     5.13e-05     2.65e-07        0.159        0.207        0.113        0.211        0.162        0.143        0.261        0.202        0.216       0.0144
     47   190     5.76e-05     5.62e-05      1.4e-06        0.161        0.216        0.117        0.211        0.164        0.156        0.269        0.212        0.506       0.0338

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     47     5     4.64e-05     4.64e-05     7.63e-09         0.14        0.197        0.109        0.174        0.142        0.165        0.227        0.196       0.0297      0.00198


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              47 1007.001    0.005     8.42e-05     3.46e-07     8.46e-05        0.191        0.265        0.134        0.257        0.195         0.18        0.336        0.258          0.2       0.0133
! Validation         47 1007.001    0.005     5.74e-05     9.96e-09     5.74e-05        0.149        0.219        0.105          0.2        0.153         0.15        0.277        0.213       0.0331      0.00221
Wall time: 1007.0017609829993
! Best model       47    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     48    10     6.38e-05     6.35e-05     2.94e-07        0.166         0.23       0.0954        0.247        0.171         0.12        0.311        0.215        0.234       0.0156
     48    20     8.23e-05     8.23e-05     2.76e-08        0.202        0.262        0.146        0.266        0.206        0.181        0.331        0.256       0.0594      0.00396
     48    30     6.91e-05     6.74e-05     1.65e-06        0.178        0.237         0.13        0.232        0.181        0.166        0.297        0.232         0.55       0.0367
     48    40     0.000111     0.000111      1.1e-07        0.221        0.303        0.158        0.292        0.225        0.228        0.371          0.3        0.125      0.00833
     48    50      7.2e-05     7.16e-05     4.29e-07        0.183        0.244        0.141        0.231        0.186        0.191        0.293        0.242        0.275       0.0183
     48    60     7.16e-05     7.16e-05     2.69e-08        0.174        0.244         0.12        0.237        0.178         0.15        0.319        0.235         0.05      0.00333
     48    70     9.22e-05     9.21e-05     1.73e-07        0.218        0.277        0.173        0.269        0.221         0.21        0.337        0.274        0.162       0.0108
     48    80     6.42e-05      6.4e-05     1.84e-07        0.173        0.231        0.122        0.232        0.177         0.16        0.291        0.226        0.172       0.0115
     48    90     5.95e-05     5.95e-05     7.33e-08        0.167        0.222        0.126        0.213        0.169         0.17         0.27         0.22        0.112       0.0075
     48   100     7.66e-05     7.63e-05     3.17e-07        0.188        0.252        0.132        0.253        0.192        0.169        0.321        0.245        0.241        0.016
     48   110     8.28e-05     8.28e-05     2.06e-08        0.205        0.262        0.176        0.238        0.207        0.217        0.306        0.262       0.0594      0.00396
     48   120     0.000117     0.000116     6.86e-07        0.229        0.311        0.157        0.311        0.234        0.194        0.405          0.3        0.356       0.0238
     48   130     0.000241     0.000241     3.58e-07        0.352        0.448        0.284         0.43        0.357        0.357        0.533        0.445        0.253       0.0169
     48   140     0.000199     0.000198     2.62e-07        0.312        0.406        0.237        0.398        0.318        0.297        0.503          0.4        0.213       0.0142
     48   150     0.000131      0.00013     9.74e-07        0.243        0.328        0.139        0.361         0.25        0.183        0.439        0.311        0.428       0.0285
     48   160     9.62e-05      9.5e-05     1.27e-06         0.21        0.281        0.158         0.27        0.214        0.197        0.353        0.275        0.491       0.0327
     48   170     8.33e-05      8.3e-05     3.03e-07          0.2        0.263        0.114        0.298        0.206        0.143        0.353        0.248        0.234       0.0156
     48   180     5.06e-05     4.98e-05     8.08e-07        0.154        0.204        0.102        0.213        0.158        0.127        0.265        0.196        0.391        0.026
     48   190     6.71e-05      6.7e-05     1.25e-07        0.172        0.236        0.138        0.211        0.174        0.176        0.289        0.233        0.144      0.00958

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     48     5     4.57e-05     4.57e-05     1.36e-08        0.139        0.195        0.107        0.175        0.141        0.162        0.227        0.194       0.0422      0.00281


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              48 1028.300    0.005     8.77e-05     4.63e-07     8.82e-05        0.195         0.27        0.138        0.261        0.199        0.185        0.342        0.264        0.242       0.0162
! Validation         48 1028.300    0.005      5.6e-05     1.24e-08     5.61e-05        0.148        0.216        0.104        0.199        0.151        0.148        0.274        0.211       0.0353      0.00235
Wall time: 1028.300977691999
! Best model       48    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     49    10     6.51e-05     6.47e-05     4.09e-07        0.162        0.232        0.118        0.212        0.165        0.159        0.294        0.227        0.275       0.0183
     49    20     8.81e-05      8.8e-05     1.19e-07         0.18         0.27        0.135        0.233        0.184        0.213        0.324        0.268        0.147      0.00979
     49    30      7.1e-05     7.06e-05     4.46e-07        0.178        0.242        0.119        0.245        0.182        0.167        0.307        0.237        0.278       0.0185
     49    40      8.2e-05     8.19e-05     4.11e-08        0.181        0.261        0.112        0.261        0.186        0.145        0.349        0.247       0.0781      0.00521
     49    50     9.32e-05     9.28e-05     4.13e-07        0.196        0.278        0.135        0.266        0.201         0.21        0.339        0.275        0.256       0.0171
     49    60      7.5e-05     7.49e-05     1.56e-07         0.19         0.25        0.141        0.247        0.194        0.168        0.318        0.243        0.172       0.0115
     49    70     9.49e-05     9.49e-05     3.81e-09        0.196        0.281        0.124        0.278        0.201        0.177        0.365        0.271       0.0219      0.00146
     49    80     0.000126     0.000126     1.57e-08        0.255        0.324        0.197        0.321        0.259        0.238        0.401        0.319       0.0437      0.00292
     49    90      0.00011     0.000109     6.25e-07        0.221        0.301        0.117         0.34        0.228        0.148        0.412         0.28        0.338       0.0225
     49   100      0.00011     0.000108     1.36e-06        0.242          0.3        0.186        0.305        0.246        0.226        0.367        0.297        0.497       0.0331
     49   110     6.35e-05     6.32e-05     2.82e-07        0.175        0.229        0.139        0.217        0.178        0.176        0.278        0.227        0.228       0.0152
     49   120     6.17e-05     6.15e-05      1.7e-07        0.167        0.226        0.117        0.224         0.17        0.154        0.287        0.221        0.175       0.0117
     49   130     6.85e-05     6.77e-05     7.53e-07        0.165        0.237        0.123        0.213        0.168        0.187        0.284        0.236        0.378       0.0252
     49   140     8.03e-05     8.02e-05     1.16e-07        0.188        0.258        0.133         0.25        0.192         0.18        0.325        0.253        0.128      0.00854
     49   150      6.4e-05     6.39e-05     1.39e-07        0.167         0.23        0.109        0.233        0.171        0.145          0.3        0.222        0.156       0.0104
     49   160     3.97e-05     3.97e-05     5.98e-08        0.135        0.182        0.108        0.166        0.137        0.148        0.214        0.181       0.0875      0.00583
     49   170     8.16e-05     8.06e-05     9.71e-07        0.198        0.259         0.14        0.264        0.202        0.177        0.329        0.253        0.422       0.0281
     49   180     0.000134     0.000134     9.88e-08        0.236        0.334        0.129        0.358        0.243        0.171        0.454        0.312       0.0906      0.00604
     49   190     5.04e-05     5.04e-05     9.11e-09        0.153        0.205        0.116        0.195        0.156        0.149        0.254        0.201       0.0375       0.0025

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     49     5     4.49e-05     4.49e-05     1.01e-08        0.137        0.193        0.108        0.171        0.139         0.16        0.226        0.193       0.0375       0.0025


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              49 1049.589    0.005     7.65e-05     3.98e-07     7.69e-05        0.182        0.252        0.126        0.246        0.186        0.168        0.322        0.245        0.223       0.0148
! Validation         49 1049.589    0.005     5.54e-05     1.02e-08     5.54e-05        0.147        0.215        0.103        0.197         0.15        0.147        0.272        0.209       0.0322      0.00215
Wall time: 1049.5904501839996
! Best model       49    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     50    10     0.000124     0.000124     6.57e-09        0.246        0.321        0.172         0.33        0.251        0.215         0.41        0.312       0.0344      0.00229
     50    20     6.08e-05      5.9e-05     1.78e-06        0.163        0.222        0.108        0.225        0.166        0.139        0.288        0.214        0.575       0.0383
     50    30     6.39e-05     6.38e-05     1.17e-07        0.165         0.23        0.102        0.238         0.17        0.132        0.307        0.219        0.144      0.00958
     50    40     8.22e-05      8.2e-05     1.75e-07        0.185        0.261        0.127        0.251        0.189        0.175        0.334        0.254        0.178       0.0119
     50    50     6.72e-05     6.39e-05     3.27e-06        0.168         0.23       0.0979        0.248        0.173        0.132        0.306        0.219        0.781       0.0521
     50    60     6.02e-05        6e-05      1.8e-07        0.167        0.223         0.12        0.222        0.171        0.159        0.279        0.219        0.175       0.0117
     50    70     0.000136     0.000136      1.4e-07         0.23        0.336        0.115        0.361        0.238        0.152        0.465        0.309        0.153       0.0102
     50    80     0.000131     0.000131     2.72e-07         0.24         0.33        0.168        0.322        0.245         0.24        0.409        0.324        0.206       0.0137
     50    90     9.42e-05     9.42e-05     6.02e-08        0.195         0.28        0.118        0.283        0.201         0.15        0.377        0.263          0.1      0.00667
     50   100     4.83e-05     4.78e-05     4.69e-07        0.148        0.199       0.0912        0.212        0.152        0.121        0.262        0.191        0.297       0.0198
     50   110     7.99e-05     7.97e-05     2.34e-07        0.193        0.257         0.13        0.266        0.198        0.163        0.334        0.249        0.206       0.0137
     50   120     8.34e-05     8.21e-05     1.35e-06         0.19        0.261        0.129        0.259        0.194        0.167        0.338        0.253        0.497       0.0331
     50   130        7e-05     6.95e-05     4.86e-07        0.175         0.24        0.118        0.241        0.179        0.158        0.309        0.234          0.3         0.02
     50   140     4.45e-05     4.44e-05     1.33e-07        0.141        0.192       0.0943        0.195        0.144        0.125        0.247        0.186         0.15         0.01
     50   150     8.29e-05     8.28e-05     6.99e-08        0.202        0.262        0.148        0.263        0.205        0.185        0.329        0.257          0.1      0.00667
     50   160     5.69e-05     5.69e-05     1.67e-08        0.159        0.218        0.102        0.225        0.164        0.135        0.284        0.209         0.05      0.00333
     50   170     5.35e-05     5.12e-05      2.3e-06        0.152        0.206       0.0998        0.213        0.156        0.125        0.271        0.198        0.659        0.044
     50   180      6.2e-05     6.16e-05     3.65e-07        0.171        0.226        0.124        0.224        0.174        0.156        0.286        0.221        0.256       0.0171
     50   190     0.000113     0.000113     1.21e-08        0.211        0.306        0.129        0.305        0.217        0.165        0.412        0.289       0.0375       0.0025

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     50     5      4.4e-05      4.4e-05     1.26e-08        0.135        0.191        0.106        0.168        0.137        0.159        0.222        0.191       0.0422      0.00281


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              50 1070.853    0.005     7.52e-05     5.14e-07     7.57e-05        0.181         0.25        0.126        0.245        0.185        0.169        0.318        0.244        0.252       0.0168
! Validation         50 1070.853    0.005     5.45e-05     1.19e-08     5.45e-05        0.146        0.213        0.102        0.196        0.149        0.145         0.27        0.208       0.0353      0.00235
Wall time: 1070.8539829210004
! Best model       50    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     51    10     0.000121     0.000121      1.9e-07        0.212        0.317        0.156        0.275        0.216        0.227        0.396        0.312        0.181       0.0121
     51    20     0.000119     0.000116     3.14e-06        0.225         0.31        0.138        0.324        0.231         0.18        0.411        0.295        0.766        0.051
     51    30     7.42e-05     7.39e-05     2.81e-07        0.182        0.248        0.127        0.245        0.186        0.158        0.321         0.24        0.222       0.0148
     51    40     0.000147     0.000146     7.76e-08        0.251        0.349        0.178        0.336        0.257        0.254        0.433        0.343        0.106      0.00708
     51    50     6.02e-05     6.01e-05     6.78e-08        0.165        0.224        0.135        0.199        0.167        0.174        0.269        0.222          0.1      0.00667
     51    60     0.000105     0.000102     2.53e-06        0.209        0.292        0.141        0.286        0.214        0.196        0.372        0.284        0.688       0.0458
     51    70     5.68e-05     5.62e-05      5.8e-07        0.162        0.216        0.133        0.195        0.164        0.173        0.257        0.215        0.328       0.0219
     51    80     7.11e-05      7.1e-05     7.57e-08        0.176        0.243        0.116        0.246        0.181        0.158        0.313        0.236        0.112       0.0075
     51    90     8.28e-05     8.22e-05     5.65e-07        0.188        0.261        0.118        0.268        0.193        0.156        0.344         0.25        0.322       0.0215
     51   100     7.15e-05     7.14e-05     1.93e-08        0.188        0.244        0.146        0.235        0.191        0.187        0.296        0.241       0.0531      0.00354
     51   110      6.5e-05      6.5e-05      1.4e-08         0.17        0.232        0.134        0.212        0.173        0.171        0.287        0.229       0.0469      0.00313
     51   120     0.000135     0.000132     2.74e-06        0.262        0.332          0.2        0.332        0.266        0.247        0.407        0.327        0.716       0.0477
     51   130     6.18e-05     6.01e-05     1.75e-06        0.167        0.224        0.112         0.23        0.171        0.155        0.282        0.219        0.572       0.0381
     51   140     9.31e-05      9.3e-05     2.12e-08        0.211        0.278        0.133          0.3        0.216        0.178         0.36        0.269       0.0531      0.00354
     51   150     7.21e-05     7.17e-05     4.16e-07        0.166        0.244       0.0948        0.248        0.172        0.128         0.33        0.229        0.278       0.0185
     51   160     8.08e-05     7.68e-05     4.01e-06        0.172        0.253       0.0788        0.277        0.178        0.103        0.353        0.228        0.866       0.0577
     51   170     6.89e-05     6.77e-05     1.16e-06         0.18        0.237        0.128        0.241        0.184         0.16        0.302        0.231        0.466        0.031
     51   180     5.11e-05     5.06e-05     5.28e-07        0.153        0.205        0.118        0.193        0.156        0.147        0.256        0.201        0.303       0.0202
     51   190     9.62e-05     9.61e-05     1.16e-07        0.216        0.283        0.161        0.278         0.22        0.192        0.359        0.276        0.138      0.00917

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     51     5     4.42e-05     4.42e-05     9.64e-09        0.136        0.192        0.106         0.17        0.138        0.158        0.224        0.191       0.0344      0.00229


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              51 1092.427    0.005      7.7e-05     7.43e-07     7.77e-05        0.183        0.253        0.126        0.248        0.187        0.168        0.324        0.246        0.299         0.02
! Validation         51 1092.427    0.005     5.34e-05     1.19e-08     5.34e-05        0.144        0.211        0.101        0.194        0.147        0.144        0.267        0.206       0.0334      0.00223
Wall time: 1092.4276689010003
! Best model       51    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     52    10     0.000179     0.000179     3.98e-08        0.287        0.386        0.207        0.378        0.293         0.26        0.491        0.376        0.075        0.005
     52    20      0.00014     0.000138     1.54e-06        0.258        0.339        0.175        0.352        0.264        0.221        0.437        0.329        0.538       0.0358
     52    30     6.75e-05     6.75e-05     9.11e-08        0.171        0.237        0.133        0.213        0.173        0.175        0.292        0.234        0.125      0.00833
     52    40      6.4e-05     6.38e-05     1.85e-07         0.17         0.23        0.113        0.236        0.175        0.146        0.299        0.223        0.181       0.0121
     52    50     6.55e-05     6.52e-05     3.12e-07         0.18        0.233        0.156        0.208        0.182        0.198        0.267        0.233        0.237       0.0158
     52    60     6.49e-05     6.49e-05     3.45e-08        0.178        0.232        0.131        0.232        0.181        0.162        0.292        0.227       0.0688      0.00458
     52    70     0.000105     0.000105     2.06e-07        0.227        0.296        0.161        0.302        0.232         0.21         0.37         0.29        0.191       0.0127
     52    80     0.000142     0.000142     3.38e-07        0.249        0.343        0.135        0.378        0.257        0.163        0.471        0.317        0.247       0.0165
     52    90     6.91e-05     6.83e-05     7.72e-07        0.167        0.238        0.109        0.232        0.171        0.156        0.307        0.231        0.378       0.0252
     52   100     6.43e-05     6.34e-05     8.87e-07        0.169         0.23        0.114        0.232        0.173        0.143        0.299        0.221        0.406       0.0271
     52   110     0.000124     0.000122     1.21e-06        0.221        0.319        0.141        0.312        0.227        0.203        0.414        0.308        0.466        0.031
     52   120     5.22e-05     5.06e-05     1.63e-06        0.146        0.205       0.0961        0.204         0.15        0.128        0.267        0.198        0.547       0.0365
     52   130     8.15e-05     8.04e-05     1.13e-06        0.195        0.259        0.156        0.239        0.198        0.203         0.31        0.257        0.459       0.0306
     52   140     8.63e-05     8.63e-05      2.2e-08        0.218        0.268        0.187        0.252         0.22        0.226        0.309        0.267       0.0594      0.00396
     52   150      7.8e-05      7.8e-05     1.55e-08        0.186        0.255        0.118        0.264        0.191        0.146        0.338        0.242       0.0406      0.00271
     52   160     5.78e-05     5.74e-05     4.21e-07        0.163        0.218        0.103         0.23        0.167        0.129        0.288        0.209        0.281       0.0188
     52   170     6.72e-05     6.49e-05     2.29e-06         0.17        0.232         0.13        0.215        0.173        0.163        0.292        0.228        0.653       0.0435
     52   180     0.000101     0.000101     4.26e-08         0.22         0.29        0.163        0.286        0.224        0.202        0.365        0.284       0.0719      0.00479
     52   190     5.55e-05     5.39e-05     1.55e-06        0.162        0.212        0.126        0.204        0.165        0.155        0.262        0.208        0.538       0.0358

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     52     5     4.24e-05     4.24e-05     9.54e-09        0.134        0.188        0.105        0.168        0.136        0.155        0.219        0.187       0.0359       0.0024


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              52 1113.443    0.005      8.8e-05     4.31e-07     8.84e-05        0.197        0.271        0.137        0.266        0.201        0.181        0.346        0.263        0.227       0.0152
! Validation         52 1113.443    0.005     5.21e-05     1.11e-08     5.21e-05        0.142        0.208       0.0995        0.191        0.145        0.142        0.264        0.203       0.0338      0.00225
Wall time: 1113.4444853799996
! Best model       52    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     53    10     9.54e-05     9.49e-05     5.03e-07        0.218        0.281        0.155        0.289        0.222        0.193        0.356        0.274        0.306       0.0204
     53    20     7.84e-05     7.81e-05     2.66e-07        0.194        0.255        0.145        0.249        0.197         0.19        0.313        0.251        0.219       0.0146
     53    30     6.62e-05      6.6e-05     2.82e-07        0.168        0.234        0.103        0.243        0.173        0.142        0.308        0.225        0.228       0.0152
     53    40     7.84e-05     7.84e-05     4.24e-09        0.179        0.255        0.123        0.242        0.183         0.16        0.333        0.246       0.0219      0.00146
     53    50      5.3e-05      5.3e-05     2.52e-08        0.153         0.21       0.0983        0.215        0.157        0.128        0.275        0.201       0.0469      0.00313
     53    60     3.91e-05     3.84e-05     6.47e-07         0.13        0.179        0.081        0.186        0.133        0.102        0.238         0.17        0.347       0.0231
     53    70     3.82e-05     3.81e-05     8.75e-08        0.125        0.178       0.0814        0.175        0.128        0.105        0.235         0.17        0.125      0.00833
     53    80     0.000107     0.000107     3.41e-07        0.204        0.298        0.151        0.265        0.208        0.199        0.381         0.29        0.234       0.0156
     53    90     6.37e-05     6.36e-05     7.23e-08        0.174         0.23        0.138        0.215        0.176        0.181        0.276        0.228        0.103      0.00688
     53   100     6.08e-05     6.08e-05     9.32e-09        0.172        0.225        0.124        0.228        0.176        0.155        0.284         0.22       0.0312      0.00208
     53   110     0.000105     0.000105     4.79e-07        0.209        0.295        0.111        0.322        0.216        0.143        0.404        0.274          0.3         0.02
     53   120     0.000101     0.000101     3.05e-08        0.212         0.29         0.13        0.307        0.218        0.176         0.38        0.278       0.0625      0.00417
     53   130     6.52e-05     6.45e-05     6.65e-07        0.177        0.232        0.127        0.233         0.18        0.165         0.29        0.227         0.35       0.0233
     53   140     0.000109     0.000108     4.58e-07        0.234          0.3        0.169        0.309        0.239        0.206         0.38        0.293        0.287       0.0192
     53   150     6.56e-05     6.43e-05     1.26e-06         0.16        0.231         0.12        0.207        0.163        0.155        0.295        0.225        0.484       0.0323
     53   160     6.27e-05     6.26e-05      6.1e-08        0.169        0.228        0.108        0.238        0.173        0.148        0.294        0.221          0.1      0.00667
     53   170     4.26e-05     4.25e-05     6.65e-08        0.138        0.188        0.106        0.174         0.14        0.142         0.23        0.186        0.103      0.00687
     53   180      4.7e-05     4.45e-05      2.5e-06        0.146        0.192        0.113        0.184        0.148        0.143        0.236         0.19        0.684       0.0456
     53   190     6.76e-05     6.76e-05     5.91e-08        0.179        0.237        0.141        0.222        0.181         0.18        0.289        0.234        0.103      0.00687

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     53     5     4.19e-05     4.19e-05     6.99e-09        0.133        0.187        0.104        0.166        0.135        0.153        0.219        0.186       0.0297      0.00198


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              53 1134.628    0.005     7.27e-05     3.79e-07      7.3e-05        0.177        0.246        0.121         0.24        0.181        0.162        0.315        0.239        0.209        0.014
! Validation         53 1134.628    0.005     5.19e-05     1.03e-08     5.19e-05        0.142        0.208       0.0986        0.192        0.145         0.14        0.265        0.202       0.0322      0.00215
Wall time: 1134.6289930450002
! Best model       53    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     54    10     5.99e-05     5.98e-05     4.87e-08        0.162        0.223        0.106        0.227        0.166        0.136        0.293        0.214       0.0812      0.00542
     54    20     9.44e-05     9.43e-05     1.44e-07         0.21         0.28        0.143        0.286        0.215        0.183         0.36        0.272        0.162       0.0108
     54    30      5.6e-05     5.57e-05     3.48e-07        0.154        0.215          0.1        0.215        0.158        0.124        0.286        0.205         0.25       0.0167
     54    40     7.19e-05     7.19e-05     2.18e-08        0.183        0.245        0.112        0.263        0.188        0.137        0.327        0.232       0.0625      0.00417
     54    50     6.29e-05     6.28e-05      2.5e-08        0.161        0.229        0.105        0.225        0.165        0.138          0.3        0.219       0.0562      0.00375
     54    60     0.000163      0.00016     3.05e-06        0.278        0.365          0.2        0.368        0.284        0.246        0.464        0.355         0.75         0.05
     54    70     6.85e-05     6.79e-05     6.01e-07        0.158        0.238       0.0939        0.232        0.163        0.127         0.32        0.224        0.331       0.0221
     54    80     3.59e-05     3.59e-05     6.23e-08        0.126        0.173       0.0758        0.183         0.13       0.0968        0.231        0.164        0.103      0.00687
     54    90        8e-05     7.93e-05     7.04e-07        0.194        0.257        0.129        0.268        0.198        0.159        0.335        0.247        0.359        0.024
     54   100     5.57e-05     5.46e-05     1.12e-06        0.157        0.213         0.11        0.211         0.16        0.151        0.267        0.209        0.459       0.0306
     54   110     4.33e-05     4.31e-05     2.41e-07         0.14        0.189        0.107        0.179        0.143         0.15        0.226        0.188        0.209        0.014
     54   120     8.32e-05     8.24e-05     7.97e-07        0.194        0.262        0.125        0.273        0.199        0.166         0.34        0.253        0.391        0.026
     54   130     4.21e-05     4.18e-05     2.35e-07        0.138        0.186       0.0899        0.193        0.141        0.119        0.242         0.18        0.203       0.0135
     54   140     0.000101     0.000101     1.67e-08        0.214        0.289        0.116        0.326        0.221        0.144        0.395        0.269       0.0469      0.00313
     54   150     9.17e-05     9.17e-05      5.3e-08        0.198        0.276        0.132        0.275        0.203        0.175        0.358        0.267       0.0844      0.00562
     54   160      4.9e-05     4.87e-05     3.06e-07        0.161        0.201        0.131        0.197        0.164         0.16         0.24          0.2        0.234       0.0156
     54   170      8.8e-05      8.6e-05     2.04e-06        0.194        0.267        0.101          0.3        0.201        0.134        0.364        0.249        0.616        0.041
     54   180        9e-05      8.9e-05     1.02e-06        0.198        0.272        0.134         0.27        0.202        0.174        0.352        0.263        0.434        0.029
     54   190     7.22e-05     7.21e-05     6.42e-08         0.18        0.245        0.135        0.231        0.183        0.182        0.301        0.242       0.0875      0.00583

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     54     5     4.12e-05     4.12e-05     7.31e-09        0.131        0.185        0.103        0.164        0.133        0.152        0.217        0.184       0.0297      0.00198


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              54 1156.193    0.005     7.19e-05     4.82e-07     7.23e-05        0.176        0.244         0.12        0.239         0.18        0.161        0.314        0.237        0.234       0.0156
! Validation         54 1156.193    0.005     5.06e-05     1.06e-08     5.06e-05         0.14        0.205        0.098        0.189        0.143         0.14        0.261          0.2       0.0328      0.00219
Wall time: 1156.1936201939989
! Best model       54    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     55    10     3.99e-05     3.98e-05     5.98e-08        0.136        0.182        0.101        0.176        0.138        0.126        0.229        0.178        0.106      0.00708
     55    20     6.46e-05     6.43e-05     3.02e-07        0.168        0.231       0.0889        0.259        0.174        0.113        0.316        0.215        0.237       0.0158
     55    30     4.51e-05      4.5e-05     8.96e-08        0.148        0.193        0.124        0.177         0.15        0.153        0.231        0.192        0.119      0.00792
     55    40     7.66e-05     7.66e-05      2.5e-08        0.185        0.252        0.153        0.222        0.187        0.193        0.306         0.25         0.05      0.00333
     55    50     6.63e-05     6.62e-05     9.24e-08        0.173        0.235       0.0974        0.259        0.178        0.128        0.315        0.221        0.128      0.00854
     55    60     5.02e-05     4.98e-05     3.48e-07         0.15        0.204        0.102        0.204        0.153        0.138        0.259        0.198         0.25       0.0167
     55    70     6.88e-05     6.83e-05     4.98e-07        0.177        0.238        0.118        0.244        0.181        0.151        0.309         0.23        0.303       0.0202
     55    80     0.000101       0.0001     1.94e-07        0.196        0.289        0.108        0.297        0.203        0.148        0.392         0.27        0.184       0.0123
     55    90     7.38e-05     7.31e-05     7.45e-07        0.176        0.247         0.12        0.241        0.181         0.17        0.312        0.241        0.366       0.0244
     55   100     0.000113     0.000113      1.4e-08        0.229        0.306        0.152        0.317        0.235        0.192        0.398        0.295       0.0469      0.00313
     55   110     6.37e-05     6.37e-05     4.03e-09        0.167         0.23        0.109        0.234        0.171        0.138        0.303        0.221       0.0281      0.00188
     55   120     4.92e-05      4.9e-05     1.59e-07        0.154        0.202        0.114          0.2        0.157        0.154        0.246          0.2        0.169       0.0113
     55   130     0.000147     0.000145     1.94e-06        0.256        0.347        0.148        0.381        0.264        0.204         0.46        0.332        0.606       0.0404
     55   140     3.42e-05     3.39e-05     3.82e-07        0.127        0.168       0.0865        0.172        0.129        0.113        0.214        0.164        0.266       0.0177
     55   150     6.97e-05     6.95e-05     1.27e-07        0.179         0.24        0.121        0.244        0.183        0.158        0.309        0.233        0.141      0.00938
     55   160     6.33e-05     6.24e-05     9.18e-07        0.172        0.228        0.117        0.234        0.176        0.153         0.29        0.222        0.412       0.0275
     55   170     7.02e-05     6.99e-05     2.98e-07        0.166        0.241       0.0952        0.248        0.171        0.138        0.321        0.229        0.234       0.0156
     55   180     6.51e-05     6.51e-05     1.93e-08        0.161        0.233        0.102        0.227        0.165         0.13        0.311         0.22         0.05      0.00333
     55   190     7.45e-05     7.39e-05     5.87e-07        0.195        0.248        0.156        0.239        0.197        0.201        0.292        0.247        0.325       0.0217

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     55     5     4.01e-05     4.01e-05     5.19e-09        0.129        0.183        0.102        0.159        0.131        0.151        0.213        0.182       0.0219      0.00146


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              55 1177.639    0.005     6.65e-05     3.94e-07     6.69e-05        0.169        0.235        0.114        0.231        0.172        0.153        0.303        0.228        0.208       0.0139
! Validation         55 1177.639    0.005        5e-05     9.85e-09        5e-05        0.139        0.204       0.0971        0.186        0.142        0.139        0.259        0.199       0.0278      0.00185
Wall time: 1177.639914416999
! Best model       55    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     56    10     7.04e-05     6.99e-05     5.04e-07        0.179        0.241         0.12        0.247        0.184        0.155        0.312        0.233        0.306       0.0204
     56    20     6.22e-05     5.99e-05     2.32e-06         0.16        0.223         0.11        0.217        0.164        0.146        0.287        0.217        0.659        0.044
     56    30     5.57e-05     5.55e-05     2.28e-07        0.163        0.215        0.122        0.209        0.166        0.155        0.267        0.211          0.2       0.0133
     56    40     6.42e-05     6.39e-05     3.23e-07        0.164        0.231        0.111        0.224        0.167        0.152        0.296        0.224        0.244       0.0162
     56    50     3.89e-05     3.89e-05     3.77e-08        0.129         0.18       0.0857        0.179        0.132        0.114        0.233        0.174       0.0812      0.00542
     56    60      7.7e-05      7.7e-05     1.21e-08         0.17        0.253        0.105        0.245        0.175        0.147        0.336        0.241       0.0469      0.00313
     56    70     8.17e-05     8.17e-05     3.26e-08        0.186        0.261        0.122        0.259         0.19        0.165        0.339        0.252       0.0625      0.00417
     56    80     9.74e-05     9.64e-05     1.05e-06        0.208        0.283        0.143        0.283        0.213        0.195        0.358        0.277        0.441       0.0294
     56    90     6.49e-05     6.45e-05     3.97e-07        0.169        0.232        0.099        0.249        0.174        0.126        0.311        0.219        0.269       0.0179
     56   100     6.01e-05     5.93e-05     7.69e-07        0.163        0.222        0.126        0.205        0.165        0.169        0.271         0.22        0.381       0.0254
     56   110     4.58e-05     4.58e-05     4.51e-08        0.141        0.195       0.0992        0.188        0.143        0.136        0.246        0.191       0.0875      0.00583
     56   120      8.5e-05     8.44e-05     5.44e-07        0.203        0.265        0.163        0.249        0.206        0.215        0.313        0.264        0.319       0.0213
     56   130     6.25e-05     6.22e-05     2.82e-07        0.172        0.227          0.1        0.255        0.178        0.126        0.304        0.215        0.228       0.0152
     56   140        6e-05     5.97e-05     3.31e-07        0.165        0.223        0.124        0.212        0.168        0.166        0.274         0.22        0.241        0.016
     56   150     9.98e-05     9.97e-05     3.96e-08        0.198        0.288        0.151        0.252        0.201        0.234        0.339        0.287       0.0719      0.00479
     56   160     6.49e-05     6.49e-05     3.18e-09        0.174        0.232        0.125        0.231        0.178        0.161        0.293        0.227       0.0219      0.00146
     56   170     7.41e-05     7.34e-05     7.21e-07        0.176        0.247        0.106        0.257        0.181         0.14        0.329        0.235        0.366       0.0244
     56   180     7.82e-05     7.77e-05     5.14e-07        0.196        0.254        0.146        0.252        0.199        0.195        0.308        0.252        0.306       0.0204
     56   190      6.9e-05     6.79e-05      1.1e-06        0.177        0.238        0.123        0.238        0.181        0.166        0.299        0.233         0.45         0.03

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     56     5     4.04e-05     4.04e-05     6.57e-09         0.13        0.183        0.101        0.163        0.132        0.149        0.216        0.182       0.0266      0.00177


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              56 1199.258    0.005     6.65e-05     3.44e-07     6.68e-05        0.169        0.235        0.117        0.229        0.173        0.157        0.301        0.229          0.2       0.0133
! Validation         56 1199.258    0.005      4.9e-05     1.07e-08      4.9e-05        0.138        0.202       0.0972        0.185        0.141        0.138        0.256        0.197       0.0303      0.00202
Wall time: 1199.2583017159996
! Best model       56    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     57    10     3.47e-05     3.38e-05     9.21e-07        0.126        0.168       0.0957         0.16        0.128        0.123        0.207        0.165        0.416       0.0277
     57    20     5.77e-05     5.67e-05     9.52e-07        0.161        0.217        0.132        0.195        0.163        0.165        0.264        0.215        0.419       0.0279
     57    30     4.91e-05     4.91e-05     2.63e-08        0.145        0.202       0.0921        0.206        0.149        0.116        0.268        0.192       0.0594      0.00396
     57    40     8.91e-05     8.88e-05     3.14e-07        0.178        0.272       0.0992        0.268        0.184        0.127        0.374         0.25        0.241        0.016
     57    50     4.01e-05     3.93e-05     7.89e-07        0.132        0.181       0.0828        0.188        0.135        0.107        0.239        0.173        0.381       0.0254
     57    60     5.97e-05     5.95e-05     1.34e-07        0.172        0.223        0.119        0.233        0.176        0.152        0.283        0.217        0.159       0.0106
     57    70     9.05e-05     8.92e-05     1.22e-06        0.206        0.272        0.131        0.292        0.211        0.158        0.361         0.26        0.478       0.0319
     57    80     3.27e-05     3.19e-05     7.17e-07        0.122        0.163       0.0893         0.16        0.125         0.12        0.201        0.161        0.363       0.0242
     57    90     0.000102     0.000102     1.84e-08        0.238        0.292        0.209        0.272         0.24         0.25        0.333        0.292       0.0469      0.00313
     57   100     3.36e-05     3.34e-05     1.11e-07        0.132        0.167        0.108         0.16        0.134         0.13          0.2        0.165        0.131      0.00875
     57   110     8.42e-05     8.36e-05     5.55e-07        0.203        0.264        0.165        0.246        0.206        0.198        0.323         0.26        0.319       0.0213
     57   120     3.98e-05     3.96e-05     2.61e-07        0.137        0.181        0.105        0.174        0.139        0.139         0.22         0.18        0.225        0.015
     57   130     7.41e-05     7.37e-05     3.18e-07        0.174        0.248         0.12        0.236        0.178        0.157        0.321        0.239        0.237       0.0158
     57   140     6.84e-05     6.84e-05     3.88e-08        0.172        0.238        0.122        0.228        0.175        0.159        0.305        0.232       0.0656      0.00438
     57   150     5.48e-05     5.47e-05     9.41e-08         0.16        0.213        0.124        0.202        0.163         0.16        0.261        0.211        0.128      0.00854
     57   160     5.05e-05     5.05e-05     4.68e-08        0.154        0.205        0.138        0.173        0.156         0.18         0.23        0.205       0.0812      0.00542
     57   170     0.000126     0.000126     1.53e-07        0.243        0.324        0.196        0.296        0.246        0.258        0.385        0.322        0.169       0.0113
     57   180      5.2e-05     5.19e-05     1.65e-07        0.153        0.208        0.093        0.221        0.157        0.122        0.275        0.198        0.166        0.011
     57   190     0.000113     0.000113     5.84e-07        0.225        0.306        0.168        0.289        0.229        0.232        0.374        0.303        0.325       0.0217

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     57     5     4.19e-05     4.19e-05     5.93e-09        0.131        0.187        0.102        0.165        0.133        0.154        0.218        0.186       0.0281      0.00188


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              57 1220.367    0.005     6.87e-05     4.04e-07     6.91e-05        0.174        0.239         0.12        0.235        0.177         0.16        0.305        0.232        0.222       0.0148
! Validation         57 1220.367    0.005     4.83e-05      9.9e-09     4.83e-05        0.138          0.2       0.0961        0.185        0.141        0.138        0.254        0.196       0.0306      0.00204
Wall time: 1220.3673583290001
! Best model       57    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     58    10     4.93e-05     4.93e-05     7.82e-08        0.153        0.202        0.122        0.188        0.155        0.152        0.248          0.2        0.116      0.00771
     58    20      6.5e-05     6.47e-05     3.16e-07        0.169        0.232        0.129        0.215        0.172        0.174        0.284        0.229        0.241        0.016
     58    30     0.000164     0.000164     3.12e-08        0.278         0.37        0.178        0.393        0.286        0.219        0.488        0.353       0.0625      0.00417
     58    40     7.19e-05     7.13e-05     6.54e-07        0.182        0.243        0.132         0.24        0.186        0.169        0.307        0.238         0.35       0.0233
     58    50     9.37e-05     9.36e-05     3.94e-08        0.204        0.279        0.142        0.275        0.208        0.176        0.362        0.269       0.0781      0.00521
     58    60     9.23e-05      9.2e-05     2.51e-07        0.198        0.277        0.127        0.278        0.203        0.165        0.364        0.265        0.209        0.014
     58    70     6.49e-05     6.44e-05     5.25e-07         0.18        0.231        0.144        0.221        0.182        0.176        0.282        0.229        0.309       0.0206
     58    80     3.57e-05      3.5e-05     6.87e-07        0.126        0.171       0.0827        0.174        0.129        0.112        0.219        0.166        0.353       0.0235
     58    90     5.32e-05     5.32e-05      6.4e-08        0.161         0.21        0.129        0.198        0.164        0.164        0.253        0.209        0.106      0.00708
     58   100     2.18e-05     2.17e-05     5.32e-08        0.105        0.134       0.0736        0.141        0.107        0.091        0.171        0.131       0.0969      0.00646
     58   110     8.89e-05     8.75e-05     1.35e-06        0.201         0.27        0.149        0.261        0.205        0.198        0.333        0.266        0.497       0.0331
     58   120     5.17e-05     5.17e-05     4.13e-08        0.145        0.207        0.114        0.181        0.147        0.145        0.261        0.203       0.0625      0.00417
     58   130     5.22e-05     5.18e-05     3.91e-07        0.141        0.208       0.0984         0.19        0.144        0.141        0.264        0.202        0.269       0.0179
     58   140     8.19e-05     8.12e-05     7.81e-07        0.202         0.26         0.13        0.283        0.207        0.171        0.334        0.252        0.375        0.025
     58   150      5.1e-05     5.05e-05     5.03e-07         0.15        0.205        0.096        0.212        0.154        0.122         0.27        0.196          0.3         0.02
     58   160     9.06e-05     9.04e-05     1.77e-07        0.195        0.274        0.105        0.298        0.201        0.138        0.373        0.256        0.175       0.0117
     58   170     7.45e-05     7.31e-05     1.35e-06        0.168        0.247        0.113        0.231        0.172        0.151        0.323        0.237          0.5       0.0333
     58   180     5.03e-05     4.92e-05     1.07e-06        0.162        0.202        0.135        0.192        0.163        0.167        0.236        0.202        0.447       0.0298
     58   190     6.36e-05     6.35e-05      8.9e-08        0.177         0.23        0.117        0.247        0.182         0.15        0.296        0.223        0.112       0.0075

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     58     5     3.97e-05     3.97e-05     6.57e-09         0.13        0.182       0.0987        0.166        0.132        0.146        0.215        0.181       0.0297      0.00198


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              58 1241.997    0.005     6.86e-05     3.39e-07     6.89e-05        0.173        0.239        0.119        0.235        0.177        0.159        0.306        0.232          0.2       0.0133
! Validation         58 1241.997    0.005     4.76e-05     7.93e-09     4.76e-05        0.136        0.199       0.0948        0.184        0.139        0.135        0.253        0.194       0.0262      0.00175
Wall time: 1241.9976393710003
! Best model       58    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     59    10     8.12e-05     8.06e-05     5.75e-07          0.2        0.259        0.169        0.235        0.202        0.202        0.312        0.257        0.328       0.0219
     59    20     7.14e-05     7.02e-05     1.21e-06        0.178        0.242        0.123        0.241        0.182         0.16         0.31        0.235        0.481       0.0321
     59    30     8.33e-05     8.32e-05     1.67e-08        0.207        0.263         0.17         0.25         0.21        0.203        0.318        0.261         0.05      0.00333
     59    40     7.12e-05     7.11e-05     8.58e-08        0.179        0.243        0.122        0.244        0.183        0.152        0.316        0.234        0.116      0.00771
     59    50     6.85e-05     6.84e-05     2.84e-08        0.164        0.239        0.101        0.235        0.168        0.131         0.32        0.226       0.0719      0.00479
     59    60     3.58e-05     3.56e-05     2.53e-07        0.128        0.172       0.0822        0.181        0.132        0.101        0.227        0.164        0.216       0.0144
     59    70      4.7e-05     4.67e-05     2.63e-07        0.146        0.197        0.109        0.189        0.149        0.144        0.244        0.194        0.216       0.0144
     59    80     2.83e-05     2.82e-05     1.16e-07        0.119        0.153       0.0978        0.143         0.12        0.126        0.179        0.153        0.144      0.00958
     59    90     5.22e-05     5.21e-05     4.77e-08        0.154        0.208        0.097        0.219        0.158        0.127        0.273          0.2       0.0875      0.00583
     59   100     6.92e-05     6.85e-05     6.57e-07        0.178        0.239        0.132        0.232        0.182        0.173        0.297        0.235        0.344       0.0229
     59   110     9.15e-05     9.14e-05     1.41e-07        0.206        0.276        0.139        0.283        0.211        0.174        0.358        0.266        0.156       0.0104
     59   120     5.16e-05     5.14e-05     1.71e-07        0.147        0.207       0.0928        0.209        0.151        0.128         0.27        0.199        0.175       0.0117
     59   130     4.85e-05     4.84e-05     1.04e-07        0.149        0.201        0.113         0.19        0.152         0.15        0.246        0.198        0.128      0.00854
     59   140     4.28e-05     4.27e-05     1.13e-07        0.132        0.188       0.0932        0.177        0.135        0.124        0.242        0.183        0.144      0.00958
     59   150     8.95e-05     8.95e-05     2.14e-08        0.196        0.273        0.134        0.267        0.201        0.197        0.339        0.268       0.0437      0.00292
     59   160      7.7e-05     7.68e-05     2.15e-07        0.186        0.253        0.118        0.264        0.191        0.151        0.333        0.242        0.194       0.0129
     59   170     0.000131      0.00013     7.45e-07        0.232        0.329        0.157        0.318        0.238        0.218        0.422         0.32        0.369       0.0246
     59   180     7.64e-05      7.6e-05     4.05e-07         0.19        0.251        0.139        0.248        0.193        0.174        0.317        0.246        0.275       0.0183
     59   190     5.62e-05      5.6e-05        2e-07        0.152        0.216       0.0915         0.22        0.156        0.124        0.287        0.205        0.188       0.0125

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     59     5     3.98e-05     3.98e-05     4.87e-09         0.13        0.182       0.0995        0.164        0.132        0.149        0.214        0.181       0.0234      0.00156


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              59 1263.533    0.005     7.02e-05     2.94e-07     7.05e-05        0.174        0.242        0.119        0.237        0.178        0.159         0.31        0.234        0.188       0.0126
! Validation         59 1263.533    0.005     4.71e-05      9.6e-09     4.71e-05        0.136        0.198       0.0947        0.183        0.139        0.135        0.251        0.193       0.0294      0.00196
Wall time: 1263.5333504649989
! Best model       59    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     60    10     6.67e-05     6.66e-05     3.07e-08        0.182        0.235        0.177        0.189        0.183        0.216        0.256        0.236       0.0594      0.00396
     60    20     8.49e-05     8.48e-05     1.49e-07        0.177        0.266        0.103        0.262        0.183         0.15        0.354        0.252        0.159       0.0106
     60    30     5.63e-05     5.57e-05     5.82e-07        0.175        0.215        0.156        0.197        0.176         0.19        0.241        0.215        0.328       0.0219
     60    40     6.36e-05     6.36e-05     1.63e-08        0.165         0.23        0.112        0.225        0.168        0.149        0.296        0.223         0.05      0.00333
     60    50      6.1e-05     6.09e-05     1.39e-07        0.165        0.225        0.104        0.234        0.169        0.138        0.295        0.216        0.159       0.0106
     60    60     0.000102     0.000102     6.34e-08        0.215        0.291        0.152        0.287        0.219        0.199        0.369        0.284       0.0906      0.00604
     60    70      4.4e-05     4.38e-05     2.18e-07        0.147        0.191        0.114        0.185         0.15        0.144        0.233        0.188        0.197       0.0131
     60    80     5.99e-05     5.99e-05     1.17e-08        0.163        0.223        0.117        0.216        0.166        0.156        0.281        0.218       0.0406      0.00271
     60    90     6.01e-05     6.01e-05     9.75e-09        0.162        0.224        0.129        0.201        0.165        0.172         0.27        0.221       0.0406      0.00271
     60   100      6.7e-05     6.62e-05     8.09e-07        0.173        0.235       0.0996        0.258        0.179        0.126        0.316        0.221        0.394       0.0262
     60   110     7.33e-05     7.32e-05     1.01e-07        0.186        0.247        0.126        0.255        0.191        0.163        0.317         0.24        0.131      0.00875
     60   120     8.66e-05      8.6e-05     5.72e-07        0.192        0.267        0.116        0.279        0.197         0.15        0.357        0.254        0.322       0.0215
     60   130     5.01e-05     4.98e-05     3.44e-07        0.142        0.204       0.0909        0.199        0.145        0.116        0.271        0.193         0.25       0.0167
     60   140     0.000125     0.000125     1.83e-07        0.228        0.322        0.145        0.323        0.234        0.177        0.432        0.304        0.184       0.0123
     60   150     8.79e-05     8.78e-05     4.47e-08        0.203         0.27        0.138        0.276        0.207         0.18        0.346        0.263       0.0781      0.00521
     60   160     0.000105     0.000104     1.16e-06        0.228        0.295        0.171        0.293        0.232          0.2        0.374        0.287        0.466        0.031
     60   170     3.88e-05     3.88e-05     1.84e-08         0.13         0.18       0.0993        0.164        0.132        0.131        0.222        0.177       0.0469      0.00313
     60   180     5.38e-05     5.37e-05     7.18e-08        0.162        0.211         0.11        0.221        0.166        0.139        0.271        0.205       0.0781      0.00521
     60   190     6.74e-05     6.72e-05     2.31e-07        0.171        0.236        0.121        0.228        0.174        0.163        0.299        0.231        0.203       0.0135

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     60     5     3.93e-05     3.93e-05     6.78e-09         0.13        0.181       0.0993        0.165        0.132        0.147        0.213         0.18       0.0297      0.00198


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              60 1285.045    0.005     7.15e-05     4.03e-07     7.19e-05        0.174        0.244        0.119        0.238        0.178        0.159        0.314        0.236        0.212       0.0142
! Validation         60 1285.045    0.005     4.66e-05     8.75e-09     4.66e-05        0.135        0.197       0.0942        0.182        0.138        0.135         0.25        0.192       0.0291      0.00194
Wall time: 1285.0460368429995
! Best model       60    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     61    10     3.99e-05     3.99e-05     1.65e-08        0.137        0.182       0.0907        0.189         0.14        0.117        0.236        0.176         0.05      0.00333
     61    20     0.000125     0.000123     1.28e-06        0.223         0.32        0.122        0.339         0.23        0.159        0.437        0.298        0.491       0.0327
     61    30     8.69e-05     8.67e-05     2.63e-07        0.184        0.268        0.106        0.274         0.19        0.142        0.363        0.252        0.216       0.0144
     61    40     3.74e-05     3.68e-05     5.75e-07        0.131        0.175       0.0793        0.189        0.134        0.101        0.232        0.167        0.325       0.0217
     61    50     4.78e-05     4.75e-05     2.42e-07        0.139        0.199       0.0834        0.204        0.143        0.112        0.265        0.189        0.213       0.0142
     61    60     6.22e-05     6.22e-05     3.16e-08        0.167        0.227        0.101        0.241        0.171        0.129        0.303        0.216       0.0562      0.00375
     61    70     6.72e-05     6.69e-05     3.23e-07        0.167        0.236       0.0997        0.244        0.172        0.134        0.314        0.224        0.247       0.0165
     61    80     8.13e-05     8.08e-05     5.18e-07        0.193        0.259        0.139        0.255        0.197        0.171        0.333        0.252        0.309       0.0206
     61    90     8.47e-05     8.43e-05     4.33e-07        0.186        0.265        0.118        0.263        0.191        0.143        0.356         0.25        0.281       0.0188
     61   100     6.35e-05     6.35e-05     1.61e-08        0.174         0.23        0.132        0.223        0.177        0.162        0.288        0.225       0.0406      0.00271
     61   110     5.82e-05     5.78e-05     3.71e-07        0.165        0.219        0.104        0.234        0.169        0.137        0.286        0.211        0.256       0.0171
     61   120      8.6e-05     8.59e-05     1.08e-07        0.211        0.267        0.156        0.275        0.215        0.201        0.327        0.264        0.131      0.00875
     61   130     8.78e-05     8.71e-05     7.38e-07        0.197        0.269        0.162        0.237          0.2        0.213        0.322        0.267        0.372       0.0248
     61   140     6.18e-05     6.18e-05     3.94e-08        0.167        0.227        0.119        0.222        0.171        0.147        0.292         0.22       0.0688      0.00458
     61   150     5.31e-05     5.31e-05     1.25e-08        0.148         0.21        0.108        0.194        0.151        0.137         0.27        0.204       0.0406      0.00271
     61   160     5.45e-05     5.44e-05     1.07e-07        0.159        0.213         0.11        0.214        0.162        0.138        0.274        0.206        0.131      0.00875
     61   170     4.23e-05     4.23e-05     5.09e-09        0.132        0.188       0.0882        0.182        0.135         0.12        0.243        0.182       0.0219      0.00146
     61   180     0.000121     0.000121     2.25e-08        0.241        0.318        0.177        0.313        0.245        0.224        0.398        0.311       0.0531      0.00354
     61   190     0.000194     0.000194     3.45e-08        0.291        0.402         0.15        0.452        0.301         0.19        0.552        0.371       0.0719      0.00479

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     61     5     3.76e-05     3.76e-05     6.46e-09        0.126        0.177       0.0969        0.158        0.128        0.144        0.208        0.176       0.0281      0.00188


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              61 1306.243    0.005     6.83e-05      5.2e-07     6.88e-05        0.171        0.238        0.117        0.234        0.175        0.156        0.307        0.231        0.253       0.0169
! Validation         61 1306.243    0.005     4.59e-05     1.01e-08     4.59e-05        0.133        0.195       0.0925         0.18        0.136        0.133        0.248         0.19       0.0294      0.00196
Wall time: 1306.2440369349988
! Best model       61    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     62    10      4.8e-05      4.8e-05     1.21e-08        0.152          0.2        0.106        0.204        0.155        0.144        0.249        0.196       0.0437      0.00292
     62    20     7.94e-05     7.91e-05     3.03e-07         0.19        0.257        0.107        0.285        0.196        0.135        0.347        0.241        0.234       0.0156
     62    30     7.28e-05     7.28e-05     1.84e-08        0.189        0.246        0.129        0.257        0.193        0.165        0.314         0.24       0.0375       0.0025
     62    40     8.98e-05      8.9e-05     8.12e-07        0.199        0.272        0.138        0.268        0.203        0.186        0.345        0.265        0.384       0.0256
     62    50     5.92e-05     5.91e-05     4.49e-08        0.165        0.222        0.123        0.213        0.168        0.159        0.277        0.218       0.0781      0.00521
     62    60     8.48e-05     8.48e-05     4.05e-08        0.187        0.266        0.119        0.265        0.192        0.177        0.339        0.258       0.0781      0.00521
     62    70      5.7e-05     5.69e-05     7.86e-08        0.167        0.217        0.115        0.226         0.17        0.146        0.278        0.212        0.106      0.00708
     62    80     4.66e-05      4.4e-05     2.52e-06        0.146        0.191        0.118        0.177        0.147        0.159        0.223        0.191        0.691        0.046
     62    90     5.07e-05     5.06e-05     1.65e-08        0.157        0.205         0.12          0.2         0.16        0.163        0.245        0.204         0.05      0.00333
     62   100     5.56e-05     5.53e-05     3.52e-07         0.16        0.214        0.129        0.195        0.162        0.163        0.261        0.212        0.253       0.0169
     62   110     4.75e-05     4.69e-05     5.72e-07        0.139        0.198       0.0859        0.199        0.143        0.115        0.261        0.188        0.322       0.0215
     62   120     7.06e-05     7.04e-05     2.09e-07        0.175        0.242        0.124        0.233        0.179        0.163        0.308        0.236        0.191       0.0127
     62   130     4.82e-05     4.82e-05     1.29e-08        0.146          0.2        0.113        0.183        0.148        0.167        0.232          0.2       0.0406      0.00271
     62   140     4.53e-05      4.5e-05     2.85e-07        0.154        0.194        0.126        0.187        0.156        0.152        0.232        0.192        0.219       0.0146
     62   150     7.37e-05     7.26e-05     1.16e-06        0.183        0.246         0.13        0.243        0.186        0.175        0.307        0.241        0.469       0.0312
     62   160     0.000103     0.000102     1.23e-06        0.203        0.291        0.116        0.303        0.209        0.151        0.394        0.273        0.481       0.0321
     62   170     0.000141      0.00014     1.89e-06         0.22        0.341        0.135        0.318        0.226         0.17        0.465        0.317        0.594       0.0396
     62   180     0.000113     0.000112     1.05e-06        0.195        0.305        0.116        0.286        0.201        0.168        0.408        0.288        0.434        0.029
     62   190      0.00012      0.00012     2.76e-08        0.203        0.316        0.108        0.311        0.209        0.144        0.436         0.29       0.0719      0.00479

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     62     5     3.72e-05     3.72e-05     6.04e-09        0.125        0.176       0.0953        0.159        0.127        0.143        0.207        0.175       0.0297      0.00198


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              62 1327.286    0.005     6.85e-05     4.99e-07      6.9e-05        0.171        0.239        0.117        0.232        0.175        0.157        0.306        0.232        0.241       0.0161
! Validation         62 1327.286    0.005      4.5e-05     9.01e-09      4.5e-05        0.133        0.193       0.0924         0.18        0.136        0.132        0.245        0.189         0.03        0.002
Wall time: 1327.2879597459996
! Best model       62    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     63    10      4.8e-05      4.8e-05     3.26e-08         0.14          0.2       0.0916        0.195        0.143        0.115        0.265         0.19       0.0656      0.00438
     63    20     4.31e-05     4.28e-05      3.9e-07        0.136        0.189       0.0985        0.178        0.138        0.127         0.24        0.184        0.269       0.0179
     63    30     5.02e-05     5.01e-05     1.68e-07        0.158        0.204        0.126        0.194         0.16        0.156        0.248        0.202        0.169       0.0113
     63    40      7.9e-05     7.89e-05     1.55e-08         0.19        0.256        0.134        0.254        0.194        0.184        0.319        0.252       0.0437      0.00292
     63    50     8.09e-05     8.08e-05      7.4e-08        0.206        0.259        0.172        0.245        0.208        0.213        0.304        0.258        0.112       0.0075
     63    60     6.22e-05     6.07e-05     1.49e-06        0.159        0.225        0.112        0.213        0.162        0.139        0.293        0.216        0.525        0.035
     63    70     6.11e-05     6.09e-05     1.65e-07        0.175        0.225        0.144        0.211        0.177        0.172        0.274        0.223        0.172       0.0115
     63    80      8.5e-05     8.46e-05     4.34e-07        0.202        0.265        0.145        0.267        0.206        0.192        0.329        0.261        0.278       0.0185
     63    90     7.46e-05     7.42e-05     3.85e-07        0.186        0.248        0.122        0.258         0.19        0.158        0.322         0.24        0.262       0.0175
     63   100     8.15e-05     8.06e-05     9.11e-07        0.182        0.259         0.12        0.254        0.187        0.161        0.338        0.249        0.409       0.0273
     63   110     5.21e-05     5.21e-05     4.05e-08        0.153        0.208        0.101        0.212        0.156        0.132         0.27        0.201       0.0562      0.00375
     63   120     4.36e-05     4.35e-05      2.1e-08        0.138         0.19       0.0909        0.192        0.142        0.117        0.249        0.183       0.0562      0.00375
     63   130     3.85e-05     3.82e-05     2.97e-07        0.128        0.178       0.0785        0.185        0.132       0.0982        0.239        0.169        0.234       0.0156
     63   140     4.39e-05     4.36e-05     2.74e-07        0.146        0.191        0.111        0.186        0.148        0.136        0.238        0.187        0.222       0.0148
     63   150     6.76e-05     6.68e-05     8.03e-07        0.159        0.236       0.0943        0.233        0.164        0.123        0.319        0.221        0.387       0.0258
     63   160     6.47e-05     6.47e-05     2.25e-08        0.161        0.232       0.0949        0.236        0.165         0.13         0.31         0.22       0.0562      0.00375
     63   170     4.52e-05      4.5e-05     1.32e-07        0.146        0.194        0.108         0.19        0.149        0.134        0.245        0.189        0.153       0.0102
     63   180     5.82e-05     5.82e-05     1.57e-08        0.166         0.22        0.117        0.221        0.169        0.163        0.271        0.217       0.0469      0.00313
     63   190     7.96e-05      7.9e-05     6.55e-07        0.197        0.256        0.167        0.232        0.199        0.219        0.293        0.256        0.347       0.0231

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     63     5     3.78e-05     3.78e-05     8.79e-09        0.126        0.177       0.0965        0.159        0.128        0.146        0.208        0.177       0.0312      0.00208


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              63 1348.500    0.005     5.68e-05     3.72e-07     5.72e-05        0.157        0.217        0.109        0.212        0.161        0.145        0.278        0.211        0.214       0.0142
! Validation         63 1348.500    0.005     4.48e-05     7.95e-09     4.48e-05        0.132        0.193       0.0914        0.178        0.135        0.132        0.245        0.188       0.0288      0.00192
Wall time: 1348.5004194699995
! Best model       63    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     64    10     3.31e-05     3.31e-05     5.04e-08        0.121        0.166       0.0867        0.161        0.124        0.117        0.208        0.162       0.0906      0.00604
     64    20     4.55e-05     4.49e-05     5.81e-07        0.141        0.193         0.09        0.199        0.145        0.115        0.255        0.185        0.325       0.0217
     64    30     5.66e-05     5.62e-05     3.98e-07        0.162        0.216        0.106        0.226        0.166        0.136        0.281        0.209        0.269       0.0179
     64    40     7.95e-05     7.93e-05     1.88e-07        0.182        0.257        0.124        0.248        0.186        0.191        0.316        0.253        0.178       0.0119
     64    50      3.2e-05     3.15e-05     5.16e-07        0.117        0.162       0.0854        0.153        0.119        0.117        0.201        0.159        0.306       0.0204
     64    60     3.08e-05     2.93e-05     1.57e-06        0.115        0.156       0.0766         0.16        0.118       0.0981        0.203         0.15        0.541        0.036
     64    70     5.99e-05     5.98e-05        1e-07        0.164        0.223        0.104        0.233        0.169        0.139        0.291        0.215        0.122      0.00813
     64    80     5.24e-05     5.23e-05     1.17e-08        0.144        0.209        0.113        0.179        0.146        0.164         0.25        0.207       0.0406      0.00271
     64    90     7.11e-05     7.05e-05     6.37e-07        0.174        0.242         0.11        0.246        0.178         0.14        0.321        0.231        0.338       0.0225
     64   100     7.27e-05     7.23e-05     4.45e-07        0.178        0.245        0.112        0.253        0.183        0.139        0.326        0.233        0.284        0.019
     64   110     9.44e-05     9.37e-05     6.38e-07        0.196        0.279        0.113         0.29        0.201        0.151        0.376        0.263        0.338       0.0225
     64   120     5.01e-05     4.78e-05     2.31e-06        0.137        0.199        0.077        0.205        0.141        0.105         0.27        0.187        0.663       0.0442
     64   130     7.55e-05     7.52e-05     3.32e-07        0.191         0.25        0.145        0.243        0.194        0.179        0.312        0.246        0.244       0.0162
     64   140     4.53e-05     4.53e-05     3.05e-08        0.137        0.194       0.0864        0.196        0.141        0.117        0.255        0.186        0.075        0.005
     64   150     5.04e-05        5e-05     3.77e-07        0.143        0.204       0.0982        0.195        0.147        0.126        0.266        0.196        0.259       0.0173
     64   160     4.56e-05     4.56e-05     1.08e-08        0.143        0.195        0.109        0.182        0.146        0.143         0.24        0.192       0.0375       0.0025
     64   170     4.87e-05     4.84e-05     3.18e-07        0.144        0.201       0.0941        0.202        0.148        0.127        0.261        0.194        0.234       0.0156
     64   180      5.5e-05      5.5e-05     4.87e-08        0.154        0.214       0.0953        0.221        0.158        0.121        0.285        0.203       0.0781      0.00521
     64   190     3.77e-05     3.76e-05     5.49e-08        0.132        0.177       0.0937        0.176        0.135        0.126        0.221        0.174       0.0938      0.00625

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     64     5     3.66e-05     3.66e-05     3.81e-09        0.125        0.174       0.0953        0.158        0.127        0.144        0.204        0.174       0.0203      0.00135


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              64 1369.723    0.005     5.34e-05     5.31e-07      5.4e-05        0.152        0.211        0.105        0.207        0.156         0.14         0.27        0.205        0.261       0.0174
! Validation         64 1369.723    0.005      4.4e-05     6.78e-09      4.4e-05        0.131        0.191       0.0909        0.177        0.134        0.131        0.243        0.187        0.025      0.00167
Wall time: 1369.7240843250001
! Best model       64    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     65    10     4.53e-05     4.52e-05     5.07e-08         0.15        0.194        0.119        0.186        0.152        0.152        0.233        0.192       0.0938      0.00625
     65    20     4.69e-05     4.67e-05     1.25e-07        0.142        0.197       0.0881        0.203        0.146        0.125        0.256         0.19        0.144      0.00958
     65    30     5.98e-05     5.98e-05      1.8e-08        0.181        0.223         0.15        0.217        0.184        0.179        0.265        0.222       0.0531      0.00354
     65    40     6.74e-05     6.74e-05     7.84e-09        0.177        0.237        0.131        0.228         0.18        0.167        0.297        0.232       0.0406      0.00271
     65    50     4.66e-05     4.63e-05     3.24e-07        0.149        0.196        0.115        0.187        0.151        0.148         0.24        0.194        0.244       0.0162
     65    60     6.18e-05     6.17e-05     8.05e-09        0.167        0.227        0.107        0.235        0.171        0.131        0.301        0.216       0.0281      0.00188
     65    70     4.71e-05     4.69e-05     2.42e-07        0.146        0.197       0.0932        0.207         0.15         0.12        0.259        0.189        0.213       0.0142
     65    80     5.28e-05     5.26e-05     1.81e-07        0.156        0.209        0.112        0.206        0.159        0.148        0.262        0.205        0.188       0.0125
     65    90     5.09e-05     5.06e-05      3.2e-07         0.15        0.205        0.103        0.204        0.154        0.134        0.264        0.199        0.234       0.0156
     65   100     6.56e-05     6.56e-05     8.65e-08        0.171        0.234        0.129         0.22        0.174        0.174        0.287         0.23       0.0969      0.00646
     65   110     4.87e-05     4.87e-05     4.39e-08        0.146        0.201        0.101        0.198         0.15        0.129         0.26        0.195       0.0844      0.00563
     65   120     5.66e-05     5.63e-05     3.67e-07        0.162        0.216        0.116        0.215        0.165        0.139         0.28        0.209        0.262       0.0175
     65   130     6.74e-05     6.73e-05     1.25e-07        0.171        0.237        0.106        0.245        0.176        0.136        0.314        0.225        0.144      0.00958
     65   140     8.69e-05     8.68e-05      4.2e-08        0.204        0.269        0.159        0.257        0.208        0.208        0.324        0.266       0.0812      0.00542
     65   150     6.71e-05     6.69e-05     2.43e-07        0.166        0.236        0.108        0.233        0.171         0.15        0.306        0.228        0.206       0.0138
     65   160     8.98e-05     8.73e-05     2.48e-06        0.201        0.269        0.144        0.267        0.206        0.173        0.348        0.261        0.681       0.0454
     65   170     6.04e-05     6.04e-05     3.09e-08        0.161        0.224       0.0919         0.24        0.166         0.12        0.302        0.211       0.0656      0.00438
     65   180     5.94e-05     5.94e-05     3.37e-08        0.167        0.222        0.112         0.23        0.171        0.145        0.286        0.216       0.0688      0.00458
     65   190     0.000101     0.000101     1.31e-08        0.215        0.291        0.135        0.307        0.221        0.166        0.386        0.276       0.0437      0.00292

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     65     5     3.57e-05     3.57e-05     5.09e-09        0.122        0.172       0.0948        0.154        0.124        0.142        0.202        0.172       0.0266      0.00177


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              65 1390.880    0.005     6.16e-05     4.21e-07      6.2e-05        0.164        0.226        0.114        0.222        0.168        0.152        0.289         0.22        0.225        0.015
! Validation         65 1390.880    0.005     4.33e-05      7.4e-09     4.33e-05        0.129         0.19       0.0901        0.174        0.132         0.13        0.241        0.185       0.0262      0.00175
Wall time: 1390.8809174099988
! Best model       65    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     66    10      7.5e-05     7.44e-05     5.94e-07        0.181        0.249        0.103        0.271        0.187        0.133        0.335        0.234        0.334       0.0223
     66    20     5.07e-05     5.06e-05     6.25e-08        0.155        0.205        0.114        0.203        0.158        0.144        0.258        0.201        0.103      0.00688
     66    30     5.92e-05     5.88e-05     4.18e-07        0.155        0.221         0.11        0.206        0.158        0.148        0.282        0.215        0.275       0.0183
     66    40     7.11e-05     7.06e-05     5.79e-07        0.174        0.242        0.135        0.218        0.176        0.189        0.292         0.24        0.322       0.0215
     66    50     4.29e-05     4.28e-05     1.44e-07         0.14        0.189       0.0973        0.188        0.143        0.134        0.236        0.185        0.162       0.0108
     66    60     6.64e-05     6.58e-05     5.69e-07        0.165        0.234        0.148        0.183        0.166        0.213        0.256        0.234        0.322       0.0215
     66    70     5.28e-05     5.27e-05     1.46e-08        0.148        0.209       0.0968        0.207        0.152        0.134        0.271        0.203       0.0406      0.00271
     66    80     3.61e-05     3.61e-05     9.96e-09        0.126        0.173       0.0763        0.182        0.129        0.101         0.23        0.165       0.0375       0.0025
     66    90     6.27e-05     6.16e-05     1.02e-06        0.168        0.226        0.126        0.216        0.171        0.166         0.28        0.223        0.434        0.029
     66   100     4.38e-05     4.38e-05     4.34e-08        0.145        0.191       0.0989        0.198        0.148        0.128        0.244        0.186       0.0875      0.00583
     66   110     5.89e-05     5.89e-05      2.1e-08        0.163        0.221        0.113         0.22        0.167        0.149        0.282        0.215       0.0531      0.00354
     66   120     3.41e-05     3.41e-05     7.23e-08        0.128        0.168       0.0851        0.177        0.131        0.106        0.219        0.162        0.109      0.00729
     66   130     4.44e-05     4.44e-05     8.48e-10        0.144        0.192       0.0775        0.219        0.148       0.0968        0.261        0.179       0.0125     0.000833
     66   140     6.24e-05     6.13e-05     1.13e-06        0.165        0.226        0.111        0.226        0.169        0.137        0.296        0.217        0.456       0.0304
     66   150     6.46e-05     6.43e-05      2.9e-07        0.179        0.231        0.131        0.234        0.183        0.164         0.29        0.227        0.222       0.0148
     66   160     5.81e-05     5.78e-05     2.68e-07        0.171        0.219        0.126        0.223        0.174        0.157        0.274        0.215        0.228       0.0152
     66   170     6.32e-05     6.07e-05     2.43e-06        0.167        0.225        0.123        0.218         0.17        0.148        0.289        0.218        0.675        0.045
     66   180     3.06e-05     3.05e-05     6.95e-08        0.115        0.159        0.074        0.163        0.118       0.0979        0.208        0.153        0.106      0.00708
     66   190     5.25e-05     5.24e-05     1.24e-07        0.145        0.209        0.087        0.212         0.15        0.111        0.281        0.196         0.15         0.01

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     66     5      3.5e-05      3.5e-05     5.62e-09        0.122        0.171       0.0946        0.154        0.124        0.139        0.201         0.17       0.0281      0.00188


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              66 1412.375    0.005      5.7e-05     3.19e-07     5.73e-05        0.158        0.218        0.109        0.215        0.162        0.145        0.279        0.212        0.198       0.0132
! Validation         66 1412.375    0.005      4.3e-05      6.7e-09      4.3e-05        0.129        0.189       0.0897        0.174        0.132        0.129         0.24        0.184       0.0269      0.00179
Wall time: 1412.3763039409987
! Best model       66    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     67    10      5.2e-05     5.19e-05     9.73e-08        0.155        0.208        0.104        0.214        0.159        0.135        0.267        0.201        0.128      0.00854
     67    20     4.19e-05     4.18e-05     8.01e-08         0.14        0.187        0.109        0.175        0.142        0.141        0.227        0.184        0.116      0.00771
     67    30     4.18e-05     4.18e-05     4.45e-09        0.136        0.187       0.0945        0.182        0.138        0.122         0.24        0.181       0.0281      0.00188
     67    40      4.2e-05     4.19e-05     8.52e-08        0.149        0.187        0.136        0.163         0.15        0.174          0.2        0.187        0.116      0.00771
     67    50     0.000105     0.000105     2.91e-07        0.231        0.296        0.177        0.293        0.235        0.223        0.361        0.292        0.225        0.015
     67    60     4.83e-05     4.82e-05     7.54e-08        0.147          0.2       0.0972        0.205        0.151        0.123        0.262        0.192        0.109      0.00729
     67    70     5.52e-05      5.5e-05     2.81e-07        0.157        0.214        0.131        0.187        0.159        0.181        0.246        0.214        0.231       0.0154
     67    80     6.19e-05     6.19e-05     2.67e-08        0.161        0.227        0.114        0.214        0.164        0.147        0.293         0.22       0.0656      0.00438
     67    90     6.89e-05     6.89e-05     3.71e-08         0.16        0.239       0.0829        0.248        0.166         0.11         0.33         0.22       0.0656      0.00438
     67   100     4.65e-05     4.64e-05     5.19e-08        0.138        0.196       0.0898        0.194        0.142        0.128        0.253        0.191       0.0844      0.00562
     67   110     6.06e-05     6.05e-05     9.47e-08        0.165        0.224        0.106        0.232        0.169         0.14        0.292        0.216        0.134      0.00896
     67   120     5.42e-05     5.42e-05      4.3e-08        0.152        0.212        0.126        0.182        0.154        0.165        0.256         0.21       0.0719      0.00479
     67   130      5.3e-05      5.3e-05     5.83e-08        0.158         0.21        0.102        0.222        0.162        0.132        0.273        0.203       0.0969      0.00646
     67   140     0.000106     0.000106     7.51e-07        0.239        0.296        0.221         0.26        0.241        0.267        0.327        0.297        0.372       0.0248
     67   150     9.09e-05     9.05e-05     4.15e-07        0.217        0.274        0.174        0.266         0.22        0.217        0.328        0.272        0.275       0.0183
     67   160     0.000112     0.000111      7.3e-07        0.228        0.304        0.175        0.289        0.232        0.231         0.37          0.3        0.369       0.0246
     67   170      4.6e-05     4.59e-05     1.25e-07        0.131        0.195       0.0909        0.176        0.133        0.129        0.251         0.19        0.138      0.00917
     67   180     8.11e-05     8.09e-05     1.62e-07        0.179        0.259        0.119        0.247        0.183         0.18        0.327        0.254        0.166        0.011
     67   190     6.64e-05     6.49e-05     1.49e-06        0.171        0.232        0.117        0.233        0.175        0.147        0.302        0.224        0.522       0.0348

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     67     5     3.55e-05     3.55e-05     3.18e-09        0.122        0.172       0.0937        0.154        0.124        0.141        0.202        0.171       0.0203      0.00135


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              67 1433.924    0.005     5.96e-05     2.18e-07     5.98e-05        0.161        0.223        0.113        0.216        0.165        0.152        0.283        0.217        0.159       0.0106
! Validation         67 1433.924    0.005      4.3e-05     8.27e-09      4.3e-05        0.129        0.189       0.0888        0.174        0.132        0.127        0.241        0.184       0.0284       0.0019
Wall time: 1433.924350666999
! Best model       67    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     68    10     0.000123     0.000123     2.86e-08        0.236         0.32        0.168        0.315        0.241        0.216        0.408        0.312       0.0594      0.00396
     68    20     0.000156     0.000155     6.86e-07        0.267        0.359        0.209        0.334        0.272        0.268        0.441        0.354        0.363       0.0242
     68    30      9.3e-05     9.29e-05     3.01e-08        0.201        0.278        0.152        0.257        0.205        0.213        0.337        0.275       0.0656      0.00438
     68    40     6.11e-05     6.05e-05     5.34e-07        0.172        0.224        0.139        0.209        0.174        0.174         0.27        0.222        0.316        0.021
     68    50     5.02e-05     4.98e-05     4.37e-07         0.15        0.203        0.115        0.191        0.153        0.156        0.246        0.201        0.284        0.019
     68    60     4.01e-05        4e-05     6.48e-08        0.139        0.182        0.107        0.175        0.141        0.135        0.225         0.18        0.109      0.00729
     68    70     4.17e-05     4.17e-05     5.51e-09        0.135        0.186       0.0987        0.176        0.137         0.13        0.234        0.182       0.0281      0.00188
     68    80     9.24e-05     9.24e-05     1.23e-08        0.211        0.277        0.153        0.277        0.215        0.196        0.347        0.272       0.0469      0.00313
     68    90     9.41e-05     9.33e-05     7.68e-07        0.178        0.279       0.0891        0.279        0.184        0.113         0.39        0.251        0.378       0.0252
     68   100     0.000157     0.000155     1.13e-06        0.278         0.36        0.211        0.354        0.283        0.264        0.445        0.354        0.463       0.0308
     68   110     3.48e-05     3.44e-05     3.18e-07        0.126        0.169       0.0849        0.172        0.129        0.113        0.216        0.165        0.241        0.016
     68   120     6.44e-05     6.38e-05     6.18e-07        0.162         0.23        0.115        0.216        0.166        0.146        0.299        0.222        0.341       0.0227
     68   130      0.00013     0.000129     1.04e-06        0.236        0.328         0.19        0.288        0.239        0.264        0.388        0.326        0.441       0.0294
     68   140     4.57e-05     4.55e-05     2.32e-07        0.145        0.195       0.0971        0.199        0.148        0.131        0.248        0.189        0.206       0.0137
     68   150     6.93e-05     6.92e-05     1.18e-07        0.169         0.24        0.111        0.234        0.173        0.141        0.317        0.229        0.147      0.00979
     68   160     3.25e-05      3.2e-05      4.7e-07        0.121        0.163       0.0845        0.162        0.123        0.107         0.21        0.158        0.297       0.0198
     68   170     4.17e-05     4.11e-05     5.48e-07        0.135        0.185       0.0868         0.19        0.138        0.114        0.242        0.178        0.319       0.0212
     68   180     4.49e-05     4.43e-05     6.21e-07        0.148        0.192        0.106        0.195        0.151        0.133        0.243        0.188        0.344       0.0229
     68   190      4.9e-05      4.9e-05      1.5e-08         0.15        0.202        0.101        0.205        0.153        0.137        0.256        0.197         0.05      0.00333

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     68     5     3.53e-05     3.53e-05     4.34e-09        0.123        0.171       0.0941        0.156        0.125        0.141        0.201        0.171       0.0234      0.00156


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              68 1455.407    0.005     7.24e-05     5.12e-07      7.3e-05        0.177        0.245        0.123        0.239        0.181        0.164        0.314        0.239        0.256       0.0171
! Validation         68 1455.407    0.005     4.17e-05     8.03e-09     4.17e-05        0.128        0.186       0.0883        0.174        0.131        0.128        0.236        0.182       0.0278      0.00185
Wall time: 1455.4072802089995
! Best model       68    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     69    10     6.68e-05     6.67e-05     1.27e-07        0.185        0.236        0.145         0.23        0.187        0.181        0.286        0.233         0.15         0.01
     69    20     4.08e-05     4.08e-05     9.75e-09        0.134        0.184       0.0964        0.177        0.137        0.124        0.234        0.179       0.0375       0.0025
     69    30     5.16e-05     5.16e-05     4.47e-08        0.152        0.207       0.0999        0.211        0.155        0.133        0.268          0.2       0.0844      0.00563
     69    40     7.37e-05     7.27e-05     1.03e-06        0.168        0.246        0.108        0.236        0.172        0.179        0.305        0.242        0.431       0.0287
     69    50     3.61e-05     3.55e-05     5.78e-07        0.123        0.172       0.0827        0.169        0.126        0.111        0.222        0.166        0.328       0.0219
     69    60     4.41e-05     4.37e-05     3.71e-07        0.142        0.191       0.0999        0.189        0.144        0.131        0.241        0.186        0.259       0.0173
     69    70     5.34e-05     5.31e-05     3.09e-07         0.16         0.21        0.121        0.206        0.163        0.153        0.261        0.207        0.237       0.0158
     69    80     3.91e-05     3.77e-05     1.36e-06        0.128        0.177       0.0696        0.195        0.132       0.0901        0.241        0.165          0.5       0.0333
     69    90     5.32e-05     5.29e-05     3.62e-07        0.152         0.21       0.0856        0.228        0.157        0.112        0.282        0.197        0.259       0.0173
     69   100     4.19e-05     4.17e-05     1.32e-07        0.138        0.186       0.0922         0.19        0.141        0.119        0.241         0.18        0.147      0.00979
     69   110     3.89e-05     3.87e-05      1.7e-07        0.129        0.179       0.0904        0.174        0.132        0.117        0.231        0.174        0.175       0.0117
     69   120     3.95e-05     3.95e-05      8.9e-09        0.147        0.181        0.128        0.169        0.148        0.156        0.206        0.181       0.0312      0.00208
     69   130     4.07e-05     4.03e-05     4.57e-07        0.141        0.183       0.0986         0.19        0.144        0.126        0.232        0.179        0.291       0.0194
     69   140     3.96e-05     3.86e-05     9.86e-07        0.134        0.179       0.0925        0.182        0.137        0.116        0.231        0.174        0.425       0.0283
     69   150     4.21e-05     4.19e-05     2.37e-07        0.144        0.187       0.0981        0.197        0.148        0.123        0.239        0.181        0.206       0.0137
     69   160     6.12e-05      6.1e-05     1.27e-07        0.169        0.225       0.0958        0.252        0.174        0.122        0.303        0.212         0.15         0.01
     69   170     6.88e-05     6.86e-05     1.97e-07        0.159        0.239        0.112        0.213        0.162        0.163        0.303        0.233        0.191       0.0127
     69   180     5.18e-05      5.1e-05     7.67e-07        0.145        0.206       0.0949        0.203        0.149        0.127        0.269        0.198        0.375        0.025
     69   190     5.82e-05     5.69e-05      1.3e-06        0.163        0.218       0.0997        0.236        0.168         0.13        0.287        0.208        0.491       0.0327

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     69     5     3.39e-05     3.39e-05     4.45e-09         0.12        0.168       0.0915        0.152        0.122        0.135        0.198        0.167       0.0203      0.00135


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              69 1476.996    0.005     5.15e-05     2.45e-07     5.18e-05         0.15        0.207        0.104        0.203        0.154        0.139        0.264        0.202        0.172       0.0114
! Validation         69 1476.996    0.005     4.12e-05      8.9e-09     4.12e-05        0.127        0.185        0.088        0.171        0.129        0.127        0.234        0.181       0.0275      0.00183
Wall time: 1476.9963788299992
! Best model       69    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     70    10     7.48e-05     7.29e-05     1.96e-06        0.177        0.246        0.129        0.233        0.181        0.161        0.317        0.239          0.6         0.04
     70    20     6.45e-05     6.41e-05     3.33e-07        0.163        0.231        0.135        0.195        0.165        0.166        0.288        0.227        0.253       0.0169
     70    30     4.74e-05     4.73e-05     2.92e-08        0.142        0.198       0.0921        0.199        0.146        0.125        0.258        0.191       0.0656      0.00438
     70    40     4.98e-05     4.92e-05     5.31e-07        0.146        0.202       0.0975        0.201        0.149        0.134        0.259        0.197        0.312       0.0208
     70    50     5.74e-05     5.66e-05     8.48e-07        0.162        0.217        0.104        0.229        0.167        0.139        0.281         0.21        0.397       0.0265
     70    60      7.1e-05     7.09e-05     1.03e-07        0.184        0.243        0.149        0.225        0.187        0.197        0.286        0.242        0.131      0.00875
     70    70     5.88e-05     5.83e-05      5.6e-07        0.158         0.22       0.0997        0.224        0.162        0.128        0.292         0.21        0.322       0.0215
     70    80     5.47e-05     5.45e-05     1.85e-07        0.155        0.213        0.116          0.2        0.158        0.158        0.262         0.21        0.191       0.0127
     70    90     2.97e-05     2.94e-05     3.06e-07        0.121        0.156        0.103        0.141        0.122        0.125        0.186        0.155        0.231       0.0154
     70   100     3.02e-05        3e-05     1.74e-07        0.118        0.158       0.0875        0.153         0.12         0.11        0.199        0.154        0.181       0.0121
     70   110     5.57e-05     5.56e-05     9.88e-08        0.154        0.215        0.107        0.208        0.158        0.136        0.279        0.208        0.131      0.00875
     70   120     5.18e-05     5.09e-05     9.13e-07        0.149        0.206       0.0867         0.22        0.154        0.109        0.278        0.193        0.416       0.0277
     70   130      5.1e-05      5.1e-05      3.5e-08        0.146        0.206       0.0941        0.206         0.15        0.122        0.272        0.197       0.0625      0.00417
     70   140     3.72e-05     3.71e-05     6.36e-10        0.131        0.176       0.0932        0.174        0.134        0.119        0.223        0.171      0.00938     0.000625
     70   150     3.75e-05     3.75e-05     2.31e-08        0.125        0.177       0.0912        0.163        0.127        0.123        0.223        0.173       0.0469      0.00313
     70   160     3.35e-05     3.35e-05     2.33e-09        0.123        0.167       0.0849        0.167        0.126        0.107        0.216        0.161       0.0219      0.00146
     70   170     3.97e-05      3.9e-05     7.27e-07         0.13         0.18       0.0814        0.185        0.133         0.11        0.236        0.173        0.363       0.0242
     70   180     3.79e-05     3.78e-05     9.18e-08        0.127        0.177       0.0895         0.17         0.13        0.129         0.22        0.174        0.125      0.00833
     70   190     4.81e-05     4.63e-05     1.86e-06        0.145        0.196        0.108        0.187        0.147        0.136        0.248        0.192        0.584        0.039

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     70     5     3.28e-05     3.28e-05     6.46e-09        0.117        0.165       0.0897        0.149        0.119        0.132        0.196        0.164       0.0281      0.00188


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              70 1498.368    0.005     5.33e-05     4.14e-07     5.37e-05        0.152         0.21        0.105        0.205        0.155        0.139         0.27        0.205        0.221       0.0148
! Validation         70 1498.368    0.005     4.06e-05      8.2e-09     4.06e-05        0.126        0.184       0.0872        0.169        0.128        0.126        0.233        0.179       0.0284       0.0019
Wall time: 1498.3696473479995
! Best model       70    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     71    10     2.02e-05     2.02e-05     1.17e-08       0.0903        0.129       0.0536        0.132       0.0929       0.0719        0.173        0.123       0.0375       0.0025
     71    20     4.26e-05     4.26e-05     3.45e-08        0.141        0.188        0.108         0.18        0.144        0.143        0.229        0.186       0.0688      0.00458
     71    30     3.37e-05     3.36e-05     1.08e-07        0.114        0.167       0.0777        0.156        0.117         0.11        0.215        0.162        0.138      0.00917
     71    40     7.09e-05     7.09e-05     1.27e-08        0.173        0.243        0.103        0.253        0.178        0.142        0.321        0.232       0.0437      0.00292
     71    50     4.96e-05     4.95e-05     1.31e-07        0.157        0.203        0.114        0.207         0.16        0.145        0.253        0.199        0.144      0.00958
     71    60     5.95e-05     5.85e-05     9.73e-07        0.158        0.221        0.113        0.209        0.161        0.152        0.279        0.216        0.425       0.0283
     71    70     6.97e-05     6.95e-05     1.22e-07        0.168         0.24        0.143        0.196         0.17        0.207        0.274         0.24         0.15         0.01
     71    80      5.4e-05     5.37e-05     3.11e-07        0.168        0.211         0.14          0.2         0.17         0.17         0.25         0.21        0.241        0.016
     71    90     8.97e-05     8.95e-05     1.22e-07        0.196        0.273        0.118        0.286        0.202        0.149        0.366        0.258        0.147      0.00979
     71   100     4.65e-05     4.64e-05     9.16e-08         0.14        0.196       0.0897        0.197        0.143        0.109        0.263        0.186        0.128      0.00854
     71   110      4.4e-05     4.29e-05     1.11e-06        0.131        0.189       0.0877        0.181        0.134        0.119        0.245        0.182        0.453       0.0302
     71   120     3.52e-05      3.5e-05     2.47e-07         0.13        0.171        0.104         0.16        0.132        0.133        0.205        0.169        0.216       0.0144
     71   130     9.89e-05     9.89e-05     5.21e-08        0.199        0.287       0.0959        0.317        0.207        0.136        0.394        0.265       0.0594      0.00396
     71   140     7.23e-05     7.17e-05     6.05e-07        0.178        0.244        0.113        0.253        0.183        0.154        0.317        0.236        0.331       0.0221
     71   150     5.75e-05     5.72e-05     2.82e-07        0.164        0.218        0.114        0.221        0.167        0.147        0.278        0.212        0.222       0.0148
     71   160     4.23e-05     4.17e-05     6.32e-07        0.138        0.186       0.0866        0.196        0.141        0.115        0.243        0.179        0.347       0.0231
     71   170      6.1e-05     6.03e-05     6.65e-07        0.158        0.224       0.0891        0.238        0.163        0.111        0.306        0.208        0.347       0.0231
     71   180     8.11e-05     7.99e-05     1.24e-06        0.178        0.258       0.0937        0.273        0.184        0.127        0.352         0.24        0.478       0.0319
     71   190     4.79e-05     4.72e-05     7.66e-07        0.146        0.198        0.109        0.188        0.149        0.136        0.251        0.193        0.375        0.025

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     71     5     3.25e-05     3.25e-05     6.46e-09        0.118        0.165        0.091        0.149         0.12        0.131        0.196        0.163       0.0281      0.00188


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              71 1519.362    0.005     5.63e-05     3.96e-07     5.67e-05        0.156        0.216        0.108        0.211         0.16        0.144        0.277         0.21        0.226       0.0151
! Validation         71 1519.362    0.005     4.05e-05     7.42e-09     4.05e-05        0.126        0.184       0.0866        0.171        0.129        0.124        0.234        0.179       0.0262      0.00175
Wall time: 1519.3628466440005
! Best model       71    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     72    10     7.04e-05        7e-05     3.84e-07        0.159        0.241       0.0941        0.233        0.163         0.13        0.325        0.227        0.266       0.0177
     72    20     6.55e-05     6.52e-05     2.71e-07        0.175        0.233        0.117        0.242        0.179         0.15        0.301        0.225        0.222       0.0148
     72    30     6.64e-05      6.6e-05      3.8e-07        0.175        0.234        0.115        0.243        0.179        0.143        0.307        0.225        0.259       0.0173
     72    40     4.27e-05     4.26e-05     7.35e-08        0.134        0.188       0.0962        0.178        0.137         0.13        0.238        0.184        0.116      0.00771
     72    50        6e-05     5.92e-05     7.86e-07        0.162        0.222        0.096        0.237        0.166        0.134        0.291        0.213        0.372       0.0248
     72    60     5.53e-05     5.49e-05     3.77e-07        0.148        0.214       0.0883        0.217        0.153        0.124        0.284        0.204        0.262       0.0175
     72    70     2.52e-05     2.52e-05     6.61e-08        0.108        0.145       0.0779        0.142         0.11        0.101        0.182        0.142        0.106      0.00708
     72    80     3.84e-05     3.84e-05     1.93e-08        0.129        0.179       0.0914        0.173        0.132        0.128        0.223        0.176       0.0562      0.00375
     72    90     3.98e-05     3.94e-05     3.96e-07        0.135        0.181       0.0959         0.18        0.138        0.123         0.23        0.177        0.269       0.0179
     72   100     4.65e-05     4.64e-05     7.78e-08        0.142        0.196       0.0873        0.204        0.145         0.11        0.263        0.186        0.116      0.00771
     72   110     5.86e-05     5.85e-05     7.63e-08        0.159        0.221         0.11        0.215        0.162        0.142        0.285        0.214        0.112       0.0075
     72   120     4.88e-05     4.85e-05     2.85e-07        0.153        0.201        0.109        0.204        0.156        0.142        0.252        0.197        0.222       0.0148
     72   130     3.46e-05     3.45e-05     4.05e-08        0.122        0.169       0.0845        0.165        0.125        0.111        0.218        0.165       0.0812      0.00542
     72   140     5.92e-05      5.9e-05     2.27e-07        0.165        0.221        0.113        0.224        0.169        0.147        0.284        0.215          0.2       0.0133
     72   150     6.08e-05     6.06e-05      1.4e-07        0.157        0.225       0.0842         0.24        0.162        0.116        0.304         0.21         0.15         0.01
     72   160     5.65e-05     5.57e-05     7.47e-07        0.163        0.215        0.104         0.23        0.167        0.134        0.281        0.207        0.369       0.0246
     72   170     4.78e-05     4.78e-05     6.57e-09        0.144        0.199        0.107        0.187        0.147        0.142        0.249        0.196       0.0281      0.00188
     72   180     0.000103     0.000103     6.26e-07         0.21        0.292        0.144        0.285        0.214         0.18        0.382        0.281        0.341       0.0227
     72   190      4.2e-05      4.2e-05     1.23e-08        0.132        0.187       0.0828        0.187        0.135         0.11        0.247        0.179       0.0437      0.00292

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     72     5     3.31e-05     3.31e-05     4.34e-09        0.119        0.166       0.0897        0.153        0.121        0.132        0.198        0.165        0.025      0.00167


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              72 1540.651    0.005     5.62e-05     2.63e-07     5.65e-05        0.157        0.216        0.109        0.212        0.161        0.145        0.276         0.21         0.18        0.012
! Validation         72 1540.651    0.005        4e-05     7.78e-09        4e-05        0.125        0.182       0.0858         0.17        0.128        0.123        0.232        0.178       0.0256      0.00171
Wall time: 1540.6520885749997
! Best model       72    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     73    10     7.09e-05     6.87e-05     2.19e-06        0.165        0.239          0.1        0.238        0.169        0.126        0.323        0.224        0.644       0.0429
     73    20     6.74e-05     6.74e-05     5.93e-09        0.169        0.237       0.0926        0.257        0.175        0.117        0.324         0.22       0.0312      0.00208
     73    30     6.22e-05     6.22e-05     2.97e-09        0.145        0.227        0.107        0.189        0.148        0.168         0.28        0.224       0.0219      0.00146
     73    40     4.19e-05     4.18e-05     8.92e-08         0.15        0.187        0.131        0.172        0.152        0.165        0.208        0.187        0.128      0.00854
     73    50     6.83e-05     6.82e-05     1.55e-07        0.172        0.238        0.096         0.26        0.178        0.125        0.322        0.223        0.166        0.011
     73    60     4.53e-05     4.52e-05     1.13e-07        0.142        0.194       0.0969        0.195        0.146        0.125         0.25        0.188        0.134      0.00896
     73    70     4.15e-05     4.14e-05     1.15e-07         0.14        0.186        0.102        0.183        0.142        0.129        0.234        0.182        0.138      0.00917
     73    80     4.07e-05     4.06e-05     1.15e-07        0.129        0.184       0.0861        0.178        0.132        0.116        0.239        0.177        0.141      0.00938
     73    90     5.14e-05     5.08e-05      6.3e-07        0.157        0.205        0.116        0.204         0.16         0.15        0.254        0.202        0.344       0.0229
     73   100     4.62e-05      4.6e-05     1.62e-07        0.139        0.196        0.086          0.2        0.143        0.113        0.259        0.186        0.162       0.0108
     73   110     4.33e-05      4.3e-05     2.47e-07        0.134        0.189       0.0886        0.185        0.137        0.111         0.25        0.181        0.213       0.0142
     73   120     4.24e-05     4.24e-05     9.32e-08        0.142        0.188        0.106        0.184        0.145        0.132        0.236        0.184        0.131      0.00875
     73   130     6.44e-05     6.42e-05     1.22e-07        0.175        0.231        0.132        0.224        0.178        0.171        0.285        0.228        0.147      0.00979
     73   140     4.24e-05     4.24e-05     7.21e-09        0.137        0.188       0.0884        0.193        0.141        0.116        0.246        0.181       0.0312      0.00208
     73   150     5.31e-05      5.3e-05     1.03e-07        0.156         0.21         0.11        0.209        0.159        0.144        0.266        0.205        0.131      0.00875
     73   160     9.88e-05     9.86e-05     1.81e-07        0.208        0.286        0.114        0.314        0.214        0.159        0.383        0.271        0.175       0.0117
     73   170     4.09e-05     4.01e-05     7.46e-07        0.144        0.183        0.114        0.179        0.146        0.141        0.221        0.181        0.369       0.0246
     73   180     6.46e-05     6.45e-05     1.81e-07        0.168        0.232        0.122         0.22        0.171        0.161        0.292        0.226        0.188       0.0125
     73   190      4.9e-05     4.87e-05     3.67e-07        0.144        0.201       0.0937        0.201        0.147        0.116        0.267        0.192        0.259       0.0173

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     73     5     3.29e-05     3.29e-05     4.24e-09        0.118        0.165       0.0901         0.15         0.12        0.132        0.196        0.164       0.0234      0.00156


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              73 1561.929    0.005     4.98e-05     2.91e-07     5.01e-05        0.147        0.203        0.102        0.199        0.151        0.135        0.261        0.198        0.183       0.0122
! Validation         73 1561.929    0.005     3.98e-05     8.94e-09     3.98e-05        0.125        0.182       0.0857        0.169        0.127        0.123        0.232        0.177       0.0266      0.00177
Wall time: 1561.9295292570005
! Best model       73    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     74    10     4.52e-05     4.52e-05     1.48e-08        0.139        0.194       0.0924        0.192        0.142        0.118        0.254        0.186       0.0469      0.00313
     74    20     4.81e-05      4.8e-05     8.46e-08        0.154          0.2         0.12        0.192        0.156        0.153        0.243        0.198        0.116      0.00771
     74    30     3.86e-05     3.86e-05     5.21e-08        0.136        0.179        0.096        0.182        0.139        0.132        0.221        0.176       0.0938      0.00625
     74    40     4.37e-05     4.36e-05     5.15e-08        0.149         0.19        0.124        0.177         0.15        0.157        0.223         0.19       0.0875      0.00583
     74    50     2.62e-05     2.62e-05     1.44e-08        0.117        0.148       0.0888        0.149        0.119         0.11        0.181        0.146       0.0375       0.0025
     74    60      7.9e-05     7.89e-05     4.11e-08        0.195        0.256         0.14        0.257        0.199        0.176        0.325         0.25       0.0844      0.00562
     74    70     2.44e-05     2.42e-05     2.09e-07        0.108        0.142       0.0823        0.138         0.11        0.105        0.175         0.14        0.197       0.0131
     74    80     3.51e-05     3.47e-05     4.08e-07        0.131         0.17       0.0971        0.169        0.133        0.125         0.21        0.167        0.278       0.0185
     74    90     4.42e-05     4.41e-05     8.01e-08        0.141        0.191       0.0911        0.198        0.144        0.111        0.254        0.182        0.116      0.00771
     74   100     3.05e-05     3.05e-05     4.15e-08        0.117        0.159       0.0868        0.151        0.119         0.11        0.201        0.156       0.0812      0.00542
     74   110     5.51e-05     5.47e-05     4.38e-07        0.146        0.213       0.0908        0.209         0.15        0.122        0.284        0.203        0.269       0.0179
     74   120     5.32e-05     5.31e-05     1.48e-07        0.155         0.21         0.11        0.206        0.158        0.137         0.27        0.204        0.159       0.0106
     74   130     7.99e-05     7.98e-05     1.11e-07        0.185        0.258        0.108        0.272         0.19        0.148        0.343        0.245        0.131      0.00875
     74   140      6.7e-05     6.63e-05     6.14e-07         0.17        0.235        0.109         0.24        0.174        0.135        0.312        0.223        0.334       0.0223
     74   150     3.11e-05     3.09e-05      1.1e-07        0.118         0.16       0.0868        0.153         0.12        0.112        0.202        0.157        0.141      0.00938
     74   160     5.96e-05     5.96e-05     1.38e-08        0.162        0.223         0.11        0.222        0.166        0.147        0.285        0.216       0.0375       0.0025
     74   170     4.01e-05     3.95e-05     6.08e-07        0.137        0.181       0.0957        0.185         0.14        0.117        0.234        0.175        0.338       0.0225
     74   180      3.2e-05     3.18e-05     1.45e-07        0.121        0.163       0.0765        0.172        0.124        0.104        0.211        0.157        0.159       0.0106
     74   190     6.18e-05      6.1e-05      8.2e-07        0.148        0.225        0.102          0.2        0.151        0.139        0.294        0.217        0.391        0.026

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     74     5     3.23e-05     3.23e-05     5.72e-09        0.117        0.164       0.0886         0.15         0.12         0.13        0.196        0.163       0.0281      0.00188


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              74 1583.563    0.005     4.76e-05     2.26e-07     4.78e-05        0.145        0.199        0.103        0.194        0.148        0.137        0.252        0.194        0.161       0.0107
! Validation         74 1583.563    0.005     3.92e-05     7.16e-09     3.92e-05        0.124        0.181       0.0847        0.168        0.126        0.122         0.23        0.176       0.0291      0.00194
Wall time: 1583.564102340999
! Best model       74    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     75    10      3.1e-05     3.02e-05     8.07e-07        0.125        0.159        0.112         0.14        0.126        0.142        0.176        0.159        0.387       0.0258
     75    20     6.71e-05      6.7e-05     8.88e-08        0.172        0.236        0.103        0.252        0.177        0.128        0.317        0.223        0.125      0.00833
     75    30     3.49e-05     3.38e-05     1.13e-06        0.123        0.168       0.0879        0.164        0.126         0.12        0.209        0.164        0.463       0.0308
     75    40     4.54e-05     4.46e-05     7.75e-07        0.147        0.193        0.105        0.195         0.15         0.13        0.245        0.188        0.381       0.0254
     75    50     3.97e-05     3.94e-05     3.29e-07        0.127        0.181       0.0939        0.165         0.13         0.12        0.232        0.176        0.244       0.0162
     75    60     3.21e-05      3.2e-05     1.14e-07        0.127        0.163       0.0933        0.166        0.129        0.118        0.203         0.16        0.141      0.00938
     75    70     2.79e-05     2.79e-05     3.77e-08        0.115        0.152       0.0773        0.158        0.118       0.0996        0.196        0.148       0.0781      0.00521
     75    80     4.21e-05     4.21e-05     4.66e-09        0.141        0.187        0.105        0.182        0.143        0.136        0.232        0.184        0.025      0.00167
     75    90      7.8e-05     7.64e-05     1.63e-06        0.179        0.252        0.119        0.248        0.183        0.169        0.322        0.245        0.553       0.0369
     75   100     6.03e-05     6.01e-05     1.32e-07         0.16        0.224        0.106        0.223        0.164        0.142         0.29        0.216        0.156       0.0104
     75   110      4.9e-05      4.8e-05     9.61e-07        0.152          0.2        0.119         0.19        0.154        0.146        0.247        0.197        0.419       0.0279
     75   120     4.09e-05     4.07e-05     2.34e-07        0.129        0.184        0.072        0.195        0.134       0.0981        0.248        0.173        0.203       0.0135
     75   130     6.34e-05     6.29e-05     4.97e-07        0.186        0.229        0.165        0.209        0.187        0.202        0.256        0.229          0.3         0.02
     75   140     2.98e-05     2.94e-05     3.85e-07        0.111        0.156       0.0774         0.15        0.114          0.1        0.202        0.151        0.266       0.0177
     75   150     5.51e-05      5.4e-05      1.1e-06        0.163        0.212        0.103        0.232        0.167        0.127        0.279        0.203         0.45         0.03
     75   160     5.46e-05     5.46e-05     1.53e-08        0.163        0.213        0.121         0.21        0.166        0.159        0.261         0.21       0.0437      0.00292
     75   170     4.91e-05      4.9e-05     4.13e-08        0.154        0.202        0.111        0.204        0.157        0.144        0.252        0.198       0.0844      0.00563
     75   180     6.01e-05     5.99e-05     1.52e-07        0.165        0.223        0.121        0.215        0.168        0.162        0.277         0.22        0.169       0.0113
     75   190     4.59e-05     4.56e-05     3.47e-07        0.151        0.195         0.12        0.186        0.153        0.156        0.231        0.194        0.253       0.0169

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     75     5     3.23e-05     3.23e-05     5.72e-09        0.117        0.164       0.0889         0.15        0.119        0.129        0.196        0.163       0.0297      0.00198


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              75 1605.014    0.005        5e-05     3.48e-07     5.04e-05        0.148        0.204        0.104        0.199        0.151        0.138         0.26        0.199        0.218       0.0145
! Validation         75 1605.014    0.005      3.9e-05     6.82e-09      3.9e-05        0.123         0.18        0.085        0.167        0.126        0.122        0.229        0.176       0.0262      0.00175
Wall time: 1605.0148634969992
! Best model       75    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     76    10     6.23e-05     6.23e-05     2.76e-09        0.165        0.228        0.106        0.232        0.169        0.128        0.304        0.216       0.0219      0.00146
     76    20     6.25e-05     6.25e-05     2.44e-08        0.166        0.228        0.104        0.236         0.17        0.135        0.301        0.218       0.0594      0.00396
     76    30     6.02e-05     5.96e-05     6.02e-07        0.161        0.223        0.119        0.209        0.164        0.157        0.279        0.218        0.334       0.0223
     76    40     4.22e-05     4.21e-05     1.93e-08        0.143        0.187        0.103        0.188        0.146        0.129        0.237        0.183       0.0469      0.00313
     76    50     3.44e-05     3.44e-05     2.69e-08        0.128        0.169       0.0873        0.174        0.131        0.115        0.215        0.165       0.0562      0.00375
     76    60     3.58e-05     3.52e-05     5.66e-07        0.125        0.171       0.0995        0.155        0.127        0.131        0.208        0.169        0.319       0.0213
     76    70     3.46e-05     3.46e-05     2.92e-08         0.13         0.17        0.104        0.161        0.132        0.129        0.207        0.168       0.0688      0.00458
     76    80     5.06e-05     5.06e-05     2.63e-08        0.159        0.205        0.134        0.188        0.161        0.166        0.242        0.204       0.0594      0.00396
     76    90     5.26e-05     5.22e-05     3.67e-07        0.143        0.208       0.0897        0.204        0.147         0.13        0.272        0.201        0.259       0.0173
     76   100     7.25e-05      7.2e-05     4.73e-07        0.187        0.245         0.15         0.23         0.19        0.195        0.291        0.243        0.291       0.0194
     76   110     3.46e-05     3.44e-05     1.88e-07        0.118        0.169       0.0954        0.143        0.119        0.145        0.193        0.169        0.191       0.0127
     76   120     3.88e-05     3.86e-05     2.72e-07        0.139        0.179        0.101        0.182        0.142         0.13        0.222        0.176        0.225        0.015
     76   130     5.36e-05     5.35e-05     1.85e-07        0.157        0.211        0.103        0.218         0.16        0.128        0.277        0.202        0.181       0.0121
     76   140     4.34e-05      4.3e-05     3.95e-07         0.14        0.189       0.0919        0.195        0.144        0.121        0.244        0.183        0.272       0.0181
     76   150     4.03e-05     4.03e-05      8.9e-09        0.138        0.183       0.0944        0.188        0.141        0.124        0.233        0.178        0.025      0.00167
     76   160     5.01e-05     4.97e-05     4.41e-07        0.153        0.203        0.118        0.193        0.156         0.16        0.244        0.202        0.281       0.0188
     76   170      3.5e-05      3.5e-05     5.09e-08        0.121        0.171        0.079        0.169        0.124        0.102        0.225        0.163       0.0938      0.00625
     76   180     3.52e-05     3.51e-05     5.59e-08        0.129        0.171        0.111        0.149         0.13        0.142        0.199         0.17       0.0875      0.00583
     76   190     4.02e-05        4e-05     1.96e-07        0.127        0.182       0.0866        0.173         0.13         0.13        0.228        0.179        0.188       0.0125

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     76     5     3.29e-05     3.28e-05     5.72e-09        0.118        0.165       0.0893         0.15         0.12        0.133        0.196        0.164       0.0266      0.00177


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              76 1626.216    0.005     4.99e-05     2.27e-07     5.01e-05        0.148        0.204        0.105        0.198        0.151        0.139        0.258        0.199        0.171       0.0114
! Validation         76 1626.216    0.005     3.89e-05     7.65e-09     3.89e-05        0.123         0.18       0.0849        0.166        0.126        0.123        0.228        0.175       0.0278      0.00185
Wall time: 1626.2170666210004
! Best model       76    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     77    10     4.37e-05      4.3e-05     6.89e-07        0.146        0.189        0.102        0.195        0.149        0.133        0.238        0.185        0.353       0.0235
     77    20     5.51e-05     5.49e-05        2e-07         0.16        0.214        0.129        0.197        0.163        0.162         0.26        0.211        0.197       0.0131
     77    30     6.08e-05     6.08e-05     3.92e-08        0.161        0.225        0.105        0.225        0.165        0.143        0.292        0.217       0.0812      0.00542
     77    40     3.73e-05     3.71e-05     1.71e-07        0.126        0.176       0.0935        0.162        0.128        0.123        0.221        0.172        0.175       0.0117
     77    50     4.53e-05     4.49e-05     4.72e-07        0.144        0.193       0.0985        0.196        0.147        0.127        0.248        0.188        0.294       0.0196
     77    60     4.78e-05     4.62e-05     1.62e-06        0.145        0.196       0.0953        0.202        0.149        0.117        0.258        0.188        0.553       0.0369
     77    70     4.67e-05     4.64e-05     3.74e-07        0.146        0.196        0.102        0.196        0.149        0.129        0.252        0.191        0.259       0.0173
     77    80     4.36e-05     4.36e-05     1.57e-08        0.144         0.19       0.0919        0.203        0.147        0.119        0.248        0.184       0.0437      0.00292
     77    90     4.01e-05        4e-05      1.1e-07         0.13        0.182       0.0773        0.191        0.134       0.0991        0.245        0.172        0.138      0.00917
     77   100     6.23e-05     6.22e-05     1.25e-07        0.168        0.227        0.104        0.241        0.172        0.131        0.302        0.216        0.147      0.00979
     77   110     4.66e-05     4.65e-05     4.17e-08        0.142        0.197       0.0923        0.199        0.146         0.12        0.258        0.189        0.075        0.005
     77   120     4.47e-05     4.47e-05     6.57e-09         0.14        0.193       0.0887        0.199        0.144         0.11        0.256        0.183       0.0312      0.00208
     77   130     2.46e-05     2.44e-05     1.82e-07        0.102        0.142       0.0661        0.143        0.104       0.0828        0.189        0.136        0.184       0.0123
     77   140     5.24e-05     5.15e-05     9.62e-07        0.157        0.207        0.127         0.19        0.159        0.157        0.252        0.205        0.419       0.0279
     77   150     2.83e-05     2.79e-05     3.94e-07        0.117        0.152       0.0797        0.159        0.119        0.102        0.194        0.148        0.269       0.0179
     77   160     5.23e-05     5.23e-05      4.2e-08         0.16        0.208        0.124        0.201        0.163        0.153        0.258        0.205       0.0812      0.00542
     77   170     4.75e-05     4.75e-05     3.86e-08        0.146        0.199        0.102        0.197        0.149        0.129        0.256        0.193       0.0781      0.00521
     77   180     5.27e-05     5.26e-05     6.53e-08        0.155        0.209        0.112        0.205        0.158        0.149        0.262        0.205       0.0906      0.00604
     77   190     6.71e-05      6.7e-05     7.25e-08        0.176        0.236        0.127        0.232        0.179        0.162        0.299         0.23        0.106      0.00708

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     77     5     3.18e-05     3.18e-05     3.81e-09        0.117        0.163       0.0889        0.149        0.119        0.131        0.192        0.162       0.0172      0.00115


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              77 1647.435    0.005     4.86e-05     4.45e-07     4.91e-05        0.146        0.201        0.101        0.197        0.149        0.135        0.257        0.196        0.232       0.0155
! Validation         77 1647.435    0.005     3.81e-05     5.76e-09     3.81e-05        0.122        0.178       0.0846        0.165        0.125        0.122        0.226        0.174       0.0234      0.00156
Wall time: 1647.435427893999
! Best model       77    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     78    10     5.75e-05      5.7e-05     5.36e-07        0.158        0.218        0.101        0.223        0.162        0.132        0.286        0.209        0.312       0.0208
     78    20     8.03e-05     7.99e-05     4.09e-07        0.177        0.258       0.0975        0.269        0.183        0.124        0.353        0.239        0.266       0.0177
     78    30     4.54e-05     4.54e-05     1.34e-08        0.137        0.194        0.083        0.198        0.141        0.106        0.261        0.183       0.0437      0.00292
     78    40     3.24e-05     3.21e-05     2.51e-07        0.123        0.163       0.0855        0.166        0.126        0.109        0.209        0.159        0.209        0.014
     78    50     3.04e-05        3e-05     3.53e-07        0.122        0.158          0.1        0.147        0.124        0.125        0.189        0.157        0.256       0.0171
     78    60     5.01e-05     5.01e-05     1.48e-08        0.139        0.204        0.104        0.179        0.142        0.148        0.253        0.201       0.0437      0.00292
     78    70     5.99e-05     5.97e-05     1.88e-07        0.168        0.223        0.117        0.227        0.172        0.149        0.285        0.217        0.184       0.0123
     78    80     3.77e-05     3.77e-05     1.99e-08        0.135        0.177       0.0875         0.19        0.139        0.108        0.232         0.17       0.0594      0.00396
     78    90     4.14e-05     4.12e-05      1.4e-07        0.131        0.185       0.0795         0.19        0.135        0.101        0.249        0.175        0.156       0.0104
     78   100     7.38e-05     7.38e-05     8.48e-09        0.171        0.248        0.113        0.237        0.175         0.15        0.325        0.238       0.0375       0.0025
     78   110     5.67e-05     5.67e-05     1.74e-08        0.163        0.217        0.121         0.21        0.166        0.151        0.274        0.212       0.0375       0.0025
     78   120     5.65e-05     5.65e-05     1.97e-08        0.159        0.217       0.0991        0.227        0.163        0.125        0.288        0.206         0.05      0.00333
     78   130     5.66e-05     5.64e-05     2.35e-07        0.149        0.217       0.0861        0.222        0.154        0.119         0.29        0.205        0.203       0.0135
     78   140     4.95e-05     4.92e-05     2.42e-07        0.148        0.202        0.108        0.195        0.151        0.148        0.251        0.199        0.216       0.0144
     78   150     5.99e-05     5.97e-05     2.37e-07        0.167        0.223        0.108        0.235        0.172        0.142        0.288        0.215        0.206       0.0137
     78   160      5.3e-05      5.3e-05     1.02e-08        0.149         0.21        0.074        0.235        0.155        0.095         0.29        0.193       0.0375       0.0025
     78   170      5.4e-05      5.4e-05     4.03e-09        0.149        0.212        0.084        0.224        0.154         0.11        0.287        0.199       0.0156      0.00104
     78   180     5.59e-05     5.57e-05     1.83e-07        0.158        0.215        0.112         0.21        0.161        0.141        0.277        0.209        0.188       0.0125
     78   190     5.08e-05     5.06e-05     1.86e-07        0.147        0.205        0.101        0.199         0.15        0.138        0.261          0.2        0.172       0.0115

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     78     5     3.12e-05     3.12e-05     5.19e-09        0.115        0.161       0.0864        0.148        0.117        0.128        0.192         0.16       0.0266      0.00177


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              78 1668.636    0.005     5.13e-05     2.42e-07     5.16e-05        0.147        0.207       0.0979        0.203         0.15         0.13        0.269        0.199        0.176       0.0117
! Validation         78 1668.636    0.005     3.72e-05      7.5e-09     3.72e-05        0.121        0.176       0.0832        0.164        0.124         0.12        0.223        0.172       0.0278      0.00185
Wall time: 1668.6364478319992
! Best model       78    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     79    10     6.27e-05     6.24e-05     2.73e-07        0.166        0.228        0.096        0.246        0.171        0.121        0.308        0.214        0.222       0.0148
     79    20     2.92e-05     2.92e-05     1.78e-08        0.114        0.156       0.0851        0.147        0.116        0.109        0.196        0.153       0.0437      0.00292
     79    30     3.09e-05     3.09e-05     2.14e-08        0.115         0.16       0.0806        0.155        0.118        0.108        0.205        0.156         0.05      0.00333
     79    40     4.92e-05      4.9e-05     1.58e-07        0.152        0.202       0.0989        0.212        0.155        0.129        0.262        0.195        0.172       0.0115
     79    50     4.34e-05     4.33e-05     1.31e-07        0.143         0.19        0.101        0.191        0.146        0.128        0.242        0.185        0.153       0.0102
     79    60     7.53e-05     7.51e-05     1.55e-07        0.173         0.25        0.109        0.246        0.177        0.144        0.332        0.238        0.169       0.0112
     79    70     3.66e-05     3.64e-05     2.87e-07         0.12        0.174       0.0914        0.152        0.122        0.128        0.215        0.171        0.225        0.015
     79    80     5.77e-05     5.77e-05     2.44e-08        0.165        0.219        0.133        0.202        0.168        0.181        0.256        0.218       0.0469      0.00313
     79    90     5.65e-05     5.65e-05     9.75e-09        0.151        0.217       0.0978        0.211        0.155        0.124        0.288        0.206       0.0312      0.00208
     79   100     3.89e-05     3.89e-05     3.26e-08        0.132         0.18       0.0806         0.19        0.135        0.102        0.239        0.171       0.0688      0.00458
     79   110     4.42e-05      4.4e-05     1.46e-07        0.139        0.191       0.0931        0.192        0.143        0.128        0.244        0.186        0.166        0.011
     79   120     4.57e-05     4.57e-05      3.9e-08         0.14        0.195       0.0863        0.201        0.144        0.117        0.256        0.187        0.075        0.005
     79   130     5.75e-05     5.74e-05     6.99e-08        0.165        0.219        0.116         0.22        0.168        0.148        0.278        0.213        0.106      0.00708
     79   140     4.95e-05     4.95e-05     7.29e-08        0.143        0.203       0.0878        0.206        0.147        0.121        0.268        0.194          0.1      0.00667
     79   150     4.41e-05      4.4e-05     1.12e-07        0.152        0.191        0.121        0.187        0.154        0.153        0.227         0.19        0.144      0.00958
     79   160     4.43e-05     4.43e-05     9.75e-09        0.136        0.192       0.0903        0.187        0.139        0.117        0.252        0.184       0.0312      0.00208
     79   170     4.37e-05     4.36e-05     6.61e-08        0.139         0.19       0.0917        0.193        0.143        0.122        0.246        0.184       0.0969      0.00646
     79   180     5.56e-05     5.56e-05        5e-08        0.159        0.215        0.104        0.222        0.163        0.131        0.282        0.207       0.0969      0.00646
     79   190     5.22e-05      5.2e-05     2.35e-07         0.16        0.208        0.113        0.214        0.164        0.138        0.267        0.202        0.206       0.0137

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     79     5      3.1e-05      3.1e-05     3.71e-09        0.115        0.161       0.0861        0.147        0.117        0.127        0.192        0.159       0.0219      0.00146


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              79 1690.561    0.005     4.57e-05     1.47e-07     4.58e-05        0.141        0.195       0.0965        0.192        0.144        0.128         0.25        0.189        0.135      0.00901
! Validation         79 1690.561    0.005     3.66e-05     5.17e-09     3.66e-05         0.12        0.174       0.0824        0.163        0.123        0.119        0.221         0.17       0.0222      0.00148
Wall time: 1690.561933948
! Best model       79    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     80    10     4.48e-05     4.31e-05     1.65e-06        0.146        0.189        0.113        0.182        0.148        0.141        0.233        0.187        0.556       0.0371
     80    20     4.61e-05      4.6e-05     1.13e-07        0.151        0.196        0.112        0.195        0.153        0.144        0.242        0.193        0.138      0.00917
     80    30     3.05e-05     3.04e-05     8.69e-08        0.109        0.159       0.0668        0.157        0.112       0.0918        0.211        0.151        0.125      0.00833
     80    40     2.62e-05     2.62e-05     5.02e-08        0.112        0.148       0.0921        0.134        0.113        0.123        0.171        0.147       0.0844      0.00563
     80    50     3.58e-05     3.54e-05     3.94e-07        0.125        0.172       0.0893        0.166        0.128        0.115        0.219        0.167        0.269       0.0179
     80    60     6.74e-05     6.74e-05     5.62e-08         0.17        0.237       0.0962        0.254        0.175         0.12        0.322        0.221       0.0969      0.00646
     80    70     5.08e-05     5.08e-05     7.42e-08        0.153        0.205        0.119        0.191        0.155         0.16        0.247        0.204        0.112       0.0075
     80    80     4.15e-05     4.07e-05     8.34e-07        0.135        0.184        0.101        0.175        0.138        0.126        0.233        0.179        0.394       0.0262
     80    90     3.86e-05     3.78e-05     8.83e-07        0.128        0.177       0.0864        0.176        0.131        0.114        0.229        0.171        0.406       0.0271
     80   100     4.39e-05     4.37e-05     1.74e-07        0.139        0.191       0.0981        0.185        0.142        0.127        0.244        0.185        0.178       0.0119
     80   110     3.09e-05     3.08e-05     5.23e-08         0.12         0.16       0.0822        0.164        0.123        0.103        0.207        0.155       0.0844      0.00562
     80   120     3.96e-05     3.94e-05     1.98e-07        0.137        0.181       0.0987         0.18        0.139        0.124        0.229        0.177        0.181       0.0121
     80   130     3.76e-05     3.64e-05     1.17e-06        0.121        0.174       0.0836        0.164        0.124        0.111        0.226        0.168        0.466        0.031
     80   140      4.7e-05     4.69e-05     1.34e-07        0.147        0.197        0.117        0.181        0.149        0.147        0.243        0.195        0.156       0.0104
     80   150     3.91e-05     3.91e-05     4.32e-08        0.126         0.18        0.072        0.188         0.13       0.0899        0.246        0.168       0.0812      0.00542
     80   160     0.000107     0.000105     2.25e-06        0.209        0.295        0.123        0.308        0.215        0.151        0.401        0.276         0.65       0.0433
     80   170     7.21e-05     7.14e-05     7.06e-07        0.184        0.244        0.128        0.248        0.188        0.161        0.312        0.237        0.356       0.0237
     80   180      5.2e-05     5.12e-05     7.68e-07        0.149        0.206        0.101        0.203        0.152        0.134        0.266          0.2        0.378       0.0252
     80   190     2.91e-05     2.87e-05     4.56e-07        0.114        0.154       0.0766        0.156        0.116        0.101        0.199         0.15        0.294       0.0196

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     80     5     3.06e-05     3.06e-05     5.51e-09        0.114         0.16       0.0869        0.145        0.116        0.128        0.189        0.159       0.0297      0.00198


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              80 1711.901    0.005     4.39e-05     3.25e-07     4.43e-05        0.139        0.191       0.0959        0.188        0.142        0.127        0.245        0.186        0.194       0.0129
! Validation         80 1711.901    0.005     3.67e-05     6.61e-09     3.67e-05         0.12        0.175       0.0831        0.162        0.123         0.12        0.221        0.171       0.0259      0.00173
Wall time: 1711.901268444999

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     81    10     6.95e-05     6.91e-05     3.21e-07        0.182         0.24        0.131        0.241        0.186        0.168        0.301        0.235        0.244       0.0163
     81    20     5.07e-05     5.07e-05     2.12e-09        0.153        0.205       0.0837        0.233        0.158        0.104        0.279        0.192       0.0188      0.00125
     81    30     4.13e-05      4.1e-05     2.58e-07        0.125        0.185        0.071        0.186        0.128       0.0937        0.251        0.172        0.216       0.0144
     81    40     5.37e-05     5.35e-05     2.45e-07        0.152        0.211        0.106        0.204        0.155        0.142        0.269        0.206        0.209        0.014
     81    50     3.92e-05     3.87e-05     4.51e-07        0.129        0.179       0.0869        0.178        0.132         0.11        0.235        0.172        0.281       0.0188
     81    60     2.34e-05     2.34e-05     5.09e-09        0.104         0.14       0.0802        0.131        0.106        0.107        0.169        0.138       0.0312      0.00208
     81    70      3.3e-05     3.29e-05     9.54e-08        0.118        0.165        0.076        0.165        0.121        0.106        0.214         0.16        0.131      0.00875
     81    80     3.27e-05     3.27e-05     4.24e-08        0.126        0.165        0.105        0.151        0.128        0.129        0.198        0.164       0.0812      0.00542
     81    90     4.18e-05     4.17e-05     4.75e-08        0.145        0.186        0.121        0.174        0.147        0.152        0.219        0.185       0.0844      0.00563
     81   100     2.82e-05     2.75e-05     6.86e-07        0.114        0.151       0.0872        0.145        0.116        0.114        0.185        0.149        0.363       0.0242
     81   110     3.48e-05     3.47e-05     9.92e-08        0.123         0.17       0.0856        0.165        0.126        0.109         0.22        0.164        0.125      0.00833
     81   120     2.71e-05     2.68e-05     2.25e-07        0.111        0.149       0.0833        0.143        0.113        0.114        0.182        0.148        0.206       0.0137
     81   130     3.31e-05     3.31e-05     2.54e-08        0.123        0.166       0.0942        0.156        0.125        0.123        0.204        0.163       0.0562      0.00375
     81   140     3.74e-05     3.67e-05     6.52e-07        0.132        0.175       0.0969        0.172        0.134        0.125        0.218        0.172        0.344       0.0229
     81   150     4.66e-05     4.66e-05     9.75e-09        0.144        0.197          0.1        0.194        0.147         0.13        0.252        0.191       0.0312      0.00208
     81   160     2.84e-05     2.77e-05      6.8e-07        0.114        0.152        0.076        0.156        0.116        0.101        0.194        0.147        0.353       0.0235
     81   170     3.73e-05     3.72e-05     6.99e-08        0.129        0.176       0.0858        0.179        0.132        0.113        0.227         0.17        0.112       0.0075
     81   180      5.3e-05     5.29e-05     6.48e-08        0.146         0.21       0.0987          0.2        0.149        0.134        0.272        0.203       0.0938      0.00625
     81   190     3.13e-05     3.12e-05     1.33e-07         0.12        0.161       0.0964        0.147        0.122        0.127        0.193         0.16        0.162       0.0108

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     81     5     3.11e-05     3.11e-05     5.51e-09        0.114        0.161       0.0865        0.146        0.116        0.128        0.191         0.16        0.025      0.00167


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              81 1733.066    0.005     4.47e-05     2.31e-07     4.49e-05         0.14        0.193       0.0965         0.19        0.143        0.128        0.247        0.187        0.167       0.0112
! Validation         81 1733.066    0.005     3.64e-05     6.29e-09     3.64e-05         0.12        0.174       0.0823        0.162        0.122        0.119        0.221         0.17       0.0234      0.00156
Wall time: 1733.0668482290002
! Best model       81    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     82    10     4.51e-05      4.4e-05     1.12e-06        0.147        0.191        0.124        0.173        0.149        0.158        0.223        0.191        0.456       0.0304
     82    20     4.02e-05     3.89e-05      1.4e-06        0.136         0.18        0.094        0.185        0.139        0.121        0.229        0.175        0.512       0.0342
     82    30     3.44e-05     3.42e-05     2.24e-07        0.125        0.169       0.0859        0.169        0.128        0.114        0.215        0.164        0.203       0.0135
     82    40      3.1e-05     3.07e-05     2.94e-07        0.117         0.16       0.0822        0.157         0.12        0.105        0.205        0.155        0.228       0.0152
     82    50     3.58e-05     3.55e-05     2.52e-07        0.139        0.172        0.109        0.172        0.141        0.132        0.208         0.17        0.213       0.0142
     82    60     3.64e-05     3.64e-05     2.44e-08        0.129        0.174        0.089        0.174        0.132        0.121        0.219         0.17       0.0688      0.00458
     82    70     2.74e-05      2.7e-05     4.25e-07        0.115         0.15       0.0958        0.137        0.117        0.116        0.181        0.148        0.278       0.0185
     82    80     7.96e-05     7.95e-05     5.62e-08        0.182        0.257       0.0996        0.276        0.188        0.137        0.347        0.242       0.0781      0.00521
     82    90     5.06e-05     5.04e-05     2.55e-07        0.141        0.205       0.0872        0.201        0.144        0.122         0.27        0.196        0.219       0.0146
     82   100     4.78e-05     4.76e-05     1.93e-07        0.152        0.199        0.111        0.199        0.155        0.137        0.252        0.194        0.188       0.0125
     82   110     2.97e-05     2.97e-05     1.42e-08        0.118        0.157       0.0905        0.149         0.12        0.122         0.19        0.156       0.0437      0.00292
     82   120     3.69e-05     3.68e-05     5.64e-08        0.124        0.175       0.0869        0.166        0.127        0.116        0.224         0.17       0.0938      0.00625
     82   130     6.12e-05     6.12e-05     1.99e-08        0.176        0.226        0.139        0.218        0.178        0.176        0.272        0.224       0.0531      0.00354
     82   140     4.51e-05     4.51e-05     1.34e-08        0.144        0.194        0.105         0.19        0.147        0.137        0.243         0.19       0.0469      0.00313
     82   150     5.71e-05     5.68e-05     2.57e-07        0.166        0.217        0.142        0.193        0.168        0.185        0.249        0.217        0.216       0.0144
     82   160     6.86e-05     6.86e-05      2.2e-08        0.179        0.239        0.123        0.243        0.183        0.165        0.302        0.233       0.0594      0.00396
     82   170     3.16e-05     3.15e-05     6.32e-08        0.121        0.162       0.0945        0.151        0.123        0.119          0.2        0.159        0.106      0.00708
     82   180     5.12e-05     5.11e-05     6.68e-08        0.156        0.206        0.118        0.199        0.158        0.147        0.258        0.202        0.109      0.00729
     82   190     5.67e-05     5.67e-05      3.2e-08        0.167        0.217        0.112        0.228         0.17        0.144        0.278        0.211       0.0688      0.00458

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     82     5     3.06e-05     3.06e-05     4.03e-09        0.113         0.16       0.0861        0.144        0.115        0.126        0.191        0.159       0.0234      0.00156


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              82 1754.526    0.005      4.7e-05     2.83e-07     4.73e-05        0.144        0.198          0.1        0.194        0.147        0.133        0.252        0.193        0.176       0.0117
! Validation         82 1754.526    0.005     3.59e-05     6.65e-09     3.59e-05        0.119        0.173       0.0822         0.16        0.121        0.118        0.219        0.169       0.0256      0.00171
Wall time: 1754.5274732790003
! Best model       82    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     83    10     5.21e-05     5.17e-05     3.69e-07         0.15        0.207       0.0907        0.217        0.154        0.121        0.275        0.198        0.259       0.0173
     83    20     4.75e-05     4.75e-05     1.27e-08        0.151        0.199         0.11        0.197        0.154        0.144        0.247        0.196       0.0437      0.00292
     83    30     3.43e-05     3.43e-05     2.92e-08        0.125        0.169       0.0801        0.176        0.128        0.103        0.221        0.162       0.0719      0.00479
     83    40     3.35e-05     3.35e-05     2.12e-09        0.122        0.167       0.0816        0.167        0.124        0.105        0.217        0.161       0.0188      0.00125
     83    50     2.76e-05     2.75e-05     6.38e-08        0.116        0.151       0.0778        0.161        0.119       0.0982        0.195        0.147        0.103      0.00687
     83    60     4.49e-05     4.49e-05     5.93e-09        0.144        0.193        0.105         0.19        0.147         0.14         0.24         0.19        0.025      0.00167
     83    70     6.15e-05     6.13e-05     2.02e-07        0.165        0.226        0.104        0.234        0.169        0.129          0.3        0.215        0.197       0.0131
     83    80      4.9e-05     4.89e-05     3.37e-08        0.145        0.202       0.0884        0.209        0.149        0.122        0.265        0.193       0.0594      0.00396
     83    90     3.62e-05     3.61e-05     1.07e-07        0.132        0.173       0.0865        0.184        0.135        0.106        0.227        0.166        0.134      0.00896
     83   100     7.78e-05     7.77e-05     4.26e-08        0.195        0.254        0.161        0.234        0.198        0.203        0.302        0.253       0.0844      0.00562
     83   110     4.63e-05     4.63e-05     2.44e-08        0.146        0.196        0.111        0.186        0.149        0.139        0.246        0.192       0.0625      0.00417
     83   120     3.11e-05     3.07e-05     4.17e-07        0.116         0.16        0.078        0.159        0.119        0.101        0.208        0.154        0.278       0.0185
     83   130     4.39e-05     4.39e-05     7.21e-09        0.142        0.191        0.108        0.182        0.145        0.145        0.233        0.189       0.0344      0.00229
     83   140     4.08e-05     4.02e-05     6.13e-07        0.143        0.183        0.116        0.174        0.145        0.148        0.216        0.182        0.334       0.0223
     83   150     2.89e-05     2.89e-05     2.48e-08        0.111        0.155       0.0767        0.151        0.114        0.105        0.197        0.151       0.0531      0.00354
     83   160     4.54e-05     4.53e-05     4.03e-09         0.14        0.194       0.0986        0.187        0.143        0.136        0.244         0.19       0.0219      0.00146
     83   170     3.38e-05     3.37e-05     1.52e-07        0.124        0.167       0.0856        0.167        0.126        0.107        0.217        0.162        0.162       0.0108
     83   180     3.81e-05     3.78e-05     2.76e-07         0.13        0.177       0.0756        0.191        0.134        0.104        0.235        0.169        0.225        0.015
     83   190     4.17e-05     4.13e-05     4.82e-07        0.139        0.185       0.0859          0.2        0.143        0.112        0.243        0.178        0.294       0.0196

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     83     5     2.94e-05     2.94e-05     4.56e-09        0.112        0.156       0.0852        0.142        0.113        0.124        0.187        0.155       0.0219      0.00146


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              83 1776.200    0.005     3.95e-05     1.79e-07     3.97e-05        0.133        0.181       0.0931        0.178        0.135        0.124         0.23        0.177        0.149      0.00993
! Validation         83 1776.200    0.005     3.54e-05     6.04e-09     3.54e-05        0.117        0.172       0.0815        0.159         0.12        0.117        0.217        0.167       0.0237      0.00158
Wall time: 1776.2011027949993
! Best model       83    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     84    10     4.37e-05     4.37e-05     6.55e-08        0.143        0.191       0.0935          0.2        0.147        0.118        0.249        0.183          0.1      0.00667
     84    20     9.53e-05     9.52e-05     1.24e-07          0.2        0.281         0.11        0.304        0.207        0.146        0.381        0.263        0.144      0.00958
     84    30     3.47e-05     3.46e-05     1.05e-07        0.128         0.17       0.0836        0.178        0.131        0.109        0.219        0.164        0.134      0.00896
     84    40     4.57e-05     4.57e-05     1.08e-08        0.149        0.195        0.108        0.196        0.152        0.138        0.244        0.191       0.0344      0.00229
     84    50     3.76e-05     3.75e-05     1.29e-07        0.135        0.177        0.103        0.172        0.137         0.13        0.218        0.174         0.15         0.01
     84    60      7.1e-05     7.08e-05     1.99e-07        0.187        0.243        0.166        0.212        0.189        0.214        0.272        0.243        0.188       0.0125
     84    70     6.45e-05     6.45e-05     5.19e-08        0.167        0.232        0.126        0.215         0.17        0.179         0.28        0.229       0.0938      0.00625
     84    80     9.29e-05     9.28e-05     6.57e-08        0.209        0.278        0.158        0.268        0.213        0.202        0.345        0.273        0.106      0.00708
     84    90     3.57e-05     3.52e-05     4.65e-07        0.128        0.171       0.0923        0.168         0.13        0.117        0.217        0.167        0.291       0.0194
     84   100     3.48e-05     3.46e-05     1.61e-07        0.128         0.17       0.0739         0.19        0.132       0.0954        0.227        0.161        0.169       0.0112
     84   110     3.86e-05     3.86e-05     4.66e-09        0.128        0.179       0.0825         0.18        0.131        0.111        0.234        0.172        0.025      0.00167
     84   120     5.95e-05     5.95e-05     1.34e-08        0.164        0.222          0.1        0.237        0.169        0.131        0.294        0.212       0.0406      0.00271
     84   130     3.94e-05     3.92e-05     1.72e-07        0.136        0.181       0.0993        0.179        0.139        0.133        0.223        0.178        0.181       0.0121
     84   140      3.1e-05      3.1e-05     1.12e-08         0.12        0.161       0.0841        0.161        0.123        0.106        0.206        0.156       0.0406      0.00271
     84   150     3.13e-05     3.09e-05      3.8e-07        0.123         0.16       0.0882        0.162        0.125        0.112        0.202        0.157        0.262       0.0175
     84   160     4.79e-05     4.79e-05     1.97e-08        0.143          0.2          0.1        0.193        0.146        0.124         0.26        0.192       0.0562      0.00375
     84   170      3.3e-05     3.29e-05     7.95e-08         0.12        0.165       0.0823        0.163        0.123        0.111        0.211        0.161        0.116      0.00771
     84   180     6.21e-05      6.2e-05     1.04e-07         0.17        0.227        0.108        0.242        0.175        0.134          0.3        0.217        0.138      0.00917
     84   190     2.97e-05     2.97e-05     2.84e-08        0.118        0.157       0.0771        0.165        0.121       0.0999        0.204        0.152       0.0656      0.00438

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     84     5     3.05e-05     3.05e-05     4.98e-09        0.113        0.159       0.0856        0.145        0.115        0.127         0.19        0.158       0.0188      0.00125


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              84 1798.316    0.005     4.61e-05     1.23e-07     4.62e-05        0.143        0.196       0.0988        0.193        0.146        0.132         0.25        0.191        0.122      0.00812
! Validation         84 1798.316    0.005     3.54e-05     6.21e-09     3.54e-05        0.117        0.172        0.081        0.158         0.12        0.117        0.217        0.167       0.0225       0.0015
Wall time: 1798.3165915509999

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     85    10      3.4e-05     3.39e-05     2.14e-08        0.123        0.168       0.0938        0.157        0.126        0.123        0.208        0.165       0.0625      0.00417
     85    20     4.39e-05     4.39e-05     2.54e-08        0.147        0.191        0.124        0.173        0.148        0.156        0.224         0.19       0.0531      0.00354
     85    30     6.33e-05     6.31e-05      1.9e-07        0.158        0.229        0.104        0.219        0.162        0.154        0.292        0.223        0.184       0.0123
     85    40     3.42e-05     3.42e-05     1.46e-08        0.129        0.169        0.101        0.161        0.131        0.135          0.2        0.168       0.0437      0.00292
     85    50     4.39e-05     4.39e-05     5.51e-08        0.138        0.191        0.095        0.188        0.141        0.119        0.249        0.184       0.0969      0.00646
     85    60     2.51e-05      2.5e-05     1.21e-07       0.0987        0.144       0.0667        0.135        0.101       0.0996        0.182        0.141         0.15         0.01
     85    70     6.21e-05     6.19e-05     2.05e-07        0.161        0.227       0.0945        0.237        0.166        0.121        0.306        0.213        0.175       0.0117
     85    80        3e-05     2.98e-05     2.08e-07         0.12        0.157       0.0847         0.16        0.122        0.111        0.197        0.154        0.197       0.0131
     85    90     3.72e-05     3.72e-05     1.42e-08        0.128        0.176       0.0912        0.171        0.131        0.124         0.22        0.172       0.0406      0.00271
     85   100     3.18e-05     3.15e-05     3.08e-07        0.128        0.162       0.0934        0.167         0.13        0.115        0.203        0.159        0.241        0.016
     85   110     2.79e-05     2.79e-05     4.73e-08        0.111        0.152       0.0878        0.137        0.112        0.117        0.185        0.151       0.0844      0.00563
     85   120     3.52e-05     3.52e-05     2.63e-08        0.129        0.171       0.0777        0.187        0.132       0.0964        0.228        0.162       0.0719      0.00479
     85   130     5.56e-05     5.53e-05     3.25e-07        0.156        0.214       0.0857        0.237        0.161        0.107        0.292          0.2        0.244       0.0162
     85   140     5.76e-05     5.76e-05     7.63e-08        0.157        0.219       0.0981        0.224        0.161        0.129        0.289        0.209       0.0969      0.00646
     85   150       0.0001       0.0001      7.8e-08        0.219        0.289        0.148          0.3        0.224        0.192        0.369        0.281       0.0938      0.00625
     85   160     6.02e-05        6e-05     1.49e-07        0.168        0.223        0.131        0.209         0.17        0.169        0.273        0.221        0.166        0.011
     85   170     6.18e-05     5.99e-05      1.9e-06        0.142        0.223       0.0735         0.22        0.147       0.0961         0.31        0.203        0.591       0.0394
     85   180     3.86e-05     3.86e-05     5.81e-08        0.135        0.179        0.096        0.179        0.138        0.125        0.226        0.175       0.0969      0.00646
     85   190     3.56e-05     3.54e-05     1.42e-07        0.124        0.172       0.0804        0.175        0.127        0.107        0.224        0.165        0.162       0.0108

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     85     5     2.99e-05     2.99e-05      3.5e-09        0.112        0.158       0.0849        0.143        0.114        0.126        0.188        0.157       0.0219      0.00146


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              85 1820.025    0.005     4.23e-05     2.39e-07     4.25e-05        0.136        0.188       0.0963        0.182        0.139        0.128        0.238        0.183        0.159       0.0106
! Validation         85 1820.025    0.005     3.49e-05      6.1e-09     3.49e-05        0.117         0.17       0.0808        0.158        0.119        0.117        0.216        0.166       0.0244      0.00163
Wall time: 1820.0260502759993
! Best model       85    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     86    10        3e-05     2.99e-05     1.06e-08        0.116        0.158       0.0827        0.154        0.119         0.11        0.199        0.154       0.0375       0.0025
     86    20     3.44e-05     3.41e-05     3.12e-07        0.126        0.168       0.0966         0.16        0.128        0.125        0.207        0.166        0.231       0.0154
     86    30     4.82e-05     4.79e-05     2.92e-07        0.148          0.2         0.11        0.191         0.15        0.151        0.244        0.197        0.231       0.0154
     86    40      3.6e-05     3.59e-05     5.89e-08        0.129        0.173       0.0962        0.167        0.131        0.127        0.214         0.17        0.103      0.00687
     86    50     3.79e-05     3.79e-05     4.45e-08        0.128        0.177        0.086        0.176        0.131         0.12        0.226        0.173       0.0781      0.00521
     86    60      2.9e-05     2.87e-05     3.77e-07         0.12        0.154       0.0869        0.157        0.122        0.113        0.191        0.152        0.269       0.0179
     86    70      4.1e-05     4.08e-05      2.2e-07        0.133        0.184       0.0889        0.184        0.136        0.116         0.24        0.178        0.197       0.0131
     86    80     3.04e-05     3.03e-05     6.91e-08        0.114        0.159       0.0767        0.157        0.117       0.0983        0.207        0.153        0.109      0.00729
     86    90     5.02e-05     4.97e-05     4.88e-07        0.151        0.203       0.0939        0.217        0.156        0.115        0.271        0.193          0.3         0.02
     86   100     7.77e-05     7.77e-05     6.99e-08        0.188        0.254        0.122        0.263        0.192        0.159        0.331        0.245        0.103      0.00687
     86   110     5.12e-05     5.09e-05     2.84e-07        0.145        0.206       0.0738        0.226         0.15          0.1        0.281        0.191        0.228       0.0152
     86   120     5.24e-05     5.18e-05     5.59e-07        0.146        0.208        0.107         0.19        0.149        0.152        0.257        0.204        0.316        0.021
     86   130     5.73e-05     5.64e-05     8.89e-07        0.152        0.217       0.0931        0.219        0.156         0.13        0.285        0.207          0.4       0.0267
     86   140     9.74e-05     9.67e-05     6.99e-07        0.205        0.284        0.115        0.307        0.211        0.151        0.382        0.267        0.359        0.024
     86   150     0.000135     0.000135     5.24e-07        0.263        0.335        0.176        0.362        0.269        0.215        0.433        0.324        0.312       0.0208
     86   160     4.63e-05     4.61e-05     2.05e-07        0.146        0.196         0.11        0.188        0.149        0.144        0.241        0.193        0.188       0.0125
     86   170     3.72e-05     3.72e-05     4.94e-08        0.135        0.176       0.0934        0.183        0.138        0.114        0.227         0.17       0.0812      0.00542
     86   180     3.58e-05     3.51e-05     7.12e-07        0.125        0.171       0.0968        0.158        0.127        0.133        0.205        0.169        0.366       0.0244
     86   190     3.12e-05      3.1e-05     2.63e-07        0.124        0.161       0.0905        0.161        0.126        0.117        0.199        0.158        0.222       0.0148

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     86     5     3.05e-05     3.05e-05      5.3e-09        0.113        0.159       0.0857        0.144        0.115        0.125        0.191        0.158       0.0234      0.00156


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              86 1841.369    0.005     4.89e-05      3.2e-07     4.92e-05        0.145        0.202       0.0979        0.199        0.148         0.13         0.26        0.195        0.202       0.0134
! Validation         86 1841.369    0.005      3.5e-05     6.25e-09      3.5e-05        0.117        0.171        0.081        0.159         0.12        0.117        0.216        0.167       0.0241       0.0016
Wall time: 1841.369284196

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     87    10     4.47e-05     4.47e-05     6.36e-09        0.148        0.193       0.0928         0.21        0.152        0.118        0.252        0.185       0.0219      0.00146
     87    20     5.23e-05     5.13e-05     1.03e-06        0.131        0.206       0.0721        0.199        0.136       0.0916        0.286        0.189        0.438       0.0292
     87    30     3.41e-05     3.31e-05     1.06e-06        0.123        0.166        0.101        0.147        0.124         0.14        0.191        0.166        0.444       0.0296
     87    40     4.27e-05     4.27e-05     1.27e-08        0.142        0.188       0.0947        0.196        0.145        0.126        0.241        0.183       0.0375       0.0025
     87    50     2.91e-05     2.91e-05     5.04e-08        0.118        0.155       0.0837        0.158        0.121        0.107        0.197        0.152        0.103      0.00687
     87    60     4.73e-05     4.72e-05     1.43e-07        0.144        0.198       0.0925        0.203        0.148        0.117        0.262        0.189        0.162       0.0108
     87    70     5.04e-05     4.96e-05     7.46e-07        0.142        0.203       0.0902        0.202        0.146        0.125        0.266        0.195        0.375        0.025
     87    80     3.43e-05     3.43e-05     4.66e-09        0.126        0.169       0.0774        0.181        0.129        0.107        0.219        0.163       0.0281      0.00188
     87    90     3.98e-05     3.95e-05     2.82e-07        0.132        0.181       0.0784        0.193        0.135        0.101        0.242        0.172        0.228       0.0152
     87   100     3.79e-05     3.74e-05     4.27e-07        0.128        0.176       0.0858        0.176        0.131        0.114        0.228        0.171        0.281       0.0188
     87   110     3.77e-05     3.74e-05     3.17e-07        0.131        0.176        0.106        0.159        0.133        0.139        0.211        0.175        0.244       0.0162
     87   120     3.65e-05     3.64e-05     9.73e-08        0.129        0.174       0.0865        0.178        0.132        0.111        0.226        0.168        0.128      0.00854
     87   130     4.15e-05     4.11e-05     4.17e-07        0.136        0.185        0.103        0.174        0.139         0.14        0.225        0.183        0.278       0.0185
     87   140     4.76e-05     4.74e-05     2.13e-07        0.135        0.199       0.0905        0.186        0.138        0.121        0.261        0.191        0.194       0.0129
     87   150     5.14e-05     5.14e-05     2.56e-08        0.147        0.207        0.104        0.197         0.15        0.141        0.262        0.202       0.0469      0.00313
     87   160     3.34e-05     3.32e-05     1.67e-07        0.124        0.166       0.0851        0.169        0.127        0.108        0.214        0.161        0.175       0.0117
     87   170     2.15e-05     2.09e-05     6.02e-07       0.0989        0.132       0.0782        0.123          0.1        0.102        0.159        0.131        0.341       0.0227
     87   180     3.74e-05     3.72e-05     1.74e-07         0.12        0.176       0.0762        0.169        0.123        0.105        0.232        0.168        0.175       0.0117
     87   190     6.93e-05     6.92e-05     2.18e-08        0.167         0.24        0.109        0.233        0.171        0.143        0.316         0.23       0.0594      0.00396

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     87     5     2.97e-05     2.97e-05     4.34e-09        0.111        0.157        0.084        0.143        0.113        0.123        0.189        0.156        0.025      0.00167


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              87 1862.340    0.005     4.61e-05     3.11e-07     4.64e-05        0.141        0.196       0.0959        0.193        0.144        0.128        0.252         0.19        0.189       0.0126
! Validation         87 1862.340    0.005     3.45e-05     6.65e-09     3.46e-05        0.116         0.17       0.0803        0.157        0.119        0.116        0.215        0.165       0.0256      0.00171
Wall time: 1862.340899929999
! Best model       87    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     88    10     2.23e-05     2.22e-05     9.37e-08       0.0996        0.136       0.0708        0.132        0.102       0.0893        0.174        0.132        0.125      0.00833
     88    20     4.81e-05     4.75e-05     6.08e-07        0.154        0.199        0.107        0.207        0.157        0.138        0.251        0.194        0.331       0.0221
     88    30      4.8e-05      4.8e-05     1.76e-08        0.133          0.2       0.0732        0.201        0.137       0.0921        0.275        0.184       0.0312      0.00208
     88    40     3.19e-05     3.18e-05     1.39e-07        0.123        0.163       0.0877        0.163        0.125        0.111        0.207        0.159        0.156       0.0104
     88    50     5.58e-05     5.58e-05     4.39e-08        0.151        0.215       0.0856        0.227        0.156        0.115         0.29        0.203       0.0844      0.00563
     88    60     4.13e-05     4.09e-05     4.18e-07        0.132        0.184       0.0856        0.185        0.135         0.11        0.243        0.177        0.278       0.0185
     88    70     5.24e-05     5.23e-05     1.09e-07        0.154        0.208        0.102        0.214        0.158        0.139        0.267        0.203        0.144      0.00958
     88    80     5.94e-05     5.93e-05     1.07e-07        0.159        0.222        0.093        0.233        0.163         0.12        0.299        0.209        0.141      0.00938
     88    90     5.34e-05     5.24e-05     1.01e-06        0.164        0.209        0.126        0.206        0.166        0.159        0.254        0.206        0.431       0.0288
     88   100     3.22e-05     3.19e-05     2.76e-07        0.119        0.163       0.0875        0.155        0.121         0.11        0.208        0.159        0.228       0.0152
     88   110      3.3e-05      3.3e-05      5.3e-09        0.122        0.166       0.0843        0.166        0.125        0.107        0.214         0.16        0.025      0.00167
     88   120     1.86e-05     1.86e-05     3.18e-09          0.1        0.124       0.0757        0.128        0.102       0.0904        0.154        0.122       0.0188      0.00125
     88   130     4.53e-05     4.48e-05     4.51e-07        0.149        0.193        0.101        0.203        0.152        0.132        0.245        0.188        0.287       0.0192
     88   140     5.95e-05     5.81e-05     1.35e-06         0.15         0.22       0.0863        0.223        0.155        0.107        0.301        0.204        0.506       0.0338
     88   150     6.63e-05     6.56e-05     7.06e-07         0.18        0.234        0.158        0.205        0.181        0.204        0.264        0.234        0.356       0.0237
     88   160      4.3e-05     4.27e-05     2.32e-07        0.144        0.189        0.106        0.186        0.146        0.137        0.234        0.186        0.209        0.014
     88   170      2.9e-05     2.86e-05     3.92e-07        0.113        0.154       0.0868        0.144        0.115        0.117        0.188        0.152        0.269       0.0179
     88   180      2.2e-05      2.2e-05     6.78e-09        0.101        0.135       0.0747         0.13        0.102       0.0988        0.167        0.133        0.025      0.00167
     88   190     3.01e-05     3.01e-05     1.08e-08        0.124        0.158       0.0979        0.154        0.126        0.123        0.191        0.157       0.0406      0.00271

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     88     5     2.92e-05     2.92e-05     4.13e-09        0.111        0.156       0.0844        0.141        0.113        0.125        0.185        0.155        0.025      0.00167


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              88 1883.972    0.005     4.53e-05     3.26e-07     4.56e-05         0.14        0.194       0.0956        0.191        0.143        0.127         0.25        0.188        0.204       0.0136
! Validation         88 1883.972    0.005     3.43e-05     7.01e-09     3.43e-05        0.116        0.169       0.0801        0.157        0.118        0.116        0.214        0.165       0.0272      0.00181
Wall time: 1883.9733754709996
! Best model       88    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     89    10     4.01e-05        4e-05     1.62e-07        0.139        0.182          0.1        0.183        0.142        0.129        0.228        0.179        0.169       0.0112
     89    20     4.56e-05     4.48e-05     7.91e-07        0.143        0.193       0.0902        0.203        0.146        0.121        0.251        0.186        0.381       0.0254
     89    30     4.17e-05     4.17e-05     3.62e-08        0.137        0.186       0.0928        0.188        0.141        0.125        0.238        0.181        0.075        0.005
     89    40     5.81e-05      5.8e-05     9.52e-08        0.154         0.22        0.089        0.228        0.159        0.117        0.296        0.207        0.131      0.00875
     89    50     4.54e-05     4.54e-05     5.17e-08        0.147        0.194        0.107        0.192         0.15        0.146        0.238        0.192       0.0844      0.00563
     89    60     7.57e-05     7.57e-05     1.29e-08        0.187        0.251        0.139        0.243        0.191        0.184         0.31        0.247       0.0469      0.00313
     89    70     3.56e-05     3.55e-05     1.43e-07         0.13        0.172       0.0885        0.178        0.133        0.113        0.221        0.167        0.159       0.0106
     89    80     6.15e-05      6.1e-05     4.74e-07        0.164        0.225        0.119        0.215        0.167         0.17        0.275        0.223        0.291       0.0194
     89    90     4.45e-05     4.44e-05      4.7e-08         0.14        0.192       0.0907        0.196        0.143        0.122        0.249        0.186       0.0938      0.00625
     89   100     2.62e-05      2.6e-05     2.31e-07        0.105        0.147       0.0712        0.143        0.107       0.0951         0.19        0.142        0.206       0.0138
     89   110     4.28e-05     4.24e-05     4.13e-07        0.134        0.188       0.0912        0.184        0.137        0.128        0.238        0.183        0.275       0.0183
     89   120     3.18e-05      3.1e-05     7.65e-07        0.118        0.161       0.0826        0.159        0.121        0.105        0.207        0.156        0.381       0.0254
     89   130     3.41e-05     3.41e-05     5.57e-08        0.124        0.168       0.0715        0.185        0.128       0.0924        0.226        0.159        0.103      0.00687
     89   140     4.08e-05     4.08e-05     5.53e-08        0.129        0.184       0.0843        0.181        0.133        0.111        0.242        0.177       0.0875      0.00583
     89   150     3.99e-05     3.98e-05     1.19e-07        0.138        0.182        0.105        0.176        0.141        0.135        0.223        0.179         0.15         0.01
     89   160      4.2e-05     4.17e-05     2.91e-07        0.136        0.186       0.0838        0.196         0.14        0.112        0.245        0.178        0.231       0.0154
     89   170     3.26e-05     3.26e-05     3.54e-08         0.12        0.165       0.0944         0.15        0.122        0.125        0.201        0.163       0.0781      0.00521
     89   180      3.6e-05     3.59e-05     6.74e-08        0.127        0.173          0.1        0.158        0.129        0.127        0.214         0.17        0.106      0.00708
     89   190     2.58e-05     2.58e-05     5.28e-08        0.111        0.146       0.0814        0.144        0.113        0.106        0.182        0.144          0.1      0.00667

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     89     5     2.98e-05     2.98e-05     4.03e-09        0.111        0.157       0.0842        0.142        0.113        0.124        0.188        0.156       0.0172      0.00115


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              89 1905.232    0.005     4.19e-05     2.27e-07     4.21e-05        0.136        0.187       0.0928        0.184        0.139        0.124        0.239        0.181        0.166       0.0111
! Validation         89 1905.232    0.005      3.4e-05     6.29e-09      3.4e-05        0.115        0.168       0.0798        0.156        0.118        0.116        0.213        0.164       0.0225       0.0015
Wall time: 1905.2330426789995
! Best model       89    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     90    10     4.48e-05     4.47e-05      3.6e-08        0.141        0.193       0.0937        0.196        0.145        0.131        0.245        0.188       0.0688      0.00458
     90    20     4.49e-05     4.48e-05      5.4e-08        0.144        0.193       0.0994        0.194        0.147        0.124         0.25        0.187       0.0969      0.00646
     90    30     4.03e-05     4.03e-05      8.9e-09         0.14        0.183       0.0965         0.19        0.143        0.125        0.232        0.179       0.0406      0.00271
     90    40     2.09e-05        2e-05     9.45e-07       0.0966        0.129       0.0769        0.119        0.098        0.101        0.154        0.128        0.422       0.0281
     90    50     2.87e-05     2.87e-05     5.34e-08        0.109        0.154       0.0716        0.153        0.112       0.0913        0.204        0.148       0.0969      0.00646
     90    60     3.75e-05     3.71e-05     3.75e-07        0.131        0.176        0.093        0.174        0.134        0.116        0.225        0.171        0.259       0.0173
     90    70     5.51e-05     5.44e-05     6.87e-07        0.154        0.213         0.12        0.192        0.156         0.17        0.253        0.211         0.35       0.0233
     90    80     3.28e-05     3.22e-05     5.46e-07        0.118        0.164       0.0722         0.17        0.121       0.0964        0.216        0.156        0.312       0.0208
     90    90     3.13e-05     3.12e-05     2.16e-08         0.12        0.161       0.0849         0.16        0.123         0.11        0.205        0.157       0.0594      0.00396
     90   100     4.74e-05     4.73e-05     6.25e-08        0.149        0.198         0.11        0.194        0.152        0.151        0.241        0.196        0.106      0.00708
     90   110     2.46e-05     2.46e-05     1.25e-08          0.1        0.143       0.0678        0.137        0.103       0.0954        0.183        0.139       0.0406      0.00271
     90   120     3.72e-05     3.71e-05     8.75e-08        0.133        0.176       0.0947        0.176        0.136        0.122        0.222        0.172        0.122      0.00813
     90   130     7.95e-05     7.86e-05     8.97e-07        0.198        0.256        0.127         0.28        0.203        0.162        0.332        0.247        0.409       0.0273
     90   140     3.62e-05     3.58e-05     3.96e-07        0.126        0.173       0.0849        0.172        0.129        0.115        0.221        0.168        0.269       0.0179
     90   150     3.79e-05     3.65e-05     1.39e-06        0.119        0.174       0.0664         0.18        0.123        0.087        0.238        0.162        0.509        0.034
     90   160     5.06e-05     5.06e-05     2.33e-09        0.149        0.205       0.0958        0.211        0.153        0.127        0.268        0.197       0.0125     0.000833
     90   170     3.05e-05     3.04e-05      1.5e-08        0.116        0.159        0.081        0.157        0.119        0.106        0.204        0.155       0.0375       0.0025
     90   180     4.96e-05     4.94e-05     2.15e-07        0.144        0.203       0.0908        0.205        0.148        0.119        0.268        0.193        0.191       0.0127
     90   190     2.66e-05      2.6e-05     5.47e-07        0.114        0.147       0.0894        0.142        0.116        0.113        0.178        0.146        0.316        0.021

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     90     5     2.88e-05     2.88e-05     2.97e-09         0.11        0.155       0.0822        0.142        0.112         0.12        0.187        0.153       0.0172      0.00115


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              90 1926.707    0.005        4e-05      3.4e-07     4.03e-05        0.132        0.182       0.0915        0.179        0.135        0.122        0.233        0.177        0.207       0.0138
! Validation         90 1926.707    0.005     3.38e-05     5.64e-09     3.38e-05        0.115        0.168        0.079        0.156        0.117        0.115        0.212        0.164       0.0241       0.0016
Wall time: 1926.7079509920004
! Best model       90    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     91    10        4e-05     3.78e-05     2.19e-06        0.136        0.177       0.0993        0.179        0.139        0.125        0.222        0.174        0.644       0.0429
     91    20      2.4e-05      2.4e-05     9.11e-09        0.103        0.141       0.0705        0.139        0.105       0.0944         0.18        0.137       0.0312      0.00208
     91    30     3.71e-05     3.65e-05     5.99e-07        0.121        0.174       0.0784        0.169        0.124        0.107        0.228        0.168        0.331       0.0221
     91    40     2.39e-05     2.38e-05     1.15e-07        0.107        0.141        0.085        0.131        0.108        0.114        0.166         0.14        0.144      0.00958
     91    50     3.24e-05     3.15e-05     9.16e-07        0.118        0.162       0.0761        0.166        0.121       0.0981        0.212        0.155        0.412       0.0275
     91    60     2.11e-05     2.11e-05     6.36e-09        0.104        0.132       0.0892        0.121        0.105        0.113        0.152        0.132        0.025      0.00167
     91    70     4.98e-05     4.89e-05     8.45e-07        0.154        0.202        0.113          0.2        0.157        0.145        0.252        0.198        0.394       0.0262
     91    80     3.26e-05     3.26e-05     3.54e-08        0.124        0.165       0.0912        0.161        0.126        0.118        0.205        0.162        0.075        0.005
     91    90     2.82e-05     2.82e-05     3.77e-08        0.114        0.153       0.0781        0.155        0.117        0.101        0.197        0.149       0.0719      0.00479
     91   100     6.23e-05     6.23e-05     9.96e-09        0.163        0.228        0.101        0.235        0.168        0.128        0.304        0.216       0.0312      0.00208
     91   110     3.69e-05     3.68e-05     7.16e-08        0.134        0.175        0.113        0.159        0.136         0.14        0.208        0.174        0.112       0.0075
     91   120     4.22e-05     4.22e-05     4.24e-09        0.141        0.187       0.0968        0.191        0.144        0.122        0.241        0.182        0.025      0.00167
     91   130     3.25e-05     3.25e-05     6.78e-09        0.125        0.164       0.0861         0.17        0.128        0.111        0.209         0.16       0.0344      0.00229
     91   140     6.34e-05     6.32e-05     1.77e-07        0.181        0.229        0.142        0.226        0.184        0.178        0.277        0.227        0.175       0.0117
     91   150     3.37e-05     3.25e-05     1.21e-06        0.119        0.164        0.105        0.136        0.121        0.143        0.186        0.164        0.472       0.0315
     91   160     2.84e-05     2.83e-05     8.24e-08         0.12        0.153        0.104        0.138        0.121        0.127        0.179        0.153        0.122      0.00813
     91   170     3.78e-05     3.78e-05     2.59e-08        0.116        0.177       0.0663        0.173         0.12       0.0935         0.24        0.167       0.0656      0.00438
     91   180     8.49e-05     8.48e-05     1.03e-07        0.196        0.266        0.143        0.256          0.2        0.183        0.336         0.26        0.128      0.00854
     91   190      6.3e-05     6.29e-05     1.47e-07         0.17        0.229        0.116        0.231        0.174        0.145        0.297        0.221        0.162       0.0108

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     91     5     2.87e-05     2.87e-05     4.24e-09        0.109        0.155        0.081        0.142        0.111         0.12        0.187        0.153       0.0203      0.00135


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              91 1947.926    0.005     3.79e-05     3.18e-07     3.82e-05         0.13        0.178       0.0919        0.173        0.133        0.121        0.225        0.173        0.196       0.0131
! Validation         91 1947.926    0.005     3.37e-05        6e-09     3.37e-05        0.115        0.167       0.0792        0.155        0.117        0.115        0.212        0.163       0.0237      0.00158
Wall time: 1947.9268738909996
! Best model       91    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     92    10      3.7e-05      3.7e-05     2.39e-08        0.133        0.175        0.103        0.166        0.135        0.136        0.212        0.174       0.0625      0.00417
     92    20      2.9e-05     2.88e-05     1.69e-07        0.115        0.155       0.0878        0.145        0.117        0.116         0.19        0.153        0.181       0.0121
     92    30     4.37e-05     4.32e-05      4.4e-07        0.143         0.19       0.0885        0.205        0.147        0.113         0.25        0.182        0.281       0.0188
     92    40     3.97e-05     3.95e-05     2.09e-07        0.134        0.181       0.0949         0.18        0.137        0.129        0.227        0.178          0.2       0.0133
     92    50     3.82e-05     3.82e-05     1.65e-08        0.127        0.178       0.0807         0.18         0.13        0.111        0.232        0.172       0.0437      0.00292
     92    60     2.07e-05     2.05e-05     2.42e-07       0.0959         0.13       0.0659         0.13        0.098       0.0839        0.169        0.126        0.213       0.0142
     92    70     3.21e-05     3.19e-05      2.2e-07        0.125        0.163       0.0987        0.154        0.126        0.126        0.197        0.161        0.203       0.0135
     92    80     6.12e-05     6.08e-05     4.03e-07        0.165        0.225        0.119        0.219        0.169        0.153        0.285        0.219        0.275       0.0183
     92    90     3.49e-05     3.39e-05     9.93e-07        0.134        0.168        0.107        0.166        0.136         0.13        0.203        0.166        0.431       0.0287
     92   100      3.5e-05     3.41e-05     9.18e-07        0.128        0.168        0.088        0.174        0.131        0.108        0.218        0.163        0.416       0.0277
     92   110     4.52e-05      4.5e-05     1.79e-07        0.142        0.193         0.09        0.201        0.146        0.114        0.256        0.185        0.184       0.0123
     92   120      2.8e-05     2.76e-05     4.23e-07        0.113        0.151       0.0844        0.146        0.115         0.11        0.188        0.149        0.281       0.0188
     92   130     3.19e-05     3.19e-05     6.59e-08        0.117        0.163       0.0774        0.163         0.12       0.0999        0.213        0.156        0.106      0.00708
     92   140     3.85e-05      3.8e-05     5.59e-07        0.131        0.178        0.101        0.166        0.133        0.133        0.218        0.175        0.322       0.0215
     92   150     5.57e-05     5.53e-05     4.23e-07        0.153        0.214        0.105        0.209        0.157        0.145        0.273        0.209        0.278       0.0185
     92   160     4.72e-05     4.72e-05     4.03e-09        0.144        0.198       0.0971        0.198        0.148        0.124        0.258        0.191       0.0219      0.00146
     92   170     4.27e-05     4.24e-05     3.53e-07        0.145        0.188        0.113        0.181        0.147        0.144        0.227        0.186         0.25       0.0167
     92   180     3.46e-05     3.46e-05      1.1e-08        0.126         0.17       0.0825        0.177         0.13         0.12        0.212        0.166       0.0375       0.0025
     92   190     4.93e-05     4.93e-05     3.88e-08        0.145        0.202       0.0845        0.215         0.15        0.109        0.273        0.191       0.0812      0.00542

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     92     5      2.9e-05      2.9e-05     3.81e-09         0.11        0.155       0.0814        0.142        0.112        0.122        0.186        0.154       0.0203      0.00135


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              92 1969.253    0.005     4.06e-05     2.96e-07     4.09e-05        0.134        0.184       0.0939         0.18        0.137        0.124        0.234        0.179        0.193       0.0128
! Validation         92 1969.253    0.005     3.32e-05     5.49e-09     3.32e-05        0.113        0.166       0.0785        0.153        0.116        0.115         0.21        0.162       0.0222      0.00148
Wall time: 1969.2540199769992
! Best model       92    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     93    10     3.01e-05     3.01e-05     7.42e-09        0.117        0.158       0.0784        0.161         0.12        0.107        0.201        0.154       0.0281      0.00188
     93    20     5.33e-05     5.29e-05      3.9e-07        0.153         0.21        0.108        0.204        0.156        0.141        0.268        0.204        0.266       0.0177
     93    30     4.35e-05     4.32e-05     2.75e-07        0.131         0.19       0.0822        0.187        0.135        0.116        0.249        0.182        0.219       0.0146
     93    40      3.6e-05      3.6e-05     6.36e-09         0.12        0.173       0.0705        0.177        0.124       0.0918        0.233        0.163       0.0312      0.00208
     93    50     4.35e-05     4.35e-05     1.97e-08        0.147         0.19        0.108        0.193         0.15        0.134        0.239        0.186       0.0531      0.00354
     93    60     5.86e-05     5.72e-05     1.34e-06        0.143        0.218        0.094        0.198        0.146        0.137        0.284         0.21        0.497       0.0331
     93    70     3.91e-05      3.9e-05      1.6e-07        0.123         0.18       0.0788        0.173        0.126        0.106        0.238        0.172        0.172       0.0115
     93    80     2.43e-05     2.37e-05     6.13e-07        0.109         0.14       0.0765        0.145        0.111       0.0919         0.18        0.136        0.344       0.0229
     93    90     4.46e-05     4.46e-05     4.87e-09        0.136        0.193       0.0994        0.177        0.138        0.136        0.242        0.189        0.025      0.00167
     93   100     3.36e-05     3.27e-05     8.99e-07         0.12        0.165       0.0835        0.161        0.122        0.107        0.212         0.16        0.409       0.0273
     93   110     3.27e-05     3.27e-05     6.23e-08        0.116        0.165       0.0739        0.164        0.119       0.0966        0.218        0.157        0.103      0.00687
     93   120     5.93e-05     5.93e-05     8.48e-09        0.168        0.222        0.115        0.229        0.172        0.148        0.284        0.216       0.0312      0.00208
     93   130      3.3e-05     3.29e-05     1.13e-07        0.118        0.165       0.0764        0.166        0.121       0.0961        0.219        0.158        0.141      0.00938
     93   140     6.83e-05     6.82e-05     1.11e-07         0.17        0.238       0.0922        0.259        0.176        0.119        0.325        0.222        0.144      0.00958
     93   150      4.3e-05      4.3e-05     8.27e-09        0.131        0.189        0.077        0.193        0.135        0.097        0.257        0.177       0.0375       0.0025
     93   160     5.88e-05     5.87e-05     3.41e-08        0.154        0.221       0.0829        0.236        0.159        0.108        0.302        0.205       0.0625      0.00417
     93   170     2.85e-05     2.85e-05     8.27e-09        0.112        0.154       0.0725        0.157        0.115       0.0921        0.203        0.147       0.0406      0.00271
     93   180     3.18e-05     3.18e-05     2.97e-09        0.118        0.163       0.0744        0.168        0.121       0.0931        0.216        0.155       0.0219      0.00146
     93   190     3.88e-05     3.88e-05     5.72e-09        0.137         0.18        0.119        0.158        0.139        0.147        0.211        0.179       0.0344      0.00229

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     93     5     2.85e-05     2.85e-05     3.92e-09        0.109        0.154       0.0827         0.14        0.111        0.121        0.185        0.153        0.025      0.00167


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              93 1990.644    0.005      4.5e-05     2.22e-07     4.52e-05        0.139        0.193        0.094        0.191        0.142        0.124         0.25        0.187        0.161       0.0107
! Validation         93 1990.644    0.005     3.29e-05     4.96e-09     3.29e-05        0.113        0.165       0.0786        0.152        0.115        0.115        0.209        0.162       0.0234      0.00156
Wall time: 1990.645040067
! Best model       93    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     94    10        5e-05     4.99e-05     7.97e-08        0.146        0.204       0.0887        0.212         0.15        0.114        0.272        0.193        0.119      0.00792
     94    20      3.9e-05     3.88e-05     1.74e-07        0.131         0.18       0.0848        0.184        0.134         0.11        0.236        0.173        0.178       0.0119
     94    30     5.01e-05     4.98e-05     2.45e-07        0.144        0.204       0.0954          0.2        0.148        0.126        0.266        0.196        0.206       0.0137
     94    40     4.33e-05     4.32e-05     6.89e-08        0.142         0.19        0.087        0.205        0.146        0.108        0.252         0.18        0.103      0.00687
     94    50     6.21e-05     6.18e-05     3.66e-07        0.161        0.227        0.106        0.223        0.165        0.144        0.294        0.219         0.25       0.0167
     94    60      3.5e-05      3.5e-05     5.32e-08        0.121        0.171       0.0708        0.179        0.125       0.0912         0.23        0.161          0.1      0.00667
     94    70     4.98e-05     4.96e-05      1.9e-07        0.151        0.203       0.0982        0.211        0.155        0.128        0.264        0.196        0.184       0.0123
     94    80     2.34e-05     2.28e-05     5.29e-07        0.101        0.138       0.0644        0.143        0.104       0.0834        0.181        0.132        0.312       0.0208
     94    90     2.67e-05     2.63e-05     3.81e-07        0.112        0.148        0.081        0.148        0.114        0.101        0.188        0.144        0.262       0.0175
     94   100     4.62e-05     4.61e-05     8.73e-08        0.147        0.196       0.0961        0.204         0.15        0.128        0.252         0.19        0.119      0.00792
     94   110     5.71e-05      5.7e-05     3.03e-08         0.16        0.218        0.113        0.214        0.164         0.15        0.275        0.213       0.0688      0.00458
     94   120     3.88e-05     3.83e-05      4.6e-07        0.129        0.179        0.085        0.179        0.132        0.109        0.234        0.171        0.294       0.0196
     94   130     2.84e-05     2.83e-05     9.28e-08        0.117        0.153       0.0878         0.15        0.119        0.115        0.188        0.152        0.131      0.00875
     94   140     4.69e-05     4.68e-05     6.48e-08        0.149        0.197        0.117        0.185        0.151        0.168        0.226        0.197        0.103      0.00687
     94   150     4.38e-05     4.35e-05     2.87e-07        0.146         0.19        0.102        0.197        0.149        0.125        0.244        0.185        0.228       0.0152
     94   160     6.03e-05     5.92e-05     1.09e-06        0.151        0.222       0.0855        0.226        0.156        0.113        0.302        0.207         0.45         0.03
     94   170     4.66e-05     4.66e-05     1.76e-08        0.137        0.197       0.0709        0.213        0.142       0.0979        0.269        0.183       0.0375       0.0025
     94   180     3.03e-05     3.01e-05     1.65e-07        0.122        0.158       0.0835        0.165        0.124        0.105        0.202        0.154        0.178       0.0119
     94   190     2.56e-05     2.56e-05     3.79e-08         0.11        0.146       0.0728        0.152        0.112       0.0912         0.19        0.141       0.0844      0.00563

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     94     5     2.81e-05     2.81e-05     2.12e-09        0.107        0.153       0.0814        0.137        0.109        0.121        0.183        0.152       0.0188      0.00125


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              94 2012.034    0.005     4.25e-05     3.62e-07     4.28e-05        0.136        0.188       0.0925        0.186        0.139        0.123        0.242        0.182        0.217       0.0145
! Validation         94 2012.034    0.005     3.25e-05     4.68e-09     3.25e-05        0.112        0.164       0.0777        0.151        0.114        0.113        0.208        0.161       0.0203      0.00135
Wall time: 2012.034547207999
! Best model       94    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     95    10     3.96e-05     3.95e-05     1.47e-07        0.138        0.181        0.105        0.176         0.14         0.13        0.226        0.178        0.166        0.011
     95    20     4.17e-05     4.15e-05     2.09e-07         0.14        0.186       0.0921        0.196        0.144        0.117        0.242        0.179        0.203       0.0135
     95    30     3.63e-05      3.6e-05     2.62e-07        0.131        0.173       0.0934        0.174        0.134        0.119        0.219        0.169        0.219       0.0146
     95    40     3.99e-05     3.99e-05     3.88e-08        0.134        0.182        0.101        0.172        0.136        0.136        0.224         0.18       0.0781      0.00521
     95    50     3.04e-05     3.03e-05     1.45e-07        0.122        0.159       0.0872        0.162        0.124        0.108        0.202        0.155        0.162       0.0108
     95    60     2.68e-05     2.65e-05     2.78e-07        0.109        0.148       0.0787        0.144        0.111        0.109        0.183        0.146        0.225        0.015
     95    70     4.26e-05     4.26e-05      5.3e-09        0.137        0.188       0.0784        0.203        0.141        0.104        0.252        0.178       0.0281      0.00188
     95    80     3.63e-05     3.57e-05     5.79e-07        0.128        0.172       0.0832        0.178        0.131        0.112        0.222        0.167        0.328       0.0219
     95    90     3.13e-05     3.13e-05     1.06e-08        0.117        0.161       0.0769        0.162        0.119        0.107        0.207        0.157       0.0406      0.00271
     95   100     3.18e-05     3.18e-05     1.06e-08        0.123        0.163       0.0726         0.18        0.126       0.0886        0.219        0.154       0.0406      0.00271
     95   110     4.81e-05     4.78e-05     3.32e-07        0.147        0.199       0.0951        0.207        0.151        0.125        0.259        0.192        0.247       0.0165
     95   120     2.89e-05     2.88e-05     8.48e-08        0.112        0.155       0.0783         0.15        0.114        0.103        0.198         0.15        0.125      0.00833
     95   130     4.07e-05     4.06e-05     1.78e-07        0.136        0.184       0.0952        0.183        0.139        0.118        0.238        0.178        0.181       0.0121
     95   140     3.21e-05      3.2e-05     3.33e-08        0.121        0.163        0.092        0.155        0.124        0.123        0.199        0.161       0.0656      0.00438
     95   150      3.7e-05     3.62e-05     7.53e-07         0.14        0.174        0.124        0.158        0.141        0.154        0.193        0.174        0.372       0.0248
     95   160     6.51e-05     6.49e-05     1.49e-07        0.166        0.232       0.0854        0.259        0.172        0.115        0.317        0.216        0.156       0.0104
     95   170      4.2e-05     4.12e-05     8.92e-07        0.135        0.185       0.0792        0.199        0.139        0.111        0.243        0.177        0.409       0.0273
     95   180     0.000111     0.000111     2.06e-07        0.205        0.304       0.0974        0.329        0.213        0.133        0.421        0.277        0.188       0.0125
     95   190     3.72e-05     3.66e-05     5.39e-07        0.125        0.175       0.0845        0.171        0.128        0.112        0.226        0.169        0.316        0.021

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     95     5     2.75e-05     2.75e-05     2.97e-09        0.106        0.151       0.0805        0.136        0.108        0.119        0.181         0.15       0.0219      0.00146


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              95 2033.269    0.005     4.22e-05     2.12e-07     4.24e-05        0.137        0.187       0.0945        0.185         0.14        0.125        0.239        0.182        0.159       0.0106
! Validation         95 2033.269    0.005     3.22e-05     6.08e-09     3.22e-05        0.112        0.164       0.0776        0.151        0.115        0.113        0.207         0.16       0.0244      0.00163
Wall time: 2033.270165480999
! Best model       95    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     96    10     4.47e-05     4.42e-05     5.61e-07        0.136        0.192       0.0794        0.201         0.14        0.116        0.252        0.184        0.322       0.0215
     96    20     5.33e-05     5.32e-05     8.41e-08        0.143         0.21       0.0777        0.218        0.148        0.103        0.288        0.195        0.119      0.00792
     96    30     6.22e-05     6.16e-05     6.69e-07        0.172        0.226        0.116        0.236        0.176        0.139        0.296        0.217         0.35       0.0233
     96    40     6.01e-05        6e-05     6.17e-08        0.168        0.223        0.112        0.233        0.172        0.146        0.288        0.217       0.0969      0.00646
     96    50     5.03e-05     5.01e-05     2.04e-07         0.14        0.204       0.0761        0.212        0.144          0.1        0.279         0.19        0.197       0.0131
     96    60     5.95e-05     5.87e-05      7.6e-07        0.156        0.221       0.0885        0.233        0.161        0.116        0.299        0.207        0.369       0.0246
     96    70     4.49e-05     4.48e-05     1.74e-08        0.131        0.193       0.0784        0.191        0.135        0.101        0.261        0.181         0.05      0.00333
     96    80     5.57e-05     5.57e-05     1.67e-08         0.15        0.215       0.0915        0.217        0.154         0.12        0.288        0.204       0.0469      0.00313
     96    90     3.81e-05      3.8e-05     1.38e-07        0.138        0.178        0.108        0.172         0.14        0.143        0.211        0.177        0.156       0.0104
     96   100     3.82e-05     3.81e-05     9.32e-08        0.133        0.178       0.0881        0.184        0.136        0.111        0.232        0.172        0.128      0.00854
     96   110     3.68e-05     3.66e-05     1.65e-07        0.128        0.175       0.0899        0.172        0.131        0.119        0.221         0.17        0.175       0.0117
     96   120     4.34e-05      4.3e-05     3.86e-07        0.138        0.189       0.0864        0.198        0.142        0.107        0.252        0.179        0.269       0.0179
     96   130     3.42e-05      3.4e-05     1.79e-07        0.125        0.168       0.0785        0.178        0.128        0.099        0.222        0.161        0.178       0.0119
     96   140     4.08e-05     4.06e-05      1.6e-07        0.133        0.184       0.0901        0.183        0.136        0.112        0.241        0.177        0.166        0.011
     96   150     4.86e-05     4.86e-05      3.6e-09        0.143        0.201        0.107        0.184        0.146         0.16         0.24          0.2       0.0188      0.00125
     96   160     6.02e-05     6.01e-05     2.95e-08        0.163        0.224        0.108        0.225        0.167        0.136        0.293        0.215       0.0719      0.00479
     96   170     4.17e-05      4.1e-05     7.67e-07        0.126        0.185       0.0819        0.177        0.129        0.102        0.247        0.175        0.378       0.0252
     96   180     2.62e-05     2.61e-05     1.03e-07        0.112        0.147       0.0782        0.152        0.115       0.0966        0.189        0.143        0.134      0.00896
     96   190     1.96e-05     1.96e-05     1.23e-08        0.095        0.128       0.0744        0.119       0.0965       0.0955        0.157        0.126       0.0406      0.00271

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     96     5      2.8e-05      2.8e-05     4.24e-09        0.109        0.153       0.0815         0.14        0.111        0.121        0.182        0.152       0.0203      0.00135


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              96 2054.512    0.005     4.25e-05     2.61e-07     4.27e-05        0.135        0.188        0.091        0.186        0.139         0.12        0.243        0.182        0.187       0.0125
! Validation         96 2054.512    0.005     3.25e-05     6.74e-09     3.25e-05        0.113        0.164        0.078        0.153        0.115        0.113        0.208        0.161       0.0256      0.00171
Wall time: 2054.5135262149997

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     97    10     3.56e-05     3.55e-05     1.38e-07        0.127        0.172       0.0895        0.171         0.13         0.12        0.216        0.168        0.159       0.0106
     97    20     2.97e-05     2.91e-05     6.15e-07        0.116        0.156       0.0757        0.162        0.119       0.0944        0.204        0.149        0.341       0.0227
     97    30     5.08e-05     5.07e-05      1.3e-07         0.15        0.205       0.0981        0.208        0.153        0.133        0.265        0.199        0.156       0.0104
     97    40     4.97e-05     4.97e-05     1.06e-08         0.14        0.203       0.0758        0.213        0.145       0.0988        0.278        0.188       0.0344      0.00229
     97    50     2.99e-05     2.93e-05     6.74e-07        0.108        0.156        0.073        0.148        0.111       0.0951        0.205         0.15        0.356       0.0237
     97    60      4.4e-05     4.39e-05     1.36e-08        0.144        0.191       0.0936        0.201        0.148        0.118         0.25        0.184       0.0437      0.00292
     97    70     3.23e-05     3.23e-05     6.57e-09        0.114        0.164        0.071        0.163        0.117        0.097        0.216        0.157       0.0312      0.00208
     97    80     3.42e-05     3.33e-05     9.34e-07        0.123        0.166       0.0766        0.177        0.127        0.103        0.217         0.16        0.412       0.0275
     97    90     4.67e-05     4.67e-05     2.99e-08        0.144        0.197       0.0883        0.207        0.148        0.114        0.261        0.188       0.0625      0.00417
     97   100     3.51e-05      3.5e-05     5.76e-08        0.123        0.171       0.0716        0.182        0.127       0.0871        0.232        0.159       0.0969      0.00646
     97   110      2.6e-05      2.6e-05     2.12e-08         0.11        0.147       0.0784        0.147        0.113       0.0973        0.188        0.143       0.0562      0.00375
     97   120     3.41e-05     3.41e-05     1.31e-08        0.126        0.168       0.0958        0.161        0.129        0.124        0.208        0.166       0.0344      0.00229
     97   130     5.43e-05     5.42e-05     6.02e-08        0.165        0.212        0.117         0.22        0.168         0.15        0.266        0.208        0.103      0.00687
     97   140     2.04e-05        2e-05     3.61e-07          0.1        0.129       0.0765        0.128        0.102       0.0994        0.156        0.128        0.259       0.0173
     97   150     4.57e-05     4.55e-05     2.34e-07        0.137        0.195       0.0933        0.187         0.14        0.117        0.256        0.186        0.213       0.0142
     97   160     2.35e-05     2.35e-05     1.27e-08        0.104         0.14       0.0855        0.125        0.105        0.118        0.161         0.14       0.0375       0.0025
     97   170     3.43e-05     3.35e-05     7.23e-07        0.123        0.167       0.0814         0.17        0.126        0.102        0.219         0.16        0.366       0.0244
     97   180     3.33e-05     3.29e-05     4.51e-07         0.12        0.165         0.08        0.166        0.123        0.103        0.216        0.159        0.291       0.0194
     97   190     2.47e-05     2.47e-05     2.84e-08        0.107        0.143       0.0787        0.139        0.109        0.108        0.175        0.142       0.0719      0.00479

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     97     5     2.79e-05     2.79e-05     4.13e-09        0.108        0.152       0.0817        0.139         0.11        0.122        0.181        0.151       0.0219      0.00146


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              97 2076.834    0.005     3.57e-05     2.37e-07     3.59e-05        0.126        0.172       0.0872        0.169        0.128        0.116         0.22        0.168        0.168       0.0112
! Validation         97 2076.834    0.005     3.19e-05     6.19e-09     3.19e-05        0.112        0.163       0.0773        0.151        0.114        0.112        0.206        0.159       0.0231      0.00154
Wall time: 2076.834904194
! Best model       97    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     98    10     2.44e-05     2.43e-05     1.24e-07       0.0999        0.142        0.064        0.141        0.102       0.0904        0.184        0.137        0.147      0.00979
     98    20     3.66e-05     3.65e-05     6.93e-08        0.127        0.174       0.0828        0.178         0.13        0.117        0.222         0.17        0.103      0.00687
     98    30     5.09e-05     5.09e-05     3.14e-08        0.155        0.206        0.126        0.188        0.157        0.164        0.245        0.204       0.0656      0.00438
     98    40     2.16e-05     2.05e-05     1.14e-06        0.103        0.131       0.0897        0.118        0.104        0.111         0.15         0.13        0.463       0.0308
     98    50     2.75e-05     2.74e-05     8.03e-08        0.111        0.151        0.075        0.153        0.114       0.0947        0.196        0.146        0.112       0.0075
     98    60     3.43e-05     3.41e-05     1.52e-07        0.128        0.168       0.0988        0.161         0.13        0.132        0.202        0.167        0.169       0.0113
     98    70     4.34e-05     4.33e-05     5.32e-08        0.133         0.19       0.0762        0.197        0.137        0.098        0.257        0.178       0.0906      0.00604
     98    80     4.62e-05     4.62e-05     3.45e-08        0.148        0.196       0.0939        0.211        0.152        0.122        0.256        0.189       0.0781      0.00521
     98    90     3.75e-05      3.7e-05     4.06e-07        0.134        0.176         0.11         0.16        0.135        0.139         0.21        0.174        0.269       0.0179
     98   100     3.65e-05     3.65e-05     2.84e-08        0.128        0.174       0.0911        0.169         0.13        0.125        0.217        0.171       0.0719      0.00479
     98   110     2.18e-05     2.18e-05     2.76e-09       0.0989        0.135       0.0699        0.132        0.101       0.0885        0.173        0.131       0.0156      0.00104
     98   120      2.8e-05      2.8e-05     3.39e-09         0.11        0.153        0.075        0.149        0.112        0.102        0.195        0.149       0.0188      0.00125
     98   130     2.65e-05     2.59e-05     6.26e-07        0.102        0.147        0.057        0.153        0.105       0.0723          0.2        0.136        0.341       0.0227
     98   140     2.94e-05     2.94e-05     2.88e-08         0.12        0.156       0.0907        0.154        0.122        0.119         0.19        0.155       0.0656      0.00438
     98   150     6.63e-05     6.63e-05     8.05e-09         0.17        0.235       0.0949        0.256        0.175        0.124        0.317         0.22       0.0312      0.00208
     98   160        4e-05        4e-05     3.35e-08        0.131        0.182       0.0844        0.184        0.134        0.113        0.238        0.176       0.0719      0.00479
     98   170     2.98e-05     2.97e-05     4.96e-08        0.113        0.157       0.0738        0.158        0.116        0.101        0.203        0.152       0.0906      0.00604
     98   180     7.41e-05     7.39e-05     2.02e-07        0.187        0.248        0.115         0.27        0.192        0.144        0.329        0.236        0.188       0.0125
     98   190     2.98e-05     2.95e-05     3.71e-07        0.118        0.157       0.0781        0.163        0.121       0.0971        0.204        0.151        0.266       0.0177

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     98     5     2.86e-05     2.86e-05     2.76e-09        0.109        0.154       0.0826         0.14        0.111        0.123        0.184        0.153       0.0172      0.00115


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              98 2098.284    0.005     3.71e-05     2.62e-07     3.74e-05        0.127        0.176       0.0871        0.173         0.13        0.115        0.226         0.17        0.178       0.0119
! Validation         98 2098.284    0.005     3.23e-05     5.43e-09     3.23e-05        0.112        0.164       0.0777        0.151        0.115        0.113        0.207         0.16       0.0216      0.00144
Wall time: 2098.28506975

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     99    10     1.86e-05     1.86e-05     5.72e-09       0.0921        0.125       0.0687        0.119       0.0937       0.0873        0.157        0.122       0.0344      0.00229
     99    20     3.19e-05     3.18e-05     1.06e-07        0.118        0.163       0.0706        0.173        0.122       0.0885        0.218        0.153        0.131      0.00875
     99    30      4.3e-05      4.3e-05     1.86e-08        0.143        0.189        0.099        0.194        0.147        0.123        0.243        0.183       0.0625      0.00417
     99    40     5.26e-05     5.26e-05     3.39e-09        0.154        0.209       0.0895        0.227        0.158        0.118        0.279        0.198        0.025      0.00167
     99    50     2.22e-05     2.22e-05     2.29e-08       0.0994        0.136       0.0625        0.141        0.102       0.0841        0.177        0.131       0.0531      0.00354
     99    60     3.27e-05     3.26e-05     4.45e-08        0.122        0.165       0.0952        0.153        0.124        0.117        0.206        0.162       0.0844      0.00563
     99    70      3.2e-05      3.2e-05      8.9e-09         0.12        0.163       0.0743        0.171        0.123       0.0916        0.218        0.155       0.0375       0.0025
     99    80     3.63e-05      3.6e-05     2.99e-07        0.131        0.173       0.0912        0.177        0.134         0.12        0.218        0.169        0.237       0.0158
     99    90     5.51e-05      5.5e-05     1.15e-07         0.16        0.214       0.0993        0.229        0.164        0.127        0.282        0.205        0.147      0.00979
     99   100      3.5e-05     3.49e-05     1.51e-07        0.127         0.17       0.0833        0.176         0.13        0.108        0.221        0.164        0.169       0.0113
     99   110     3.09e-05     3.09e-05     4.87e-08        0.122         0.16          0.1        0.147        0.124        0.132        0.187         0.16       0.0875      0.00583
     99   120     4.69e-05     4.69e-05     3.22e-08        0.147        0.198          0.1          0.2         0.15        0.132        0.252        0.192       0.0688      0.00458
     99   130     3.68e-05     3.68e-05     2.35e-08         0.13        0.175       0.0924        0.172        0.132        0.115        0.225         0.17       0.0531      0.00354
     99   140     0.000104     0.000104     9.54e-08        0.236        0.294        0.202        0.275        0.238        0.253        0.336        0.294        0.125      0.00833
     99   150     4.22e-05     4.18e-05     3.78e-07        0.142        0.186        0.097        0.193        0.145         0.12        0.241        0.181        0.259       0.0173
     99   160     5.52e-05     5.49e-05     3.13e-07        0.164        0.214        0.129        0.204        0.167         0.17        0.255        0.212        0.244       0.0163
     99   170     0.000113     0.000113     3.35e-07        0.213        0.307        0.136        0.302        0.219        0.189        0.401        0.295        0.247       0.0165
     99   180     4.42e-05     4.42e-05     2.86e-08        0.137        0.192       0.0921        0.188         0.14        0.126        0.246        0.186       0.0625      0.00417
     99   190     5.05e-05     4.97e-05     7.84e-07        0.155        0.203         0.13        0.182        0.156        0.165        0.239        0.202        0.378       0.0252

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
     99     5     2.78e-05     2.78e-05     3.28e-09        0.108        0.152       0.0829        0.136        0.109        0.121        0.181        0.151       0.0188      0.00125


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train              99 2119.651    0.005     4.48e-05     1.69e-07      4.5e-05        0.141        0.193       0.0986        0.189        0.144        0.131        0.245        0.188        0.141      0.00942
! Validation         99 2119.651    0.005     3.17e-05     5.74e-09     3.17e-05        0.111        0.162       0.0776         0.15        0.114        0.112        0.205        0.159       0.0231      0.00154
Wall time: 2119.652954628
! Best model       99    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    100    10     2.66e-05     2.64e-05     2.33e-07         0.11        0.148       0.0802        0.144        0.112        0.107        0.184        0.146        0.206       0.0137
    100    20     4.16e-05     4.15e-05     6.72e-08        0.126        0.186       0.0692         0.19         0.13       0.0899        0.255        0.172        0.109      0.00729
    100    30      5.1e-05     5.04e-05      5.6e-07        0.153        0.205        0.103         0.21        0.157        0.131        0.265        0.198        0.328       0.0219
    100    40     3.64e-05     3.64e-05     8.69e-09        0.127        0.174       0.0785        0.183        0.131        0.104        0.229        0.167       0.0219      0.00146
    100    50     3.12e-05     3.09e-05     3.01e-07        0.128         0.16        0.124        0.133        0.128        0.153        0.169        0.161        0.234       0.0156
    100    60     2.62e-05     2.62e-05     5.93e-09        0.108        0.148       0.0717         0.15        0.111       0.0954        0.191        0.143       0.0281      0.00188
    100    70     4.05e-05     4.04e-05      9.2e-08        0.131        0.183       0.0873        0.181        0.134         0.12        0.236        0.178        0.128      0.00854
    100    80     3.07e-05     3.07e-05     2.54e-09        0.116         0.16       0.0703        0.167        0.119       0.0899        0.213        0.152       0.0156      0.00104
    100    90     2.62e-05     2.61e-05     1.15e-07        0.112        0.147       0.0829        0.145        0.114        0.111         0.18        0.145        0.147      0.00979
    100   100     4.45e-05     4.41e-05     3.95e-07        0.129        0.191       0.0705        0.195        0.133       0.0883        0.264        0.176        0.269       0.0179
    100   110     5.95e-05     5.92e-05     2.97e-07        0.149        0.222       0.0849        0.223        0.154        0.109        0.303        0.206        0.231       0.0154
    100   120     5.95e-05     5.92e-05     2.84e-07        0.143        0.222       0.0739        0.222        0.148       0.0969        0.308        0.202        0.222       0.0148
    100   130     3.76e-05     3.74e-05     2.48e-07        0.129        0.176       0.0974        0.165        0.131        0.125        0.221        0.173        0.216       0.0144
    100   140      2.6e-05     2.59e-05      3.9e-08        0.112        0.147       0.0789         0.15        0.115          0.1        0.186        0.143       0.0812      0.00542
    100   150     4.06e-05     4.05e-05     1.05e-07        0.136        0.184       0.0828        0.198         0.14        0.107        0.243        0.175        0.138      0.00917
    100   160     3.01e-05     2.88e-05     1.27e-06        0.111        0.155       0.0703        0.157        0.114       0.0974        0.201        0.149        0.484       0.0323
    100   170     5.69e-05     5.68e-05     5.79e-08        0.147        0.217       0.0913        0.211        0.151        0.132        0.285        0.209       0.0938      0.00625
    100   180     3.77e-05     3.76e-05     1.45e-07        0.134        0.177        0.118        0.152        0.135        0.148        0.205        0.176        0.166        0.011
    100   190      5.5e-05     5.41e-05     8.95e-07        0.157        0.212        0.102         0.22        0.161        0.127        0.279        0.203        0.406       0.0271

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    100     5     2.64e-05     2.64e-05     3.81e-09        0.106        0.148       0.0796        0.136        0.108        0.115        0.178        0.147       0.0203      0.00135


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             100 2141.144    0.005     3.72e-05     2.45e-07     3.75e-05        0.127        0.176       0.0871        0.173         0.13        0.115        0.226        0.171        0.167       0.0112
! Validation        100 2141.144    0.005     3.11e-05     5.23e-09     3.11e-05         0.11        0.161       0.0765        0.149        0.113        0.111        0.204        0.157       0.0219      0.00146
Wall time: 2141.1443995480004
! Best model      100    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    101    10     5.43e-05     5.42e-05     6.15e-08        0.153        0.212       0.0923        0.222        0.157        0.119        0.284        0.201       0.0906      0.00604
    101    20     5.76e-05     5.75e-05     8.54e-08        0.155        0.219       0.0908        0.228        0.159        0.121        0.293        0.207        0.116      0.00771
    101    30     0.000101       0.0001     9.64e-07        0.202        0.289        0.103        0.316         0.21        0.134        0.398        0.266        0.416       0.0277
    101    40      3.8e-05     3.79e-05     9.11e-09        0.137        0.178       0.0979        0.182         0.14         0.13         0.22        0.175       0.0281      0.00188
    101    50     2.82e-05     2.81e-05     1.17e-07        0.114        0.153       0.0778        0.155        0.117        0.104        0.194        0.149        0.144      0.00958
    101    60     2.13e-05      2.1e-05     3.32e-07        0.101        0.132       0.0683        0.138        0.103       0.0876        0.169        0.128        0.244       0.0162
    101    70     2.26e-05     2.25e-05     6.59e-08       0.0986        0.137       0.0656        0.136        0.101       0.0846        0.179        0.132        0.109      0.00729
    101    80     4.69e-05     4.61e-05     8.36e-07        0.144        0.196         0.11        0.182        0.146        0.138        0.246        0.192        0.397       0.0265
    101    90     4.02e-05     4.01e-05     7.71e-08        0.131        0.183       0.0919        0.176        0.134        0.126        0.231        0.178        0.119      0.00792
    101   100     2.76e-05     2.75e-05     1.22e-07        0.109        0.151       0.0733        0.151        0.112       0.0941        0.197        0.146        0.147      0.00979
    101   110     5.24e-05     5.21e-05     2.87e-07        0.146        0.208       0.0759        0.226        0.151        0.105        0.283        0.194        0.225        0.015
    101   120     2.81e-05     2.81e-05     2.12e-09        0.118        0.153        0.106        0.132        0.119        0.132        0.174        0.153       0.0156      0.00104
    101   130     3.16e-05     3.15e-05     1.32e-07        0.119        0.162       0.0924        0.149        0.121        0.125        0.196         0.16        0.153       0.0102
    101   140     4.37e-05     4.36e-05     1.61e-07        0.139         0.19       0.0892        0.195        0.142        0.112        0.252        0.182        0.169       0.0113
    101   150      2.6e-05     2.59e-05     4.34e-08        0.113        0.147       0.0839        0.147        0.116        0.108        0.181        0.145       0.0875      0.00583
    101   160     3.12e-05     3.11e-05     9.73e-08        0.119        0.161       0.0854        0.157        0.121        0.106        0.206        0.156        0.134      0.00896
    101   170     3.12e-05      3.1e-05     2.82e-07        0.115         0.16       0.0703        0.166        0.118       0.0882        0.215        0.152        0.225        0.015
    101   180     5.19e-05     5.18e-05      6.1e-08        0.155        0.208        0.126        0.189        0.157        0.164        0.249        0.206       0.0969      0.00646
    101   190     3.27e-05     3.27e-05     8.27e-09        0.123        0.165       0.0994        0.151        0.125        0.128        0.199        0.163       0.0312      0.00208

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    101     5     2.68e-05     2.68e-05     5.19e-09        0.106        0.149       0.0806        0.136        0.108        0.117        0.179        0.148        0.025      0.00167


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             101 2162.447    0.005     3.84e-05        2e-07     3.86e-05         0.13        0.179       0.0899        0.175        0.132        0.119        0.229        0.174        0.155       0.0103
! Validation        101 2162.447    0.005     3.13e-05     5.43e-09     3.13e-05         0.11        0.161       0.0764        0.149        0.112        0.111        0.204        0.158       0.0219      0.00146
Wall time: 2162.448170783

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    102    10     2.94e-05     2.94e-05     6.04e-08        0.118        0.156       0.0774        0.165        0.121       0.0957        0.205         0.15        0.103      0.00688
    102    20     2.59e-05     2.59e-05     2.76e-08        0.102        0.147       0.0579        0.152        0.105       0.0775        0.198        0.138       0.0688      0.00458
    102    30     3.49e-05     3.49e-05     9.75e-09        0.127         0.17       0.0815        0.179         0.13        0.107        0.222        0.164       0.0344      0.00229
    102    40      1.5e-05      1.5e-05     8.48e-10       0.0869        0.112       0.0663         0.11       0.0883       0.0833        0.137         0.11      0.00938     0.000625
    102    50     2.81e-05     2.81e-05     4.03e-09        0.113        0.153       0.0725         0.16        0.116       0.0931          0.2        0.147       0.0281      0.00188
    102    60     3.57e-05     3.56e-05     1.01e-07        0.123        0.172       0.0768        0.176        0.126        0.107        0.225        0.166        0.122      0.00812
    102    70     3.86e-05     3.69e-05      1.7e-06        0.122        0.175       0.0779        0.172        0.125        0.106         0.23        0.168        0.559       0.0373
    102    80     6.29e-05     6.29e-05     1.29e-08        0.169        0.229        0.108        0.239        0.174        0.133        0.303        0.218       0.0406      0.00271
    102    90     3.62e-05      3.6e-05     1.24e-07        0.132        0.173         0.11        0.156        0.133        0.141        0.203        0.172        0.144      0.00958
    102   100     2.42e-05     2.32e-05     9.17e-07        0.105        0.139       0.0758        0.138        0.107       0.0984        0.174        0.136        0.416       0.0277
    102   110     2.46e-05     2.45e-05     1.19e-07        0.109        0.143       0.0755        0.147        0.111        0.096        0.182        0.139        0.147      0.00979
    102   120     2.69e-05     2.64e-05     5.52e-07        0.109        0.148       0.0762        0.148        0.112        0.104        0.186        0.145        0.325       0.0217
    102   130     2.51e-05     2.51e-05     3.18e-09        0.106        0.144       0.0662        0.151        0.108       0.0832        0.192        0.137       0.0188      0.00125
    102   140     5.36e-05      5.3e-05     5.39e-07        0.154         0.21       0.0966         0.22        0.159        0.126        0.276        0.201        0.316        0.021
    102   150        5e-05      4.9e-05     1.01e-06        0.149        0.202        0.102        0.204        0.153        0.129        0.262        0.195        0.438       0.0292
    102   160     2.91e-05     2.91e-05     1.93e-08        0.109        0.156       0.0713        0.153        0.112       0.0935        0.205        0.149       0.0469      0.00313
    102   170     2.84e-05     2.84e-05     4.13e-08        0.112        0.154       0.0798        0.149        0.114        0.105        0.195         0.15       0.0719      0.00479
    102   180     2.77e-05     2.77e-05      2.1e-08         0.11        0.152       0.0681        0.157        0.113       0.0869        0.202        0.144       0.0594      0.00396
    102   190     3.27e-05     3.25e-05      1.5e-07        0.124        0.164       0.0891        0.164        0.126         0.12        0.204        0.162        0.166        0.011

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    102     5     2.58e-05     2.57e-05     3.39e-09        0.104        0.146       0.0786        0.133        0.106        0.115        0.175        0.145       0.0172      0.00115


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             102 2183.619    0.005      3.3e-05     2.29e-07     3.33e-05        0.121        0.166       0.0843        0.163        0.124        0.111        0.211        0.161        0.159       0.0106
! Validation        102 2183.619    0.005     3.07e-05     5.34e-09     3.07e-05        0.109         0.16       0.0758        0.147        0.111         0.11        0.202        0.156       0.0225       0.0015
Wall time: 2183.620324063999
! Best model      102    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    103    10        6e-05     5.99e-05     2.76e-08        0.164        0.223        0.121        0.212        0.167        0.161        0.278        0.219       0.0656      0.00438
    103    20     5.55e-05     5.49e-05     5.66e-07        0.156        0.214          0.1         0.22         0.16        0.123        0.284        0.203        0.322       0.0215
    103    30     4.28e-05     4.25e-05     2.39e-07        0.137        0.188       0.0967        0.184         0.14        0.128        0.239        0.183        0.206       0.0137
    103    40     4.86e-05     4.85e-05     4.94e-08        0.153        0.201       0.0919        0.222        0.157        0.118        0.266        0.192       0.0812      0.00542
    103    50     3.21e-05     3.21e-05     8.27e-09        0.119        0.163       0.0882        0.154        0.121        0.117        0.204         0.16       0.0344      0.00229
    103    60     2.95e-05     2.94e-05     9.43e-08        0.112        0.156       0.0685        0.162        0.115       0.0864        0.209        0.148        0.125      0.00833
    103    70     4.28e-05     4.28e-05     3.88e-08        0.138        0.189       0.0972        0.186        0.141        0.136        0.235        0.185       0.0719      0.00479
    103    80      4.8e-05      4.8e-05      3.2e-08        0.151          0.2        0.106        0.203        0.154        0.132        0.256        0.194       0.0531      0.00354
    103    90      9.6e-05      9.6e-05     1.42e-08        0.228        0.283        0.166        0.299        0.232        0.202        0.353        0.277       0.0406      0.00271
    103   100     6.18e-05     6.18e-05     2.01e-08        0.166        0.227        0.123        0.215        0.169        0.157        0.286        0.222         0.05      0.00333
    103   110     3.74e-05     3.74e-05     2.84e-08         0.13        0.176        0.103        0.161        0.132        0.145        0.207        0.176       0.0625      0.00417
    103   120        4e-05        4e-05     6.19e-08        0.141        0.182       0.0953        0.192        0.144        0.124        0.232        0.178        0.109      0.00729
    103   130     4.61e-05     4.61e-05     2.25e-08        0.145        0.196        0.104        0.191        0.148         0.14        0.245        0.192       0.0562      0.00375
    103   140     2.95e-05     2.93e-05     2.41e-07         0.12        0.156         0.08        0.165        0.123        0.102        0.201        0.151        0.216       0.0144
    103   150     3.26e-05     3.26e-05     1.67e-08        0.127        0.165       0.0939        0.165         0.13        0.119        0.205        0.162         0.05      0.00333
    103   160     3.06e-05     3.05e-05     3.94e-08        0.119        0.159       0.0868        0.156        0.122        0.109        0.202        0.156       0.0656      0.00438
    103   170     3.33e-05     3.33e-05     5.51e-08        0.127        0.166       0.0958        0.162        0.129        0.125        0.204        0.164       0.0969      0.00646
    103   180     2.62e-05     2.61e-05     9.98e-08        0.115        0.147       0.0843         0.15        0.117        0.104        0.185        0.144        0.138      0.00917
    103   190     6.64e-05     6.62e-05     1.37e-07        0.162        0.235        0.111         0.22        0.165        0.155        0.301        0.228        0.147      0.00979

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    103     5     2.56e-05     2.56e-05     4.56e-09        0.103        0.146       0.0781        0.132        0.105        0.114        0.175        0.145        0.025      0.00167


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             103 2205.313    0.005     4.05e-05     9.37e-08     4.06e-05        0.134        0.183       0.0933        0.181        0.137        0.123        0.234        0.179        0.105      0.00697
! Validation        103 2205.313    0.005     3.07e-05     5.51e-09     3.07e-05        0.109         0.16       0.0757        0.147        0.111         0.11        0.202        0.156       0.0234      0.00156
Wall time: 2205.314394240999

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    104    10     5.41e-05     5.41e-05     1.65e-08        0.146        0.212       0.0836        0.217         0.15        0.113        0.286        0.199         0.05      0.00333
    104    20     3.03e-05     3.02e-05     4.54e-08        0.128        0.159         0.11        0.149         0.13        0.137         0.18        0.159       0.0844      0.00562
    104    30     4.98e-05     4.96e-05     1.65e-07        0.156        0.203        0.112        0.208         0.16         0.14        0.257        0.199        0.175       0.0117
    104    40      2.6e-05     2.59e-05     1.01e-07        0.113        0.147       0.0744        0.156        0.115       0.0992        0.187        0.143        0.128      0.00854
    104    50     3.57e-05     3.56e-05     8.92e-08        0.126        0.172       0.0829        0.176        0.129        0.107        0.225        0.166        0.122      0.00813
    104    60     2.84e-05     2.83e-05     7.44e-08        0.113        0.153       0.0719         0.16        0.116       0.0895        0.203        0.146        0.112       0.0075
    104    70     4.56e-05     4.46e-05     1.04e-06        0.136        0.192       0.0753        0.206        0.141       0.0984        0.261         0.18        0.434        0.029
    104    80     3.47e-05     3.46e-05     1.06e-07         0.12         0.17       0.0665        0.182        0.124       0.0892        0.229        0.159        0.138      0.00917
    104    90     2.89e-05     2.85e-05     3.93e-07         0.12        0.154       0.0995        0.142        0.121        0.133        0.175        0.154        0.275       0.0183
    104   100     3.78e-05     3.68e-05     9.45e-07        0.128        0.175       0.0901        0.171        0.131        0.125        0.219        0.172        0.416       0.0277
    104   110     3.18e-05     3.18e-05     4.66e-09         0.12        0.163        0.071        0.175        0.123       0.0929        0.217        0.155       0.0219      0.00146
    104   120     2.48e-05     2.48e-05     2.76e-09        0.103        0.144       0.0708         0.14        0.105       0.0965        0.183         0.14       0.0219      0.00146
    104   130      2.4e-05      2.4e-05     7.52e-08        0.106        0.141       0.0787        0.138        0.108        0.104        0.174        0.139        0.106      0.00708
    104   140     3.56e-05     3.56e-05     5.04e-08        0.132        0.172       0.0957        0.174        0.135        0.125        0.214        0.169       0.0906      0.00604
    104   150     2.68e-05     2.68e-05     5.72e-09        0.111        0.149       0.0877        0.137        0.112        0.115        0.181        0.148       0.0344      0.00229
    104   160     3.48e-05      3.4e-05     8.34e-07        0.126        0.168       0.0859        0.173        0.129         0.11        0.216        0.163        0.394       0.0262
    104   170     0.000109     0.000109     2.04e-07        0.217        0.301        0.148        0.296        0.222        0.185        0.393        0.289        0.188       0.0125
    104   180     3.64e-05     3.63e-05     4.81e-08        0.129        0.174       0.0933        0.169        0.131        0.121        0.219         0.17       0.0812      0.00542
    104   190     1.97e-05     1.96e-05     6.23e-08       0.0962        0.128       0.0744        0.121       0.0978       0.0971        0.155        0.126        0.103      0.00687

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    104     5      2.6e-05      2.6e-05     3.81e-09        0.104        0.147       0.0774        0.133        0.105        0.115        0.177        0.146       0.0203      0.00135


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             104 2226.796    0.005      3.8e-05     2.46e-07     3.83e-05        0.129        0.178       0.0893        0.175        0.132        0.118        0.228        0.173        0.174       0.0116
! Validation        104 2226.796    0.005     3.04e-05     5.47e-09     3.04e-05        0.108        0.159       0.0749        0.146        0.111        0.109        0.201        0.155       0.0225       0.0015
Wall time: 2226.7966239180005
! Best model      104    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    105    10     2.85e-05     2.85e-05     5.64e-08        0.118        0.154       0.0909         0.15         0.12        0.109        0.193        0.151       0.0875      0.00583
    105    20     2.13e-05     2.13e-05     7.21e-09       0.0987        0.133       0.0694        0.132        0.101       0.0921        0.168         0.13       0.0344      0.00229
    105    30     2.19e-05     2.17e-05     2.09e-07       0.0967        0.134       0.0593        0.139       0.0994       0.0773        0.178        0.128        0.197       0.0131
    105    40     3.32e-05      3.2e-05     1.17e-06        0.118        0.163       0.0879        0.153         0.12        0.116        0.204         0.16        0.469       0.0312
    105    50     2.25e-05      2.2e-05     4.79e-07        0.101        0.135       0.0718        0.134        0.103       0.0928        0.171        0.132          0.3         0.02
    105    60      2.1e-05     2.09e-05     6.59e-08       0.0945        0.132       0.0587        0.135        0.097       0.0754        0.176        0.125        0.109      0.00729
    105    70     2.45e-05     2.45e-05     1.63e-08        0.101        0.143       0.0697        0.136        0.103       0.0978        0.181        0.139       0.0469      0.00313
    105    80     2.69e-05     2.68e-05     9.28e-08        0.106        0.149       0.0655        0.153        0.109       0.0905        0.196        0.143        0.128      0.00854
    105    90     2.86e-05     2.81e-05     5.42e-07        0.115        0.153       0.0713        0.164        0.118       0.0967        0.198        0.148        0.319       0.0213
    105   100      2.9e-05     2.88e-05     2.32e-07        0.116        0.155       0.0874        0.149        0.118        0.115         0.19        0.153        0.203       0.0135
    105   110     2.32e-05     2.29e-05     3.02e-07        0.107        0.138       0.0955         0.12        0.108         0.12        0.156        0.138        0.231       0.0154
    105   120     3.56e-05     3.48e-05     8.05e-07        0.131         0.17       0.0949        0.172        0.134        0.115        0.216        0.166        0.391        0.026
    105   130     3.97e-05     3.97e-05     4.03e-09        0.128        0.182       0.0765        0.186        0.131       0.0984        0.244        0.171        0.025      0.00167
    105   140     3.13e-05     2.99e-05     1.42e-06        0.119        0.158       0.0846        0.157        0.121         0.11        0.198        0.154        0.519       0.0346
    105   150     3.25e-05     3.25e-05     3.12e-08        0.128        0.164       0.0952        0.166         0.13         0.12        0.204        0.162       0.0719      0.00479
    105   160     4.37e-05     4.36e-05     1.67e-07        0.139         0.19       0.0791        0.208        0.144        0.101        0.257        0.179        0.178       0.0119
    105   170     3.79e-05     3.78e-05      4.2e-08        0.127        0.177       0.0831        0.177         0.13         0.11        0.232        0.171       0.0812      0.00542
    105   180     4.07e-05     4.06e-05     6.38e-08        0.131        0.184       0.0951        0.171        0.133        0.132        0.229        0.181       0.0969      0.00646
    105   190     3.01e-05     2.98e-05     3.17e-07         0.12        0.157       0.0871        0.157        0.122        0.115        0.195        0.155        0.244       0.0163

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    105     5     2.53e-05     2.53e-05     3.28e-09        0.103        0.145       0.0759        0.133        0.105        0.112        0.176        0.144       0.0188      0.00125


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             105 2248.237    0.005     3.36e-05     3.15e-07     3.39e-05        0.122        0.167        0.085        0.164        0.125        0.113        0.213        0.163        0.202       0.0135
! Validation        105 2248.237    0.005     3.04e-05      4.9e-09     3.04e-05        0.109        0.159        0.075        0.147        0.111        0.109        0.201        0.155       0.0225       0.0015
Wall time: 2248.2373060699992
! Best model      105    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    106    10      3.7e-05     3.68e-05     2.28e-07        0.129        0.175       0.0828        0.183        0.133        0.114        0.225         0.17        0.209        0.014
    106    20     5.48e-05     5.48e-05     4.37e-08        0.159        0.213        0.102        0.224        0.163         0.14        0.274        0.207       0.0719      0.00479
    106    30     3.27e-05      3.2e-05     7.05e-07        0.116        0.163       0.0771         0.16        0.119        0.108        0.209        0.158        0.359        0.024
    106    40     5.59e-05     5.57e-05     1.84e-07        0.151        0.215       0.0903         0.22        0.155        0.124        0.286        0.205        0.175       0.0117
    106    50      2.8e-05     2.79e-05     1.83e-07        0.115        0.152       0.0877        0.145        0.117        0.107        0.191        0.149        0.184       0.0123
    106    60     5.85e-05     5.85e-05     5.32e-08        0.166         0.22        0.108        0.233         0.17        0.137        0.288        0.212       0.0875      0.00583
    106    70     2.78e-05     2.77e-05     7.93e-08        0.114        0.152        0.103        0.128        0.115        0.142        0.162        0.152        0.112       0.0075
    106    80      4.2e-05     4.17e-05     2.23e-07        0.137        0.186        0.119        0.158        0.139        0.152        0.219        0.186        0.188       0.0125
    106    90     2.09e-05     2.09e-05     3.77e-08       0.0966        0.132       0.0658        0.132       0.0988       0.0955        0.164         0.13        0.075        0.005
    106   100     3.57e-05     3.56e-05     4.37e-08         0.13        0.172       0.0841        0.182        0.133        0.113        0.221        0.167       0.0812      0.00542
    106   110     3.12e-05     3.11e-05     1.46e-07        0.121        0.161        0.078        0.169        0.124        0.101        0.209        0.155        0.166        0.011
    106   120     7.34e-05      7.3e-05     3.57e-07        0.175        0.246       0.0968        0.265        0.181        0.125        0.335         0.23        0.253       0.0169
    106   130     3.26e-05     3.25e-05     9.45e-08        0.114        0.164       0.0763        0.156        0.116        0.101        0.215        0.158        0.128      0.00854
    106   140     2.19e-05     2.19e-05     1.59e-08        0.104        0.135       0.0806         0.13        0.105          0.1        0.166        0.133       0.0531      0.00354
    106   150     4.47e-05     4.44e-05     2.94e-07        0.138        0.192        0.081        0.204        0.142        0.107        0.257        0.182        0.237       0.0158
    106   160      4.2e-05     4.19e-05     5.49e-08        0.138        0.187         0.11        0.171         0.14        0.142        0.227        0.185          0.1      0.00667
    106   170     5.93e-05      5.9e-05     3.05e-07        0.159        0.221        0.087         0.24        0.164        0.109        0.303        0.206        0.237       0.0158
    106   180     3.09e-05     2.92e-05     1.69e-06        0.121        0.156        0.091        0.155        0.123        0.112        0.194        0.153        0.562       0.0375
    106   190     2.63e-05     2.63e-05     2.14e-08        0.111        0.148       0.0784        0.147        0.113        0.107        0.184        0.145       0.0531      0.00354

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    106     5     2.54e-05     2.54e-05     2.44e-09        0.103        0.145       0.0772        0.133        0.105        0.112        0.176        0.144       0.0203      0.00135


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             106 2269.397    0.005     3.77e-05     1.64e-07     3.79e-05        0.129        0.177       0.0916        0.173        0.132        0.121        0.225        0.173        0.139      0.00928
! Validation        106 2269.397    0.005     2.99e-05     5.81e-09     2.99e-05        0.108        0.158       0.0746        0.146         0.11        0.108          0.2        0.154       0.0253      0.00169
Wall time: 2269.397441470999
! Best model      106    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    107    10     3.72e-05     3.71e-05     1.29e-08         0.13        0.176       0.0958         0.17        0.133        0.125         0.22        0.172       0.0469      0.00313
    107    20     3.03e-05     3.02e-05     4.87e-09        0.117        0.159       0.0762        0.164         0.12       0.0995        0.206        0.153        0.025      0.00167
    107    30     3.48e-05     3.48e-05     5.55e-08        0.129         0.17       0.0912        0.173        0.132        0.119        0.214        0.167        0.103      0.00687
    107    40     3.46e-05     3.46e-05     6.36e-09        0.116         0.17        0.075        0.162        0.119       0.0904        0.229         0.16       0.0281      0.00188
    107    50     3.61e-05      3.6e-05     1.68e-07        0.131        0.173       0.0911        0.176        0.134        0.113        0.223        0.168        0.172       0.0115
    107    60     3.36e-05     3.36e-05      1.7e-08        0.121        0.167       0.0817        0.165        0.123        0.105        0.217        0.161         0.05      0.00333
    107    70     3.87e-05     3.85e-05      2.2e-07        0.125        0.179       0.0838        0.173        0.128        0.121        0.228        0.174        0.191       0.0127
    107    80     3.14e-05     3.12e-05     1.55e-07        0.113        0.161       0.0719        0.161        0.116       0.0948        0.213        0.154        0.169       0.0113
    107    90     3.61e-05     3.61e-05     3.18e-09         0.12        0.173       0.0758        0.172        0.124        0.105        0.227        0.166       0.0219      0.00146
    107   100     3.66e-05     3.65e-05        6e-08        0.128        0.174       0.0815        0.181        0.131        0.106        0.229        0.167        0.103      0.00687
    107   110     3.34e-05     3.34e-05     2.01e-08        0.125        0.167       0.0893        0.166        0.128        0.111        0.213        0.162       0.0437      0.00292
    107   120     2.68e-05     2.57e-05     1.03e-06        0.111        0.146       0.0856        0.139        0.112        0.115        0.175        0.145        0.441       0.0294
    107   130     2.24e-05     2.16e-05     7.65e-07       0.0977        0.134        0.066        0.134          0.1       0.0867        0.173         0.13        0.375        0.025
    107   140     3.48e-05     3.48e-05     9.54e-09        0.116         0.17       0.0675        0.171        0.119       0.0918        0.229         0.16       0.0281      0.00188
    107   150      2.2e-05     2.19e-05     1.36e-07       0.0959        0.135       0.0617        0.135       0.0983       0.0793        0.178        0.129        0.159       0.0106
    107   160     3.86e-05     3.84e-05     2.34e-07        0.127        0.179       0.0916        0.167        0.129        0.122        0.227        0.174        0.209        0.014
    107   170     3.05e-05     3.02e-05     3.67e-07        0.109        0.158       0.0698        0.154        0.112       0.0948        0.209        0.152        0.262       0.0175
    107   180     3.89e-05     3.89e-05     1.17e-08        0.135         0.18        0.103        0.172        0.137        0.132        0.222        0.177       0.0375       0.0025
    107   190     3.14e-05     3.11e-05     3.69e-07        0.116        0.161       0.0801        0.157        0.118        0.104        0.207        0.156        0.259       0.0173

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    107     5     2.49e-05     2.49e-05     5.09e-09        0.103        0.144       0.0761        0.134        0.105         0.11        0.175        0.142       0.0266      0.00177


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             107 2290.870    0.005     3.62e-05     1.89e-07     3.64e-05        0.126        0.174       0.0871         0.17        0.129        0.115        0.222        0.169        0.146      0.00975
! Validation        107 2290.870    0.005     2.96e-05     5.62e-09     2.96e-05        0.108        0.157       0.0744        0.146         0.11        0.108        0.199        0.153       0.0234      0.00156
Wall time: 2290.8716379769994
! Best model      107    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    108    10     3.08e-05     3.03e-05     4.77e-07        0.124        0.159       0.0872        0.166        0.127        0.107        0.203        0.155          0.3         0.02
    108    20      3.7e-05      3.7e-05     1.59e-08        0.131        0.175       0.0927        0.176        0.134         0.12        0.223        0.171         0.05      0.00333
    108    30     2.85e-05     2.78e-05     6.23e-07        0.113        0.152       0.0739        0.157        0.116        0.099        0.196        0.148        0.341       0.0227
    108    40      4.1e-05      4.1e-05     1.08e-08        0.134        0.185       0.0787        0.198        0.138          0.1        0.248        0.174       0.0375       0.0025
    108    50     2.67e-05     2.67e-05     2.63e-08        0.113        0.149       0.0806         0.15        0.115        0.103        0.188        0.146       0.0688      0.00458
    108    60      4.4e-05     4.39e-05     4.26e-08        0.136        0.191       0.0771        0.204        0.141       0.0949        0.261        0.178       0.0906      0.00604
    108    70     4.39e-05     4.33e-05     5.66e-07         0.14         0.19        0.101        0.184        0.143        0.131         0.24        0.185        0.322       0.0215
    108    80     3.16e-05     3.16e-05     5.32e-08        0.121        0.162        0.093        0.154        0.123        0.118        0.201        0.159       0.0969      0.00646
    108    90     4.88e-05     4.87e-05      5.3e-08         0.15        0.201        0.098         0.21        0.154        0.125        0.263        0.194       0.0781      0.00521
    108   100     3.17e-05     3.17e-05     2.97e-09        0.114        0.162       0.0645        0.172        0.118       0.0833         0.22        0.152        0.025      0.00167
    108   110      2.4e-05     2.39e-05      9.2e-08        0.104        0.141       0.0736        0.138        0.106       0.0975        0.178        0.138        0.131      0.00875
    108   120     4.39e-05     4.37e-05     2.48e-07        0.135        0.191       0.0764        0.202        0.139       0.0963        0.259        0.178        0.206       0.0137
    108   130      4.1e-05      4.1e-05     3.41e-08         0.14        0.185        0.111        0.174        0.142        0.139        0.226        0.182       0.0688      0.00458
    108   140     2.43e-05     2.33e-05     1.08e-06        0.103        0.139       0.0677        0.144        0.106       0.0905        0.179        0.135        0.444       0.0296
    108   150     2.97e-05     2.96e-05     1.45e-07        0.117        0.157       0.0812        0.158         0.12       0.0998        0.203        0.152        0.159       0.0106
    108   160     2.82e-05      2.8e-05     1.78e-07        0.116        0.153       0.0778        0.161        0.119        0.101        0.196        0.148        0.172       0.0115
    108   170     3.52e-05     3.52e-05     1.14e-08         0.13        0.171       0.0929        0.172        0.133        0.126        0.211        0.169       0.0344      0.00229
    108   180     2.69e-05     2.68e-05     1.16e-07        0.108        0.149       0.0793         0.14         0.11         0.11        0.184        0.147        0.144      0.00958
    108   190     3.73e-05     3.72e-05     1.33e-07         0.13        0.176       0.0929        0.173        0.133        0.122        0.222        0.172        0.153       0.0102

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    108     5     2.54e-05     2.54e-05     3.39e-09        0.103        0.145       0.0762        0.134        0.105         0.11        0.177        0.144       0.0203      0.00135


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             108 2312.199    0.005     3.41e-05     1.84e-07     3.43e-05        0.123        0.168       0.0834        0.167        0.125         0.11        0.216        0.163        0.148      0.00989
! Validation        108 2312.199    0.005     2.94e-05     5.38e-09     2.94e-05        0.107        0.156       0.0741        0.145        0.109        0.107        0.198        0.153       0.0231      0.00154
Wall time: 2312.1998786179993
! Best model      108    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    109    10      3.8e-05      3.8e-05     7.63e-09        0.134        0.178        0.105        0.167        0.136        0.144         0.21        0.177        0.025      0.00167
    109    20      2.9e-05     2.89e-05     2.65e-08        0.116        0.155       0.0826        0.154        0.118        0.106        0.197        0.151       0.0656      0.00438
    109    30     2.88e-05     2.87e-05     4.37e-08        0.115        0.155       0.0969        0.137        0.117        0.119        0.187        0.153       0.0844      0.00563
    109    40      6.4e-05      6.4e-05     4.87e-09        0.175        0.231        0.124        0.233        0.179        0.167        0.287        0.227       0.0219      0.00146
    109    50     3.09e-05     2.98e-05     1.11e-06        0.113        0.157       0.0602        0.173        0.117       0.0775        0.215        0.146        0.453       0.0302
    109    60     2.73e-05     2.73e-05     1.21e-08        0.119        0.151       0.0908        0.151        0.121        0.106        0.189        0.147       0.0437      0.00292
    109    70     3.94e-05     3.93e-05     1.01e-07        0.143        0.181        0.122        0.167        0.145        0.154        0.207        0.181        0.138      0.00917
    109    80     2.67e-05     2.67e-05     4.98e-08        0.112        0.149        0.087         0.14        0.114         0.11        0.184        0.147       0.0906      0.00604
    109    90     4.69e-05     4.67e-05     2.03e-07        0.146        0.197        0.104        0.194        0.149        0.133        0.251        0.192        0.194       0.0129
    109   100     4.32e-05     4.31e-05      9.2e-08        0.135        0.189       0.0985        0.178        0.138        0.124        0.243        0.184        0.122      0.00813
    109   110     3.07e-05     3.04e-05     2.96e-07        0.126        0.159        0.116        0.137        0.127        0.149         0.17        0.159        0.231       0.0154
    109   120     5.05e-05     5.04e-05     1.49e-07        0.148        0.205       0.0974        0.205        0.151        0.127        0.267        0.197        0.162       0.0108
    109   130     4.88e-05     4.88e-05      8.9e-09        0.148        0.202       0.0907        0.213        0.152        0.114        0.268        0.191       0.0281      0.00188
    109   140     5.54e-05     5.52e-05     2.31e-07        0.147        0.214       0.0916        0.209         0.15        0.123        0.285        0.204        0.203       0.0135
    109   150        4e-05     3.98e-05     2.34e-07        0.136        0.182       0.0922        0.187        0.139        0.113        0.237        0.175        0.203       0.0135
    109   160     2.48e-05     2.39e-05     8.56e-07        0.109        0.141       0.0904         0.13         0.11        0.119        0.163        0.141          0.4       0.0267
    109   170     2.99e-05     2.99e-05     2.86e-08        0.114        0.158       0.0631        0.173        0.118       0.0805        0.214        0.147       0.0656      0.00438
    109   180     3.01e-05     3.01e-05     1.48e-08        0.122        0.158       0.0868        0.162        0.124        0.117        0.195        0.156       0.0437      0.00292
    109   190     1.96e-05     1.96e-05     4.96e-08          0.1        0.128       0.0817        0.121        0.101        0.102        0.152        0.127       0.0969      0.00646

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    109     5     2.57e-05     2.57e-05      5.3e-09        0.104        0.146       0.0768        0.135        0.106        0.112        0.177        0.145       0.0266      0.00177


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             109 2333.569    0.005      3.5e-05     1.87e-07     3.52e-05        0.125        0.171       0.0874        0.168        0.128        0.116        0.217        0.166        0.148      0.00986
! Validation        109 2333.569    0.005     2.94e-05     5.98e-09     2.94e-05        0.107        0.156       0.0743        0.145        0.109        0.108        0.198        0.153       0.0237      0.00158
Wall time: 2333.570067880999
! Best model      109    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    110    10     3.35e-05     3.33e-05     1.46e-07        0.115        0.167       0.0846        0.149        0.117        0.111        0.213        0.162        0.159       0.0106
    110    20     3.54e-05     3.53e-05     7.76e-08        0.132        0.171        0.109        0.159        0.134        0.143        0.199        0.171        0.116      0.00771
    110    30     4.12e-05     4.12e-05     2.48e-08        0.144        0.185        0.117        0.176        0.146        0.152        0.217        0.184       0.0688      0.00458
    110    40      2.2e-05     2.15e-05     5.64e-07       0.0963        0.134       0.0692        0.127       0.0982       0.0922        0.169        0.131        0.325       0.0217
    110    50     4.16e-05     4.12e-05     3.77e-07        0.129        0.185       0.0896        0.173        0.131        0.119        0.239        0.179        0.262       0.0175
    110    60     3.66e-05     3.63e-05     3.74e-07        0.129        0.174        0.101        0.162        0.131        0.132        0.211        0.172        0.262       0.0175
    110    70      2.6e-05     2.58e-05     2.43e-07        0.107        0.146       0.0746        0.143        0.109       0.0934         0.19        0.142        0.209        0.014
    110    80     2.25e-05     2.25e-05     4.03e-09        0.102        0.137       0.0692         0.14        0.104       0.0884        0.177        0.132        0.025      0.00167
    110    90      2.8e-05      2.8e-05     2.78e-08        0.118        0.153       0.0846        0.155         0.12        0.107        0.192        0.149       0.0656      0.00438
    110   100     2.38e-05     2.38e-05     2.95e-08       0.0991        0.141       0.0516        0.153        0.102       0.0656        0.194         0.13        0.075        0.005
    110   110     2.85e-05     2.85e-05     7.63e-09        0.119        0.154        0.108        0.131         0.12        0.136        0.172        0.154       0.0344      0.00229
    110   120     2.81e-05      2.8e-05     4.58e-08        0.105        0.153       0.0771        0.136        0.107        0.109        0.191         0.15       0.0812      0.00542
    110   130     3.48e-05     3.48e-05     9.96e-09        0.124         0.17        0.083         0.17        0.126        0.114        0.217        0.165       0.0344      0.00229
    110   140     2.95e-05     2.95e-05     5.11e-08        0.118        0.157       0.0875        0.153         0.12        0.111        0.196        0.154       0.0938      0.00625
    110   150     2.03e-05     1.99e-05     3.52e-07       0.0915        0.129       0.0722        0.114       0.0929       0.0915        0.161        0.126        0.259       0.0173
    110   160     1.96e-05     1.96e-05     8.05e-09       0.0942        0.128       0.0673        0.125       0.0961       0.0853        0.163        0.124       0.0312      0.00208
    110   170     4.96e-05     4.92e-05     3.81e-07        0.143        0.202       0.0894        0.203        0.146        0.114         0.27        0.192        0.262       0.0175
    110   180      2.3e-05     2.29e-05     8.63e-08        0.102        0.138       0.0728        0.135        0.104       0.0901        0.177        0.134        0.128      0.00854
    110   190     2.85e-05     2.84e-05     2.29e-08        0.117        0.154       0.0916        0.146        0.119        0.121        0.184        0.153       0.0562      0.00375

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    110     5     2.49e-05     2.49e-05     3.92e-09        0.101        0.144       0.0745        0.132        0.103        0.109        0.176        0.142       0.0219      0.00146


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             110 2354.785    0.005     3.22e-05     1.46e-07     3.23e-05         0.12        0.164        0.084         0.16        0.122        0.111        0.208         0.16        0.129      0.00859
! Validation        110 2354.785    0.005      2.9e-05     5.62e-09      2.9e-05        0.106        0.155       0.0735        0.143        0.108        0.107        0.197        0.152       0.0209       0.0014
Wall time: 2354.7858282899997
! Best model      110    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    111    10     2.64e-05     2.62e-05        2e-07        0.112        0.147       0.0825        0.145        0.114        0.104        0.185        0.145        0.194       0.0129
    111    20     2.17e-05     2.17e-05     3.12e-08       0.0973        0.134        0.069         0.13       0.0994       0.0912        0.171        0.131       0.0625      0.00417
    111    30     2.99e-05     2.99e-05     2.76e-08        0.114        0.158       0.0761        0.157        0.117       0.0949        0.207        0.151       0.0594      0.00396
    111    40     3.08e-05     3.07e-05     1.11e-07        0.119         0.16       0.0946        0.147        0.121        0.119        0.196        0.158        0.144      0.00958
    111    50     2.78e-05     2.76e-05     1.23e-07        0.107        0.152       0.0711        0.148         0.11       0.0898          0.2        0.145        0.153       0.0102
    111    60     1.81e-05     1.79e-05     2.55e-07       0.0905        0.122       0.0659        0.119       0.0923       0.0899         0.15         0.12        0.222       0.0148
    111    70     2.58e-05     2.57e-05     7.71e-08        0.105        0.146       0.0746        0.139        0.107          0.1        0.185        0.143        0.119      0.00792
    111    80     3.42e-05     3.42e-05     4.64e-08        0.121        0.169       0.0856        0.161        0.123        0.114        0.215        0.164       0.0844      0.00563
    111    90     3.44e-05     3.44e-05     2.01e-08        0.127        0.169       0.0893         0.17         0.13        0.122        0.211        0.166       0.0594      0.00396
    111   100     3.97e-05     3.95e-05     1.95e-07        0.118        0.181       0.0637        0.181        0.122        0.084         0.25        0.167        0.188       0.0125
    111   110     6.22e-05     6.22e-05     6.97e-08        0.164        0.227       0.0899         0.25         0.17        0.112         0.31        0.211        0.103      0.00687
    111   120     4.33e-05     4.26e-05     6.97e-07        0.139        0.188       0.0901        0.195        0.143         0.12        0.244        0.182        0.363       0.0242
    111   130     3.82e-05     3.82e-05     3.14e-08        0.135        0.178       0.0862        0.191        0.138        0.111        0.232        0.172       0.0625      0.00417
    111   140     2.48e-05     2.48e-05     4.87e-09        0.111        0.144       0.0893        0.136        0.113         0.11        0.174        0.142       0.0219      0.00146
    111   150     4.07e-05     4.07e-05     1.48e-08        0.138        0.184       0.0916         0.19        0.141        0.118        0.238        0.178       0.0531      0.00354
    111   160     3.08e-05     3.07e-05     9.03e-08        0.119         0.16       0.0776        0.166        0.122        0.101        0.207        0.154        0.131      0.00875
    111   170     3.47e-05     3.47e-05     1.42e-08        0.124         0.17       0.0815        0.173        0.127        0.106        0.221        0.164         0.05      0.00333
    111   180     5.25e-05     5.25e-05     3.18e-09        0.156        0.209        0.112        0.206        0.159        0.144        0.265        0.204       0.0219      0.00146
    111   190     5.12e-05     5.12e-05      2.1e-08         0.15        0.206        0.114         0.19        0.152        0.156        0.252        0.204       0.0437      0.00292

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    111     5     2.48e-05     2.48e-05     3.39e-09        0.103        0.143       0.0766        0.132        0.104        0.111        0.174        0.142        0.025      0.00167


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             111 2376.040    0.005     3.39e-05      1.8e-07     3.41e-05        0.123        0.168        0.085        0.166        0.125        0.112        0.215        0.163        0.139      0.00929
! Validation        111 2376.040    0.005     2.83e-05     5.81e-09     2.83e-05        0.106        0.154       0.0733        0.142        0.108        0.106        0.194         0.15       0.0237      0.00158
Wall time: 2376.040740818
! Best model      111    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    112    10     3.12e-05     3.12e-05     3.48e-08        0.126        0.161       0.0996        0.157        0.128        0.124        0.195        0.159       0.0844      0.00563
    112    20     2.82e-05     2.81e-05     1.08e-07        0.118        0.153       0.0957        0.143        0.119        0.117        0.185        0.151        0.141      0.00938
    112    30     2.26e-05     2.24e-05     1.13e-07        0.105        0.137       0.0851        0.128        0.107        0.103        0.167        0.135        0.144      0.00958
    112    40     4.03e-05     3.94e-05     9.04e-07        0.126        0.181       0.0881        0.169        0.129        0.131        0.225        0.178        0.409       0.0273
    112    50     2.76e-05     2.72e-05     3.68e-07        0.114         0.15       0.0916         0.14        0.116         0.11        0.186        0.148        0.262       0.0175
    112    60     3.42e-05     3.42e-05      5.4e-08        0.121        0.169       0.0707        0.178        0.124       0.0933        0.226        0.159       0.0969      0.00646
    112    70     3.31e-05      3.3e-05      7.4e-08        0.117        0.166       0.0872        0.151        0.119        0.116        0.208        0.162        0.122      0.00813
    112    80     2.58e-05     2.57e-05     2.35e-08        0.109        0.146       0.0732        0.149        0.111        0.105        0.182        0.144       0.0656      0.00438
    112    90     3.04e-05     3.04e-05     3.69e-08        0.119        0.159       0.0782        0.167        0.122       0.0986        0.207        0.153        0.075        0.005
    112   100     3.14e-05     3.13e-05     9.22e-08        0.117        0.161       0.0743        0.165         0.12       0.0965        0.212        0.154        0.125      0.00833
    112   110     2.64e-05     2.64e-05        6e-08         0.11        0.148       0.0887        0.134        0.111        0.115        0.179        0.147        0.103      0.00687
    112   120     1.96e-05      1.9e-05     5.48e-07       0.0955        0.126       0.0601        0.136       0.0981       0.0773        0.165        0.121        0.319       0.0213
    112   130     2.43e-05     2.36e-05        7e-07        0.103         0.14       0.0653        0.145        0.105       0.0857        0.184        0.135        0.356       0.0237
    112   140     2.11e-05     2.11e-05     6.78e-09       0.0972        0.132       0.0715        0.126        0.099       0.0951        0.165         0.13       0.0188      0.00125
    112   150     2.98e-05     2.96e-05     2.81e-07        0.116        0.157       0.0787        0.159        0.119          0.1        0.203        0.152        0.228       0.0152
    112   160     4.01e-05        4e-05     3.45e-08         0.13        0.182       0.0839        0.182        0.133        0.103        0.243        0.173       0.0719      0.00479
    112   170     3.58e-05     3.58e-05      2.9e-08        0.125        0.173       0.0901        0.165        0.127         0.12        0.218        0.169       0.0688      0.00458
    112   180     1.84e-05     1.83e-05     9.49e-08       0.0873        0.123       0.0576        0.121       0.0895       0.0727        0.163        0.118        0.131      0.00875
    112   190      3.3e-05     3.27e-05     2.96e-07         0.12        0.165       0.0925        0.151        0.122         0.13        0.198        0.164        0.231       0.0154

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    112     5     2.58e-05     2.58e-05     4.24e-09        0.103        0.146       0.0762        0.135        0.105        0.113        0.177        0.145       0.0219      0.00146


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             112 2397.495    0.005     3.08e-05     1.33e-07      3.1e-05        0.117         0.16       0.0828        0.156        0.119         0.11        0.203        0.156        0.125      0.00834
! Validation        112 2397.495    0.005     2.87e-05     6.68e-09     2.88e-05        0.106        0.155       0.0733        0.143        0.108        0.107        0.195        0.151       0.0244      0.00163
Wall time: 2397.4958336189993

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    113    10      1.9e-05      1.9e-05     1.97e-08       0.0967        0.126       0.0844        0.111       0.0976        0.111         0.14        0.126       0.0562      0.00375
    113    20     3.37e-05     3.37e-05     9.11e-09        0.127        0.167        0.104        0.153        0.129        0.137        0.196        0.167       0.0312      0.00208
    113    30     3.04e-05     3.03e-05     1.52e-07        0.119        0.159       0.0869        0.156        0.121        0.115        0.197        0.156        0.162       0.0108
    113    40     3.13e-05     3.12e-05     3.79e-08        0.125        0.161       0.0966        0.158        0.127        0.125        0.195         0.16       0.0781      0.00521
    113    50     3.44e-05     3.43e-05     3.16e-08        0.121        0.169       0.0757        0.172        0.124        0.104        0.221        0.162       0.0688      0.00458
    113    60     3.26e-05     3.21e-05     4.74e-07         0.12        0.163        0.081        0.164        0.123        0.117        0.204         0.16        0.297       0.0198
    113    70     4.21e-05     4.19e-05     1.64e-07        0.133        0.187       0.0959        0.176        0.136        0.133        0.234        0.183         0.15         0.01
    113    80     3.17e-05     3.17e-05     1.14e-08        0.115        0.162       0.0682        0.168        0.118       0.0883        0.218        0.153       0.0469      0.00313
    113    90     4.13e-05     4.13e-05     1.44e-08        0.133        0.185       0.0962        0.175        0.135        0.129        0.234        0.181       0.0344      0.00229
    113   100     3.82e-05     3.82e-05     2.63e-08        0.135        0.178        0.087        0.189        0.138        0.109        0.233        0.171       0.0625      0.00417
    113   110     4.44e-05     4.41e-05     2.56e-07        0.148        0.192       0.0928        0.211        0.152        0.112        0.253        0.183        0.213       0.0142
    113   120      3.2e-05     3.18e-05     1.34e-07        0.115        0.163       0.0751        0.162        0.118       0.0971        0.214        0.156        0.156       0.0104
    113   130     2.68e-05     2.67e-05     6.65e-08        0.116        0.149        0.088        0.148        0.118        0.111        0.183        0.147        0.109      0.00729
    113   140     3.09e-05     3.09e-05     1.48e-09        0.116         0.16       0.0855        0.152        0.119        0.111        0.203        0.157       0.0125     0.000833
    113   150     2.91e-05     2.91e-05     1.27e-08        0.115        0.155       0.0732        0.162        0.118       0.0948        0.204        0.149       0.0469      0.00313
    113   160     2.09e-05     2.08e-05     1.28e-07        0.101        0.132        0.087        0.118        0.102        0.109        0.153        0.131        0.153       0.0102
    113   170     2.52e-05     2.45e-05     7.13e-07        0.109        0.143       0.0893        0.131         0.11         0.12        0.165        0.142        0.359        0.024
    113   180     3.28e-05     3.21e-05     6.11e-07        0.129        0.164        0.108        0.153        0.131        0.133        0.193        0.163        0.338       0.0225
    113   190     2.71e-05     2.69e-05      2.1e-07        0.115         0.15       0.0905        0.144        0.117        0.115        0.181        0.148          0.2       0.0133

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    113     5     2.56e-05     2.56e-05     3.18e-09        0.103        0.146       0.0755        0.134        0.105        0.112        0.177        0.144       0.0203      0.00135


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             113 2418.960    0.005     3.16e-05     1.38e-07     3.18e-05        0.119        0.162       0.0847        0.159        0.122        0.112        0.205        0.158        0.128      0.00852
! Validation        113 2418.960    0.005     2.85e-05     4.26e-09     2.85e-05        0.106        0.154        0.073        0.143        0.108        0.107        0.194         0.15         0.02      0.00133
Wall time: 2418.960697773

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    114    10      3.5e-05     3.49e-05     1.12e-07        0.123         0.17       0.0764        0.176        0.126        0.102        0.224        0.163        0.141      0.00938
    114    20     2.75e-05     2.75e-05     2.23e-08        0.122        0.151        0.113        0.131        0.122        0.133         0.17        0.151         0.05      0.00333
    114    30     5.13e-05     5.12e-05     7.93e-08        0.153        0.206        0.103         0.21        0.157        0.133        0.266          0.2        0.119      0.00792
    114    40      2.5e-05     2.47e-05     3.34e-07        0.109        0.143       0.0852        0.136         0.11        0.107        0.175        0.141        0.244       0.0162
    114    50     3.16e-05     3.09e-05     7.11e-07        0.119         0.16        0.085        0.159        0.122        0.106        0.206        0.156        0.366       0.0244
    114    60     3.88e-05     3.88e-05      1.5e-08        0.135         0.18       0.0856        0.191        0.138        0.114        0.233        0.173         0.05      0.00333
    114    70     4.73e-05     4.73e-05     9.54e-09        0.148        0.198       0.0938         0.21        0.152        0.118        0.262         0.19       0.0406      0.00271
    114    80     4.52e-05     4.35e-05     1.65e-06        0.133         0.19       0.0848        0.188        0.136         0.11        0.252        0.181         0.55       0.0367
    114    90     3.19e-05     3.18e-05     1.08e-08        0.123        0.163       0.0863        0.165        0.126         0.11        0.207        0.159       0.0344      0.00229
    114   100     4.61e-05     4.58e-05     3.02e-07        0.132        0.195       0.0646        0.208        0.137       0.0835        0.271        0.178        0.228       0.0152
    114   110     4.44e-05     4.44e-05     2.54e-08        0.129        0.192       0.0687        0.198        0.133       0.0967        0.261        0.179       0.0531      0.00354
    114   120     2.74e-05      2.7e-05     3.66e-07        0.109         0.15       0.0756        0.148        0.112        0.104        0.189        0.146        0.262       0.0175
    114   130     2.01e-05     2.01e-05     5.21e-08       0.0972        0.129       0.0776         0.12       0.0986          0.1        0.156        0.128       0.0938      0.00625
    114   140     2.98e-05     2.94e-05     4.44e-07        0.117        0.156       0.0697         0.17         0.12       0.0898        0.208        0.149        0.284        0.019
    114   150     4.94e-05     4.93e-05     9.85e-08        0.141        0.203       0.0811         0.21        0.145        0.109        0.273        0.191        0.128      0.00854
    114   160     5.12e-05      5.1e-05     2.46e-07        0.155        0.206        0.114        0.202        0.158        0.139        0.262        0.201        0.209        0.014
    114   170     2.83e-05     2.74e-05     8.73e-07        0.105        0.151       0.0665         0.15        0.108        0.088          0.2        0.144          0.4       0.0267
    114   180     3.04e-05     3.04e-05     1.61e-08         0.11        0.159       0.0704        0.156        0.113       0.0927        0.211        0.152       0.0469      0.00313
    114   190     3.59e-05     3.58e-05     4.17e-08        0.134        0.173        0.088        0.186        0.137        0.115        0.221        0.168       0.0812      0.00542

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    114     5      2.5e-05      2.5e-05     2.97e-09        0.103        0.144       0.0755        0.135        0.105        0.112        0.173        0.143       0.0203      0.00135


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             114 2440.362    0.005     3.57e-05     2.31e-07     3.59e-05        0.125        0.172       0.0851         0.17        0.128        0.112        0.222        0.167        0.171       0.0114
! Validation        114 2440.362    0.005     2.83e-05     4.37e-09     2.83e-05        0.106        0.153       0.0729        0.143        0.108        0.107        0.193         0.15       0.0225       0.0015
Wall time: 2440.362687535
! Best model      114    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    115    10     2.25e-05     2.25e-05     2.12e-09        0.101        0.137       0.0641        0.144        0.104       0.0831        0.179        0.131       0.0156      0.00104
    115    20     2.43e-05     2.42e-05     8.01e-08        0.105        0.142       0.0702        0.145        0.108       0.0931        0.182        0.138        0.119      0.00792
    115    30     4.74e-05     4.73e-05     1.86e-08        0.154        0.198        0.124        0.189        0.157        0.152        0.241        0.196       0.0594      0.00396
    115    40     2.81e-05      2.8e-05     3.94e-08        0.113        0.153       0.0832        0.148        0.116        0.106        0.193        0.149       0.0844      0.00562
    115    50     4.76e-05     4.73e-05      3.2e-07        0.148        0.198        0.106        0.195        0.151        0.145        0.246        0.195        0.241        0.016
    115    60     3.46e-05     3.45e-05     8.52e-08        0.124        0.169       0.0949        0.156        0.126        0.118        0.214        0.166        0.116      0.00771
    115    70     4.25e-05      4.2e-05     5.54e-07        0.124        0.187       0.0727        0.182        0.128       0.0954        0.254        0.175        0.316        0.021
    115    80     2.91e-05     2.91e-05     7.42e-09        0.114        0.155       0.0779        0.156        0.117        0.103        0.199        0.151       0.0344      0.00229
    115    90     3.43e-05     3.42e-05     1.27e-07         0.12        0.169       0.0767         0.17        0.123          0.1        0.223        0.161        0.153       0.0102
    115   100     2.64e-05     2.62e-05     2.07e-07        0.107        0.148       0.0633        0.158        0.111       0.0807        0.198        0.139        0.191       0.0127
    115   110     2.62e-05     2.59e-05     3.62e-07        0.115        0.147       0.0932         0.14        0.117        0.121        0.171        0.146        0.256       0.0171
    115   120     3.62e-05     3.61e-05      1.1e-07        0.132        0.173       0.0899        0.179        0.135        0.118         0.22        0.169        0.141      0.00938
    115   130     2.17e-05     2.17e-05     3.81e-09       0.0991        0.134       0.0633         0.14        0.102       0.0859        0.174         0.13       0.0156      0.00104
    115   140     2.42e-05     2.41e-05     1.07e-07        0.101        0.142       0.0692        0.138        0.103       0.0895        0.184        0.137        0.138      0.00917
    115   150     3.13e-05     3.13e-05     5.09e-09        0.123        0.161       0.0967        0.152        0.125        0.122        0.197        0.159       0.0312      0.00208
    115   160      3.2e-05     3.16e-05      4.9e-07        0.122        0.162       0.0847        0.165        0.125        0.106        0.208        0.157        0.297       0.0198
    115   170     3.64e-05     3.63e-05     4.37e-08         0.12        0.174       0.0797        0.167        0.123        0.115        0.223        0.169       0.0812      0.00542
    115   180     3.38e-05     3.32e-05     5.92e-07        0.129        0.166        0.102        0.159        0.131         0.13          0.2        0.165        0.331       0.0221
    115   190     2.21e-05      2.2e-05     1.38e-07          0.1        0.135       0.0634        0.142        0.103       0.0849        0.176         0.13         0.15         0.01

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    115     5     2.47e-05     2.47e-05     4.34e-09        0.102        0.143        0.074        0.133        0.103         0.11        0.174        0.142       0.0219      0.00146


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             115 2461.645    0.005     3.22e-05     2.12e-07     3.24e-05        0.119        0.164       0.0811        0.162        0.121        0.107         0.21        0.159        0.164        0.011
! Validation        115 2461.645    0.005     2.82e-05     6.32e-09     2.82e-05        0.105        0.153       0.0724        0.142        0.107        0.106        0.194         0.15       0.0244      0.00163
Wall time: 2461.645238560999
! Best model      115    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    116    10     2.85e-05     2.83e-05     2.16e-07         0.11        0.153       0.0751        0.151        0.113        0.102        0.196        0.149          0.2       0.0133
    116    20     2.31e-05      2.3e-05     3.88e-08        0.103        0.138       0.0784        0.131        0.105          0.1        0.172        0.136       0.0812      0.00542
    116    30     3.32e-05     3.31e-05     4.51e-08        0.125        0.166       0.0937        0.161        0.127        0.118        0.208        0.163       0.0844      0.00563
    116    40     3.42e-05     3.41e-05      1.5e-08        0.131        0.169        0.101        0.164        0.133        0.129        0.204        0.167       0.0375       0.0025
    116    50     2.28e-05     2.27e-05     9.92e-08        0.104        0.137       0.0833        0.129        0.106        0.106        0.166        0.136        0.128      0.00854
    116    60     2.62e-05     2.62e-05     3.18e-09        0.114        0.148       0.0828        0.149        0.116        0.109        0.182        0.145       0.0219      0.00146
    116    70     2.22e-05     2.21e-05     7.01e-08        0.101        0.136       0.0656        0.142        0.104         0.08        0.179         0.13        0.109      0.00729
    116    80     2.17e-05     2.17e-05     6.15e-09       0.0981        0.134       0.0573        0.145        0.101        0.072        0.181        0.126        0.025      0.00167
    116    90     3.35e-05     3.34e-05     1.22e-07        0.121        0.167       0.0648        0.186        0.125       0.0822        0.228        0.155        0.147      0.00979
    116   100     3.01e-05     2.95e-05     5.54e-07        0.115        0.157       0.0774        0.157        0.117        0.101        0.202        0.152        0.325       0.0217
    116   110     2.91e-05     2.84e-05     6.88e-07        0.119        0.154       0.0912        0.152        0.121        0.118        0.187        0.152        0.353       0.0235
    116   120     4.37e-05     4.37e-05     1.08e-08        0.139        0.191       0.0858          0.2        0.143        0.114        0.251        0.182       0.0375       0.0025
    116   130     3.03e-05        3e-05     3.03e-07        0.115        0.158       0.0745        0.162        0.118       0.0989        0.206        0.152        0.234       0.0156
    116   140     3.51e-05      3.5e-05     1.17e-07        0.125        0.171       0.0835        0.172        0.128        0.118        0.215        0.167        0.144      0.00958
    116   150     3.63e-05     3.57e-05     5.35e-07        0.131        0.172       0.0955        0.171        0.133        0.115         0.22        0.168        0.316        0.021
    116   160     3.79e-05     3.75e-05     4.51e-07        0.128        0.177       0.0859        0.175        0.131        0.117        0.226        0.172        0.291       0.0194
    116   170     1.77e-05     1.76e-05     5.47e-08       0.0867        0.121       0.0542        0.124       0.0891       0.0733        0.159        0.116          0.1      0.00667
    116   180     2.63e-05     2.62e-05     6.23e-08         0.11        0.148       0.0693        0.156        0.113       0.0881        0.195        0.141        0.103      0.00688
    116   190     4.37e-05     4.36e-05     1.37e-07        0.143         0.19        0.101        0.192        0.146        0.129        0.242        0.186        0.156       0.0104

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    116     5     2.45e-05     2.45e-05     4.03e-09        0.101        0.143       0.0731        0.132        0.102        0.109        0.173        0.141       0.0219      0.00146


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             116 2482.953    0.005      2.9e-05     2.32e-07     2.93e-05        0.114        0.155       0.0778        0.154        0.116        0.103        0.199        0.151        0.168       0.0112
! Validation        116 2482.953    0.005      2.8e-05     4.68e-09      2.8e-05        0.104        0.153       0.0721        0.141        0.107        0.106        0.193        0.149       0.0216      0.00144
Wall time: 2482.95349462
! Best model      116    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    117    10     2.63e-05     2.59e-05     3.67e-07        0.108        0.147       0.0826        0.137         0.11        0.106        0.182        0.144        0.259       0.0173
    117    20     3.12e-05     3.11e-05     9.49e-08        0.118        0.161       0.0788        0.164        0.121        0.107        0.206        0.156        0.128      0.00854
    117    30     2.31e-05      2.3e-05     6.32e-08        0.105        0.138       0.0748        0.139        0.107       0.0926        0.177        0.135        0.109      0.00729
    117    40      4.1e-05     4.04e-05     5.94e-07        0.142        0.183        0.119        0.167        0.143        0.154        0.211        0.183        0.331       0.0221
    117    50     3.26e-05     3.25e-05     1.42e-08        0.123        0.165       0.0931        0.158        0.125         0.12        0.204        0.162       0.0437      0.00292
    117    60     3.19e-05     3.19e-05     1.59e-08        0.122        0.163        0.098        0.149        0.124        0.126        0.197        0.161       0.0406      0.00271
    117    70     3.68e-05     3.67e-05     1.17e-07        0.135        0.175        0.107        0.166        0.137        0.143        0.205        0.174        0.141      0.00938
    117    80     2.66e-05     2.63e-05     2.73e-07        0.115        0.148        0.087        0.147        0.117        0.108        0.184        0.146        0.222       0.0148
    117    90     5.38e-05     5.38e-05     1.34e-08        0.158        0.211        0.126        0.194         0.16        0.177        0.245        0.211       0.0437      0.00292
    117   100     3.59e-05     3.58e-05      1.2e-07        0.133        0.172       0.0984        0.172        0.135        0.124        0.215        0.169        0.141      0.00938
    117   110     4.33e-05     4.31e-05     2.13e-07        0.145        0.189        0.109        0.186        0.147        0.137        0.235        0.186        0.197       0.0131
    117   120     2.05e-05     2.01e-05     4.34e-07       0.0887        0.129       0.0621        0.119       0.0906       0.0846        0.166        0.125        0.281       0.0188
    117   130     2.23e-05     2.23e-05     2.03e-08        0.102        0.136       0.0781         0.13        0.104       0.0989        0.169        0.134       0.0531      0.00354
    117   140     4.14e-05     4.14e-05     4.13e-08        0.119        0.185       0.0681        0.178        0.123        0.093        0.253        0.173       0.0875      0.00583
    117   150     4.63e-05     4.49e-05     1.38e-06        0.138        0.193       0.0699        0.216        0.143       0.0922        0.265        0.179        0.512       0.0342
    117   160     4.64e-05     4.62e-05     2.32e-07        0.152        0.196         0.13        0.177        0.153         0.16         0.23        0.195          0.2       0.0133
    117   170     4.61e-05     4.59e-05     2.13e-07        0.147        0.195        0.107        0.193         0.15        0.137        0.245        0.191        0.197       0.0131
    117   180     3.29e-05     3.29e-05      2.5e-08        0.125        0.165       0.0828        0.174        0.128        0.106        0.214         0.16       0.0594      0.00396
    117   190     2.85e-05     2.84e-05     6.76e-08        0.112        0.154       0.0781        0.152        0.115       0.0992        0.199        0.149        0.116      0.00771

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    117     5     2.42e-05     2.42e-05     3.81e-09          0.1        0.142       0.0733        0.131        0.102        0.109        0.172         0.14       0.0234      0.00156


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             117 2504.367    0.005     3.45e-05     1.56e-07     3.47e-05        0.124        0.169        0.087        0.167        0.127        0.115        0.216        0.165        0.136      0.00906
! Validation        117 2504.367    0.005     2.76e-05     5.45e-09     2.76e-05        0.104        0.151       0.0722         0.14        0.106        0.106        0.191        0.148       0.0241       0.0016
Wall time: 2504.3682979570003
! Best model      117    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    118    10     2.42e-05     2.42e-05     3.58e-08        0.103        0.142       0.0612         0.15        0.106       0.0816        0.188        0.135        0.075        0.005
    118    20     2.21e-05      2.2e-05     9.88e-08       0.0979        0.135       0.0643        0.136          0.1       0.0804        0.179        0.129        0.134      0.00896
    118    30     2.36e-05     2.35e-05     7.21e-08        0.102         0.14       0.0741        0.133        0.104       0.0986        0.175        0.137        0.109      0.00729
    118    40     4.58e-05     4.51e-05     6.62e-07        0.151        0.194        0.124        0.182        0.153        0.162        0.225        0.193         0.35       0.0233
    118    50     4.85e-05     4.81e-05     4.64e-07        0.148          0.2       0.0955        0.208        0.152        0.129        0.258        0.194        0.291       0.0194
    118    60     3.44e-05     3.42e-05     1.58e-07        0.114        0.169       0.0747        0.159        0.117       0.0953        0.225         0.16        0.175       0.0117
    118    70     3.48e-05     3.46e-05     1.57e-07        0.134         0.17        0.103         0.17        0.137        0.126        0.209        0.167        0.162       0.0108
    118    80     2.83e-05     2.78e-05     5.58e-07        0.109        0.152        0.065        0.159        0.112       0.0903          0.2        0.145        0.325       0.0217
    118    90     2.41e-05      2.4e-05     8.79e-08        0.103        0.141       0.0708        0.139        0.105        0.091        0.183        0.137        0.128      0.00854
    118   100     4.16e-05     4.16e-05     7.99e-08        0.138        0.186         0.11         0.17         0.14         0.15         0.22        0.185        0.119      0.00792
    118   110      3.5e-05      3.5e-05     3.43e-08        0.133        0.171        0.101         0.17        0.135        0.125        0.211        0.168       0.0688      0.00458
    118   120     2.88e-05     2.87e-05     7.33e-08        0.111        0.155       0.0637        0.166        0.115       0.0799         0.21        0.145        0.112       0.0075
    118   130     2.95e-05     2.95e-05     1.93e-08        0.118        0.157       0.0834        0.158        0.121        0.111        0.196        0.154         0.05      0.00333
    118   140     2.75e-05     2.74e-05        1e-07        0.115        0.151       0.0891        0.145        0.117        0.118        0.181         0.15        0.128      0.00854
    118   150     2.41e-05     2.41e-05     1.74e-08        0.103        0.142       0.0584        0.155        0.107       0.0756        0.191        0.133         0.05      0.00333
    118   160     3.78e-05     3.78e-05     4.37e-08        0.132        0.177       0.0963        0.173        0.135        0.121        0.225        0.173       0.0875      0.00583
    118   170     7.41e-05      7.4e-05     3.88e-08        0.188        0.248        0.125         0.26        0.193        0.154        0.324        0.239       0.0781      0.00521
    118   180     4.54e-05     4.53e-05     1.77e-07        0.138        0.194       0.0983        0.183        0.141        0.135        0.245         0.19        0.178       0.0119
    118   190      3.7e-05     3.68e-05     2.06e-07        0.125        0.175        0.065        0.194         0.13       0.0814        0.241        0.161        0.191       0.0127

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    118     5     2.45e-05     2.45e-05     2.97e-09          0.1        0.143       0.0733         0.13        0.102         0.11        0.173        0.141       0.0219      0.00146


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             118 2525.592    0.005     3.18e-05     1.87e-07      3.2e-05        0.119        0.163       0.0824         0.16        0.121        0.109        0.207        0.158        0.146      0.00971
! Validation        118 2525.592    0.005     2.77e-05        6e-09     2.77e-05        0.104        0.152       0.0725         0.14        0.106        0.106        0.191        0.149       0.0222      0.00148
Wall time: 2525.592785731

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    119    10     4.82e-05     4.77e-05     5.66e-07        0.141        0.199       0.0835        0.207        0.145        0.112        0.266        0.189        0.322       0.0215
    119    20     3.67e-05     3.64e-05     3.58e-07        0.131        0.174       0.0944        0.174        0.134         0.12         0.22         0.17        0.253       0.0169
    119    30     1.74e-05     1.74e-05      1.7e-08       0.0907         0.12       0.0609        0.125       0.0928        0.078        0.155        0.117       0.0469      0.00313
    119    40     2.42e-05     2.41e-05     5.09e-08        0.108        0.142       0.0796         0.14         0.11       0.0995        0.178        0.139       0.0844      0.00563
    119    50     4.04e-05     4.02e-05     2.15e-07         0.12        0.183        0.063        0.186        0.125       0.0833        0.253        0.168        0.197       0.0131
    119    60     2.59e-05     2.59e-05     5.57e-08        0.108        0.147       0.0705         0.15         0.11       0.0899        0.192        0.141       0.0969      0.00646
    119    70      1.8e-05      1.8e-05     3.98e-08       0.0894        0.122       0.0585        0.125       0.0916       0.0735        0.161        0.117       0.0812      0.00542
    119    80     2.26e-05     2.25e-05     4.66e-08         0.11        0.137       0.0943        0.128        0.111        0.116        0.157        0.137       0.0875      0.00583
    119    90     3.79e-05     3.79e-05     5.13e-08        0.138        0.177          0.1         0.18         0.14        0.123        0.224        0.174        0.075        0.005
    119   100     2.39e-05     2.39e-05     4.13e-08        0.105        0.141       0.0815        0.132        0.107        0.102        0.175        0.139       0.0812      0.00542
    119   110     3.58e-05     3.58e-05     1.84e-08        0.119        0.173       0.0929        0.149        0.121        0.144          0.2        0.172         0.05      0.00333
    119   120     3.33e-05     3.32e-05     1.84e-07        0.128        0.166        0.124        0.133        0.129        0.153         0.18        0.166        0.181       0.0121
    119   130     2.88e-05     2.64e-05     2.38e-06        0.112        0.148       0.0847        0.143        0.114        0.109        0.183        0.146        0.666       0.0444
    119   140     2.61e-05     2.58e-05     2.32e-07        0.101        0.147       0.0744        0.131        0.103        0.111        0.179        0.145        0.213       0.0142
    119   150     3.78e-05     3.74e-05     4.06e-07         0.13        0.176       0.0952        0.171        0.133         0.12        0.224        0.172        0.275       0.0183
    119   160     2.51e-05     2.48e-05     2.94e-07         0.11        0.144        0.103        0.119        0.111         0.13        0.158        0.144        0.231       0.0154
    119   170     2.12e-05     2.12e-05     8.69e-09        0.101        0.133       0.0633        0.144        0.103       0.0798        0.174        0.127       0.0406      0.00271
    119   180     3.66e-05     3.65e-05     1.52e-07        0.128        0.174       0.0813        0.182        0.132        0.114        0.224        0.169        0.166        0.011
    119   190      4.2e-05      4.2e-05     3.79e-08        0.131        0.187          0.1        0.166        0.133        0.139         0.23        0.184       0.0812      0.00542

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    119     5     2.49e-05     2.49e-05     2.65e-09        0.102        0.144       0.0743        0.133        0.104        0.109        0.176        0.142       0.0156      0.00104


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             119 2546.821    0.005     3.09e-05     2.57e-07     3.12e-05        0.118         0.16       0.0825        0.158         0.12        0.109        0.204        0.156        0.169       0.0113
! Validation        119 2546.821    0.005     2.78e-05     5.87e-09     2.78e-05        0.105        0.152       0.0726        0.142        0.107        0.106        0.192        0.149       0.0234      0.00156
Wall time: 2546.8224290319995

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    120    10     2.75e-05     2.75e-05     2.44e-08        0.115        0.151       0.0807        0.155        0.118        0.109        0.188        0.149       0.0594      0.00396
    120    20     2.41e-05     2.41e-05     7.93e-08        0.103        0.141       0.0719         0.14        0.106       0.0954         0.18        0.138        0.119      0.00792
    120    30     3.07e-05     3.07e-05     6.91e-08         0.12         0.16       0.0972        0.145        0.121        0.122        0.194        0.158          0.1      0.00667
    120    40     1.71e-05     1.71e-05     1.14e-08       0.0934        0.119       0.0816        0.107       0.0943        0.099        0.139        0.119       0.0375       0.0025
    120    50     4.48e-05     4.48e-05     1.17e-08        0.147        0.193        0.102        0.198         0.15        0.134        0.244        0.189       0.0437      0.00292
    120    60     4.06e-05     4.06e-05     9.54e-09        0.141        0.184       0.0954        0.194        0.145         0.12        0.237        0.178       0.0375       0.0025
    120    70     2.83e-05     2.83e-05     6.99e-09        0.121        0.154       0.0885        0.158        0.123        0.107        0.193         0.15       0.0219      0.00146
    120    80     3.02e-05     2.98e-05      3.2e-07        0.124        0.158       0.0999        0.152        0.126        0.125        0.188        0.157        0.241        0.016
    120    90     1.79e-05     1.77e-05      2.3e-07       0.0909        0.121       0.0639        0.122       0.0928       0.0829        0.154        0.118          0.2       0.0133
    120   100     2.53e-05     2.51e-05     1.35e-07        0.109        0.145       0.0766        0.146        0.111       0.0989        0.183        0.141        0.156       0.0104
    120   110      4.1e-05     4.08e-05     1.77e-07        0.148        0.184        0.122        0.178         0.15        0.145         0.22        0.183        0.175       0.0117
    120   120     3.77e-05     3.77e-05     9.47e-08        0.127        0.177       0.0772        0.184         0.13         0.09         0.24        0.165        0.131      0.00875
    120   130     5.12e-05      5.1e-05     2.39e-07        0.141        0.206       0.0804        0.209        0.145        0.103         0.28        0.192        0.206       0.0137
    120   140     2.61e-05     2.59e-05     2.46e-07        0.106        0.147       0.0729        0.144        0.108        0.103        0.184        0.144        0.213       0.0142
    120   150     3.19e-05     3.17e-05     2.33e-07        0.125        0.162       0.0903        0.165        0.128        0.114        0.204        0.159        0.209        0.014
    120   160     4.38e-05     4.37e-05     2.27e-08         0.15        0.191        0.117        0.188        0.152         0.14        0.236        0.188         0.05      0.00333
    120   170     3.94e-05     3.92e-05     2.45e-07        0.139         0.18       0.0923        0.192        0.142        0.113        0.235        0.174        0.209        0.014
    120   180     3.02e-05     3.02e-05     2.52e-08        0.121        0.159        0.103        0.141        0.122        0.138        0.179        0.159       0.0562      0.00375
    120   190     4.88e-05     4.88e-05     3.31e-08        0.151        0.201        0.102        0.207        0.154         0.13         0.26        0.195       0.0688      0.00458

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    120     5     2.46e-05     2.46e-05      3.5e-09       0.0999        0.143       0.0728        0.131        0.102        0.106        0.176        0.141       0.0234      0.00156


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             120 2568.181    0.005     3.39e-05     1.47e-07      3.4e-05        0.123        0.168       0.0853        0.167        0.126        0.112        0.214        0.163        0.133      0.00885
! Validation        120 2568.181    0.005     2.77e-05     5.98e-09     2.77e-05        0.104        0.152        0.072        0.141        0.106        0.105        0.192        0.148       0.0231      0.00154
Wall time: 2568.182182793

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    121    10     3.79e-05     3.77e-05     2.36e-07        0.138        0.177        0.118        0.161        0.139         0.15        0.203        0.177        0.206       0.0137
    121    20     3.49e-05     3.48e-05     7.33e-08        0.122         0.17        0.081        0.168        0.125        0.109         0.22        0.164        0.119      0.00792
    121    30      2.6e-05     2.59e-05     1.21e-07        0.107        0.147       0.0719        0.148         0.11       0.0964        0.189        0.143        0.147      0.00979
    121    40     1.98e-05     1.98e-05     6.99e-09       0.0943        0.128        0.064        0.129       0.0965       0.0835        0.165        0.124       0.0281      0.00188
    121    50     3.97e-05     3.95e-05     1.94e-07        0.123        0.181       0.0643         0.19        0.127       0.0819        0.251        0.166        0.191       0.0127
    121    60     4.41e-05      4.4e-05     7.08e-08        0.138        0.191       0.0741        0.211        0.142       0.0969         0.26        0.179        0.112       0.0075
    121    70     3.12e-05     3.12e-05     5.51e-09         0.12        0.161       0.0866        0.158        0.122        0.113        0.203        0.158       0.0281      0.00188
    121    80     5.15e-05     5.15e-05     3.48e-08        0.148        0.207       0.0883        0.216        0.152        0.116        0.276        0.196       0.0719      0.00479
    121    90     2.66e-05     2.65e-05     9.88e-08       0.0997        0.148       0.0612        0.144        0.102       0.0771        0.201        0.139        0.131      0.00875
    121   100     2.36e-05     2.33e-05     3.22e-07        0.105        0.139       0.0831        0.131        0.107        0.108        0.168        0.138         0.25       0.0167
    121   110     2.54e-05     2.48e-05     6.03e-07        0.105        0.144       0.0763        0.137        0.107       0.0973        0.183         0.14        0.334       0.0223
    121   120     2.98e-05     2.98e-05     1.23e-08        0.115        0.157       0.0785        0.157        0.118       0.0999        0.204        0.152       0.0281      0.00188
    121   130     7.47e-05     7.42e-05     4.61e-07        0.179        0.248        0.129        0.237        0.183        0.162         0.32        0.241        0.294       0.0196
    121   140     2.39e-05     2.32e-05      7.4e-07        0.103        0.139       0.0724        0.139        0.106       0.0945        0.176        0.135        0.372       0.0248
    121   150     4.71e-05     4.67e-05      3.4e-07        0.141        0.197        0.114        0.172        0.143        0.157        0.235        0.196         0.25       0.0167
    121   160      2.4e-05     2.39e-05     1.47e-07        0.107        0.141       0.0767        0.142         0.11       0.0985        0.177        0.138        0.159       0.0106
    121   170     2.95e-05     2.89e-05     5.49e-07        0.106        0.155       0.0627        0.155        0.109       0.0945        0.203        0.149        0.316        0.021
    121   180     2.31e-05      2.3e-05     1.51e-07        0.103        0.138       0.0752        0.136        0.105       0.0945        0.175        0.135        0.162       0.0108
    121   190     2.45e-05     2.37e-05     8.49e-07        0.104         0.14       0.0729        0.141        0.107        0.096        0.178        0.137        0.394       0.0262

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    121     5     2.31e-05     2.31e-05     4.24e-09       0.0978        0.139        0.072        0.127       0.0996        0.105        0.169        0.137       0.0234      0.00156


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             121 2589.589    0.005     3.27e-05     2.31e-07     3.29e-05         0.12        0.165        0.082        0.163        0.123        0.109        0.212         0.16        0.167       0.0111
! Validation        121 2589.589    0.005     2.72e-05      6.8e-09     2.72e-05        0.103         0.15       0.0715        0.139        0.105        0.104         0.19        0.147       0.0247      0.00165
Wall time: 2589.589141061
! Best model      121    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    122    10     3.54e-05      3.5e-05     3.76e-07        0.127        0.171       0.0863        0.173         0.13        0.113        0.218        0.166        0.262       0.0175
    122    20     2.82e-05     2.81e-05     1.65e-07        0.112        0.153       0.0711        0.158        0.115        0.091        0.201        0.146        0.169       0.0113
    122    30     2.79e-05     2.79e-05     3.18e-08        0.107        0.152        0.076        0.142        0.109        0.106        0.192        0.149       0.0719      0.00479
    122    40     2.36e-05     2.33e-05     2.94e-07        0.105        0.139       0.0809        0.133        0.107        0.106        0.169        0.138        0.234       0.0156
    122    50     2.38e-05     2.36e-05     1.97e-07        0.096         0.14       0.0587        0.139       0.0987        0.078        0.187        0.133        0.197       0.0131
    122    60     2.53e-05     2.53e-05      3.6e-08        0.109        0.145       0.0854        0.136        0.111        0.111        0.176        0.144        0.075        0.005
    122    70     3.88e-05     3.86e-05     1.81e-07        0.132        0.179       0.0769        0.196        0.136       0.0983         0.24        0.169        0.181       0.0121
    122    80     6.11e-05     6.11e-05     1.67e-08         0.15        0.225        0.085        0.224        0.154        0.115        0.306        0.211       0.0469      0.00313
    122    90     2.92e-05     2.91e-05     6.87e-08        0.121        0.156        0.095        0.151        0.123        0.117         0.19        0.154        0.109      0.00729
    122   100     2.79e-05     2.78e-05     5.23e-08        0.106        0.152       0.0567        0.162         0.11       0.0727        0.209        0.141       0.0969      0.00646
    122   110     2.92e-05     2.92e-05     1.99e-08        0.119        0.156        0.092         0.15        0.121        0.118         0.19        0.154       0.0469      0.00313
    122   120     2.62e-05     2.59e-05      2.6e-07        0.105        0.147       0.0785        0.134        0.106        0.107        0.182        0.145        0.219       0.0146
    122   130     2.29e-05     2.28e-05     2.44e-08        0.104        0.138       0.0672        0.147        0.107       0.0819        0.182        0.132       0.0656      0.00438
    122   140     4.66e-05     4.64e-05     2.55e-07        0.134        0.196       0.0845         0.19        0.137        0.111        0.262        0.186        0.219       0.0146
    122   150     3.43e-05     3.42e-05     4.73e-08        0.125        0.169       0.0862        0.169        0.128        0.113        0.215        0.164       0.0906      0.00604
    122   160     4.03e-05     3.97e-05     6.17e-07        0.136        0.182       0.0789        0.202        0.141        0.098        0.244        0.171        0.334       0.0223
    122   170     2.61e-05      2.6e-05     2.44e-08        0.106        0.147       0.0732        0.144        0.108       0.0928        0.191        0.142       0.0531      0.00354
    122   180     2.69e-05     2.69e-05     6.78e-09        0.112        0.149       0.0824        0.145        0.114        0.104        0.189        0.146       0.0375       0.0025
    122   190     2.27e-05     2.27e-05     3.09e-08        0.103        0.137       0.0784        0.132        0.105        0.105        0.167        0.136       0.0625      0.00417

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    122     5     2.35e-05     2.35e-05      3.5e-09       0.0978         0.14        0.071        0.128       0.0997        0.105        0.171        0.138       0.0219      0.00146


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             122 2611.122    0.005     2.86e-05     1.71e-07     2.88e-05        0.113        0.154       0.0788        0.152        0.115        0.104        0.196         0.15        0.144      0.00957
! Validation        122 2611.122    0.005     2.71e-05     5.45e-09     2.71e-05        0.102         0.15       0.0706        0.139        0.105        0.103         0.19        0.147       0.0234      0.00156
Wall time: 2611.122923634999
! Best model      122    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    123    10     1.93e-05     1.92e-05     7.84e-09       0.0963        0.127       0.0644        0.133       0.0986       0.0816        0.163        0.122       0.0312      0.00208
    123    20      2.5e-05      2.5e-05     5.09e-08        0.104        0.144       0.0751        0.137        0.106       0.0917        0.187        0.139       0.0938      0.00625
    123    30      3.3e-05     3.23e-05     6.79e-07         0.12        0.164        0.084        0.162        0.123        0.111        0.209         0.16        0.356       0.0237
    123    40     2.43e-05     2.42e-05     2.95e-08        0.106        0.142       0.0717        0.146        0.109       0.0936        0.182        0.138       0.0656      0.00438
    123    50     3.34e-05     3.33e-05     1.48e-08         0.12        0.167       0.0799        0.167        0.123        0.107        0.215        0.161         0.05      0.00333
    123    60      4.1e-05      4.1e-05     8.03e-08        0.136        0.185       0.0906        0.188        0.139        0.124        0.236         0.18        0.116      0.00771
    123    70     3.03e-05     2.95e-05     8.25e-07        0.118        0.157       0.0822        0.158         0.12         0.11        0.197        0.153        0.391        0.026
    123    80     2.79e-05     2.79e-05     9.32e-09         0.12        0.152        0.105        0.138        0.121        0.126        0.178        0.152       0.0344      0.00229
    123    90     5.16e-05     5.16e-05     6.68e-08        0.148        0.207       0.0789        0.228        0.153       0.0984        0.284        0.191        0.109      0.00729
    123   100     3.77e-05     3.76e-05     1.61e-07        0.126        0.177       0.0831        0.176         0.13        0.111         0.23         0.17        0.175       0.0117
    123   110     3.36e-05     3.33e-05     2.99e-07        0.125        0.166       0.0871        0.169        0.128         0.11        0.213        0.162        0.234       0.0156
    123   120      3.3e-05     3.27e-05     2.77e-07        0.121        0.165       0.0706        0.179        0.125       0.0943        0.219        0.157        0.222       0.0148
    123   130     3.47e-05     3.46e-05     8.46e-08        0.125         0.17       0.0895        0.166        0.128         0.12        0.212        0.166        0.122      0.00813
    123   140     3.77e-05     3.71e-05     5.78e-07        0.132        0.176       0.0927        0.176        0.134        0.118        0.224        0.171        0.325       0.0217
    123   150     3.38e-05     3.32e-05     5.76e-07        0.115        0.166       0.0753        0.161        0.118       0.0999        0.219        0.159        0.328       0.0219
    123   160     1.88e-05     1.87e-05     1.26e-07       0.0953        0.125       0.0643        0.131       0.0976       0.0824         0.16        0.121        0.153       0.0102
    123   170     3.48e-05     3.45e-05     3.15e-07        0.123        0.169       0.0859        0.165        0.126        0.115        0.215        0.165        0.241        0.016
    123   180     3.68e-05     3.68e-05     4.87e-09        0.136        0.175        0.104        0.173        0.138        0.132        0.214        0.173        0.025      0.00167
    123   190      2.6e-05     2.59e-05     7.12e-08        0.105        0.147       0.0724        0.143        0.107       0.0935         0.19        0.142        0.112       0.0075

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    123     5     2.43e-05     2.43e-05     3.39e-09        0.099        0.142       0.0719         0.13        0.101        0.107        0.174         0.14       0.0172      0.00115


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             123 2632.673    0.005     3.08e-05     2.26e-07      3.1e-05        0.117         0.16       0.0805        0.159         0.12        0.106        0.205        0.155        0.164        0.011
! Validation        123 2632.673    0.005     2.73e-05     5.43e-09     2.73e-05        0.103        0.151       0.0707         0.14        0.105        0.103        0.191        0.147       0.0216      0.00144
Wall time: 2632.6735498710004

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    124    10     3.79e-05     3.74e-05     5.14e-07        0.124        0.176        0.071        0.185        0.128       0.0998        0.235        0.167        0.309       0.0206
    124    20     4.17e-05     4.15e-05     2.04e-07        0.129        0.186       0.0668          0.2        0.133       0.0862        0.256        0.171        0.191       0.0127
    124    30     2.28e-05     2.28e-05     1.06e-09        0.105        0.138       0.0763        0.138        0.107       0.0961        0.173        0.135       0.0156      0.00104
    124    40     4.89e-05     4.89e-05     6.99e-08        0.142        0.202       0.0857        0.207        0.146        0.116        0.268        0.192       0.0969      0.00646
    124    50     3.73e-05     3.62e-05     1.11e-06        0.135        0.173         0.11        0.164        0.137        0.131        0.212        0.171        0.459       0.0306
    124    60     2.36e-05     2.36e-05     5.59e-08        0.102         0.14       0.0603        0.149        0.105       0.0818        0.185        0.134        0.103      0.00687
    124    70     4.36e-05     4.29e-05      7.3e-07         0.14        0.189        0.101        0.185        0.143        0.139        0.233        0.186        0.366       0.0244
    124    80     3.28e-05     3.26e-05     1.81e-07        0.119        0.165       0.0799        0.163        0.122        0.105        0.213        0.159        0.188       0.0125
    124    90     2.55e-05     2.54e-05     7.84e-08        0.105        0.145       0.0635        0.153        0.108        0.079        0.195        0.137        0.116      0.00771
    124   100     5.02e-05     5.01e-05     1.43e-07        0.151        0.204        0.118        0.189        0.153        0.158        0.246        0.202        0.159       0.0106
    124   110     2.94e-05     2.93e-05     3.09e-08        0.116        0.156       0.0729        0.164        0.119       0.0956        0.205         0.15       0.0688      0.00458
    124   120     3.26e-05      3.2e-05     5.79e-07        0.112        0.163       0.0816        0.147        0.114        0.109        0.208        0.159        0.328       0.0219
    124   130     4.22e-05     4.21e-05     2.92e-08        0.139        0.187        0.097        0.186        0.141        0.124         0.24        0.182       0.0594      0.00396
    124   140     4.52e-05     4.51e-05      7.9e-08        0.139        0.194          0.1        0.185        0.142        0.124        0.251        0.187        0.119      0.00792
    124   150     4.81e-05     4.76e-05      4.7e-07         0.13        0.199       0.0663        0.204        0.135       0.0833        0.277         0.18        0.297       0.0198
    124   160     2.76e-05     2.76e-05     4.54e-08        0.107        0.151       0.0666        0.153         0.11       0.0876        0.201        0.144       0.0844      0.00563
    124   170     3.42e-05     3.38e-05     4.33e-07        0.123        0.168       0.0869        0.164        0.125        0.116        0.212        0.164        0.284        0.019
    124   180     2.87e-05     2.87e-05     9.75e-09        0.113        0.155         0.09         0.14        0.115        0.114         0.19        0.152       0.0375       0.0025
    124   190     3.22e-05      3.2e-05     1.35e-07        0.111        0.163        0.059        0.171        0.115       0.0769        0.224        0.151        0.159       0.0106

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    124     5     2.44e-05     2.44e-05     4.03e-09       0.0994        0.142       0.0722         0.13        0.101        0.105        0.176         0.14       0.0234      0.00156


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             124 2653.924    0.005     3.63e-05     2.39e-07     3.66e-05        0.125        0.174        0.085        0.172        0.128        0.112        0.225        0.168        0.172       0.0115
! Validation        124 2653.924    0.005     2.73e-05     5.36e-09     2.73e-05        0.103        0.151       0.0708        0.139        0.105        0.103        0.191        0.147       0.0222      0.00148
Wall time: 2653.9246719169987

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    125    10     2.85e-05     2.78e-05     7.62e-07        0.118        0.152       0.0917        0.149         0.12        0.117        0.184        0.151        0.378       0.0252
    125    20      2.1e-05     2.07e-05     2.95e-07       0.0968        0.131       0.0562        0.143       0.0997       0.0773        0.173        0.125        0.234       0.0156
    125    30     4.07e-05     4.02e-05     5.51e-07        0.139        0.183        0.102        0.181        0.141        0.133        0.226         0.18        0.319       0.0213
    125    40     2.82e-05     2.82e-05     7.21e-09        0.112        0.153       0.0734        0.157        0.115       0.0935        0.201        0.147       0.0375       0.0025
    125    50     2.43e-05     2.43e-05     1.23e-08        0.099        0.142       0.0581        0.146        0.102       0.0718        0.193        0.133       0.0469      0.00313
    125    60     2.37e-05     2.33e-05      4.6e-07        0.107        0.139       0.0683        0.151         0.11       0.0847        0.182        0.134        0.291       0.0194
    125    70     3.83e-05     3.81e-05     1.06e-07        0.131        0.178       0.0878        0.179        0.134        0.122        0.226        0.174        0.134      0.00896
    125    80     2.26e-05     2.26e-05     4.66e-09        0.107        0.137       0.0817        0.135        0.109        0.103        0.168        0.136       0.0219      0.00146
    125    90      2.8e-05      2.8e-05     3.18e-09        0.115        0.153       0.0713        0.164        0.118        0.093          0.2        0.146       0.0219      0.00146
    125   100      3.1e-05      3.1e-05     1.14e-08        0.122        0.161       0.0938        0.155        0.124        0.117        0.199        0.158       0.0406      0.00271
    125   110     2.87e-05     2.87e-05     1.19e-08        0.108        0.154       0.0624         0.16        0.111       0.0816        0.209        0.145       0.0375       0.0025
    125   120     5.14e-05     5.12e-05     2.67e-07        0.159        0.206        0.121        0.203        0.162        0.152        0.254        0.203        0.219       0.0146
    125   130     6.49e-05     6.46e-05     2.28e-07         0.17        0.232        0.116        0.231        0.174        0.169        0.288        0.228        0.203       0.0135
    125   140     5.07e-05     5.06e-05     7.59e-08        0.162        0.205        0.154        0.172        0.163        0.189        0.222        0.206        0.119      0.00792
    125   150     3.16e-05      3.1e-05     6.22e-07        0.121         0.16       0.0948        0.151        0.123         0.12        0.197        0.158        0.338       0.0225
    125   160     2.72e-05     2.67e-05     4.63e-07        0.112        0.149       0.0898        0.137        0.113        0.113        0.182        0.147        0.291       0.0194
    125   170     4.25e-05     4.25e-05     5.49e-08         0.14        0.188          0.1        0.185        0.143         0.13        0.238        0.184       0.0969      0.00646
    125   180     3.04e-05     3.03e-05     1.02e-07        0.118        0.159       0.0768        0.165        0.121       0.0967        0.208        0.152        0.138      0.00917
    125   190     3.88e-05     3.87e-05     1.17e-07        0.137        0.179        0.104        0.175         0.14        0.129        0.223        0.176        0.141      0.00938

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    125     5     2.38e-05     2.38e-05     3.81e-09        0.099        0.141       0.0719         0.13        0.101        0.105        0.173        0.139       0.0234      0.00156


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             125 2675.193    0.005      3.2e-05     1.88e-07     3.22e-05         0.12        0.163       0.0835        0.161        0.122         0.11        0.208        0.159        0.151       0.0101
! Validation        125 2675.193    0.005     2.68e-05     5.34e-09     2.68e-05        0.102        0.149       0.0703        0.138        0.104        0.103        0.189        0.146       0.0225       0.0015
Wall time: 2675.1939827179995
! Best model      125    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    126    10     3.23e-05     3.21e-05     1.65e-07        0.113        0.163       0.0814         0.15        0.115        0.118        0.203        0.161        0.162       0.0108
    126    20     2.38e-05     2.37e-05        1e-07        0.113         0.14       0.0987        0.129        0.114        0.121         0.16         0.14        0.134      0.00896
    126    30     2.35e-05     2.35e-05      3.6e-09        0.105         0.14        0.079        0.134        0.106       0.0997        0.175        0.137       0.0156      0.00104
    126    40     1.55e-05     1.54e-05     4.11e-08       0.0831        0.113       0.0677        0.101       0.0842       0.0882        0.136        0.112       0.0844      0.00563
    126    50     2.14e-05     2.14e-05      2.2e-08       0.0982        0.133       0.0766        0.123       0.0997       0.0993        0.164        0.132       0.0562      0.00375
    126    60     3.27e-05     3.27e-05     1.63e-08        0.117        0.165       0.0741        0.166         0.12        0.103        0.215        0.159       0.0437      0.00292
    126    70     2.64e-05     2.63e-05     7.42e-09        0.105        0.148       0.0627        0.152        0.108       0.0871        0.196        0.141       0.0344      0.00229
    126    80     2.25e-05     2.24e-05     9.13e-08       0.0965        0.136       0.0576        0.141       0.0993       0.0747        0.183        0.129        0.125      0.00833
    126    90     2.26e-05     2.25e-05     2.69e-08        0.101        0.137       0.0667         0.14        0.103       0.0883        0.177        0.133       0.0656      0.00438
    126   100     2.13e-05      2.1e-05     3.42e-07       0.0976        0.132       0.0743        0.124       0.0993        0.105        0.158        0.131        0.253       0.0169
    126   110     2.92e-05     2.91e-05     9.37e-08        0.109        0.156       0.0579        0.167        0.113       0.0738        0.214        0.144        0.131      0.00875
    126   120      2.2e-05     2.19e-05      1.2e-07        0.102        0.135       0.0724        0.136        0.104       0.0915        0.172        0.132         0.15         0.01
    126   130     3.03e-05     3.01e-05     1.16e-07        0.118        0.158       0.0827        0.159        0.121        0.106        0.202        0.154        0.144      0.00958
    126   140     3.71e-05     3.71e-05     9.75e-09        0.128        0.176       0.0893        0.173        0.131        0.117        0.224        0.171       0.0344      0.00229
    126   150     2.92e-05     2.92e-05      3.5e-08        0.118        0.156       0.0887        0.151         0.12        0.119        0.189        0.154        0.075        0.005
    126   160     3.89e-05     3.89e-05     5.28e-08        0.134         0.18       0.0924        0.182        0.137        0.124        0.227        0.176       0.0906      0.00604
    126   170     3.47e-05     3.47e-05     1.82e-08        0.126         0.17       0.0879         0.17        0.129        0.113        0.217        0.165       0.0531      0.00354
    126   180     3.42e-05     3.42e-05     6.57e-09        0.122        0.169       0.0815        0.169        0.125        0.107        0.219        0.163        0.025      0.00167
    126   190      2.7e-05      2.7e-05     8.05e-09        0.107         0.15       0.0661        0.154         0.11       0.0837          0.2        0.142       0.0219      0.00146

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    126     5     2.35e-05     2.35e-05     2.97e-09       0.0986         0.14       0.0715         0.13        0.101        0.105        0.171        0.138       0.0172      0.00115


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             126 2696.469    0.005     2.64e-05     8.59e-08     2.64e-05        0.108        0.148       0.0754        0.146         0.11       0.0995        0.189        0.144       0.0981      0.00654
! Validation        126 2696.469    0.005     2.68e-05     4.47e-09     2.68e-05        0.102        0.149       0.0703        0.138        0.104        0.103        0.189        0.146       0.0194      0.00129
Wall time: 2696.470433991999
! Best model      126    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    127    10     4.14e-05     4.13e-05     1.51e-07        0.137        0.185       0.0998         0.18         0.14        0.128        0.234        0.181        0.159       0.0106
    127    20     1.79e-05     1.79e-05     1.27e-09       0.0884        0.122       0.0683        0.111       0.0898       0.0918        0.149         0.12      0.00938     0.000625
    127    30     2.24e-05     2.23e-05     1.11e-07       0.0997        0.136       0.0733         0.13        0.102       0.0925        0.173        0.133        0.138      0.00917
    127    40     2.49e-05     2.49e-05     9.96e-09        0.106        0.144       0.0687        0.148        0.109       0.0924        0.186        0.139       0.0344      0.00229
    127    50     2.31e-05     2.31e-05     1.27e-08        0.105        0.138       0.0849        0.127        0.106        0.108        0.167        0.137       0.0406      0.00271
    127    60     2.32e-05     2.28e-05     3.22e-07        0.109        0.138       0.0943        0.125         0.11        0.116        0.159        0.138        0.241        0.016
    127    70     3.99e-05     3.98e-05      7.9e-08        0.128        0.182       0.0741         0.19        0.132       0.0932        0.247         0.17        0.119      0.00792
    127    80      2.3e-05      2.3e-05      3.6e-08       0.0974        0.138        0.062        0.138          0.1       0.0839        0.181        0.133       0.0719      0.00479
    127    90     2.23e-05     2.23e-05     1.31e-08        0.101        0.136       0.0804        0.125        0.103        0.108        0.162        0.135       0.0375       0.0025
    127   100     2.18e-05     2.17e-05     1.02e-07        0.103        0.134       0.0746        0.136        0.105       0.0939        0.169        0.131        0.141      0.00938
    127   110     1.63e-05     1.62e-05     1.32e-07       0.0912        0.116       0.0736        0.111       0.0924        0.093        0.138        0.115        0.147      0.00979
    127   120     1.87e-05     1.87e-05     1.19e-08       0.0915        0.125       0.0687        0.118       0.0932       0.0921        0.154        0.123       0.0437      0.00292
    127   130     2.29e-05     2.29e-05     1.82e-08          0.1        0.138       0.0717        0.133        0.102       0.0919        0.177        0.134       0.0531      0.00354
    127   140     2.57e-05     2.57e-05     4.66e-09        0.106        0.146       0.0772        0.139        0.108        0.106        0.182        0.144       0.0219      0.00146
    127   150     3.91e-05      3.9e-05     1.03e-07        0.134         0.18        0.094        0.179        0.137        0.119        0.231        0.175        0.134      0.00896
    127   160      4.3e-05     4.23e-05     7.35e-07        0.132        0.187       0.0808        0.191        0.136        0.103        0.251        0.177        0.366       0.0244
    127   170     3.05e-05     3.04e-05     9.43e-08        0.118        0.159       0.0825        0.159        0.121        0.107        0.203        0.155        0.134      0.00896
    127   180     1.72e-05     1.72e-05     1.12e-08       0.0875         0.12       0.0659        0.112       0.0891       0.0885        0.147        0.118       0.0375       0.0025
    127   190      3.5e-05     3.49e-05     5.98e-08        0.122         0.17       0.0748        0.176        0.126       0.0947        0.228        0.161        0.103      0.00687

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    127     5     2.42e-05     2.42e-05      3.5e-09       0.0992        0.142       0.0719         0.13        0.101        0.106        0.174         0.14       0.0219      0.00146


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             127 2717.885    0.005     2.86e-05     1.28e-07     2.87e-05        0.112        0.154        0.077        0.152        0.114        0.102        0.198         0.15        0.123      0.00821
! Validation        127 2717.885    0.005     2.65e-05     4.96e-09     2.65e-05        0.101        0.148       0.0697        0.137        0.103        0.102        0.188        0.145       0.0216      0.00144
Wall time: 2717.886162015
! Best model      127    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    128    10     2.28e-05     2.28e-05     9.54e-09        0.103        0.138       0.0743        0.136        0.105       0.0942        0.175        0.134       0.0312      0.00208
    128    20     2.28e-05     2.28e-05     5.51e-09       0.0975        0.138       0.0618        0.138          0.1       0.0808        0.182        0.131       0.0281      0.00188
    128    30     2.19e-05     2.19e-05     8.03e-08        0.102        0.135       0.0668        0.143        0.105       0.0857        0.175         0.13        0.119      0.00792
    128    40     4.22e-05     4.19e-05      2.6e-07        0.137        0.187        0.088        0.193         0.14         0.12        0.241        0.181        0.216       0.0144
    128    50     2.62e-05     2.61e-05     3.22e-08        0.112        0.147       0.0806        0.147        0.114        0.101        0.187        0.144       0.0688      0.00458
    128    60     3.59e-05     3.59e-05     1.86e-08        0.119        0.173       0.0741         0.17        0.122         0.11        0.224        0.167         0.05      0.00333
    128    70     4.09e-05     3.97e-05     1.17e-06        0.131        0.182       0.0899        0.178        0.134        0.111        0.238        0.175        0.469       0.0312
    128    80     3.97e-05     3.96e-05     1.17e-07        0.139        0.182        0.109        0.173        0.141        0.135        0.223        0.179        0.147      0.00979
    128    90     1.62e-05     1.62e-05     6.36e-09       0.0864        0.116       0.0578        0.119       0.0884        0.077        0.148        0.113       0.0188      0.00125
    128   100     3.15e-05     3.07e-05     7.63e-07        0.122         0.16       0.0963        0.152        0.124        0.121        0.195        0.158        0.381       0.0254
    128   110     2.75e-05     2.75e-05     4.49e-08        0.111        0.151       0.0677        0.161        0.114       0.0878          0.2        0.144       0.0844      0.00563
    128   120     3.12e-05     3.12e-05     1.93e-08        0.116        0.161         0.08        0.157        0.118        0.106        0.207        0.156       0.0594      0.00396
    128   130     2.75e-05     2.75e-05     4.45e-09        0.111        0.151       0.0733        0.154        0.114       0.0956        0.196        0.146       0.0281      0.00188
    128   140      2.7e-05     2.69e-05     7.88e-08        0.115         0.15       0.0983        0.134        0.116        0.122        0.175        0.149        0.116      0.00771
    128   150      2.9e-05     2.85e-05     5.73e-07        0.122        0.154       0.0993        0.148        0.124        0.124        0.182        0.153        0.328       0.0219
    128   160     1.87e-05     1.86e-05     8.48e-08       0.0909        0.125       0.0599        0.126       0.0932       0.0819         0.16        0.121        0.125      0.00833
    128   170      2.9e-05     2.89e-05     4.58e-08        0.112        0.155       0.0616         0.17        0.116       0.0802         0.21        0.145       0.0875      0.00583
    128   180     4.93e-05     4.92e-05     9.56e-08        0.146        0.202       0.0892         0.21         0.15        0.111        0.271        0.191        0.134      0.00896
    128   190     2.27e-05      2.2e-05     7.46e-07       0.0951        0.135       0.0615        0.133       0.0975       0.0806        0.178        0.129        0.369       0.0246

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    128     5     2.29e-05     2.29e-05      3.5e-09       0.0977        0.138       0.0708        0.128       0.0996        0.103        0.169        0.136       0.0188      0.00125


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             128 2739.234    0.005     3.16e-05     2.04e-07     3.19e-05        0.118        0.162       0.0813        0.161        0.121        0.107        0.208        0.158        0.157       0.0104
! Validation        128 2739.234    0.005     2.59e-05     4.47e-09     2.59e-05          0.1        0.147       0.0696        0.136        0.103        0.102        0.185        0.144         0.02      0.00133
Wall time: 2739.235474882
! Best model      128    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    129    10     3.34e-05     3.28e-05     5.94e-07        0.121        0.165       0.0752        0.173        0.124          0.1        0.217        0.159        0.328       0.0219
    129    20     2.53e-05     2.53e-05     7.21e-09        0.107        0.145       0.0813        0.137        0.109        0.104        0.181        0.142       0.0281      0.00188
    129    30     1.96e-05     1.95e-05     1.17e-07       0.0933        0.127       0.0638        0.127       0.0954        0.082        0.164        0.123        0.147      0.00979
    129    40     4.76e-05     4.74e-05     2.13e-07        0.142        0.199       0.0901        0.201        0.145        0.113        0.265        0.189        0.197       0.0131
    129    50     2.42e-05     2.36e-05     6.37e-07        0.104         0.14       0.0692        0.143        0.106       0.0855        0.183        0.134        0.341       0.0227
    129    60     2.32e-05     2.32e-05     1.06e-08        0.106        0.139       0.0782        0.138        0.108        0.098        0.174        0.136       0.0375       0.0025
    129    70     2.78e-05     2.78e-05     2.12e-09        0.109        0.152       0.0633        0.161        0.112       0.0796        0.205        0.143       0.0188      0.00125
    129    80     4.45e-05     4.45e-05      1.8e-08        0.148        0.192        0.131        0.169         0.15        0.164         0.22        0.192       0.0531      0.00354
    129    90     3.03e-05        3e-05     2.37e-07        0.123        0.158       0.0979        0.151        0.125         0.12        0.193        0.156        0.209        0.014
    129   100     5.64e-05     5.61e-05      2.3e-07        0.171        0.216        0.132        0.215        0.174        0.162        0.264        0.213        0.206       0.0137
    129   110     2.56e-05     2.54e-05     1.98e-07        0.103        0.145       0.0657        0.146        0.106       0.0892         0.19         0.14        0.194       0.0129
    129   120     2.21e-05     2.17e-05      3.7e-07        0.103        0.134       0.0828        0.125        0.104        0.105        0.162        0.133        0.266       0.0177
    129   130     2.35e-05     2.32e-05     2.18e-07       0.0961        0.139       0.0546        0.144       0.0991       0.0698        0.189         0.13          0.2       0.0133
    129   140     1.82e-05     1.82e-05     8.27e-08        0.089        0.123       0.0551        0.128       0.0914       0.0721        0.163        0.117        0.122      0.00813
    129   150     2.72e-05     2.72e-05     5.51e-09        0.109         0.15       0.0717        0.152        0.112       0.0966        0.194        0.146        0.025      0.00167
    129   160     2.37e-05     2.36e-05     9.56e-08        0.107         0.14       0.0819        0.135        0.109       0.0983        0.176        0.137        0.131      0.00875
    129   170     2.63e-05     2.63e-05     3.79e-08        0.106        0.148       0.0673         0.15        0.109       0.0885        0.195        0.142       0.0781      0.00521
    129   180     3.76e-05     3.68e-05     8.43e-07         0.13        0.175       0.0803        0.186        0.133        0.104         0.23        0.167        0.397       0.0265
    129   190     2.38e-05     2.35e-05     3.34e-07          0.1         0.14       0.0651         0.14        0.103       0.0835        0.184        0.134        0.247       0.0165

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    129     5     2.29e-05     2.29e-05     2.23e-09       0.0975        0.138       0.0715        0.127       0.0993        0.105        0.168        0.137       0.0203      0.00135


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             129 2760.436    0.005     3.09e-05     1.67e-07     3.11e-05        0.116         0.16       0.0795        0.158        0.119        0.105        0.206        0.156        0.136      0.00906
! Validation        129 2760.436    0.005     2.59e-05     4.45e-09     2.59e-05          0.1        0.147       0.0701        0.135        0.102        0.103        0.185        0.144       0.0225       0.0015
Wall time: 2760.436968889
! Best model      129    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    130    10     2.85e-05     2.85e-05     2.95e-08        0.117        0.154       0.0832        0.155        0.119        0.105        0.195         0.15       0.0688      0.00458
    130    20     2.88e-05     2.88e-05     4.81e-08        0.116        0.155       0.0796        0.158        0.119       0.0953        0.202        0.149       0.0969      0.00646
    130    30     2.79e-05     2.78e-05     8.63e-08        0.112        0.152       0.0741        0.156        0.115       0.0933        0.199        0.146        0.125      0.00833
    130    40     1.77e-05     1.77e-05     6.57e-09       0.0948        0.121        0.073         0.12       0.0964       0.0891         0.15         0.12        0.025      0.00167
    130    50     1.54e-05     1.53e-05     6.36e-09       0.0886        0.113       0.0619        0.119       0.0905       0.0804        0.141        0.111        0.025      0.00167
    130    60      3.3e-05     3.28e-05     1.41e-07         0.12        0.165       0.0857         0.16        0.123         0.11        0.212        0.161        0.156       0.0104
    130    70     2.27e-05     2.26e-05     3.12e-08        0.106        0.137       0.0793        0.135        0.107        0.097        0.172        0.134        0.075        0.005
    130    80     2.88e-05     2.87e-05     1.53e-07        0.114        0.154       0.0772        0.156        0.117        0.103        0.197         0.15        0.169       0.0113
    130    90     2.13e-05     2.12e-05     1.48e-08       0.0978        0.133       0.0589        0.142        0.101       0.0751        0.177        0.126         0.05      0.00333
    130   100     2.94e-05     2.93e-05     1.48e-07        0.117        0.156       0.0824        0.157         0.12        0.109        0.196        0.153        0.166        0.011
    130   110      3.3e-05      3.3e-05     2.54e-09        0.127        0.166       0.0904        0.168        0.129        0.115        0.209        0.162       0.0125     0.000833
    130   120     3.48e-05     3.48e-05     2.52e-08        0.118         0.17       0.0762        0.166        0.121        0.103        0.223        0.163       0.0625      0.00417
    130   130     1.57e-05     1.57e-05     2.39e-08       0.0911        0.114       0.0693        0.116       0.0926       0.0864         0.14        0.113       0.0688      0.00458
    130   140     3.08e-05     3.07e-05     1.15e-07        0.117         0.16       0.0839        0.156         0.12        0.106        0.205        0.155        0.144      0.00958
    130   150     2.36e-05     2.35e-05     1.16e-07        0.109         0.14       0.0789        0.144        0.111        0.099        0.175        0.137         0.15         0.01
    130   160      3.2e-05      3.2e-05     6.57e-09        0.117        0.163       0.0744        0.166         0.12        0.101        0.213        0.157       0.0312      0.00208
    130   170     6.48e-05     6.47e-05     4.01e-08        0.168        0.232       0.0977        0.248        0.173        0.121        0.314        0.217        0.075        0.005
    130   180     2.65e-05     2.65e-05     1.27e-08        0.103        0.148       0.0633        0.149        0.106       0.0825        0.199        0.141       0.0406      0.00271
    130   190     2.98e-05     2.97e-05     1.76e-07        0.112        0.157       0.0687        0.162        0.115       0.0919        0.208         0.15        0.181       0.0121

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    130     5     2.34e-05     2.34e-05     2.76e-09       0.0981        0.139       0.0717        0.128       0.0999        0.106        0.169        0.138       0.0172      0.00115


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             130 2781.596    0.005        3e-05     1.37e-07     3.01e-05        0.115        0.158       0.0797        0.155        0.118        0.105        0.202        0.154        0.124      0.00827
! Validation        130 2781.596    0.005     2.57e-05     5.36e-09     2.57e-05          0.1        0.146       0.0697        0.135        0.102        0.102        0.184        0.143       0.0228      0.00152
Wall time: 2781.596383246
! Best model      130    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    131    10     2.11e-05     2.07e-05     3.31e-07        0.101        0.131       0.0842        0.119        0.102        0.105        0.156         0.13        0.247       0.0165
    131    20     3.34e-05     3.34e-05     5.83e-08        0.123        0.167        0.097        0.153        0.125        0.134        0.197        0.166       0.0906      0.00604
    131    30     1.74e-05     1.73e-05     9.28e-08       0.0967         0.12       0.0863        0.108       0.0974        0.106        0.134         0.12        0.128      0.00854
    131    40     3.86e-05     3.86e-05     5.98e-08        0.141        0.179        0.119        0.165        0.142         0.15        0.207        0.179        0.103      0.00687
    131    50     3.55e-05     3.55e-05     6.57e-09        0.134        0.172       0.0968        0.176        0.136        0.119        0.217        0.168       0.0344      0.00229
    131    60     4.04e-05     4.04e-05     7.06e-08         0.14        0.183         0.11        0.175        0.142        0.138        0.224        0.181        0.112       0.0075
    131    70     4.23e-05     4.23e-05     4.87e-09        0.131        0.188       0.0795         0.19        0.135        0.104        0.251        0.178       0.0281      0.00188
    131    80     4.27e-05     4.26e-05     9.37e-08        0.133        0.188       0.0673        0.209        0.138       0.0951        0.256        0.176        0.128      0.00854
    131    90     4.29e-05     4.25e-05     3.02e-07        0.136        0.188       0.0788        0.201         0.14        0.104        0.252        0.178        0.234       0.0156
    131   100     5.11e-05     5.03e-05     7.97e-07        0.148        0.205          0.1        0.203        0.152        0.132        0.264        0.198        0.384       0.0256
    131   110     1.85e-05     1.82e-05     2.79e-07       0.0922        0.123       0.0664        0.122       0.0941       0.0835        0.157         0.12        0.222       0.0148
    131   120     3.36e-05     3.36e-05     4.62e-08        0.124        0.167       0.0811        0.174        0.127        0.106        0.217        0.161       0.0938      0.00625
    131   130     2.56e-05     2.56e-05     2.69e-08        0.107        0.146       0.0706         0.15         0.11       0.0883        0.192         0.14       0.0656      0.00438
    131   140     3.11e-05      3.1e-05     5.21e-08         0.12        0.161       0.0899        0.155        0.122        0.112        0.202        0.157       0.0938      0.00625
    131   150     3.05e-05     3.05e-05     3.92e-08        0.122        0.159        0.085        0.164        0.124        0.113        0.199        0.156       0.0812      0.00542
    131   160     2.47e-05     2.45e-05     1.58e-07        0.107        0.143       0.0781        0.139        0.109        0.107        0.175        0.141        0.169       0.0113
    131   170     4.87e-05     4.87e-05     2.67e-08        0.153        0.201        0.104         0.21        0.157        0.132        0.259        0.195       0.0688      0.00458
    131   180     3.39e-05     3.38e-05     9.79e-08        0.113        0.168       0.0689        0.164        0.117       0.0938        0.224        0.159        0.122      0.00813
    131   190     3.36e-05     3.35e-05     7.33e-08        0.116        0.167       0.0717        0.167        0.119       0.0959        0.222        0.159        0.109      0.00729

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    131     5     2.24e-05     2.24e-05     4.03e-09       0.0952        0.136       0.0696        0.124        0.097        0.103        0.167        0.135       0.0203      0.00135


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             131 2803.028    0.005     3.29e-05     1.37e-07      3.3e-05        0.121        0.165       0.0858        0.162        0.124        0.113         0.21        0.162        0.129      0.00858
! Validation        131 2803.028    0.005     2.53e-05     4.54e-09     2.53e-05       0.0989        0.145       0.0689        0.133        0.101        0.101        0.183        0.142       0.0184      0.00123
Wall time: 2803.0289497159993
! Best model      131    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    132    10      3.9e-05     3.88e-05     1.94e-07        0.137         0.18       0.0958        0.184         0.14         0.12         0.23        0.175        0.181       0.0121
    132    20     2.74e-05     2.74e-05     4.11e-08        0.114        0.151       0.0669        0.168        0.117       0.0833        0.202        0.143       0.0781      0.00521
    132    30     2.28e-05     2.24e-05     3.92e-07        0.101        0.137       0.0668        0.139        0.103       0.0861        0.177        0.132        0.269       0.0179
    132    40     3.35e-05     3.35e-05     5.49e-08        0.129        0.167       0.0886        0.175        0.132        0.105        0.217        0.161       0.0938      0.00625
    132    50     2.91e-05     2.89e-05     2.23e-07        0.113        0.155       0.0762        0.155        0.115       0.0952        0.203        0.149        0.203       0.0135
    132    60     2.39e-05     2.38e-05     4.62e-08        0.101        0.141       0.0606        0.147        0.104       0.0772        0.189        0.133       0.0938      0.00625
    132    70      2.5e-05     2.48e-05     1.98e-07        0.102        0.144       0.0574        0.154        0.105       0.0752        0.194        0.135        0.194       0.0129
    132    80     2.19e-05     2.19e-05     8.05e-09        0.103        0.135        0.081        0.127        0.104        0.106        0.162        0.134       0.0312      0.00208
    132    90     3.49e-05     3.49e-05     1.91e-08        0.117         0.17       0.0774        0.162         0.12        0.108        0.221        0.164       0.0562      0.00375
    132   100     2.51e-05      2.5e-05     3.01e-08        0.107        0.144       0.0765        0.142        0.109       0.0998        0.182        0.141       0.0656      0.00438
    132   110     2.08e-05     2.08e-05     2.33e-08        0.103        0.132       0.0788         0.13        0.105       0.0956        0.163        0.129       0.0531      0.00354
    132   120     3.71e-05      3.7e-05     1.32e-07        0.127        0.175          0.1        0.156        0.128        0.124         0.22        0.172        0.156       0.0104
    132   130     2.22e-05     2.21e-05     1.38e-08       0.0987        0.136       0.0702        0.131        0.101       0.0909        0.173        0.132       0.0344      0.00229
    132   140     2.66e-05     2.63e-05     2.82e-07        0.107        0.148       0.0697        0.149         0.11       0.0995        0.189        0.144        0.228       0.0152
    132   150     3.77e-05     3.77e-05     7.88e-08        0.131        0.177       0.0917        0.175        0.133         0.11        0.231         0.17        0.112       0.0075
    132   160     1.64e-05     1.64e-05     2.76e-09       0.0885        0.117       0.0571        0.124       0.0907       0.0727        0.152        0.112       0.0188      0.00125
    132   170     3.31e-05     3.31e-05     2.61e-08        0.121        0.166         0.08        0.169        0.124        0.102        0.217         0.16       0.0594      0.00396
    132   180     2.89e-05     2.88e-05     1.37e-07        0.115        0.155       0.0739        0.162        0.118       0.0956        0.202        0.149        0.153       0.0102
    132   190     2.49e-05     2.48e-05     1.63e-07        0.101        0.144       0.0605        0.147        0.104       0.0811        0.191        0.136        0.169       0.0113

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    132     5     2.34e-05     2.34e-05     1.38e-09       0.0971        0.139         0.07        0.128       0.0991        0.103        0.172        0.137       0.0141     0.000938


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             132 2824.466    0.005     2.67e-05     1.06e-07     2.68e-05        0.109        0.149       0.0759        0.147        0.111       0.0999         0.19        0.145        0.117      0.00779
! Validation        132 2824.466    0.005     2.56e-05     4.07e-09     2.56e-05       0.0997        0.146       0.0686        0.135        0.102          0.1        0.185        0.143       0.0175      0.00117
Wall time: 2824.4666688859998

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    133    10     2.35e-05     2.33e-05     2.66e-07        0.108        0.139       0.0796        0.141         0.11       0.0976        0.175        0.136        0.222       0.0148
    133    20     2.21e-05     2.21e-05     3.18e-09        0.101        0.136       0.0725        0.133        0.103       0.0961         0.17        0.133       0.0188      0.00125
    133    30     1.57e-05     1.57e-05     5.93e-09       0.0825        0.114       0.0567        0.112       0.0843       0.0716        0.149         0.11        0.025      0.00167
    133    40     1.83e-05     1.83e-05      3.6e-08       0.0918        0.123       0.0565        0.132       0.0943        0.074        0.162        0.118        0.075        0.005
    133    50     2.61e-05     2.61e-05     3.94e-08        0.112        0.147       0.0765        0.153        0.115       0.0965        0.189        0.143       0.0844      0.00563
    133    60     3.25e-05      3.2e-05     4.31e-07        0.121        0.163       0.0834        0.164        0.124        0.108        0.209        0.159        0.284        0.019
    133    70     4.04e-05     4.04e-05     6.57e-09        0.132        0.183       0.0813        0.189        0.135        0.103        0.245        0.174        0.025      0.00167
    133    80     2.16e-05     2.16e-05     1.59e-08        0.103        0.134       0.0782        0.132        0.105        0.102        0.163        0.133       0.0531      0.00354
    133    90     1.29e-05     1.29e-05     1.67e-08       0.0779        0.103       0.0602       0.0981       0.0791       0.0774        0.127        0.102       0.0531      0.00354
    133   100     1.69e-05     1.69e-05     5.23e-08       0.0876        0.118       0.0536        0.126         0.09       0.0678        0.157        0.113        0.103      0.00687
    133   110     3.56e-05     3.53e-05     2.76e-07        0.132        0.171        0.103        0.165        0.134        0.125        0.212        0.169        0.219       0.0146
    133   120     5.63e-05     5.62e-05     5.66e-08        0.154        0.216       0.0867        0.231        0.159        0.109        0.294        0.202       0.0969      0.00646
    133   130     2.76e-05     2.75e-05     8.48e-08        0.109        0.151       0.0738        0.149        0.111       0.0971        0.196        0.146        0.122      0.00813
    133   140     1.86e-05     1.85e-05     1.89e-08       0.0934        0.124        0.066        0.125       0.0954       0.0895        0.155        0.122       0.0406      0.00271
    133   150      3.2e-05     3.19e-05     6.76e-08        0.121        0.163       0.0693         0.18        0.124       0.0881        0.219        0.154        0.106      0.00708
    133   160     3.14e-05     3.12e-05     2.41e-07        0.114        0.161       0.0623        0.173        0.118       0.0813        0.219         0.15        0.203       0.0135
    133   170     2.15e-05     2.14e-05     1.65e-08       0.0948        0.134       0.0704        0.123       0.0966        0.104        0.161        0.132       0.0469      0.00313
    133   180     2.84e-05     2.82e-05     1.44e-07         0.11        0.153       0.0811        0.143        0.112        0.106        0.194         0.15        0.166        0.011
    133   190     2.51e-05      2.5e-05     1.19e-07        0.106        0.144       0.0772        0.138        0.108        0.112        0.174        0.143        0.144      0.00958

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    133     5     2.31e-05     2.31e-05     2.86e-09       0.0957        0.139       0.0689        0.126       0.0976        0.101        0.172        0.136       0.0156      0.00104


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             133 2845.682    0.005     2.67e-05     1.19e-07     2.68e-05        0.109        0.149       0.0762        0.147        0.111        0.101         0.19        0.145        0.122      0.00813
! Validation        133 2845.682    0.005     2.54e-05     4.94e-09     2.54e-05       0.0992        0.145       0.0685        0.134        0.101       0.0999        0.184        0.142       0.0206      0.00138
Wall time: 2845.682229713999

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    134    10     2.91e-05     2.91e-05     9.32e-09        0.109        0.156       0.0727         0.15        0.111       0.0926        0.205        0.149       0.0375       0.0025
    134    20     2.08e-05     2.08e-05     2.76e-08        0.102        0.131       0.0834        0.124        0.104        0.104        0.157        0.131       0.0531      0.00354
    134    30     2.24e-05     2.24e-05     8.03e-08        0.106        0.136        0.091        0.123        0.107        0.115        0.158        0.136        0.119      0.00792
    134    40      3.1e-05      3.1e-05     1.25e-08        0.114         0.16       0.0793        0.155        0.117        0.126        0.193        0.159       0.0312      0.00208
    134    50     2.14e-05     2.09e-05     5.81e-07        0.101        0.132       0.0778        0.127        0.103       0.0963        0.163         0.13        0.331       0.0221
    134    60     1.67e-05     1.67e-05     5.38e-08       0.0871        0.118        0.062        0.116       0.0889       0.0794         0.15        0.115       0.0938      0.00625
    134    70     3.91e-05     3.89e-05     1.54e-07        0.126         0.18       0.0903        0.167        0.128        0.114        0.233        0.174        0.172       0.0115
    134    80      2.3e-05      2.3e-05     6.48e-08        0.106        0.138       0.0769        0.139        0.108       0.0984        0.173        0.136        0.106      0.00708
    134    90     1.51e-05     1.51e-05     1.14e-08       0.0863        0.112       0.0614        0.115       0.0881        0.078        0.141         0.11       0.0437      0.00292
    134   100     1.85e-05     1.84e-05      1.1e-07       0.0956        0.124       0.0743         0.12       0.0972       0.0955        0.149        0.122        0.144      0.00958
    134   110     2.95e-05     2.93e-05     1.33e-07        0.115        0.156       0.0816        0.153        0.117        0.103          0.2        0.152        0.156       0.0104
    134   120     1.95e-05     1.95e-05     6.72e-08       0.0975        0.127       0.0726        0.126       0.0993       0.0892         0.16        0.125        0.106      0.00708
    134   130     3.01e-05     3.01e-05     1.06e-08        0.111        0.158         0.07        0.158        0.114        0.101        0.205        0.153       0.0344      0.00229
    134   140     2.04e-05     2.03e-05     1.45e-07        0.102         0.13       0.0865        0.119        0.103        0.108        0.151        0.129        0.166        0.011
    134   150     2.02e-05     2.02e-05     5.51e-09       0.0961         0.13       0.0671        0.129       0.0982       0.0868        0.166        0.126       0.0312      0.00208
    134   160     2.76e-05     2.75e-05     1.25e-08        0.109        0.151       0.0683        0.156        0.112       0.0877        0.201        0.144       0.0406      0.00271
    134   170     4.15e-05     4.14e-05      1.5e-08        0.137        0.186       0.0951        0.185         0.14        0.122        0.239         0.18       0.0437      0.00292
    134   180     2.46e-05      2.4e-05     6.54e-07        0.104        0.141       0.0669        0.146        0.106       0.0806        0.188        0.134         0.35       0.0233
    134   190     2.96e-05     2.93e-05      2.7e-07        0.111        0.156       0.0584        0.171        0.115       0.0795        0.212        0.146        0.225        0.015

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    134     5     2.34e-05     2.34e-05      3.6e-09       0.0969         0.14       0.0703        0.127       0.0988        0.103        0.172        0.138       0.0203      0.00135


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             134 2867.245    0.005     2.54e-05     1.14e-07     2.56e-05        0.107        0.145       0.0745        0.144        0.109       0.0981        0.185        0.142        0.118      0.00788
! Validation        134 2867.245    0.005     2.54e-05     5.74e-09     2.54e-05       0.0994        0.145       0.0686        0.135        0.102          0.1        0.183        0.142       0.0228      0.00152
Wall time: 2867.245151588

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    135    10     3.07e-05     3.07e-05     4.26e-08         0.12         0.16       0.0864        0.159        0.123        0.116        0.198        0.157       0.0875      0.00583
    135    20     3.32e-05     3.32e-05     3.28e-08        0.123        0.166       0.0777        0.175        0.126        0.105        0.215         0.16        0.075        0.005
    135    30     1.65e-05      1.6e-05     5.62e-07       0.0826        0.115       0.0605        0.108       0.0841       0.0838        0.143        0.113        0.328       0.0219
    135    40     4.71e-05     4.62e-05     9.46e-07        0.144        0.196       0.0997        0.194        0.147        0.144        0.242        0.193        0.419       0.0279
    135    50     2.06e-05     2.03e-05     2.35e-07        0.098         0.13       0.0791         0.12       0.0993        0.103        0.155        0.129        0.209        0.014
    135    60     2.59e-05     2.59e-05     5.51e-09        0.109        0.147       0.0787        0.144        0.111         0.11         0.18        0.145       0.0281      0.00188
    135    70     2.27e-05     2.26e-05     4.17e-08        0.101        0.137       0.0594        0.148        0.104       0.0785        0.183        0.131       0.0844      0.00562
    135    80     1.82e-05     1.81e-05     1.13e-07        0.092        0.123       0.0742        0.112       0.0932       0.0929         0.15        0.121        0.144      0.00958
    135    90     3.32e-05     3.29e-05     3.16e-07        0.117        0.165       0.0825        0.156        0.119        0.117        0.207        0.162        0.234       0.0156
    135   100     2.57e-05     2.51e-05     5.65e-07        0.107        0.145        0.072        0.147        0.109       0.0976        0.184        0.141        0.325       0.0217
    135   110     3.83e-05     3.82e-05     3.45e-08        0.128        0.178       0.0771        0.186        0.131       0.0985        0.239        0.169       0.0719      0.00479
    135   120     2.12e-05     2.11e-05      3.2e-08       0.0926        0.133       0.0564        0.134       0.0951       0.0728        0.178        0.125       0.0781      0.00521
    135   130     4.05e-05     4.05e-05     2.33e-09        0.129        0.184       0.0967        0.166        0.132        0.133        0.228        0.181       0.0188      0.00125
    135   140     3.56e-05     3.56e-05     3.03e-08         0.12        0.172       0.0697        0.177        0.123         0.09        0.233        0.161       0.0656      0.00438
    135   150     3.17e-05     3.12e-05     4.69e-07         0.12        0.161        0.104        0.139        0.122        0.131         0.19         0.16        0.297       0.0198
    135   160     2.37e-05     2.29e-05      7.3e-07        0.101        0.138       0.0862        0.119        0.103        0.104        0.169        0.136        0.369       0.0246
    135   170     2.04e-05     2.04e-05     9.54e-09       0.0918         0.13       0.0627        0.125       0.0939       0.0783        0.171        0.125       0.0406      0.00271
    135   180     3.31e-05     3.29e-05     1.61e-07        0.121        0.165       0.0804        0.167        0.124        0.101        0.217        0.159        0.166        0.011
    135   190     4.44e-05     4.43e-05     8.67e-08        0.138        0.192       0.0849          0.2        0.142        0.108        0.256        0.182        0.128      0.00854

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    135     5     2.28e-05     2.28e-05     3.39e-09       0.0954        0.138       0.0696        0.125       0.0973        0.104        0.169        0.136       0.0203      0.00135


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             135 2888.645    0.005      2.9e-05     2.03e-07     2.92e-05        0.114        0.155       0.0792        0.153        0.116        0.104        0.198        0.151        0.162       0.0108
! Validation        135 2888.645    0.005     2.52e-05     4.41e-09     2.52e-05       0.0991        0.145       0.0689        0.134        0.101          0.1        0.183        0.142       0.0206      0.00138
Wall time: 2888.6460209099987
! Best model      135    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    136    10     2.56e-05     2.55e-05      1.3e-07        0.104        0.146       0.0596        0.154        0.107        0.079        0.196        0.137        0.153       0.0102
    136    20     3.47e-05     3.47e-05      6.8e-08        0.123         0.17       0.0823        0.169        0.126        0.109         0.22        0.164        0.116      0.00771
    136    30     3.09e-05     3.09e-05     5.51e-09         0.12         0.16       0.0795        0.166        0.123       0.0989        0.209        0.154        0.025      0.00167
    136    40     4.59e-05     4.59e-05      5.4e-08        0.141        0.195       0.0837        0.207        0.145         0.11        0.261        0.185          0.1      0.00667
    136    50     2.03e-05     2.03e-05     4.03e-09       0.0954         0.13       0.0791        0.114       0.0966        0.103        0.155        0.129       0.0188      0.00125
    136    60     3.35e-05     3.27e-05      7.9e-07        0.123        0.165        0.081        0.172        0.126       0.0999        0.217        0.158        0.381       0.0254
    136    70     3.75e-05     3.74e-05     1.13e-07        0.124        0.176       0.0785        0.176        0.127       0.0999        0.235        0.168        0.141      0.00938
    136    80     1.73e-05     1.71e-05     2.47e-07       0.0867        0.119       0.0551        0.123        0.089       0.0723        0.156        0.114        0.209        0.014
    136    90     2.45e-05     2.45e-05     1.86e-08        0.109        0.143       0.0775        0.145        0.111          0.1        0.179         0.14       0.0594      0.00396
    136   100     2.05e-05     2.05e-05     1.23e-08       0.0944        0.131       0.0721         0.12        0.096       0.0953        0.162        0.129       0.0406      0.00271
    136   110     2.56e-05     2.56e-05     1.76e-08        0.109        0.146       0.0881        0.134        0.111        0.114        0.175        0.145       0.0562      0.00375
    136   120     3.69e-05     3.66e-05     3.03e-07        0.132        0.174       0.0952        0.174        0.134        0.118        0.222         0.17        0.234       0.0156
    136   130     2.63e-05     2.61e-05     1.45e-07         0.12        0.147        0.105        0.136        0.121        0.127        0.168        0.147        0.166        0.011
    136   140     2.64e-05     2.64e-05     1.14e-08         0.11        0.148       0.0758        0.149        0.112       0.0954        0.192        0.143       0.0375       0.0025
    136   150     1.96e-05     1.95e-05     8.52e-08       0.0946        0.127       0.0606        0.133        0.097        0.076        0.168        0.122        0.122      0.00812
    136   160     2.46e-05     2.44e-05     2.18e-07        0.108        0.142       0.0725        0.149        0.111       0.0926        0.183        0.138        0.197       0.0131
    136   170     3.95e-05     3.95e-05     4.03e-08         0.14        0.181       0.0899        0.197        0.144        0.113        0.236        0.175       0.0844      0.00563
    136   180      2.5e-05     2.42e-05     8.15e-07        0.104        0.142       0.0668        0.146        0.106       0.0886        0.185        0.137        0.387       0.0258
    136   190     3.37e-05     3.37e-05     3.71e-08         0.13        0.167        0.085        0.181        0.133         0.11        0.215        0.162       0.0812      0.00542

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    136     5     2.29e-05     2.29e-05     2.44e-09       0.0965        0.138         0.07        0.127       0.0984        0.102         0.17        0.136       0.0172      0.00115


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             136 2910.096    0.005        3e-05        2e-07     3.02e-05        0.114        0.158       0.0776        0.156        0.117        0.103        0.203        0.153         0.15         0.01
! Validation        136 2910.096    0.005     2.51e-05     5.13e-09     2.51e-05       0.0988        0.144       0.0684        0.134        0.101       0.0995        0.183        0.141       0.0216      0.00144
Wall time: 2910.0969675220003
! Best model      136    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    137    10      3.7e-05     3.67e-05      3.2e-07        0.117        0.175        0.057        0.185        0.121        0.083         0.24        0.161        0.247       0.0165
    137    20     3.29e-05     3.29e-05     6.93e-08        0.124        0.165       0.0878        0.166        0.127        0.116        0.208        0.162        0.103      0.00688
    137    30     3.71e-05      3.7e-05     4.15e-08        0.124        0.176       0.0623        0.193        0.128        0.084        0.241        0.162       0.0812      0.00542
    137    40      4.1e-05     4.03e-05     7.04e-07        0.129        0.183       0.0752        0.191        0.133        0.101        0.245        0.173        0.359        0.024
    137    50     1.55e-05     1.53e-05     1.41e-07       0.0799        0.113       0.0553        0.108       0.0817       0.0721        0.146        0.109        0.156       0.0104
    137    60     2.68e-05     2.66e-05     2.22e-07        0.111        0.149       0.0725        0.155        0.114       0.0915        0.194        0.143          0.2       0.0133
    137    70     2.07e-05     2.05e-05      1.9e-07        0.101        0.131       0.0792        0.125        0.102        0.106        0.153         0.13        0.184       0.0123
    137    80     2.34e-05     2.34e-05     5.72e-09        0.103        0.139       0.0763        0.134        0.105        0.102        0.173        0.137       0.0281      0.00188
    137    90     2.64e-05      2.6e-05     4.63e-07        0.114        0.147       0.0939        0.137        0.115        0.117        0.175        0.146        0.291       0.0194
    137   100     3.49e-05     3.48e-05     3.01e-08        0.126         0.17       0.0818        0.177        0.129       0.0967        0.227        0.162       0.0656      0.00438
    137   110     3.46e-05     3.43e-05     2.53e-07        0.126        0.169       0.0791         0.18         0.13          0.1        0.223        0.162        0.216       0.0144
    137   120        2e-05     1.99e-05     4.45e-08       0.0977        0.129       0.0731        0.126       0.0995       0.0943        0.159        0.127       0.0906      0.00604
    137   130     2.14e-05     2.12e-05     1.44e-07        0.101        0.133       0.0741        0.132        0.103       0.0978        0.164        0.131        0.166        0.011
    137   140     2.05e-05     2.02e-05     2.49e-07       0.0991         0.13       0.0689        0.134        0.101       0.0852        0.167        0.126        0.209        0.014
    137   150      2.3e-05     2.27e-05     2.82e-07        0.103        0.137        0.068        0.144        0.106       0.0912        0.176        0.134        0.228       0.0152
    137   160     2.18e-05     2.16e-05     2.23e-07       0.0998        0.134       0.0683        0.136        0.102       0.0873        0.173         0.13        0.206       0.0137
    137   170     2.19e-05     2.16e-05     2.97e-07        0.104        0.134       0.0753        0.136        0.106       0.0962        0.167        0.132        0.237       0.0158
    137   180     1.65e-05     1.65e-05     6.08e-08       0.0848        0.117       0.0621        0.111       0.0865       0.0766         0.15        0.114        0.103      0.00687
    137   190     2.38e-05     2.38e-05     6.57e-09        0.107        0.141       0.0853        0.132        0.109         0.11        0.169         0.14       0.0312      0.00208

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    137     5     2.27e-05     2.27e-05     2.86e-09       0.0962        0.137       0.0696        0.127       0.0981        0.103        0.168        0.136       0.0188      0.00125


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             137 2932.130    0.005     2.86e-05     2.66e-07     2.89e-05        0.113        0.154       0.0788        0.152        0.115        0.104        0.197         0.15        0.183       0.0122
! Validation        137 2932.130    0.005     2.48e-05     5.04e-09     2.48e-05       0.0983        0.144       0.0684        0.132          0.1          0.1        0.181        0.141       0.0206      0.00138
Wall time: 2932.1306739859992
! Best model      137    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    138    10     3.12e-05     3.12e-05     1.17e-08        0.119        0.161       0.0802        0.164        0.122       0.0999         0.21        0.155       0.0437      0.00292
    138    20     2.66e-05     2.64e-05     1.23e-07          0.1        0.148       0.0613        0.145        0.103       0.0773        0.201        0.139         0.15         0.01
    138    30     2.16e-05     2.15e-05     1.45e-07       0.0975        0.134       0.0665        0.133       0.0997       0.0849        0.173        0.129        0.166        0.011
    138    40     1.75e-05     1.72e-05     2.46e-07       0.0884         0.12       0.0556        0.126       0.0908       0.0745        0.156        0.115        0.206       0.0137
    138    50     2.77e-05     2.74e-05     3.03e-07        0.112        0.151       0.0863        0.142        0.114        0.109        0.188        0.148        0.234       0.0156
    138    60     1.66e-05     1.66e-05     2.97e-09       0.0865        0.117        0.066         0.11       0.0879       0.0866        0.145        0.116       0.0188      0.00125
    138    70     2.05e-05     2.05e-05     1.48e-08        0.094         0.13       0.0634        0.129       0.0962       0.0823        0.169        0.126       0.0562      0.00375
    138    80     3.08e-05     3.08e-05     6.57e-09        0.118         0.16       0.0828        0.158        0.121        0.107        0.205        0.156       0.0281      0.00188
    138    90     3.81e-05     3.81e-05     1.42e-08        0.131        0.178       0.0734        0.198        0.136       0.0987        0.238        0.168       0.0469      0.00313
    138   100     4.11e-05     4.11e-05     2.33e-09         0.14        0.185       0.0973        0.189        0.143        0.126        0.234         0.18       0.0219      0.00146
    138   110     1.63e-05     1.62e-05     9.45e-08       0.0871        0.116       0.0627        0.115       0.0889       0.0827        0.145        0.114        0.131      0.00875
    138   120     1.91e-05      1.9e-05     4.73e-08       0.0974        0.126       0.0767        0.121       0.0989       0.0978        0.152        0.125       0.0875      0.00583
    138   130     3.07e-05     3.04e-05     3.09e-07        0.113        0.159       0.0641        0.169        0.117        0.083        0.215        0.149        0.237       0.0158
    138   140     2.51e-05      2.5e-05     1.08e-07        0.107        0.144       0.0729        0.146         0.11       0.0945        0.186         0.14        0.134      0.00896
    138   150      3.6e-05     3.56e-05     3.76e-07        0.129        0.172       0.0868        0.176        0.132        0.112        0.221        0.167        0.262       0.0175
    138   160     3.97e-05     3.94e-05     3.08e-07        0.129        0.181       0.0824        0.182        0.132        0.129        0.226        0.178        0.247       0.0165
    138   170     2.15e-05     2.15e-05     2.76e-09        0.104        0.134       0.0845        0.127        0.106        0.106         0.16        0.133       0.0219      0.00146
    138   180     4.22e-05      4.2e-05     1.51e-07        0.126        0.187       0.0853        0.172        0.129        0.123         0.24        0.181        0.156       0.0104
    138   190     2.06e-05     2.02e-05     3.15e-07       0.0999         0.13       0.0711        0.133        0.102       0.0928        0.162        0.127        0.241        0.016

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    138     5     2.21e-05     2.21e-05     2.97e-09       0.0945        0.136       0.0687        0.124       0.0964        0.101        0.166        0.134       0.0172      0.00115


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             138 2953.575    0.005     2.64e-05     1.26e-07     2.65e-05        0.109        0.148       0.0755        0.147        0.111       0.0994        0.189        0.144        0.125      0.00831
! Validation        138 2953.575    0.005     2.41e-05     4.66e-09     2.41e-05        0.097        0.142       0.0675        0.131       0.0991       0.0992        0.178        0.139       0.0206      0.00138
Wall time: 2953.5764437260004
! Best model      138    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    139    10     2.22e-05      2.2e-05     1.87e-07          0.1        0.135       0.0724        0.132        0.102       0.0933        0.171        0.132        0.181       0.0121
    139    20     2.11e-05     2.07e-05     3.81e-07        0.101        0.131       0.0753        0.131        0.103       0.0937        0.164        0.129        0.266       0.0177
    139    30     2.28e-05     2.27e-05      1.5e-08        0.104        0.138       0.0811        0.131        0.106        0.105        0.167        0.136         0.05      0.00333
    139    40     2.84e-05     2.83e-05     9.98e-08        0.113        0.154       0.0821        0.148        0.115        0.104        0.196         0.15        0.134      0.00896
    139    50     2.49e-05     2.49e-05     7.52e-08        0.105        0.144        0.076        0.139        0.107        0.101        0.181        0.141        0.116      0.00771
    139    60     5.28e-05     5.24e-05     3.65e-07        0.157        0.209        0.129        0.189        0.159        0.178        0.239        0.209        0.262       0.0175
    139    70     3.65e-05     3.65e-05     1.44e-08        0.125        0.174        0.073        0.183        0.128        0.098        0.232        0.165       0.0406      0.00271
    139    80     2.31e-05     2.31e-05     6.12e-08        0.106        0.139       0.0829        0.133        0.108        0.107        0.167        0.137        0.106      0.00708
    139    90     2.95e-05     2.93e-05     2.02e-07        0.107        0.156       0.0719        0.146        0.109        0.109        0.196        0.153        0.194       0.0129
    139   100     3.92e-05     3.91e-05     1.53e-07        0.126         0.18       0.0704        0.189         0.13       0.0896        0.246        0.168        0.169       0.0113
    139   110     3.69e-05     3.59e-05     1.01e-06        0.121        0.173        0.073        0.177        0.125       0.0962        0.231        0.164        0.434        0.029
    139   120     2.72e-05      2.7e-05     2.47e-07        0.114         0.15         0.07        0.164        0.117       0.0885        0.198        0.143        0.216       0.0144
    139   130     1.88e-05     1.86e-05     2.03e-07       0.0962        0.125       0.0685        0.128       0.0982       0.0861        0.157        0.122        0.191       0.0127
    139   140     2.63e-05     2.63e-05     3.54e-08         0.11        0.148       0.0718        0.153        0.113       0.0964         0.19        0.143       0.0781      0.00521
    139   150     2.86e-05     2.84e-05      2.2e-07        0.115        0.154       0.0778        0.157        0.117       0.0996        0.198        0.149        0.203       0.0135
    139   160     3.43e-05     3.43e-05     8.82e-08        0.125        0.169       0.0816        0.174        0.128       0.0983        0.224        0.161        0.122      0.00813
    139   170     2.87e-05     2.87e-05     2.12e-08        0.117        0.154       0.0828        0.157         0.12        0.105        0.196        0.151       0.0656      0.00438
    139   180     2.37e-05     2.33e-05     3.48e-07        0.101        0.139       0.0678        0.139        0.103       0.0907        0.179        0.135         0.25       0.0167
    139   190     2.37e-05     2.33e-05     3.84e-07       0.0955        0.139       0.0506        0.147       0.0987        0.069         0.19         0.13        0.269       0.0179

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    139     5     2.26e-05     2.26e-05     3.07e-09       0.0952        0.137       0.0688        0.125       0.0971        0.101        0.169        0.135       0.0203      0.00135


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             139 2975.294    0.005     2.71e-05     1.78e-07     2.73e-05         0.11         0.15       0.0767        0.148        0.112        0.101        0.191        0.146        0.144      0.00962
! Validation        139 2975.294    0.005     2.45e-05     4.28e-09     2.45e-05       0.0976        0.143       0.0679        0.132       0.0997       0.0994         0.18         0.14       0.0203      0.00135
Wall time: 2975.2948311210002

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    140    10     1.69e-05     1.68e-05     1.13e-07       0.0902        0.118        0.066        0.118       0.0919       0.0876        0.146        0.117        0.144      0.00958
    140    20     4.03e-05     4.02e-05     6.04e-08        0.135        0.183       0.0852        0.193        0.139        0.109        0.241        0.175          0.1      0.00667
    140    30     1.98e-05     1.97e-05     4.11e-08       0.0968        0.128       0.0682        0.129       0.0988       0.0818        0.166        0.124       0.0812      0.00542
    140    40     3.44e-05     3.44e-05     1.23e-08        0.129        0.169       0.0931        0.169        0.131        0.132        0.204        0.168       0.0437      0.00292
    140    50     1.62e-05      1.6e-05      2.2e-07       0.0879        0.115       0.0648        0.114       0.0895       0.0807        0.145        0.113        0.206       0.0137
    140    60     3.93e-05     3.92e-05     8.35e-08        0.129        0.181       0.0954        0.167        0.131        0.124        0.229        0.176        0.122      0.00812
    140    70     3.98e-05     3.98e-05     3.26e-08        0.129        0.182       0.0838        0.181        0.133        0.106        0.241        0.174       0.0719      0.00479
    140    80      2.3e-05     2.26e-05        4e-07        0.105        0.137        0.072        0.143        0.107       0.0898        0.176        0.133        0.272       0.0181
    140    90     2.94e-05     2.94e-05     2.33e-09        0.107        0.156       0.0595        0.162        0.111       0.0766        0.214        0.145       0.0125     0.000833
    140   100     2.35e-05     2.35e-05      1.5e-08        0.105         0.14       0.0745         0.14        0.107       0.0952        0.177        0.136       0.0469      0.00313
    140   110     1.87e-05     1.85e-05     1.61e-07       0.0961        0.124       0.0689        0.127       0.0981       0.0857        0.157        0.121        0.169       0.0112
    140   120     2.18e-05     2.17e-05     1.35e-07       0.0961        0.134       0.0558        0.142        0.099       0.0726        0.181        0.127        0.156       0.0104
    140   130     1.81e-05      1.8e-05     8.29e-08       0.0921        0.122       0.0566        0.133       0.0947       0.0727        0.161        0.117        0.122      0.00813
    140   140     3.45e-05     3.44e-05     8.05e-08        0.129        0.169       0.0953        0.167        0.131         0.12        0.212        0.166        0.119      0.00792
    140   150     2.46e-05     2.46e-05     8.05e-09        0.107        0.143       0.0733        0.146         0.11       0.0941        0.184        0.139       0.0375       0.0025
    140   160     1.34e-05     1.34e-05     6.36e-09       0.0809        0.106       0.0619        0.103       0.0823       0.0808        0.128        0.105        0.025      0.00167
    140   170     2.08e-05     2.08e-05     1.86e-08        0.096        0.132       0.0601        0.137       0.0986       0.0733        0.176        0.125       0.0531      0.00354
    140   180     2.05e-05     2.05e-05     4.51e-08        0.101         0.13        0.083         0.12        0.102        0.106        0.154         0.13       0.0875      0.00583
    140   190     1.67e-05     1.67e-05     3.39e-09       0.0895        0.118       0.0653        0.117       0.0912       0.0853        0.146        0.116       0.0219      0.00146

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    140     5     2.27e-05     2.27e-05     1.38e-09       0.0954        0.138       0.0681        0.127       0.0974       0.0987        0.171        0.135       0.0141     0.000938


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             140 2996.778    0.005     2.54e-05     9.91e-08     2.55e-05        0.106        0.145       0.0726        0.144        0.108       0.0959        0.186        0.141        0.106      0.00708
! Validation        140 2996.778    0.005     2.46e-05     3.48e-09     2.46e-05       0.0976        0.143       0.0675        0.132       0.0997       0.0986        0.181         0.14       0.0172      0.00115
Wall time: 2996.779072898

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    141    10     2.19e-05     2.17e-05     2.23e-07        0.101        0.134       0.0745        0.131        0.103       0.0919         0.17        0.131        0.197       0.0131
    141    20     2.31e-05     2.31e-05     5.91e-08        0.107        0.138       0.0825        0.135        0.109        0.107        0.168        0.137          0.1      0.00667
    141    30     2.52e-05     2.52e-05     9.11e-09        0.109        0.145       0.0783        0.144        0.111       0.0992        0.184        0.141       0.0281      0.00188
    141    40     2.21e-05      2.2e-05     2.92e-08        0.103        0.135       0.0694        0.141        0.105       0.0899        0.173        0.132        0.075        0.005
    141    50     1.39e-05     1.38e-05     5.21e-08       0.0799        0.107       0.0589        0.104       0.0814       0.0764        0.134        0.105          0.1      0.00667
    141    60     2.51e-05      2.5e-05     8.05e-08        0.108        0.144       0.0737        0.148        0.111          0.1        0.182        0.141        0.116      0.00771
    141    70     2.86e-05     2.85e-05     2.48e-08        0.111        0.154       0.0715        0.156        0.114       0.0908        0.204        0.147       0.0719      0.00479
    141    80     1.59e-05     1.59e-05     1.76e-08       0.0864        0.115       0.0664        0.109       0.0879       0.0868         0.14        0.114         0.05      0.00333
    141    90     1.88e-05     1.88e-05     2.33e-09       0.0945        0.125       0.0705        0.122       0.0962       0.0887        0.157        0.123       0.0125     0.000833
    141   100     2.33e-05     2.33e-05     1.34e-08        0.106        0.139        0.074        0.142        0.108       0.0918        0.179        0.135       0.0406      0.00271
    141   110     1.98e-05     1.98e-05     2.12e-09       0.0946        0.128       0.0683        0.125       0.0964       0.0933        0.159        0.126       0.0156      0.00104
    141   120     3.21e-05      3.2e-05     7.35e-08        0.118        0.163       0.0788        0.164        0.121       0.0961        0.216        0.156        0.119      0.00792
    141   130     3.01e-05     3.01e-05     3.18e-09        0.112        0.158       0.0708        0.159        0.115       0.0912         0.21        0.151       0.0219      0.00146
    141   140     3.64e-05     3.63e-05     1.95e-08        0.121        0.174       0.0788         0.17        0.124        0.104        0.229        0.167       0.0594      0.00396
    141   150     3.19e-05     3.11e-05     8.47e-07        0.115        0.161       0.0843         0.15        0.117        0.112        0.202        0.157        0.397       0.0265
    141   160     2.54e-05     2.54e-05     5.09e-09        0.114        0.145       0.0962        0.135        0.116        0.125        0.166        0.145        0.025      0.00167
    141   170     2.34e-05     2.32e-05     1.87e-07        0.105        0.139        0.073        0.141        0.107       0.0925        0.177        0.135        0.181       0.0121
    141   180     3.23e-05     3.21e-05     1.69e-07        0.119        0.163       0.0807        0.164        0.122        0.111        0.208        0.159        0.181       0.0121
    141   190     3.69e-05     3.68e-05     1.32e-07        0.134        0.175       0.0877        0.187        0.137        0.111        0.227        0.169        0.156       0.0104

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    141     5     2.24e-05     2.24e-05     2.65e-09       0.0948        0.136       0.0684        0.125       0.0967          0.1        0.169        0.134       0.0156      0.00104


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             141 3018.820    0.005     2.45e-05     1.23e-07     2.46e-05        0.105        0.143       0.0735         0.14        0.107       0.0968        0.181        0.139         0.12      0.00798
! Validation        141 3018.820    0.005     2.43e-05     3.84e-09     2.43e-05       0.0974        0.142       0.0675        0.132       0.0995       0.0987         0.18        0.139       0.0178      0.00119
Wall time: 3018.820632432

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    142    10     1.79e-05     1.78e-05      9.2e-08       0.0917        0.122       0.0612        0.127       0.0939       0.0775        0.158        0.118        0.128      0.00854
    142    20     2.07e-05     2.06e-05      1.7e-07        0.102        0.131       0.0715        0.137        0.104       0.0891        0.166        0.128        0.178       0.0119
    142    30     2.05e-05     2.05e-05      2.1e-08       0.0975        0.131       0.0635        0.136       0.0999       0.0813         0.17        0.126       0.0562      0.00375
    142    40     2.19e-05     2.18e-05      9.2e-08          0.1        0.135       0.0696        0.135        0.102       0.0892        0.173        0.131        0.128      0.00854
    142    50     1.19e-05     1.18e-05     5.72e-08       0.0771       0.0992       0.0606        0.096       0.0783       0.0801        0.117       0.0987        0.103      0.00687
    142    60      2.7e-05      2.7e-05     2.56e-08        0.113         0.15       0.0789        0.152        0.115        0.102         0.19        0.146       0.0625      0.00417
    142    70     4.39e-05     4.39e-05     1.14e-08         0.15        0.191        0.118        0.185        0.152        0.147        0.231        0.189         0.05      0.00333
    142    80     4.18e-05     4.18e-05      4.2e-08         0.15        0.186        0.135        0.168        0.152         0.16        0.213        0.186       0.0719      0.00479
    142    90     3.63e-05     3.63e-05     4.11e-08        0.127        0.174       0.0915        0.167        0.129        0.118        0.221        0.169       0.0812      0.00542
    142   100      2.6e-05     2.58e-05     2.61e-07        0.107        0.146       0.0657        0.154         0.11       0.0857        0.194         0.14        0.222       0.0148
    142   110     2.04e-05     2.02e-05     1.71e-07       0.0912         0.13       0.0665        0.119        0.093       0.0927        0.162        0.127        0.178       0.0119
    142   120     2.59e-05     2.58e-05     1.03e-07        0.115        0.147       0.0896        0.145        0.117        0.113        0.177        0.145        0.138      0.00917
    142   130     2.29e-05     2.28e-05     5.66e-08        0.108        0.138        0.096        0.122        0.109        0.125        0.151        0.138        0.103      0.00687
    142   140     3.34e-05     3.34e-05     2.33e-09        0.132        0.167        0.109        0.157        0.133        0.135        0.197        0.166       0.0156      0.00104
    142   150     2.35e-05     2.35e-05     3.37e-08        0.111         0.14       0.0953        0.129        0.112        0.123        0.157         0.14        0.075        0.005
    142   160     1.81e-05     1.81e-05     6.06e-08       0.0876        0.123       0.0655        0.113       0.0892       0.0859        0.154         0.12        0.103      0.00687
    142   170     2.12e-05     2.12e-05     6.15e-08       0.0988        0.133       0.0635        0.139        0.101        0.083        0.173        0.128          0.1      0.00667
    142   180     2.05e-05     2.04e-05     1.29e-07       0.0967         0.13       0.0582        0.141       0.0994       0.0741        0.174        0.124        0.153       0.0102
    142   190      2.3e-05     2.27e-05     3.32e-07       0.0975        0.137       0.0577        0.143          0.1       0.0732        0.185        0.129         0.25       0.0167

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    142     5     2.26e-05     2.26e-05      3.5e-09       0.0952        0.137       0.0688        0.125        0.097        0.103        0.168        0.135       0.0188      0.00125


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             142 3040.704    0.005     2.54e-05     1.13e-07     2.56e-05        0.107        0.145       0.0755        0.143        0.109       0.0999        0.184        0.142         0.12      0.00799
! Validation        142 3040.704    0.005     2.44e-05     5.38e-09     2.44e-05       0.0971        0.142       0.0673        0.131       0.0993       0.0988         0.18        0.139       0.0225       0.0015
Wall time: 3040.704995439999

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    143    10     3.75e-05     3.75e-05     1.65e-08        0.125        0.177        0.076        0.182        0.129        0.101        0.235        0.168       0.0531      0.00354
    143    20     2.33e-05     2.32e-05     3.56e-08        0.105        0.139       0.0747        0.139        0.107        0.094        0.177        0.135       0.0781      0.00521
    143    30     1.69e-05     1.69e-05     2.25e-08       0.0853        0.119       0.0632         0.11       0.0869        0.084        0.148        0.116       0.0656      0.00438
    143    40      1.3e-05      1.3e-05     2.12e-09       0.0765        0.104       0.0593       0.0962       0.0778       0.0763        0.129        0.102       0.0188      0.00125
    143    50     1.89e-05     1.89e-05     6.08e-08       0.0941        0.125       0.0657        0.127       0.0962       0.0864        0.158        0.122        0.106      0.00708
    143    60     2.67e-05     2.62e-05     4.98e-07        0.111        0.148       0.0703        0.156        0.113       0.0899        0.193        0.142        0.306       0.0204
    143    70     2.25e-05     2.25e-05     1.27e-08       0.0996        0.137       0.0665        0.138        0.102       0.0855        0.178        0.132       0.0406      0.00271
    143    80     2.98e-05     2.96e-05     1.56e-07        0.112        0.157       0.0714        0.159        0.115       0.0928        0.207         0.15        0.159       0.0106
    143    90     2.48e-05     2.48e-05     5.55e-08        0.109        0.143       0.0788        0.144        0.111        0.102         0.18        0.141       0.0938      0.00625
    143   100     2.28e-05     2.28e-05     9.54e-09        0.101        0.138       0.0686        0.138        0.103       0.0867        0.179        0.133       0.0375       0.0025
    143   110     2.17e-05     2.16e-05     5.87e-08        0.101        0.134       0.0608        0.147        0.104       0.0786        0.177        0.128        0.106      0.00708
    143   120     3.15e-05     3.15e-05     8.27e-09        0.123        0.162       0.0879        0.164        0.126        0.116        0.202        0.159       0.0344      0.00229
    143   130     2.44e-05     2.43e-05     6.04e-08        0.103        0.142       0.0797         0.13        0.105        0.106        0.174         0.14          0.1      0.00667
    143   140     2.26e-05     2.21e-05     5.07e-07          0.1        0.135       0.0753        0.129        0.102        0.107        0.162        0.135        0.309       0.0206
    143   150     1.73e-05     1.73e-05     1.17e-08       0.0914         0.12        0.063        0.124       0.0934       0.0802        0.153        0.117       0.0469      0.00313
    143   160      2.1e-05      2.1e-05     1.91e-09       0.0976        0.132       0.0622        0.138          0.1       0.0828        0.172        0.127       0.0156      0.00104
    143   170      1.3e-05      1.3e-05     2.59e-08       0.0755        0.104       0.0574       0.0963       0.0768       0.0755        0.129        0.102       0.0656      0.00438
    143   180     2.72e-05     2.71e-05     8.27e-08        0.112         0.15       0.0913        0.136        0.114        0.123        0.176         0.15        0.128      0.00854
    143   190     1.71e-05      1.7e-05     6.25e-08       0.0893        0.119       0.0599        0.123       0.0914       0.0779        0.153        0.115        0.106      0.00708

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    143     5     2.26e-05     2.26e-05     3.07e-09       0.0954        0.137       0.0675        0.127       0.0974       0.0997         0.17        0.135       0.0188      0.00125


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             143 3061.943    0.005      2.4e-05     1.24e-07     2.41e-05        0.104        0.141       0.0723        0.139        0.106       0.0952         0.18        0.138        0.122      0.00811
! Validation        143 3061.943    0.005     2.42e-05      4.6e-09     2.42e-05       0.0968        0.142       0.0669        0.131       0.0989       0.0982        0.179        0.139       0.0181      0.00121
Wall time: 3061.9443929279987

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    144    10     3.35e-05     3.35e-05     3.62e-08         0.12        0.167       0.0705        0.176        0.123       0.0942        0.223        0.158       0.0719      0.00479
    144    20     3.55e-05     3.54e-05     1.24e-07        0.127        0.171        0.103        0.155        0.129        0.137        0.204         0.17        0.144      0.00958
    144    30     5.27e-05     5.27e-05     1.23e-08        0.159        0.209        0.138        0.184        0.161        0.169        0.248        0.208       0.0375       0.0025
    144    40     2.49e-05     2.45e-05      3.4e-07        0.104        0.143       0.0642         0.15        0.107       0.0811         0.19        0.136         0.25       0.0167
    144    50     5.02e-05     5.01e-05     8.07e-08        0.154        0.204        0.112        0.202        0.157        0.144        0.256          0.2        0.116      0.00771
    144    60     6.64e-05     6.63e-05     4.32e-08        0.173        0.235        0.104        0.252        0.178        0.132        0.313        0.223       0.0812      0.00542
    144    70     2.57e-05     2.57e-05     1.08e-08        0.104        0.146       0.0639        0.149        0.107        0.085        0.194        0.139       0.0437      0.00292
    144    80     4.21e-05     4.19e-05     1.59e-07         0.14        0.187       0.0974        0.189        0.143        0.129        0.236        0.182        0.162       0.0108
    144    90     2.26e-05     2.25e-05     1.82e-08        0.103        0.137       0.0797        0.129        0.104        0.104        0.167        0.135       0.0562      0.00375
    144   100     2.18e-05     2.16e-05      1.8e-07        0.099        0.134       0.0694        0.133        0.101       0.0885        0.172         0.13        0.184       0.0123
    144   110     1.95e-05     1.95e-05     5.51e-09       0.0916        0.127       0.0585        0.129        0.094        0.074        0.169        0.121       0.0219      0.00146
    144   120     3.32e-05     3.32e-05     3.94e-08        0.122        0.166       0.0891         0.16        0.125        0.119        0.207        0.163       0.0719      0.00479
    144   130      4.5e-05     4.49e-05     6.99e-08        0.142        0.193       0.0884        0.202        0.145        0.116        0.255        0.185        0.103      0.00687
    144   140      2.6e-05     2.57e-05      2.6e-07       0.0936        0.146       0.0579        0.134       0.0961       0.0769        0.198        0.137        0.216       0.0144
    144   150     2.41e-05     2.41e-05     6.36e-10        0.106        0.141       0.0688        0.148        0.108       0.0913        0.183        0.137      0.00938     0.000625
    144   160     2.42e-05     2.41e-05     6.72e-08        0.109        0.142       0.0906        0.131        0.111        0.108        0.172         0.14        0.109      0.00729
    144   170     2.18e-05     2.18e-05     3.71e-08        0.096        0.135       0.0627        0.134       0.0984       0.0905        0.172        0.131       0.0781      0.00521
    144   180     3.59e-05     3.57e-05     2.27e-07        0.132        0.172       0.0999        0.169        0.135        0.123        0.216        0.169          0.2       0.0133
    144   190     2.12e-05     2.07e-05     5.46e-07       0.0965        0.131       0.0667        0.131       0.0987       0.0888        0.167        0.128        0.322       0.0215

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    144     5     2.32e-05     2.32e-05      1.7e-09       0.0969        0.139       0.0674        0.131        0.099       0.0989        0.173        0.136       0.0156      0.00104


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             144 3083.429    0.005     3.13e-05     1.49e-07     3.15e-05        0.117        0.161       0.0811        0.159         0.12        0.107        0.207        0.157         0.13      0.00865
! Validation        144 3083.429    0.005     2.42e-05     3.84e-09     2.42e-05       0.0971        0.142        0.067        0.131       0.0992       0.0977         0.18        0.139       0.0184      0.00123
Wall time: 3083.429478222999

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    145    10     2.39e-05     2.38e-05     1.99e-07       0.0977        0.141        0.073        0.126       0.0995        0.102        0.175        0.138        0.194       0.0129
    145    20     2.15e-05     2.15e-05     1.57e-08        0.101        0.134       0.0775        0.127        0.102        0.101        0.163        0.132       0.0469      0.00313
    145    30     3.03e-05     3.03e-05     2.76e-09        0.117        0.159       0.0809        0.159         0.12        0.105        0.204        0.154       0.0156      0.00104
    145    40     1.22e-05     1.22e-05     1.55e-08       0.0768        0.101       0.0556        0.101       0.0784       0.0714        0.126       0.0989       0.0469      0.00313
    145    50     1.97e-05     1.97e-05     1.17e-08       0.0953        0.128        0.067        0.128       0.0973       0.0835        0.165        0.124       0.0437      0.00292
    145    60     1.35e-05     1.35e-05     8.48e-10       0.0781        0.106       0.0567        0.103       0.0796       0.0792         0.13        0.105      0.00938     0.000625
    145    70     1.89e-05     1.89e-05     1.46e-08       0.0936        0.125       0.0643        0.127       0.0957       0.0871        0.158        0.123       0.0469      0.00313
    145    80     1.48e-05     1.46e-05     2.15e-07       0.0828         0.11       0.0547        0.115       0.0848       0.0741        0.141        0.107        0.194       0.0129
    145    90     3.54e-05     3.52e-05     1.09e-07        0.133        0.171        0.101        0.169        0.135        0.129        0.209        0.169        0.134      0.00896
    145   100     1.63e-05     1.59e-05     4.55e-07       0.0895        0.115       0.0645        0.118       0.0913       0.0817        0.144        0.113        0.291       0.0194
    145   110     1.65e-05     1.65e-05     3.75e-08       0.0867        0.117       0.0638        0.113       0.0883       0.0831        0.146        0.115       0.0781      0.00521
    145   120     2.79e-05     2.79e-05     4.45e-08        0.112        0.152       0.0765        0.153        0.115       0.0994        0.196        0.148       0.0969      0.00646
    145   130     2.37e-05     2.37e-05     6.57e-09        0.105         0.14       0.0861        0.127        0.107        0.114        0.166         0.14       0.0344      0.00229
    145   140     3.26e-05     3.23e-05     2.81e-07        0.123        0.164       0.0891        0.161        0.125        0.115        0.206        0.161        0.225        0.015
    145   150     1.98e-05     1.95e-05     3.07e-07       0.0935        0.127       0.0568        0.135       0.0961       0.0772        0.167        0.122        0.237       0.0158
    145   160     2.28e-05     2.27e-05     4.26e-08        0.106        0.138       0.0925        0.122        0.107        0.117        0.158        0.137       0.0688      0.00458
    145   170     2.44e-05     2.42e-05     1.77e-07        0.106        0.142       0.0727        0.145        0.109       0.0941        0.182        0.138        0.178       0.0119
    145   180     2.88e-05     2.86e-05     2.54e-07        0.114        0.154       0.0779        0.154        0.116        0.103        0.197         0.15        0.219       0.0146
    145   190     1.92e-05     1.91e-05     9.83e-08       0.0911        0.126       0.0567         0.13       0.0935       0.0765        0.165        0.121        0.134      0.00896

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    145     5     2.23e-05     2.23e-05     3.28e-09       0.0951        0.136       0.0686        0.125        0.097        0.102        0.167        0.134       0.0219      0.00146


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             145 3104.584    0.005     2.49e-05     1.22e-07      2.5e-05        0.106        0.144       0.0741        0.142        0.108       0.0972        0.183         0.14        0.125      0.00836
! Validation        145 3104.584    0.005     2.39e-05     5.38e-09     2.39e-05       0.0967        0.141       0.0673         0.13       0.0988       0.0985        0.177        0.138       0.0216      0.00144
Wall time: 3104.585324918
! Best model      145    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    146    10     3.75e-05     3.72e-05     3.34e-07        0.136        0.176       0.0947        0.184        0.139        0.118        0.224        0.171        0.253       0.0169
    146    20     4.39e-05     4.36e-05     3.71e-07        0.142         0.19       0.0841        0.208        0.146        0.105        0.255         0.18        0.262       0.0175
    146    30     2.58e-05     2.58e-05     1.06e-08        0.106        0.146       0.0605        0.157        0.109       0.0753        0.199        0.137        0.025      0.00167
    146    40     2.13e-05     2.12e-05     4.11e-08       0.0964        0.133       0.0714        0.125       0.0982       0.0919        0.168         0.13       0.0844      0.00562
    146    50     2.43e-05      2.4e-05      3.2e-07        0.102        0.141       0.0782        0.129        0.104        0.105        0.174        0.139        0.241        0.016
    146    60      2.5e-05     2.44e-05     6.26e-07       0.0979        0.142       0.0626        0.138          0.1        0.085        0.188        0.136        0.338       0.0225
    146    70      2.6e-05      2.6e-05     1.91e-09        0.113        0.147        0.094        0.135        0.114        0.118        0.175        0.146       0.0156      0.00104
    146    80     2.43e-05     2.43e-05     1.04e-08        0.114        0.142       0.0949        0.136        0.115        0.117        0.167        0.142       0.0406      0.00271
    146    90     3.23e-05     3.23e-05     3.37e-08        0.117        0.164       0.0946        0.142        0.118        0.121        0.202        0.162       0.0625      0.00417
    146   100     3.86e-05     3.86e-05     1.17e-08        0.134        0.179       0.0907        0.183        0.137        0.115        0.232        0.173       0.0312      0.00208
    146   110     3.11e-05     2.99e-05     1.21e-06        0.122        0.158        0.096        0.151        0.123         0.12        0.192        0.156        0.475       0.0317
    146   120     2.59e-05     2.53e-05     6.05e-07        0.102        0.145       0.0714        0.136        0.104        0.103        0.181        0.142        0.331       0.0221
    146   130     3.12e-05      3.1e-05     2.79e-07        0.123         0.16       0.0955        0.154        0.125        0.121        0.196        0.158        0.231       0.0154
    146   140     1.91e-05     1.89e-05     2.46e-07       0.0912        0.125       0.0651        0.121       0.0931       0.0833         0.16        0.122        0.213       0.0142
    146   150     2.66e-05     2.66e-05     5.49e-08         0.11        0.149       0.0854        0.137        0.111        0.111        0.183        0.147       0.0969      0.00646
    146   160     3.74e-05     3.73e-05     1.61e-07        0.131        0.176       0.0766        0.193        0.135       0.0949        0.237        0.166        0.162       0.0108
    146   170     2.94e-05     2.94e-05     6.57e-09        0.112        0.156       0.0694        0.161        0.115       0.0861         0.21        0.148       0.0312      0.00208
    146   180     2.33e-05     2.33e-05     7.71e-08        0.103        0.139       0.0774        0.132        0.105          0.1        0.173        0.137        0.116      0.00771
    146   190      2.5e-05      2.5e-05     3.98e-08        0.103        0.144       0.0775        0.132        0.105        0.107        0.177        0.142       0.0844      0.00562

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    146     5     2.13e-05     2.13e-05     4.03e-09       0.0925        0.133       0.0673        0.121       0.0942       0.0981        0.164        0.131       0.0234      0.00156


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             146 3125.829    0.005     2.65e-05     1.51e-07     2.67e-05        0.109        0.149       0.0771        0.146        0.111        0.102        0.188        0.145        0.127      0.00849
! Validation        146 3125.829    0.005     2.36e-05     4.81e-09     2.36e-05       0.0962         0.14       0.0672        0.129       0.0983       0.0981        0.176        0.137       0.0222      0.00148
Wall time: 3125.8294685439996
! Best model      146    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    147    10     2.58e-05     2.55e-05      3.7e-07        0.114        0.146       0.0961        0.135        0.116        0.119        0.171        0.145        0.262       0.0175
    147    20     2.15e-05     2.15e-05     3.58e-08       0.0927        0.134       0.0574        0.133       0.0953       0.0813        0.175        0.128       0.0812      0.00542
    147    30     2.43e-05     2.42e-05     6.91e-08        0.109        0.142       0.0749        0.147        0.111       0.0901        0.184        0.137        0.112       0.0075
    147    40     2.87e-05     2.86e-05     1.22e-07         0.11        0.154       0.0805        0.144        0.112        0.103        0.197         0.15         0.15         0.01
    147    50     2.95e-05     2.92e-05     2.67e-07        0.106        0.156       0.0802        0.136        0.108        0.116        0.191        0.154        0.219       0.0146
    147    60     1.68e-05     1.61e-05     7.29e-07       0.0909        0.116       0.0719        0.113       0.0923       0.0927        0.137        0.115        0.369       0.0246
    147    70     2.16e-05     2.16e-05     2.82e-08        0.102        0.134       0.0766        0.132        0.104        0.102        0.163        0.132       0.0594      0.00396
    147    80     2.68e-05     2.67e-05     8.63e-08        0.107        0.149       0.0636        0.156         0.11       0.0816          0.2        0.141        0.122      0.00813
    147    90     1.83e-05     1.83e-05     5.93e-09       0.0907        0.123       0.0627        0.123       0.0928       0.0852        0.156        0.121       0.0219      0.00146
    147   100     2.35e-05     2.34e-05     4.07e-08        0.106         0.14       0.0837        0.131        0.108        0.106         0.17        0.138       0.0844      0.00563
    147   110     2.46e-05     2.46e-05     5.72e-08        0.109        0.143       0.0821         0.14        0.111        0.101        0.179         0.14        0.103      0.00687
    147   120      3.4e-05      3.4e-05     2.99e-08        0.118        0.168       0.0797        0.162        0.121        0.118        0.212        0.165       0.0656      0.00438
    147   130     2.35e-05     2.34e-05        1e-07        0.108         0.14       0.0798         0.14         0.11       0.0972        0.176        0.137        0.134      0.00896
    147   140     3.15e-05     3.12e-05     2.87e-07        0.114        0.161       0.0666        0.168        0.117       0.0892        0.216        0.152        0.225        0.015
    147   150     1.85e-05     1.85e-05     7.31e-08       0.0948        0.124       0.0708        0.122       0.0966       0.0913        0.153        0.122        0.116      0.00771
    147   160     3.88e-05     3.86e-05     2.16e-07        0.136        0.179       0.0831        0.196        0.139        0.103        0.238        0.171        0.197       0.0131
    147   170     2.95e-05     2.95e-05     4.03e-09        0.114        0.157       0.0809        0.153        0.117       0.0996        0.203        0.151       0.0281      0.00188
    147   180      3.2e-05      3.2e-05      3.9e-08        0.118        0.163       0.0815        0.159         0.12        0.103        0.212        0.157       0.0719      0.00479
    147   190     2.66e-05     2.63e-05     2.31e-07        0.112        0.148       0.0907        0.137        0.114        0.122        0.173        0.147        0.203       0.0135

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    147     5     2.13e-05     2.13e-05     3.92e-09       0.0922        0.133       0.0675        0.121        0.094       0.0988        0.164        0.131       0.0219      0.00146


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             147 3146.920    0.005     2.39e-05      1.2e-07      2.4e-05        0.104        0.141       0.0729        0.139        0.106       0.0959        0.179        0.137        0.121      0.00804
! Validation        147 3146.920    0.005     2.35e-05     4.47e-09     2.35e-05       0.0957         0.14        0.067        0.129       0.0978       0.0979        0.176        0.137       0.0206      0.00138
Wall time: 3146.9206508650004
! Best model      147    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    148    10     2.26e-05     2.25e-05     7.01e-08        0.104        0.137       0.0724         0.14        0.106       0.0919        0.175        0.133        0.103      0.00687
    148    20     2.44e-05     2.36e-05     7.08e-07        0.104         0.14        0.066        0.148        0.107       0.0879        0.183        0.135        0.359        0.024
    148    30     2.24e-05     2.23e-05     8.29e-08       0.0921        0.136       0.0535        0.136       0.0949       0.0692        0.185        0.127        0.122      0.00813
    148    40      2.1e-05     2.07e-05     2.09e-07       0.0957        0.131       0.0652        0.131       0.0979        0.083        0.171        0.127        0.197       0.0131
    148    50      2.4e-05     2.37e-05      3.3e-07        0.102         0.14       0.0657        0.144        0.105       0.0913        0.181        0.136        0.253       0.0169
    148    60     2.52e-05     2.52e-05     5.93e-09        0.107        0.145       0.0844        0.133        0.109        0.113        0.175        0.144       0.0281      0.00188
    148    70     2.21e-05      2.2e-05     6.76e-08        0.103        0.135       0.0719        0.139        0.105       0.0916        0.172        0.132        0.106      0.00708
    148    80     2.27e-05     2.23e-05     3.77e-07        0.099        0.136       0.0737        0.128        0.101        0.103        0.166        0.135        0.266       0.0177
    148    90     2.17e-05     2.16e-05     6.55e-08        0.104        0.134       0.0778        0.134        0.106       0.0969        0.167        0.132        0.109      0.00729
    148   100     2.33e-05     2.32e-05     9.98e-08        0.106        0.139       0.0851        0.131        0.108        0.104        0.171        0.137        0.131      0.00875
    148   110     2.86e-05     2.86e-05     7.65e-08        0.113        0.154        0.073        0.159        0.116       0.0924        0.203        0.148        0.116      0.00771
    148   120     2.03e-05     2.01e-05     2.14e-07       0.0948        0.129       0.0634        0.131       0.0971       0.0812        0.168        0.125        0.203       0.0135
    148   130     2.07e-05     2.03e-05     3.78e-07       0.0984         0.13       0.0719        0.129          0.1       0.0935        0.162        0.128        0.266       0.0177
    148   140     2.29e-05     2.29e-05      2.5e-08        0.104        0.138        0.078        0.134        0.106       0.0995        0.172        0.136       0.0594      0.00396
    148   150     2.53e-05     2.53e-05     3.41e-08        0.108        0.145       0.0764        0.144         0.11        0.102        0.182        0.142       0.0719      0.00479
    148   160     2.44e-05     2.42e-05     2.32e-07        0.103        0.142       0.0657        0.145        0.105        0.083        0.188        0.135        0.203       0.0135
    148   170     2.04e-05        2e-05     4.87e-07       0.0909        0.129        0.056        0.131       0.0934       0.0762         0.17        0.123        0.303       0.0202
    148   180     2.01e-05     2.01e-05     3.77e-08       0.0945        0.129       0.0671        0.126       0.0965       0.0862        0.165        0.126        0.075        0.005
    148   190     3.19e-05     3.18e-05     1.53e-07        0.119        0.163       0.0741        0.171        0.123       0.0941        0.216        0.155        0.172       0.0115

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    148     5     2.16e-05     2.16e-05     3.81e-09       0.0935        0.134       0.0679        0.123       0.0954       0.0989        0.165        0.132       0.0203      0.00135


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             148 3168.356    0.005     2.37e-05     1.53e-07     2.38e-05        0.103         0.14       0.0731        0.138        0.105       0.0962        0.178        0.137        0.138      0.00919
! Validation        148 3168.356    0.005     2.37e-05     4.73e-09     2.37e-05        0.096         0.14       0.0669        0.129       0.0981       0.0975        0.177        0.137       0.0213      0.00142
Wall time: 3168.35722446

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    149    10     1.48e-05     1.45e-05     2.31e-07       0.0857         0.11       0.0656        0.109       0.0872        0.083        0.134        0.109        0.206       0.0137
    149    20     2.88e-05     2.88e-05     1.48e-09         0.11        0.155       0.0585         0.17        0.114       0.0756        0.211        0.144       0.0156      0.00104
    149    30     3.67e-05     3.66e-05     4.73e-08        0.138        0.175         0.12        0.159         0.14        0.146        0.202        0.174       0.0875      0.00583
    149    40     2.22e-05     2.22e-05     2.44e-08        0.102        0.136       0.0829        0.125        0.104        0.107        0.163        0.135       0.0625      0.00417
    149    50     2.97e-05     2.97e-05     1.06e-08        0.113        0.157       0.0691        0.164        0.117       0.0913        0.208         0.15       0.0312      0.00208
    149    60     2.63e-05     2.62e-05      1.7e-07        0.113        0.147       0.0827        0.147        0.115        0.109        0.181        0.145        0.178       0.0119
    149    70     2.27e-05     2.27e-05     6.15e-09        0.103        0.138       0.0692        0.142        0.105       0.0911        0.176        0.134       0.0312      0.00208
    149    80     1.84e-05     1.84e-05     4.45e-09       0.0958        0.124       0.0719        0.123       0.0975       0.0933        0.151        0.122        0.025      0.00167
    149    90     1.45e-05     1.45e-05     1.12e-08       0.0788         0.11       0.0529        0.109       0.0807       0.0665        0.144        0.105       0.0437      0.00292
    149   100     3.93e-05     3.92e-05     7.25e-08        0.129        0.181       0.0852        0.179        0.132         0.11        0.237        0.174        0.112       0.0075
    149   110     2.13e-05     2.13e-05     1.48e-08       0.0995        0.133       0.0712        0.132        0.102        0.087        0.171        0.129       0.0344      0.00229
    149   120     2.51e-05      2.5e-05     7.82e-08        0.107        0.144       0.0694        0.151         0.11       0.0888        0.189        0.139        0.112       0.0075
    149   130     2.24e-05     2.22e-05     2.27e-07        0.104        0.136       0.0758        0.135        0.105       0.0989        0.168        0.134        0.209        0.014
    149   140     1.11e-05     1.11e-05     4.54e-08       0.0746       0.0959       0.0579       0.0937       0.0758       0.0715        0.118       0.0947       0.0844      0.00563
    149   150     1.34e-05     1.33e-05     4.03e-08       0.0744        0.105       0.0455        0.107       0.0765       0.0644        0.138        0.101       0.0812      0.00542
    149   160     3.43e-05     3.43e-05      2.1e-08        0.115        0.169       0.0793        0.157        0.118        0.111        0.217        0.164       0.0594      0.00396
    149   170     2.74e-05     2.74e-05     1.14e-08        0.119        0.151       0.0985        0.142         0.12        0.124        0.176         0.15       0.0375       0.0025
    149   180     3.33e-05     3.33e-05     4.85e-08        0.122        0.166       0.0838        0.166        0.125        0.105        0.216        0.161       0.0844      0.00562
    149   190     2.61e-05     2.59e-05     2.55e-07         0.11        0.147       0.0656        0.161        0.113       0.0843        0.195         0.14        0.219       0.0146

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    149     5     2.22e-05     2.22e-05     4.24e-09       0.0943        0.136       0.0671        0.125       0.0962          0.1        0.168        0.134       0.0203      0.00135


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             149 3189.569    0.005     2.41e-05     9.56e-08     2.42e-05        0.104        0.142        0.074        0.139        0.107       0.0975        0.179        0.138        0.109      0.00729
! Validation        149 3189.569    0.005     2.37e-05     5.47e-09     2.37e-05        0.096        0.141       0.0664         0.13       0.0981       0.0977        0.177        0.137       0.0219      0.00146
Wall time: 3189.5699541569993

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    150    10     4.08e-05     4.08e-05     1.42e-08        0.136        0.184       0.0797        0.199         0.14        0.102        0.247        0.174         0.05      0.00333
    150    20     2.76e-05     2.75e-05      8.5e-08        0.112        0.151       0.0872         0.14        0.114        0.114        0.185         0.15        0.119      0.00792
    150    30     2.43e-05     2.42e-05     6.91e-08       0.0999        0.142       0.0645         0.14        0.102       0.0836        0.188        0.136        0.109      0.00729
    150    40     1.52e-05      1.5e-05     2.08e-07       0.0798        0.112       0.0514        0.112       0.0818       0.0662        0.148        0.107          0.2       0.0133
    150    50     3.55e-05     3.55e-05     6.15e-09        0.128        0.172       0.0844        0.178        0.131        0.108        0.223        0.166       0.0281      0.00188
    150    60     2.61e-05      2.6e-05     1.72e-07        0.106        0.147       0.0604        0.158        0.109        0.079        0.198        0.138        0.169       0.0113
    150    70     1.73e-05     1.72e-05     1.08e-08       0.0878         0.12       0.0663        0.112       0.0893       0.0904        0.146        0.118       0.0344      0.00229
    150    80     2.61e-05     2.61e-05     3.09e-08        0.108        0.147       0.0755        0.146        0.111        0.103        0.185        0.144       0.0594      0.00396
    150    90     2.82e-05     2.82e-05     2.67e-08        0.108        0.153       0.0647        0.158        0.112       0.0857        0.204        0.145       0.0688      0.00458
    150   100     1.97e-05     1.95e-05     2.16e-07       0.0997        0.127        0.077        0.126        0.101       0.0981        0.154        0.126          0.2       0.0133
    150   110     3.83e-05      3.8e-05     2.87e-07         0.13        0.178       0.0898        0.176        0.133        0.116        0.229        0.172        0.231       0.0154
    150   120     2.49e-05     2.49e-05     2.86e-08        0.104        0.144       0.0796        0.131        0.105       0.0977        0.183         0.14       0.0656      0.00438
    150   130      1.6e-05     1.59e-05     8.43e-08       0.0839        0.115       0.0569        0.115       0.0859       0.0714         0.15        0.111        0.125      0.00833
    150   140     2.25e-05     2.21e-05     3.77e-07          0.1        0.136       0.0656         0.14        0.103       0.0812        0.179         0.13        0.266       0.0177
    150   150     3.82e-05     3.77e-05     4.87e-07        0.123        0.177       0.0822         0.17        0.126        0.126        0.222        0.174        0.297       0.0198
    150   160     3.43e-05     3.31e-05     1.19e-06        0.123        0.166       0.0803        0.172        0.126         0.11        0.212        0.161        0.475       0.0317
    150   170      2.1e-05     1.98e-05      1.2e-06          0.1        0.128       0.0809        0.122        0.101          0.1        0.154        0.127        0.475       0.0317
    150   180      2.4e-05     2.39e-05     1.29e-07        0.103        0.141        0.076        0.135        0.105       0.0972        0.178        0.138        0.156       0.0104
    150   190     2.74e-05      2.7e-05     3.14e-07        0.109         0.15       0.0755        0.148        0.112        0.106        0.188        0.147        0.241        0.016

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    150     5     2.17e-05     2.17e-05     1.38e-09       0.0929        0.134       0.0665        0.123       0.0948       0.0994        0.165        0.132       0.0141     0.000938


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             150 3210.825    0.005     2.71e-05     2.32e-07     2.73e-05         0.11         0.15       0.0762        0.148        0.112          0.1        0.192        0.146        0.157       0.0105
! Validation        150 3210.825    0.005     2.37e-05      3.5e-09     2.37e-05       0.0961         0.14       0.0666         0.13       0.0982       0.0979        0.177        0.137       0.0178      0.00119
Wall time: 3210.8256433259994

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    151    10     3.08e-05     3.08e-05     7.84e-08        0.114         0.16       0.0702        0.163        0.117       0.0886        0.214        0.151        0.122      0.00813
    151    20      2.3e-05      2.3e-05     1.67e-08       0.0979        0.138       0.0726        0.127       0.0997          0.1        0.172        0.136       0.0562      0.00375
    151    30     2.03e-05     2.02e-05     1.31e-08       0.0949         0.13       0.0594        0.136       0.0975       0.0765        0.171        0.124       0.0469      0.00313
    151    40     2.37e-05     2.37e-05     1.06e-09        0.101         0.14       0.0572        0.151        0.104       0.0743        0.189        0.132      0.00938     0.000625
    151    50     4.14e-05     4.14e-05     5.23e-08         0.14        0.186       0.0989        0.186        0.142         0.13        0.234        0.182       0.0938      0.00625
    151    60     2.26e-05     2.26e-05     2.08e-08        0.106        0.137       0.0779        0.138        0.108       0.0964        0.172        0.134       0.0469      0.00313
    151    70     1.78e-05     1.76e-05     1.99e-07       0.0911        0.121       0.0721        0.113       0.0925        0.101         0.14        0.121        0.184       0.0123
    151    80     2.53e-05     2.52e-05     7.08e-08        0.106        0.145       0.0655        0.152        0.109       0.0809        0.193        0.137        0.116      0.00771
    151    90      2.2e-05     2.18e-05     2.02e-07       0.0965        0.135        0.068        0.129       0.0986       0.0868        0.174         0.13        0.191       0.0127
    151   100     1.56e-05     1.56e-05     1.57e-08       0.0811        0.114        0.055        0.111        0.083       0.0733        0.147         0.11       0.0469      0.00313
    151   110     1.91e-05     1.91e-05     1.59e-08       0.0906        0.126       0.0615        0.124       0.0927        0.084        0.161        0.123       0.0437      0.00292
    151   120     2.02e-05     2.01e-05     7.95e-08       0.0985        0.129        0.074        0.126          0.1       0.0976        0.158        0.128        0.125      0.00833
    151   130     2.08e-05     2.04e-05     4.55e-07       0.0895         0.13       0.0571        0.127       0.0918       0.0747        0.173        0.124        0.291       0.0194
    151   140     3.43e-05     3.43e-05     1.95e-08        0.126        0.169       0.0703        0.191         0.13       0.0932        0.226         0.16       0.0531      0.00354
    151   150     3.12e-05     3.12e-05     9.75e-09        0.115        0.161       0.0678         0.17        0.119       0.0937        0.214        0.154       0.0281      0.00188
    151   160     3.33e-05      3.3e-05     2.92e-07        0.124        0.166       0.0892        0.163        0.126        0.111        0.212        0.161        0.228       0.0152
    151   170     1.22e-05     1.21e-05     7.97e-08        0.074          0.1       0.0512          0.1       0.0756       0.0657        0.129       0.0973        0.119      0.00792
    151   180     1.94e-05     1.94e-05     4.87e-09       0.0907        0.127       0.0582        0.128        0.093       0.0755        0.167        0.121       0.0281      0.00188
    151   190     2.77e-05     2.75e-05     1.72e-07        0.103        0.151       0.0563        0.156        0.106       0.0727        0.207         0.14        0.175       0.0117

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    151     5     2.22e-05     2.22e-05      1.8e-09       0.0943        0.136       0.0679        0.124       0.0962       0.0998        0.168        0.134       0.0141     0.000938


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             151 3232.163    0.005     2.49e-05     1.44e-07      2.5e-05        0.105        0.144       0.0724        0.143        0.108       0.0954        0.184         0.14        0.134      0.00895
! Validation        151 3232.163    0.005     2.35e-05     4.75e-09     2.35e-05       0.0957         0.14       0.0667        0.129       0.0977       0.0975        0.176        0.137       0.0197      0.00131
Wall time: 3232.1636028049998
! Best model      151    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    152    10     1.78e-05     1.77e-05      3.2e-08       0.0898        0.121       0.0657        0.117       0.0915       0.0868        0.152        0.119        0.075        0.005
    152    20     1.65e-05     1.64e-05     1.37e-07       0.0859        0.117       0.0548        0.121       0.0881       0.0714        0.153        0.112        0.159       0.0106
    152    30     1.51e-05     1.48e-05     3.09e-07       0.0819        0.111       0.0502        0.118       0.0841       0.0673        0.146        0.107        0.237       0.0158
    152    40     3.02e-05     3.01e-05     3.16e-08        0.123        0.158       0.0972        0.151        0.124        0.129        0.187        0.158       0.0719      0.00479
    152    50     2.04e-05     2.03e-05     1.01e-07       0.0995         0.13       0.0791        0.123        0.101        0.097        0.159        0.128        0.134      0.00896
    152    60     2.88e-05     2.86e-05     1.44e-07        0.119        0.154       0.0864        0.156        0.121        0.109        0.193        0.151        0.159       0.0106
    152    70     2.76e-05     2.76e-05     8.48e-09        0.116        0.151       0.0833        0.154        0.119        0.105        0.191        0.148       0.0375       0.0025
    152    80     2.55e-05     2.49e-05     6.63e-07        0.105        0.144        0.084        0.129        0.107        0.114        0.171        0.143         0.35       0.0233
    152    90     2.08e-05     2.04e-05      3.3e-07       0.0916         0.13       0.0658        0.121       0.0934       0.0871        0.167        0.127        0.241        0.016
    152   100      2.3e-05      2.3e-05     8.69e-09        0.102        0.138       0.0659        0.143        0.104       0.0838        0.182        0.133       0.0312      0.00208
    152   110      1.8e-05     1.79e-05     2.59e-08       0.0884        0.122       0.0545        0.127       0.0908       0.0723        0.161        0.117       0.0656      0.00438
    152   120     1.69e-05     1.69e-05     2.33e-09       0.0881        0.119       0.0628        0.117       0.0899        0.084        0.149        0.116       0.0219      0.00146
    152   130     2.68e-05     2.67e-05     1.29e-07          0.1        0.149        0.053        0.155        0.104       0.0692        0.205        0.137        0.156       0.0104
    152   140     3.56e-05     3.52e-05     4.73e-07         0.13        0.171        0.102        0.162        0.132        0.138        0.202         0.17        0.294       0.0196
    152   150     2.08e-05     2.08e-05     3.81e-09        0.101        0.132       0.0765         0.13        0.103       0.0985        0.161         0.13       0.0188      0.00125
    152   160     3.48e-05     3.48e-05      1.5e-08        0.125         0.17       0.0771        0.181        0.129          0.1        0.225        0.163       0.0469      0.00313
    152   170      2.3e-05     2.29e-05     1.13e-07        0.104        0.138       0.0744        0.138        0.106        0.104        0.169        0.136        0.144      0.00958
    152   180     4.09e-05     4.09e-05      5.3e-09        0.133        0.184       0.0892        0.183        0.136         0.12        0.237        0.179       0.0281      0.00188
    152   190     1.75e-05     1.75e-05     2.97e-09       0.0906        0.121       0.0543        0.132       0.0932       0.0703         0.16        0.115       0.0125     0.000833

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    152     5     2.19e-05     2.19e-05     2.33e-09       0.0927        0.135       0.0667        0.122       0.0946          0.1        0.166        0.133       0.0188      0.00125


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             152 3253.772    0.005     2.24e-05     1.14e-07     2.26e-05        0.101        0.137       0.0708        0.135        0.103       0.0933        0.173        0.133        0.117      0.00778
! Validation        152 3253.772    0.005     2.31e-05     4.73e-09     2.31e-05       0.0946        0.139        0.066        0.127       0.0966       0.0973        0.174        0.136         0.02      0.00133
Wall time: 3253.7722873370003
! Best model      152    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    153    10     1.84e-05     1.81e-05     2.86e-07       0.0919        0.123        0.059         0.13       0.0943       0.0796        0.158        0.119        0.231       0.0154
    153    20     2.14e-05     2.13e-05     8.03e-08        0.104        0.133       0.0742        0.138        0.106       0.0929        0.168         0.13        0.122      0.00813
    153    30     2.74e-05     2.74e-05     3.22e-08        0.115        0.151       0.0937        0.138        0.116        0.123        0.177         0.15       0.0719      0.00479
    153    40     2.83e-05     2.77e-05     5.83e-07        0.111        0.152       0.0766        0.151        0.114        0.102        0.193        0.148        0.328       0.0219
    153    50     1.65e-05     1.62e-05     2.66e-07       0.0921        0.116       0.0863       0.0987       0.0925        0.107        0.126        0.116        0.219       0.0146
    153    60      2.4e-05     2.37e-05     2.66e-07        0.106         0.14       0.0776        0.139        0.108       0.0969        0.178        0.137        0.219       0.0146
    153    70     1.88e-05     1.87e-05     6.99e-08        0.093        0.125       0.0638        0.126        0.095       0.0766        0.163         0.12        0.116      0.00771
    153    80     1.65e-05     1.63e-05     2.21e-07       0.0887        0.116        0.063        0.118       0.0905       0.0801        0.147        0.114          0.2       0.0133
    153    90     1.88e-05     1.87e-05     1.42e-07       0.0865        0.125        0.059        0.118       0.0884        0.072        0.165        0.119        0.162       0.0108
    153   100     2.74e-05     2.74e-05     9.96e-09        0.108        0.151       0.0785        0.142         0.11        0.106         0.19        0.148       0.0375       0.0025
    153   110     2.85e-05     2.84e-05     6.99e-08        0.111        0.154       0.0715        0.157        0.114       0.0947        0.201        0.148        0.112       0.0075
    153   120     2.98e-05     2.98e-05     4.66e-08        0.124        0.157       0.0983        0.154        0.126        0.117        0.194        0.155       0.0875      0.00583
    153   130     2.26e-05     2.25e-05     6.36e-08        0.107        0.137       0.0881        0.129        0.109        0.116        0.157        0.137        0.109      0.00729
    153   140     2.24e-05     2.24e-05     2.12e-09       0.0986        0.136       0.0631        0.139        0.101       0.0841        0.178        0.131       0.0188      0.00125
    153   150     2.21e-05      2.2e-05     7.08e-08          0.1        0.135       0.0681        0.137        0.102       0.0913        0.172        0.132        0.112       0.0075
    153   160     3.38e-05     3.35e-05     2.63e-07        0.123        0.167       0.0963        0.153        0.125        0.134        0.198        0.166        0.222       0.0148
    153   170     1.48e-05     1.48e-05     3.81e-09       0.0842        0.111       0.0662        0.105       0.0855       0.0832        0.136        0.109       0.0219      0.00146
    153   180     2.69e-05     2.68e-05     1.47e-07        0.117        0.149          0.1        0.136        0.118        0.126        0.172        0.149        0.162       0.0108
    153   190     1.65e-05     1.64e-05     1.11e-07       0.0823        0.117       0.0517        0.117       0.0845       0.0687        0.155        0.112        0.138      0.00917

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    153     5     2.15e-05     2.14e-05     3.92e-09       0.0928        0.134       0.0663        0.123       0.0947       0.0999        0.164        0.132       0.0188      0.00125


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             153 3275.307    0.005     2.42e-05      1.4e-07     2.44e-05        0.105        0.142        0.074         0.14        0.107       0.0971         0.18        0.139        0.129      0.00857
! Validation        153 3275.307    0.005      2.3e-05     4.49e-09      2.3e-05       0.0948        0.138       0.0657        0.128       0.0968        0.097        0.174        0.135       0.0194      0.00129
Wall time: 3275.307409343999
! Best model      153    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    154    10     2.91e-05     2.89e-05     2.22e-07         0.11        0.155       0.0578        0.169        0.113        0.076        0.212        0.144        0.206       0.0137
    154    20     2.59e-05     2.59e-05     7.71e-08        0.104        0.147       0.0611        0.154        0.107       0.0828        0.196        0.139        0.119      0.00792
    154    30     2.01e-05     2.01e-05     3.81e-09       0.0969        0.129       0.0772        0.119       0.0983       0.0996        0.156        0.128       0.0219      0.00146
    154    40     1.83e-05     1.82e-05     1.48e-07       0.0938        0.123        0.066        0.126       0.0958       0.0811        0.158        0.119        0.169       0.0113
    154    50     1.71e-05      1.7e-05     7.54e-08       0.0898        0.119       0.0664        0.117       0.0915       0.0913        0.144        0.118        0.116      0.00771
    154    60     2.33e-05     2.33e-05     1.42e-08        0.105        0.139       0.0837         0.13        0.107        0.109        0.167        0.138         0.05      0.00333
    154    70     2.57e-05     2.56e-05     4.45e-09        0.103        0.146       0.0651        0.146        0.106       0.0827        0.195        0.139       0.0188      0.00125
    154    80      3.2e-05     3.19e-05     4.03e-09        0.115        0.163        0.074        0.162        0.118        0.097        0.215        0.156       0.0281      0.00188
    154    90     2.83e-05     2.83e-05     4.22e-08        0.112        0.153       0.0834        0.144        0.114        0.112         0.19        0.151       0.0844      0.00562
    154   100     2.12e-05     2.12e-05     1.25e-08       0.0995        0.133       0.0776        0.125        0.101        0.102        0.161        0.131       0.0437      0.00292
    154   110     2.48e-05     2.37e-05     1.06e-06       0.0991         0.14       0.0616        0.142        0.102       0.0804        0.187        0.134        0.447       0.0298
    154   120     2.22e-05     2.14e-05     7.41e-07        0.104        0.134        0.085        0.125        0.105        0.104        0.161        0.132        0.372       0.0248
    154   130     2.71e-05      2.7e-05        6e-08        0.109         0.15       0.0644        0.159        0.112       0.0807        0.202        0.141        0.103      0.00687
    154   140     1.87e-05     1.81e-05     5.73e-07       0.0932        0.123       0.0692        0.121       0.0949       0.0889        0.153        0.121        0.322       0.0215
    154   150     2.26e-05     2.26e-05     9.75e-09        0.105        0.137       0.0838        0.129        0.107        0.106        0.166        0.136       0.0437      0.00292
    154   160     2.37e-05     2.36e-05     4.09e-08        0.101         0.14       0.0662        0.141        0.104       0.0848        0.184        0.134       0.0844      0.00562
    154   170     2.21e-05     2.19e-05     1.38e-07        0.104        0.135       0.0726        0.141        0.107       0.0934        0.171        0.132        0.159       0.0106
    154   180     2.73e-05     2.72e-05     1.93e-07        0.114         0.15        0.068        0.167        0.117       0.0877        0.199        0.143        0.188       0.0125
    154   190     2.09e-05     2.09e-05     1.44e-08       0.0975        0.132       0.0652        0.134       0.0998       0.0863        0.169        0.128       0.0437      0.00292

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    154     5     2.12e-05     2.12e-05     2.54e-09       0.0918        0.133       0.0661        0.121       0.0936          0.1        0.162        0.131       0.0188      0.00125


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             154 3296.559    0.005     2.49e-05     1.45e-07      2.5e-05        0.104        0.144       0.0722        0.141        0.107       0.0948        0.185         0.14         0.13      0.00866
! Validation        154 3296.559    0.005     2.29e-05     3.39e-09     2.29e-05       0.0947        0.138       0.0658        0.128       0.0967       0.0967        0.173        0.135       0.0184      0.00123
Wall time: 3296.560167664
! Best model      154    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    155    10     2.78e-05     2.76e-05     2.25e-07        0.116        0.151       0.0827        0.154        0.118        0.108        0.189        0.149          0.2       0.0133
    155    20     2.04e-05     2.04e-05     1.08e-08       0.0936         0.13       0.0601        0.132        0.096       0.0801         0.17        0.125       0.0406      0.00271
    155    30      1.5e-05     1.45e-05     4.55e-07       0.0803         0.11       0.0636       0.0993       0.0815       0.0877        0.131        0.109        0.287       0.0192
    155    40     2.29e-05     2.28e-05     1.26e-07        0.104        0.138       0.0698        0.143        0.107       0.0877        0.179        0.133        0.153       0.0102
    155    50     2.54e-05     2.51e-05     3.09e-07        0.102        0.145       0.0608         0.15        0.105       0.0795        0.194        0.137        0.237       0.0158
    155    60     1.82e-05     1.82e-05     9.11e-09       0.0949        0.123       0.0677        0.126       0.0968       0.0856        0.155         0.12       0.0312      0.00208
    155    70     2.55e-05     2.55e-05     2.76e-09        0.106        0.146       0.0686        0.149        0.109       0.0934        0.189        0.141       0.0219      0.00146
    155    80     1.44e-05     1.44e-05      1.5e-08       0.0844         0.11       0.0593        0.113       0.0862       0.0757        0.138        0.107       0.0437      0.00292
    155    90     3.14e-05     3.14e-05     4.43e-08        0.117        0.162        0.076        0.164         0.12        0.104        0.209        0.156       0.0688      0.00458
    155   100     2.57e-05     2.56e-05     9.96e-09        0.106        0.146       0.0683        0.148        0.108       0.0881        0.192         0.14       0.0437      0.00292
    155   110     2.53e-05     2.53e-05     1.61e-08        0.107        0.145       0.0686        0.151         0.11       0.0844        0.192        0.138       0.0562      0.00375
    155   120     1.68e-05     1.67e-05     1.11e-07       0.0909        0.118       0.0602        0.126       0.0931        0.074        0.153        0.114        0.144      0.00958
    155   130     2.89e-05     2.89e-05     7.21e-09        0.112        0.155       0.0682        0.162        0.115       0.0924        0.204        0.148       0.0344      0.00229
    155   140     2.39e-05     2.39e-05     2.42e-08        0.105        0.141       0.0772        0.138        0.107       0.0959        0.179        0.137       0.0594      0.00396
    155   150     2.44e-05     2.44e-05     6.99e-09        0.106        0.143       0.0741        0.142        0.108       0.0994         0.18        0.139       0.0281      0.00188
    155   160     1.65e-05     1.65e-05      8.9e-09       0.0851        0.117       0.0635         0.11       0.0867        0.083        0.146        0.115       0.0375       0.0025
    155   170     2.11e-05     2.06e-05     4.95e-07       0.0978        0.131       0.0742        0.125       0.0995       0.0952        0.162        0.129        0.303       0.0202
    155   180     2.11e-05     2.11e-05     3.05e-08        0.099        0.133       0.0765        0.125        0.101        0.102         0.16        0.131        0.075        0.005
    155   190     2.41e-05     2.41e-05     9.45e-08        0.103        0.141        0.074        0.136        0.105       0.0933        0.181        0.137        0.122      0.00812

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    155     5      2.2e-05      2.2e-05     1.59e-09       0.0926        0.135       0.0654        0.124       0.0946        0.101        0.166        0.133       0.0172      0.00115


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             155 3319.070    0.005     2.17e-05     1.05e-07     2.18e-05       0.0982        0.134       0.0682        0.133          0.1       0.0901        0.171        0.131         0.11      0.00733
! Validation        155 3319.070    0.005      2.3e-05     4.77e-09      2.3e-05       0.0945        0.138       0.0653        0.128       0.0966       0.0963        0.174        0.135       0.0228      0.00152
Wall time: 3319.0704601529997

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    156    10      2.8e-05     2.79e-05     3.81e-09        0.111        0.152       0.0696        0.159        0.114       0.0866        0.203        0.145       0.0219      0.00146
    156    20     1.35e-05     1.34e-05      2.1e-08       0.0817        0.106       0.0648        0.101       0.0829       0.0837        0.126        0.105       0.0594      0.00396
    156    30      2.2e-05      2.2e-05     6.36e-09       0.0981        0.135       0.0635        0.138        0.101       0.0819        0.178         0.13       0.0312      0.00208
    156    40     2.06e-05     2.03e-05     3.01e-07       0.0984         0.13       0.0696        0.131          0.1       0.0917        0.163        0.127        0.237       0.0158
    156    50     1.63e-05     1.59e-05     4.01e-07       0.0815        0.115       0.0532        0.114       0.0835       0.0666        0.152        0.109        0.272       0.0181
    156    60     2.21e-05     2.18e-05     2.87e-07       0.0977        0.135       0.0707        0.128       0.0996       0.0923        0.171        0.131        0.228       0.0152
    156    70     1.68e-05     1.67e-05     1.47e-07       0.0861        0.118       0.0627        0.113       0.0877       0.0873        0.145        0.116        0.162       0.0108
    156    80     1.37e-05     1.32e-05     5.24e-07       0.0775        0.105       0.0557        0.102       0.0791       0.0705        0.133        0.102        0.312       0.0208
    156    90     3.29e-05     3.29e-05     3.98e-08        0.128        0.165       0.0892        0.173        0.131        0.115        0.209        0.162       0.0781      0.00521
    156   100     2.59e-05     2.54e-05     5.44e-07        0.107        0.145       0.0779        0.141        0.109        0.101        0.183        0.142        0.319       0.0213
    156   110     2.08e-05     2.07e-05     1.25e-07       0.0958        0.131        0.067        0.129       0.0978       0.0869        0.168        0.127        0.153       0.0102
    156   120     2.39e-05     2.37e-05     2.53e-07        0.106         0.14       0.0759        0.141        0.108       0.0999        0.176        0.138        0.213       0.0142
    156   130     3.17e-05     3.13e-05     4.03e-07        0.128        0.161        0.109         0.15        0.129        0.133        0.189        0.161        0.272       0.0181
    156   140     2.22e-05     2.22e-05     1.59e-08        0.103        0.136       0.0688        0.141        0.105       0.0907        0.173        0.132         0.05      0.00333
    156   150     2.19e-05     2.19e-05      4.3e-08        0.105        0.135       0.0855        0.127        0.106        0.111        0.158        0.134       0.0906      0.00604
    156   160     1.53e-05     1.53e-05     2.39e-08       0.0828        0.113       0.0574        0.112       0.0846       0.0707        0.147        0.109       0.0625      0.00417
    156   170     2.34e-05     2.33e-05     9.98e-08        0.102        0.139       0.0678         0.14        0.104       0.0933        0.178        0.136        0.131      0.00875
    156   180     2.66e-05     2.62e-05     3.98e-07        0.112        0.148       0.0832        0.144        0.114        0.105        0.184        0.145        0.269       0.0179
    156   190     2.03e-05     1.97e-05     6.35e-07       0.0912        0.128       0.0674        0.118       0.0929       0.0898        0.161        0.125        0.344       0.0229

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    156     5     2.08e-05     2.08e-05     1.48e-09       0.0915        0.131       0.0647        0.122       0.0934       0.0972        0.162         0.13       0.0156      0.00104


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             156 3340.484    0.005     2.29e-05     1.57e-07      2.3e-05        0.101        0.138       0.0705        0.136        0.103       0.0928        0.176        0.134        0.137      0.00913
! Validation        156 3340.484    0.005     2.23e-05     4.47e-09     2.23e-05       0.0935        0.136       0.0648        0.126       0.0955       0.0951        0.172        0.133       0.0203      0.00135
Wall time: 3340.4841726449995
! Best model      156    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    157    10     2.28e-05     2.24e-05     3.53e-07        0.102        0.137       0.0805        0.127        0.104        0.111        0.161        0.136        0.253       0.0169
    157    20     1.59e-05     1.59e-05     1.99e-08       0.0913        0.115       0.0754        0.109       0.0924       0.0932        0.135        0.114       0.0531      0.00354
    157    30     1.54e-05     1.53e-05     1.12e-08       0.0855        0.113       0.0606        0.114       0.0873       0.0774        0.143         0.11       0.0406      0.00271
    157    40     1.59e-05     1.59e-05     6.57e-09       0.0898        0.115       0.0643        0.119       0.0916       0.0833        0.143        0.113       0.0344      0.00229
    157    50     1.53e-05     1.53e-05     6.99e-08       0.0831        0.113       0.0554        0.115       0.0851       0.0702        0.147        0.108        0.109      0.00729
    157    60     1.71e-05     1.71e-05     1.59e-08       0.0895        0.119       0.0755        0.105       0.0905       0.0956        0.142        0.119       0.0562      0.00375
    157    70      1.4e-05      1.4e-05     3.48e-08       0.0839        0.108       0.0699       0.0999       0.0849       0.0886        0.126        0.107        0.075        0.005
    157    80     2.18e-05     2.17e-05     1.08e-07        0.103        0.134       0.0815        0.127        0.104        0.105        0.162        0.133        0.138      0.00917
    157    90     2.15e-05     2.14e-05     4.37e-08        0.102        0.133       0.0821        0.126        0.104       0.0999        0.164        0.132       0.0844      0.00562
    157   100      1.5e-05      1.5e-05     4.87e-09       0.0839        0.112       0.0718       0.0978       0.0848       0.0969        0.126        0.112       0.0281      0.00188
    157   110     3.47e-05     3.44e-05     3.03e-07        0.128        0.169        0.107        0.151        0.129         0.15        0.189        0.169        0.234       0.0156
    157   120     3.51e-05      3.5e-05      1.3e-07        0.124        0.171       0.0794        0.175        0.127        0.102        0.225        0.163         0.15         0.01
    157   130     1.82e-05     1.82e-05     3.67e-08        0.097        0.123       0.0747        0.122       0.0986       0.0915        0.151        0.121       0.0812      0.00542
    157   140     2.55e-05     2.55e-05     1.42e-08        0.107        0.146       0.0763        0.142        0.109        0.102        0.183        0.143         0.05      0.00333
    157   150     2.91e-05      2.9e-05     3.88e-08         0.12        0.155       0.0869        0.157        0.122        0.114        0.192        0.153       0.0844      0.00563
    157   160     2.41e-05      2.4e-05     7.84e-08        0.107        0.141       0.0646        0.155         0.11       0.0787        0.189        0.134        0.119      0.00792
    157   170     2.51e-05     2.45e-05     6.11e-07        0.109        0.143       0.0733         0.15        0.112       0.0925        0.184        0.138        0.338       0.0225
    157   180     2.62e-05     2.62e-05     1.27e-08        0.113        0.148       0.0767        0.155        0.116        0.102        0.187        0.144       0.0312      0.00208
    157   190     2.17e-05     2.16e-05     1.29e-07        0.102        0.134       0.0849        0.122        0.104         0.11        0.157        0.133        0.156       0.0104

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    157     5      2.1e-05      2.1e-05     2.23e-09       0.0918        0.132       0.0658        0.122       0.0936       0.0987        0.162         0.13       0.0125     0.000833


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             157 3361.697    0.005     2.15e-05     1.26e-07     2.17e-05       0.0988        0.134       0.0704        0.131        0.101       0.0927        0.169        0.131        0.125      0.00836
! Validation        157 3361.697    0.005     2.23e-05     5.89e-09     2.23e-05       0.0937        0.136        0.065        0.127       0.0958       0.0955        0.171        0.133       0.0209       0.0014
Wall time: 3361.6973590039997
! Best model      157    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    158    10     1.21e-05     1.21e-05     3.18e-09       0.0741          0.1       0.0509        0.101       0.0757       0.0644         0.13        0.097       0.0219      0.00146
    158    20     2.16e-05     2.15e-05     6.23e-08       0.0951        0.134       0.0652        0.129       0.0972       0.0838        0.174        0.129        0.103      0.00687
    158    30     1.79e-05     1.78e-05     4.45e-09       0.0891        0.122       0.0569        0.126       0.0914       0.0737         0.16        0.117        0.025      0.00167
    158    40     2.82e-05     2.82e-05     2.52e-08        0.109        0.153       0.0682        0.155        0.112       0.0889        0.203        0.146       0.0594      0.00396
    158    50     4.29e-05     4.29e-05     2.84e-08        0.139        0.189       0.0845        0.201        0.143        0.107        0.252        0.179        0.075        0.005
    158    60     3.61e-05     3.61e-05     1.44e-08        0.123        0.173       0.0836        0.167        0.125        0.109        0.226        0.167       0.0469      0.00313
    158    70     2.19e-05     2.13e-05     6.34e-07        0.103        0.133       0.0821        0.127        0.105        0.101        0.162        0.132        0.341       0.0227
    158    80     4.74e-05     4.74e-05     5.04e-08        0.144        0.198        0.104        0.191        0.147        0.144        0.247        0.195       0.0969      0.00646
    158    90     2.53e-05      2.5e-05     2.87e-07       0.0983        0.144       0.0618         0.14        0.101       0.0802        0.193        0.137        0.234       0.0156
    158   100     2.38e-05     2.36e-05     1.66e-07        0.102         0.14       0.0647        0.144        0.104       0.0844        0.184        0.134        0.175       0.0117
    158   110     4.75e-05     4.74e-05     9.64e-08        0.135        0.199       0.0843        0.194        0.139        0.112        0.265        0.188        0.131      0.00875
    158   120     2.37e-05     2.37e-05      2.5e-08        0.103         0.14       0.0655        0.146        0.106       0.0875        0.183        0.135       0.0625      0.00417
    158   130     1.63e-05     1.61e-05     1.31e-07       0.0837        0.116       0.0563        0.115       0.0857       0.0746         0.15        0.112        0.153       0.0102
    158   140     3.72e-05      3.7e-05     1.38e-07        0.123        0.175       0.0686        0.186        0.127       0.0996        0.234        0.167        0.153       0.0102
    158   150        4e-05     3.95e-05     4.05e-07        0.136        0.181        0.089        0.189        0.139        0.127        0.228        0.177        0.269       0.0179
    158   160     2.73e-05     2.73e-05     5.72e-09        0.104        0.151       0.0513        0.163        0.107       0.0688        0.208        0.138        0.025      0.00167
    158   170      1.4e-05     1.39e-05     1.01e-07       0.0856        0.107       0.0688        0.105       0.0868       0.0873        0.127        0.107        0.138      0.00917
    158   180     2.35e-05     2.32e-05     3.03e-07        0.105        0.139       0.0753        0.138        0.107       0.0998        0.173        0.137        0.237       0.0158
    158   190     1.82e-05     1.82e-05     1.82e-08       0.0897        0.123       0.0596        0.124       0.0919       0.0775         0.16        0.119       0.0594      0.00396

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    158     5     2.15e-05     2.15e-05     2.54e-09       0.0916        0.134       0.0658        0.121       0.0934       0.0997        0.164        0.132       0.0188      0.00125


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             158 3383.171    0.005     2.48e-05     1.07e-07     2.49e-05        0.105        0.144       0.0744         0.14        0.107       0.0989        0.182         0.14         0.11      0.00736
! Validation        158 3383.171    0.005     2.26e-05      4.3e-09     2.26e-05       0.0939        0.137        0.065        0.127       0.0959        0.096        0.173        0.134       0.0194      0.00129
Wall time: 3383.1716262579994

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    159    10     1.53e-05     1.52e-05     9.37e-08        0.087        0.112       0.0621        0.116       0.0888       0.0809         0.14         0.11        0.128      0.00854
    159    20     2.08e-05     2.08e-05      1.4e-08        0.105        0.131       0.0871        0.125        0.106        0.107        0.155        0.131       0.0437      0.00292
    159    30     3.22e-05     3.18e-05     3.42e-07         0.12        0.163       0.0678        0.179        0.123       0.0844         0.22        0.152        0.253       0.0169
    159    40     3.32e-05     3.32e-05     1.21e-08        0.121        0.166       0.0844        0.163        0.124        0.115         0.21        0.162       0.0406      0.00271
    159    50     1.59e-05     1.59e-05     1.74e-08       0.0939        0.115       0.0907       0.0977       0.0942        0.106        0.124        0.115       0.0594      0.00396
    159    60      1.8e-05     1.77e-05     3.18e-07       0.0912        0.121       0.0709        0.115       0.0927       0.0895         0.15         0.12        0.241        0.016
    159    70     2.48e-05     2.44e-05      3.6e-07        0.117        0.143       0.0941        0.144        0.119        0.113        0.171        0.142        0.259       0.0173
    159    80     1.73e-05     1.71e-05     1.25e-07       0.0873        0.119       0.0618        0.116       0.0891       0.0847         0.15        0.117         0.15         0.01
    159    90     2.03e-05     2.03e-05     7.71e-08       0.0974         0.13       0.0732        0.125       0.0991       0.0928        0.162        0.127        0.112       0.0075
    159   100     1.89e-05     1.88e-05     5.49e-08       0.0853        0.125       0.0506        0.125       0.0877       0.0627        0.171        0.117       0.0969      0.00646
    159   110     2.05e-05     2.04e-05     1.47e-07       0.0904         0.13       0.0631        0.122       0.0924       0.0892        0.165        0.127        0.162       0.0108
    159   120     2.19e-05     2.18e-05     2.39e-08       0.0975        0.135       0.0577        0.143          0.1       0.0757         0.18        0.128       0.0625      0.00417
    159   130     2.71e-05     2.66e-05     5.47e-07        0.113        0.149       0.0752        0.157        0.116       0.0895        0.195        0.142        0.316        0.021
    159   140     5.89e-05     5.82e-05     7.07e-07        0.157         0.22        0.094        0.229        0.161        0.118        0.296        0.207        0.363       0.0242
    159   150     3.01e-05        3e-05     1.64e-07        0.116        0.158       0.0744        0.163        0.119       0.0998        0.205        0.152        0.175       0.0117
    159   160     3.23e-05     3.23e-05     1.31e-08        0.125        0.164       0.0901        0.164        0.127        0.118        0.204        0.161       0.0375       0.0025
    159   170      3.1e-05     3.09e-05     1.34e-07        0.113         0.16        0.066        0.167        0.116       0.0864        0.216        0.151        0.153       0.0102
    159   180     2.55e-05     2.55e-05     9.96e-09        0.104        0.146       0.0574        0.157        0.107        0.071        0.199        0.135       0.0469      0.00313
    159   190     1.67e-05     1.61e-05     6.11e-07       0.0851        0.116       0.0554        0.119       0.0872       0.0738         0.15        0.112        0.341       0.0227

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    159     5     2.06e-05     2.06e-05     2.54e-09       0.0907        0.131       0.0644        0.121       0.0925        0.095        0.162        0.129       0.0219      0.00146


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             159 3404.628    0.005     2.72e-05     1.51e-07     2.73e-05        0.109         0.15       0.0752        0.148        0.112        0.099        0.193        0.146        0.137      0.00915
! Validation        159 3404.628    0.005     2.25e-05     4.85e-09     2.25e-05       0.0941        0.137        0.065        0.127       0.0961        0.095        0.173        0.134       0.0206      0.00138
Wall time: 3404.629357611999

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    160    10     2.79e-05     2.79e-05     3.39e-08        0.113        0.152       0.0745        0.157        0.116          0.1        0.196        0.148       0.0719      0.00479
    160    20     2.46e-05     2.45e-05      6.4e-08        0.112        0.143       0.0867         0.14        0.113         0.11        0.173        0.141        0.103      0.00688
    160    30     1.22e-05     1.22e-05     4.66e-09       0.0708        0.101       0.0432        0.102       0.0728       0.0552        0.135       0.0952       0.0281      0.00188
    160    40     1.94e-05     1.93e-05     1.04e-07        0.098        0.127       0.0649        0.136          0.1       0.0845        0.162        0.123        0.138      0.00917
    160    50     1.32e-05      1.3e-05     1.56e-07       0.0782        0.104       0.0553        0.104       0.0798       0.0764        0.128        0.102        0.166        0.011
    160    60     1.53e-05     1.47e-05     5.83e-07       0.0818         0.11       0.0628        0.104       0.0832       0.0787        0.138        0.108        0.331       0.0221
    160    70     2.16e-05     2.15e-05     1.12e-07       0.0993        0.134       0.0673        0.136        0.102       0.0886        0.171         0.13        0.141      0.00938
    160    80     1.29e-05     1.28e-05     1.81e-07       0.0789        0.103       0.0526        0.109       0.0808       0.0674        0.132       0.0999        0.181       0.0121
    160    90     1.76e-05     1.72e-05     3.79e-07       0.0904         0.12       0.0665        0.118       0.0921       0.0852         0.15        0.118        0.266       0.0177
    160   100     2.47e-05     2.46e-05     2.59e-08        0.107        0.143       0.0693         0.15         0.11       0.0891        0.187        0.138       0.0562      0.00375
    160   110     1.03e-05     1.03e-05     2.84e-08       0.0706       0.0926       0.0513       0.0927        0.072       0.0678        0.115       0.0912       0.0625      0.00417
    160   120     1.72e-05     1.71e-05      5.4e-08       0.0871        0.119       0.0607        0.117        0.089        0.075        0.155        0.115          0.1      0.00667
    160   130      2.6e-05      2.6e-05     2.48e-08        0.111        0.147        0.079        0.148        0.114        0.102        0.186        0.144       0.0469      0.00313
    160   140     1.78e-05     1.74e-05     4.26e-07        0.086         0.12       0.0564         0.12       0.0881       0.0772        0.155        0.116        0.284        0.019
    160   150     1.73e-05      1.7e-05     2.68e-07        0.088        0.119       0.0633        0.116       0.0898        0.085        0.148        0.117        0.222       0.0148
    160   160     2.87e-05     2.87e-05     2.06e-08        0.109        0.154       0.0765        0.147        0.112        0.101        0.199         0.15       0.0625      0.00417
    160   170      1.7e-05     1.64e-05     6.31e-07       0.0858        0.117       0.0551        0.121        0.088        0.067        0.155        0.111        0.338       0.0225
    160   180      1.6e-05      1.6e-05     4.62e-08       0.0803        0.115       0.0514        0.113       0.0823       0.0683        0.152         0.11       0.0875      0.00583
    160   190     2.09e-05     2.08e-05     7.84e-08       0.0924        0.132        0.056        0.134        0.095       0.0824        0.171        0.127        0.119      0.00792

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    160     5     2.13e-05     2.13e-05     2.44e-09       0.0911        0.133       0.0655         0.12       0.0929       0.0988        0.164        0.131       0.0203      0.00135


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             160 3425.865    0.005     2.01e-05     1.39e-07     2.03e-05       0.0948        0.129       0.0662        0.127       0.0968       0.0872        0.165        0.126        0.133       0.0089
! Validation        160 3425.865    0.005     2.24e-05     3.71e-09     2.24e-05       0.0936        0.136       0.0647        0.127       0.0956       0.0954        0.172        0.134       0.0187      0.00125
Wall time: 3425.865959495999

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    161    10     1.83e-05     1.83e-05     2.76e-09        0.093        0.123       0.0609         0.13       0.0952       0.0802        0.159         0.12       0.0188      0.00125
    161    20     2.14e-05     2.13e-05     1.35e-07       0.0974        0.133       0.0658        0.134       0.0997       0.0894         0.17         0.13        0.159       0.0106
    161    30     2.59e-05     2.58e-05      6.4e-08        0.112        0.146       0.0759        0.154        0.115        0.098        0.187        0.143        0.109      0.00729
    161    40     5.08e-05     5.03e-05     5.01e-07        0.161        0.205        0.122        0.205        0.164        0.148        0.254        0.201          0.3         0.02
    161    50     2.42e-05     2.42e-05     1.53e-08        0.103        0.142       0.0664        0.145        0.106       0.0862        0.186        0.136       0.0406      0.00271
    161    60     3.16e-05     3.16e-05     8.03e-08        0.115        0.162       0.0622        0.175        0.119       0.0785        0.222         0.15        0.119      0.00792
    161    70     1.94e-05     1.94e-05     4.39e-08       0.0897        0.127       0.0593        0.124       0.0919       0.0761        0.167        0.122       0.0906      0.00604
    161    80     2.57e-05     2.57e-05     2.97e-08        0.107        0.146       0.0716        0.147        0.109       0.0925         0.19        0.141       0.0688      0.00458
    161    90     3.62e-05     3.61e-05     5.23e-08        0.131        0.173        0.096        0.172        0.134        0.122        0.217         0.17       0.0969      0.00646
    161   100     1.38e-05     1.37e-05     9.28e-08       0.0834        0.107       0.0652        0.104       0.0847       0.0822        0.129        0.106        0.131      0.00875
    161   110     2.16e-05     2.16e-05     3.09e-08       0.0972        0.134       0.0596         0.14       0.0998       0.0759        0.179        0.127        0.075        0.005
    161   120     1.61e-05      1.6e-05     5.64e-08       0.0881        0.115         0.06         0.12       0.0901       0.0766        0.148        0.112          0.1      0.00667
    161   130     2.04e-05     2.04e-05     4.66e-09       0.0947         0.13       0.0648        0.129       0.0969       0.0944        0.162        0.128       0.0219      0.00146
    161   140     2.11e-05     2.11e-05     6.57e-09       0.0997        0.132       0.0853        0.116        0.101        0.115        0.149        0.132       0.0344      0.00229
    161   150      1.7e-05     1.68e-05     1.61e-07       0.0848        0.118       0.0555        0.118       0.0869       0.0738        0.154        0.114        0.166        0.011
    161   160     2.74e-05     2.73e-05      1.3e-07        0.109        0.151       0.0826        0.139        0.111        0.105         0.19        0.147         0.15         0.01
    161   170     2.72e-05     2.69e-05     2.82e-07        0.104        0.149       0.0682        0.145        0.107       0.0952        0.194        0.144        0.228       0.0152
    161   180     3.36e-05      3.3e-05     5.28e-07        0.126        0.166        0.104        0.152        0.128        0.138        0.192        0.165        0.312       0.0208
    161   190     3.52e-05      3.5e-05      1.2e-07         0.13        0.171        0.103        0.161        0.132        0.131        0.207        0.169         0.15         0.01

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    161     5     2.08e-05     2.08e-05     3.81e-09       0.0897        0.131       0.0637         0.12       0.0916       0.0946        0.164        0.129       0.0203      0.00135


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             161 3447.312    0.005     2.49e-05     9.87e-08      2.5e-05        0.105        0.144        0.073        0.141        0.107       0.0966        0.184         0.14        0.108      0.00722
! Validation        161 3447.312    0.005      2.2e-05     5.13e-09      2.2e-05       0.0928        0.135       0.0641        0.126       0.0949       0.0939        0.171        0.132       0.0209       0.0014
Wall time: 3447.313517905999
! Best model      161    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    162    10     2.73e-05     2.72e-05     1.41e-07         0.11         0.15       0.0673         0.16        0.113       0.0851          0.2        0.143        0.159       0.0106
    162    20     1.94e-05     1.94e-05      2.2e-08        0.091        0.127       0.0577        0.129       0.0934       0.0747        0.168        0.121       0.0656      0.00438
    162    30     2.36e-05     2.36e-05     3.09e-08        0.102         0.14       0.0637        0.146        0.105        0.082        0.185        0.134       0.0656      0.00438
    162    40     3.33e-05     3.32e-05     6.63e-08        0.123        0.166       0.0812        0.171        0.126        0.102        0.217         0.16        0.109      0.00729
    162    50     1.95e-05     1.95e-05     2.06e-08        0.093        0.127       0.0577        0.133       0.0955       0.0734        0.169        0.121       0.0531      0.00354
    162    60     2.21e-05      2.2e-05     5.76e-08        0.106        0.135       0.0893        0.124        0.107        0.107        0.162        0.134        0.103      0.00687
    162    70      2.9e-05      2.9e-05     6.99e-09        0.109        0.155       0.0704        0.152        0.111        0.092        0.205        0.148        0.025      0.00167
    162    80     1.71e-05     1.68e-05     2.53e-07       0.0852        0.118       0.0558        0.119       0.0873        0.074        0.154        0.114        0.219       0.0146
    162    90     2.32e-05     2.32e-05     6.34e-08        0.108        0.139       0.0816        0.137        0.109        0.099        0.173        0.136        0.103      0.00687
    162   100     1.72e-05     1.71e-05     1.29e-07       0.0872        0.119       0.0564        0.122       0.0894       0.0747        0.155        0.115        0.153       0.0102
    162   110     1.64e-05     1.63e-05     5.23e-08       0.0876        0.116       0.0572        0.122       0.0898       0.0718        0.152        0.112       0.0938      0.00625
    162   120     3.47e-05     3.46e-05     8.27e-08        0.134         0.17        0.107        0.165        0.136        0.131        0.205        0.168        0.125      0.00833
    162   130     2.57e-05     2.55e-05     1.55e-07        0.115        0.146       0.0953        0.138        0.116        0.119        0.171        0.145        0.162       0.0108
    162   140     2.08e-05     2.07e-05     7.35e-08       0.0984        0.131       0.0632        0.139        0.101       0.0817        0.171        0.126        0.112       0.0075
    162   150     2.36e-05     2.29e-05     6.45e-07        0.105        0.138       0.0804        0.134        0.107        0.103        0.169        0.136         0.35       0.0233
    162   160     1.33e-05     1.32e-05     4.13e-08       0.0743        0.105         0.05        0.102        0.076       0.0675        0.135        0.101       0.0906      0.00604
    162   170     2.92e-05     2.86e-05     6.25e-07        0.116        0.154       0.0818        0.155        0.118        0.108        0.194        0.151        0.338       0.0225
    162   180     3.56e-05     3.55e-05      5.3e-08        0.122        0.172       0.0982        0.149        0.123        0.141        0.201        0.171       0.0781      0.00521
    162   190     1.75e-05     1.74e-05     5.93e-08       0.0892         0.12       0.0565        0.127       0.0915       0.0746        0.157        0.116        0.103      0.00687

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    162     5     2.15e-05     2.15e-05     3.18e-09       0.0911        0.134       0.0641        0.122       0.0931       0.0971        0.166        0.132       0.0203      0.00135


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             162 3468.598    0.005     2.29e-05     1.31e-07     2.31e-05        0.102        0.138       0.0729        0.136        0.104       0.0961        0.174        0.135        0.123       0.0082
! Validation        162 3468.598    0.005     2.23e-05     4.47e-09     2.23e-05        0.093        0.136        0.064        0.126       0.0951       0.0946        0.172        0.133       0.0206      0.00138
Wall time: 3468.5984055259996

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    163    10     1.84e-05     1.76e-05     8.34e-07        0.095        0.121       0.0852        0.106       0.0957        0.109        0.133        0.121        0.394       0.0262
    163    20     3.54e-05     3.44e-05     1.04e-06        0.134        0.169        0.118        0.152        0.135        0.148        0.191        0.169        0.441       0.0294
    163    30      2.8e-05     2.76e-05     3.87e-07        0.111        0.151       0.0787        0.147        0.113       0.0984        0.195        0.147        0.266       0.0177
    163    40     2.68e-05     2.67e-05     1.42e-07        0.106        0.149       0.0826        0.134        0.108        0.121        0.176        0.148        0.162       0.0108
    163    50     2.78e-05     2.77e-05     1.63e-08        0.115        0.152       0.0743        0.162        0.118       0.0904          0.2        0.145       0.0562      0.00375
    163    60     2.53e-05     2.53e-05     4.87e-09        0.103        0.145       0.0655        0.146        0.106       0.0847        0.192        0.138       0.0219      0.00146
    163    70     1.87e-05     1.87e-05     1.89e-08         0.09        0.125       0.0622        0.122        0.092       0.0786        0.162         0.12       0.0656      0.00438
    163    80      2.2e-05      2.2e-05     5.57e-08        0.102        0.135       0.0697         0.14        0.105       0.0913        0.172        0.132          0.1      0.00667
    163    90     2.89e-05     2.89e-05     1.02e-08         0.12        0.155       0.0792        0.166        0.123        0.102        0.199        0.151       0.0406      0.00271
    163   100     3.23e-05     3.21e-05     2.07e-07        0.113        0.163       0.0615        0.173        0.117       0.0812        0.223        0.152        0.194       0.0129
    163   110     1.99e-05     1.95e-05     3.97e-07       0.0911        0.127         0.07        0.115       0.0926       0.0914        0.159        0.125        0.272       0.0181
    163   120     2.81e-05     2.78e-05     2.23e-07        0.108        0.152       0.0673        0.155        0.111       0.0848        0.203        0.144          0.2       0.0133
    163   130      3.9e-05     3.89e-05     2.27e-08        0.134         0.18       0.0922        0.182        0.137        0.118        0.232        0.175       0.0562      0.00375
    163   140     1.95e-05     1.95e-05     5.64e-08        0.102        0.127       0.0858         0.12        0.103        0.106        0.148        0.127        0.103      0.00687
    163   150     3.35e-05     3.35e-05      1.7e-08         0.12        0.167       0.0697        0.178        0.124       0.0924        0.224        0.158       0.0531      0.00354
    163   160     2.43e-05      2.4e-05     2.64e-07        0.105        0.141       0.0795        0.135        0.107          0.1        0.177        0.139        0.219       0.0146
    163   170     1.54e-05     1.52e-05     1.75e-07       0.0811        0.113       0.0553        0.111       0.0829       0.0711        0.146        0.109        0.184       0.0123
    163   180     2.56e-05     2.55e-05     8.71e-08        0.102        0.146       0.0626        0.147        0.105       0.0831        0.194        0.138        0.125      0.00833
    163   190     2.22e-05     2.17e-05        5e-07        0.103        0.134       0.0766        0.132        0.104       0.0961        0.168        0.132        0.303       0.0202

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    163     5     2.12e-05     2.12e-05     1.59e-09       0.0904        0.133       0.0644         0.12       0.0923       0.0989        0.163        0.131       0.0141     0.000938


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             163 3490.143    0.005     2.74e-05      1.8e-07     2.76e-05         0.11        0.151       0.0773        0.148        0.113        0.102        0.192        0.147        0.149      0.00991
! Validation        163 3490.143    0.005     2.23e-05     3.94e-09     2.23e-05       0.0928        0.136       0.0644        0.125       0.0949       0.0958        0.171        0.133       0.0187      0.00125
Wall time: 3490.143776342

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    164    10     2.44e-05     2.39e-05     4.75e-07        0.102        0.141       0.0709        0.137        0.104       0.0952         0.18        0.137        0.294       0.0196
    164    20     2.32e-05     2.32e-05     4.45e-09        0.106        0.139       0.0711        0.147        0.109       0.0938        0.177        0.135        0.025      0.00167
    164    30     1.72e-05     1.71e-05     1.41e-07       0.0906        0.119       0.0698        0.114        0.092       0.0861        0.148        0.117        0.159       0.0106
    164    40     1.61e-05     1.61e-05     2.84e-08       0.0834        0.116       0.0612        0.109        0.085       0.0825        0.144        0.114       0.0719      0.00479
    164    50     1.69e-05     1.69e-05     1.02e-08       0.0836        0.119       0.0589        0.112       0.0854       0.0787        0.152        0.115       0.0406      0.00271
    164    60     1.62e-05     1.62e-05     2.76e-09       0.0858        0.116       0.0623        0.113       0.0875       0.0778        0.148        0.113       0.0188      0.00125
    164    70     2.12e-05     2.11e-05     8.05e-08       0.0944        0.133       0.0608        0.133       0.0968       0.0802        0.174        0.127        0.119      0.00792
    164    80     2.81e-05      2.8e-05     9.75e-09        0.114        0.153       0.0763        0.156        0.116       0.0994        0.197        0.148       0.0312      0.00208
    164    90     4.07e-05     4.04e-05      3.2e-07        0.134        0.183       0.0789        0.197        0.138       0.0986        0.247        0.173        0.234       0.0156
    164   100     2.77e-05     2.76e-05     3.56e-08        0.112        0.152       0.0731        0.158        0.115       0.0953        0.197        0.146       0.0625      0.00417
    164   110     2.48e-05     2.42e-05     6.33e-07        0.105        0.142       0.0733         0.14        0.107       0.0974        0.179        0.138        0.347       0.0231
    164   120     2.32e-05     2.32e-05     3.09e-08        0.101        0.139       0.0572        0.151        0.104       0.0747        0.187        0.131       0.0719      0.00479
    164   130      2.8e-05      2.8e-05     1.74e-08        0.114        0.153        0.071        0.163        0.117       0.0953        0.199        0.147         0.05      0.00333
    164   140      2.5e-05     2.49e-05     4.26e-08        0.103        0.144       0.0684        0.142        0.105       0.0921        0.186        0.139       0.0875      0.00583
    164   150     2.27e-05     2.14e-05      1.3e-06       0.0942        0.133       0.0589        0.135       0.0967       0.0751        0.178        0.127        0.494       0.0329
    164   160     1.93e-05     1.92e-05      6.4e-08       0.0933        0.126       0.0698         0.12       0.0949       0.0886        0.159        0.124        0.103      0.00687
    164   170     2.87e-05     2.84e-05     2.92e-07         0.11        0.154       0.0657         0.16        0.113        0.085        0.206        0.145        0.231       0.0154
    164   180     1.42e-05      1.4e-05      1.5e-07       0.0782        0.108       0.0558        0.104       0.0799         0.07        0.139        0.105        0.166        0.011
    164   190     2.26e-05     2.21e-05     4.37e-07       0.0979        0.136       0.0662        0.134          0.1       0.0877        0.175        0.131        0.284        0.019

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    164     5     2.12e-05     2.12e-05      1.7e-09       0.0912        0.133        0.064        0.122       0.0932       0.0954        0.166         0.13       0.0125     0.000833


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             164 3511.307    0.005     2.24e-05     1.45e-07     2.26e-05          0.1        0.137       0.0689        0.135        0.102        0.091        0.175        0.133        0.132      0.00878
! Validation        164 3511.307    0.005     2.21e-05     3.48e-09     2.21e-05       0.0928        0.135       0.0639        0.126       0.0948        0.094        0.171        0.132       0.0181      0.00121
Wall time: 3511.307560374

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    165    10     1.88e-05     1.87e-05        6e-08       0.0995        0.125       0.0779        0.124        0.101       0.0942        0.152        0.123       0.0906      0.00604
    165    20     2.02e-05     2.01e-05     3.81e-08        0.097        0.129       0.0779        0.119       0.0983        0.109        0.149        0.129        0.075        0.005
    165    30     1.33e-05     1.33e-05     6.95e-08       0.0767        0.105       0.0593       0.0966       0.0779       0.0819        0.126        0.104        0.109      0.00729
    165    40     1.69e-05     1.69e-05     4.03e-09       0.0865        0.118       0.0547        0.123       0.0888       0.0686        0.157        0.113        0.025      0.00167
    165    50     1.65e-05     1.64e-05     9.16e-08       0.0854        0.117       0.0553         0.12       0.0875       0.0722        0.153        0.112        0.128      0.00854
    165    60     1.93e-05     1.92e-05        5e-08       0.0959        0.126       0.0586        0.139       0.0986        0.077        0.166        0.121       0.0969      0.00646
    165    70     1.16e-05     1.14e-05     2.53e-07       0.0772       0.0973       0.0518        0.106        0.079       0.0645        0.125       0.0946        0.219       0.0146
    165    80     1.91e-05     1.91e-05     5.93e-09       0.0944        0.126       0.0653        0.128       0.0964       0.0828        0.162        0.122       0.0312      0.00208
    165    90      1.3e-05      1.3e-05     2.97e-09       0.0775        0.104        0.056        0.102        0.079       0.0775        0.128        0.103       0.0219      0.00146
    165   100      3.4e-05     3.39e-05      9.3e-08        0.123        0.168       0.0796        0.173        0.126          0.1        0.221        0.161        0.128      0.00854
    165   110     2.54e-05     2.51e-05     2.67e-07        0.104        0.145       0.0702        0.143        0.106         0.09        0.188        0.139        0.225        0.015
    165   120     3.21e-05     3.21e-05     3.28e-08        0.117        0.163       0.0858        0.153         0.12        0.119        0.203        0.161        0.075        0.005
    165   130     2.23e-05     2.23e-05     5.07e-08        0.102        0.136       0.0791        0.128        0.104        0.103        0.166        0.134       0.0969      0.00646
    165   140     1.72e-05     1.71e-05     6.15e-08       0.0895        0.119       0.0659        0.117       0.0912       0.0879        0.147        0.118          0.1      0.00667
    165   150     2.96e-05     2.96e-05     3.75e-08        0.122        0.157       0.0872        0.162        0.124        0.113        0.195        0.154       0.0781      0.00521
    165   160      1.4e-05     1.39e-05     1.11e-07       0.0789        0.108       0.0565        0.104       0.0805       0.0723        0.137        0.105        0.138      0.00917
    165   170      1.2e-05     1.19e-05     2.99e-08       0.0742       0.0996       0.0552       0.0959       0.0755       0.0685        0.126       0.0973        0.075        0.005
    165   180     1.65e-05     1.65e-05     1.19e-08       0.0824        0.117       0.0521        0.117       0.0846       0.0699        0.154        0.112       0.0406      0.00271
    165   190     1.63e-05     1.63e-05     2.16e-08       0.0906        0.116       0.0642        0.121       0.0925       0.0801        0.147        0.114       0.0625      0.00417

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    165     5     2.12e-05     2.12e-05     2.33e-09        0.091        0.133       0.0643        0.122       0.0929       0.0958        0.165         0.13       0.0188      0.00125


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             165 3532.952    0.005     2.25e-05     1.51e-07     2.27e-05       0.0988        0.137       0.0668        0.135        0.101       0.0879        0.177        0.132        0.136      0.00907
! Validation        165 3532.952    0.005     2.23e-05     5.19e-09     2.23e-05        0.093        0.136       0.0642        0.126       0.0951       0.0946        0.172        0.133       0.0203      0.00135
Wall time: 3532.952492369999

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    166    10     2.32e-05     2.32e-05     7.04e-08        0.105        0.139       0.0723        0.142        0.107        0.098        0.174        0.136        0.109      0.00729
    166    20     2.35e-05     2.33e-05     1.61e-07       0.0952        0.139        0.063        0.132       0.0975       0.0767        0.187        0.132        0.169       0.0112
    166    30     2.21e-05     2.16e-05     5.35e-07       0.0939        0.134        0.048        0.146       0.0972       0.0639        0.184        0.124        0.316        0.021
    166    40     1.65e-05     1.54e-05     1.05e-06       0.0828        0.113       0.0579        0.111       0.0846       0.0768        0.144         0.11        0.441       0.0294
    166    50     1.53e-05     1.53e-05     3.18e-09        0.081        0.113        0.054        0.112       0.0829       0.0711        0.147        0.109       0.0219      0.00146
    166    60     1.51e-05     1.51e-05     4.03e-09       0.0834        0.112       0.0594        0.111       0.0851       0.0747        0.143        0.109       0.0188      0.00125
    166    70     2.09e-05     2.09e-05     7.84e-09        0.101        0.132        0.069        0.138        0.103       0.0892        0.168        0.129       0.0375       0.0025
    166    80     2.15e-05     2.15e-05      1.7e-09        0.101        0.134       0.0707        0.135        0.103        0.091         0.17         0.13       0.0156      0.00104
    166    90     2.22e-05     2.21e-05     8.29e-08        0.104        0.136       0.0722         0.14        0.106       0.0903        0.174        0.132        0.119      0.00792
    166   100     2.07e-05     2.06e-05     7.06e-08       0.0951        0.131       0.0679        0.126       0.0971       0.0937        0.163        0.129        0.103      0.00687
    166   110     3.07e-05     3.05e-05     1.49e-07         0.12        0.159        0.109        0.133        0.121        0.142        0.177        0.159        0.162       0.0108
    166   120      2.2e-05     2.19e-05     9.43e-08       0.0994        0.135       0.0634         0.14        0.102       0.0811        0.178        0.129        0.131      0.00875
    166   130     2.88e-05     2.85e-05     3.03e-07        0.107        0.154       0.0659        0.154         0.11        0.086        0.206        0.146        0.234       0.0156
    166   140     2.92e-05      2.9e-05     2.08e-07        0.117        0.155        0.088         0.15        0.119        0.117         0.19        0.153        0.194       0.0129
    166   150     1.99e-05     1.99e-05     6.99e-09       0.0996        0.129       0.0694        0.134        0.102       0.0885        0.163        0.126       0.0312      0.00208
    166   160     2.82e-05     2.82e-05     1.61e-08        0.117        0.153       0.0877         0.15        0.119        0.108        0.192         0.15       0.0406      0.00271
    166   170      2.4e-05      2.4e-05      1.8e-08          0.1        0.141       0.0706        0.135        0.103        0.093        0.181        0.137         0.05      0.00333
    166   180     1.32e-05     1.32e-05     6.78e-09       0.0796        0.105       0.0581        0.104       0.0812       0.0767         0.13        0.103       0.0312      0.00208
    166   190     3.01e-05     3.01e-05     1.59e-08        0.111        0.158       0.0674        0.161        0.114       0.0903        0.211         0.15       0.0531      0.00354

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    166     5     2.09e-05     2.09e-05     1.91e-09       0.0905        0.132       0.0638        0.121       0.0924        0.096        0.164         0.13       0.0188      0.00125


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             166 3554.383    0.005     2.29e-05     1.19e-07      2.3e-05          0.1        0.138       0.0694        0.136        0.103       0.0914        0.177        0.134         0.11      0.00734
! Validation        166 3554.383    0.005     2.21e-05     4.37e-09     2.21e-05       0.0923        0.136        0.064        0.125       0.0944       0.0945        0.171        0.133       0.0206      0.00138
Wall time: 3554.3839769789993

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    167    10     2.35e-05     2.35e-05     4.45e-09        0.107         0.14       0.0668        0.154         0.11       0.0823        0.185        0.134       0.0188      0.00125
    167    20     3.94e-05     3.91e-05      2.6e-07        0.134         0.18       0.0794        0.196        0.138       0.0988        0.242         0.17        0.216       0.0144
    167    30     1.84e-05     1.83e-05     2.46e-08       0.0913        0.123       0.0583        0.129       0.0937       0.0745        0.162        0.118       0.0562      0.00375
    167    40     2.81e-05      2.8e-05     1.03e-07         0.11        0.153       0.0614        0.165        0.113        0.079        0.207        0.143        0.138      0.00917
    167    50     3.38e-05     3.37e-05     1.18e-07        0.127        0.167       0.0844        0.176         0.13        0.105        0.218        0.161        0.141      0.00938
    167    60     2.18e-05     2.18e-05     1.78e-08        0.101        0.135       0.0742        0.131        0.102       0.0948        0.169        0.132       0.0594      0.00396
    167    70     1.56e-05     1.54e-05     1.75e-07       0.0858        0.113       0.0692        0.105        0.087       0.0896        0.135        0.112        0.175       0.0117
    167    80     2.27e-05     2.24e-05     2.82e-07        0.106        0.137       0.0871        0.128        0.108         0.11        0.161        0.136        0.228       0.0152
    167    90     3.82e-05     3.82e-05      2.8e-08        0.131        0.178       0.0779        0.191        0.134       0.0999        0.238        0.169       0.0625      0.00417
    167   100     2.71e-05     2.68e-05     2.34e-07        0.108        0.149       0.0734        0.148        0.111        0.104        0.188        0.146        0.209        0.014
    167   110     2.89e-05     2.87e-05     1.16e-07        0.121        0.155       0.0869         0.16        0.123        0.107        0.195        0.151        0.147      0.00979
    167   120      1.9e-05     1.88e-05     1.36e-07       0.0916        0.125       0.0677        0.119       0.0933       0.0858        0.159        0.122        0.156       0.0104
    167   130     2.12e-05     2.11e-05     1.16e-07       0.0959        0.132       0.0592        0.138       0.0985       0.0754        0.176        0.126        0.144      0.00958
    167   140     1.67e-05     1.67e-05     3.07e-08       0.0884        0.118       0.0629        0.118       0.0902       0.0804        0.149        0.115       0.0719      0.00479
    167   150     2.21e-05     2.21e-05     1.25e-08       0.0995        0.136        0.078        0.124        0.101        0.102        0.166        0.134       0.0344      0.00229
    167   160      2.3e-05     2.29e-05     4.98e-08       0.0991        0.138       0.0737        0.128        0.101       0.0919        0.177        0.134       0.0938      0.00625
    167   170     2.21e-05     2.21e-05     2.76e-08       0.0995        0.135       0.0717        0.131        0.101       0.0898        0.173        0.132       0.0656      0.00438
    167   180     2.95e-05     2.94e-05     1.14e-07        0.117        0.156       0.0719        0.168         0.12       0.0924        0.206        0.149        0.141      0.00938
    167   190     2.59e-05     2.59e-05     1.06e-08          0.1        0.147       0.0586        0.147        0.103       0.0828        0.196        0.139       0.0375       0.0025

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    167     5     2.07e-05     2.07e-05     1.27e-09       0.0901        0.131       0.0641         0.12        0.092       0.0962        0.162        0.129       0.0156      0.00104


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             167 3576.122    0.005      2.6e-05     9.28e-08     2.61e-05        0.108        0.147       0.0762        0.145         0.11       0.0999        0.187        0.143        0.103      0.00687
! Validation        167 3576.122    0.005     2.21e-05     3.96e-09     2.21e-05       0.0927        0.135       0.0642        0.125       0.0947       0.0943        0.171        0.133       0.0178      0.00119
Wall time: 3576.123009555

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    168    10     2.19e-05     2.19e-05     2.54e-08        0.103        0.135       0.0828        0.127        0.105        0.107        0.161        0.134       0.0656      0.00438
    168    20     2.33e-05      2.3e-05     2.96e-07        0.109        0.138        0.104        0.115         0.11        0.131        0.146        0.139        0.234       0.0156
    168    30     1.74e-05     1.74e-05     7.42e-09       0.0885         0.12       0.0644        0.116       0.0902       0.0862         0.15        0.118       0.0281      0.00188
    168    40     1.21e-05     1.21e-05     2.14e-08       0.0756          0.1       0.0627       0.0903       0.0765       0.0813        0.118       0.0997       0.0562      0.00375
    168    50     1.68e-05     1.67e-05     3.43e-08       0.0876        0.118        0.055        0.125       0.0899       0.0677        0.157        0.112       0.0812      0.00542
    168    60     2.13e-05     2.12e-05     1.41e-07       0.0966        0.133       0.0735        0.123       0.0983        0.107        0.157        0.132        0.162       0.0108
    168    70     2.34e-05     2.31e-05     2.95e-07       0.0999        0.139       0.0632        0.142        0.103       0.0814        0.183        0.132        0.234       0.0156
    168    80      3.4e-05     3.37e-05     3.15e-07        0.125        0.167       0.0856         0.17        0.128        0.106        0.218        0.162        0.241        0.016
    168    90     2.06e-05     2.03e-05     3.34e-07       0.0895         0.13       0.0575        0.126       0.0918       0.0781        0.171        0.124         0.25       0.0167
    168   100     1.97e-05     1.94e-05     3.29e-07       0.0906        0.127       0.0565         0.13       0.0931        0.073        0.169        0.121        0.247       0.0165
    168   110     2.31e-05     2.29e-05     1.45e-07       0.0993        0.138       0.0686        0.134        0.102       0.0984        0.173        0.136        0.156       0.0104
    168   120     1.47e-05     1.47e-05     5.13e-08       0.0811         0.11       0.0557         0.11        0.083       0.0731        0.142        0.107          0.1      0.00667
    168   130     1.79e-05     1.79e-05     4.66e-09       0.0872        0.122       0.0642        0.113       0.0888       0.0887        0.151         0.12       0.0312      0.00208
    168   140     2.12e-05      2.1e-05     1.36e-07       0.0966        0.132        0.059         0.14       0.0993        0.077        0.175        0.126        0.159       0.0106
    168   150     2.21e-05      2.2e-05     5.47e-08       0.0975        0.135       0.0629        0.137          0.1       0.0844        0.176         0.13       0.0969      0.00646
    168   160     1.61e-05      1.6e-05     4.47e-08       0.0821        0.115       0.0509        0.118       0.0843       0.0667        0.153         0.11       0.0875      0.00583
    168   170     1.94e-05     1.94e-05     2.16e-08       0.0943        0.127       0.0612        0.132       0.0967       0.0801        0.165        0.123       0.0625      0.00417
    168   180     1.52e-05     1.52e-05     6.17e-08       0.0801        0.112       0.0515        0.113       0.0822       0.0715        0.146        0.109       0.0969      0.00646
    168   190     2.12e-05     2.11e-05     7.67e-08       0.0938        0.132       0.0572        0.136       0.0964        0.071        0.178        0.125        0.116      0.00771

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    168     5     2.01e-05     2.01e-05     3.39e-09        0.089        0.129       0.0632        0.118       0.0909       0.0951         0.16        0.127       0.0203      0.00135


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             168 3597.250    0.005     2.18e-05     1.27e-07      2.2e-05       0.0989        0.135       0.0689        0.133        0.101       0.0906        0.172        0.131        0.123      0.00818
! Validation        168 3597.250    0.005     2.17e-05     5.23e-09     2.17e-05       0.0919        0.134        0.064        0.124       0.0939       0.0941        0.169        0.132       0.0231      0.00154
Wall time: 3597.251535907999
! Best model      168    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    169    10     1.65e-05     1.65e-05     1.25e-08       0.0843        0.117       0.0596        0.113       0.0861       0.0733        0.152        0.113       0.0469      0.00313
    169    20     1.07e-05     1.07e-05     1.67e-08        0.071       0.0945       0.0518       0.0929       0.0723       0.0673        0.118       0.0927       0.0562      0.00375
    169    30     1.89e-05     1.89e-05     1.27e-08       0.0939        0.125        0.074        0.117       0.0953       0.0981        0.151        0.124       0.0375       0.0025
    169    40     1.61e-05     1.61e-05     2.31e-08       0.0903        0.116        0.068        0.116       0.0919       0.0888         0.14        0.115       0.0688      0.00458
    169    50     1.84e-05     1.83e-05     1.12e-07        0.094        0.123       0.0696        0.122       0.0957       0.0884        0.154        0.121        0.144      0.00958
    169    60     1.35e-05     1.33e-05     2.41e-07       0.0791        0.105       0.0592        0.102       0.0805       0.0769         0.13        0.103        0.209        0.014
    169    70     1.86e-05     1.85e-05     1.27e-07       0.0926        0.124       0.0752        0.113       0.0939        0.102        0.145        0.124        0.153       0.0102
    169    80     2.56e-05     2.55e-05     5.62e-08        0.104        0.146       0.0626        0.151        0.107       0.0805        0.195        0.138          0.1      0.00667
    169    90      1.3e-05      1.3e-05     1.55e-08       0.0801        0.104       0.0657       0.0966       0.0811        0.081        0.125        0.103       0.0531      0.00354
    169   100     1.51e-05     1.49e-05     2.32e-07       0.0842        0.111        0.071       0.0994       0.0852        0.092         0.13        0.111        0.209        0.014
    169   110     1.41e-05     1.37e-05     4.34e-07       0.0796        0.107       0.0605        0.101       0.0809         0.08        0.131        0.105        0.284        0.019
    169   120     2.25e-05     2.14e-05     1.05e-06        0.106        0.134       0.0967        0.117        0.107        0.118        0.149        0.134        0.438       0.0292
    169   130      2.2e-05     2.15e-05     5.29e-07        0.101        0.134       0.0753        0.131        0.103       0.0969        0.166        0.131        0.312       0.0208
    169   140      1.3e-05     1.24e-05     6.22e-07       0.0804        0.102       0.0653       0.0976       0.0814       0.0805        0.121        0.101        0.341       0.0227
    169   150     1.75e-05     1.74e-05     1.91e-08       0.0951         0.12       0.0776        0.115       0.0963       0.0942        0.145        0.119         0.05      0.00333
    169   160     1.84e-05     1.82e-05      2.5e-07       0.0909        0.123       0.0604        0.126        0.093        0.084        0.156         0.12        0.213       0.0142
    169   170     2.13e-05     2.13e-05     2.18e-08       0.0976        0.133       0.0692         0.13       0.0996       0.0984        0.164        0.131       0.0531      0.00354
    169   180     1.87e-05     1.87e-05     1.55e-08       0.0958        0.125       0.0649        0.131        0.098       0.0805        0.161        0.121       0.0344      0.00229
    169   190     2.86e-05     2.84e-05     1.52e-07         0.11        0.154        0.068        0.157        0.112       0.0924        0.202        0.147        0.169       0.0113

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    169     5     1.99e-05     1.99e-05     2.54e-09       0.0882        0.129       0.0631        0.117         0.09       0.0956        0.158        0.127       0.0188      0.00125


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             169 3619.028    0.005      2.1e-05     1.57e-07     2.12e-05        0.097        0.132       0.0682         0.13        0.099       0.0897        0.168        0.129        0.141      0.00943
! Validation        169 3619.028    0.005     2.16e-05     4.75e-09     2.16e-05       0.0917        0.134       0.0636        0.124       0.0937       0.0938        0.169        0.131       0.0206      0.00138
Wall time: 3619.0290238119997
! Best model      169    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    170    10        2e-05     1.98e-05     1.71e-07       0.0955        0.128       0.0687        0.126       0.0975       0.0869        0.163        0.125        0.181       0.0121
    170    20      1.7e-05     1.67e-05     3.18e-07       0.0851        0.118        0.061        0.113       0.0868       0.0859        0.146        0.116        0.237       0.0158
    170    30     1.49e-05     1.49e-05      2.1e-08       0.0848        0.111       0.0667        0.105       0.0861       0.0856        0.135         0.11       0.0594      0.00396
    170    40     3.75e-05     3.74e-05     8.24e-08        0.133        0.176       0.0949        0.177        0.136        0.124        0.221        0.173        0.125      0.00833
    170    50     2.55e-05     2.49e-05     6.11e-07        0.101        0.144       0.0641        0.143        0.104       0.0847         0.19        0.137        0.338       0.0225
    170    60     3.53e-05     3.53e-05     8.27e-09        0.128        0.171        0.072        0.192        0.132        0.091        0.231        0.161       0.0312      0.00208
    170    70     2.16e-05     2.15e-05     1.86e-07        0.102        0.134       0.0813        0.126        0.104        0.103        0.161        0.132        0.181       0.0121
    170    80     2.56e-05     2.54e-05      2.3e-07        0.105        0.145       0.0585        0.158        0.108       0.0746        0.197        0.136        0.206       0.0137
    170    90     1.51e-05      1.5e-05     4.37e-08       0.0845        0.112       0.0545        0.119       0.0866       0.0681        0.147        0.107       0.0875      0.00583
    170   100     1.96e-05     1.95e-05     1.07e-07       0.0911        0.127       0.0596        0.127       0.0934       0.0819        0.164        0.123        0.141      0.00938
    170   110      2.7e-05      2.7e-05     4.75e-08        0.111         0.15       0.0666        0.161        0.114       0.0899        0.197        0.143       0.0875      0.00583
    170   120     1.72e-05     1.72e-05     3.81e-09       0.0876         0.12       0.0548        0.125       0.0899       0.0682        0.159        0.114       0.0219      0.00146
    170   130     2.56e-05     2.56e-05     1.38e-08        0.112        0.146       0.0798        0.149        0.114        0.105        0.182        0.143         0.05      0.00333
    170   140     2.68e-05     2.67e-05     1.35e-07        0.117        0.149       0.0992        0.136        0.118        0.123        0.174        0.149        0.156       0.0104
    170   150     1.57e-05     1.57e-05     9.32e-09       0.0919        0.114       0.0684        0.119       0.0935        0.083        0.142        0.112       0.0375       0.0025
    170   160     1.49e-05     1.49e-05     1.34e-08       0.0854        0.111       0.0702        0.103       0.0865       0.0889        0.133        0.111       0.0344      0.00229
    170   170     1.35e-05     1.35e-05      3.6e-08       0.0754        0.106       0.0449         0.11       0.0776       0.0583        0.142          0.1       0.0812      0.00542
    170   180     1.63e-05     1.63e-05     4.03e-09       0.0889        0.116        0.075        0.105       0.0899       0.0992        0.133        0.116       0.0219      0.00146
    170   190     1.36e-05     1.36e-05     1.12e-08       0.0789        0.106       0.0592        0.102       0.0803       0.0829        0.128        0.105       0.0406      0.00271

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    170     5     1.98e-05     1.98e-05     2.65e-09       0.0883        0.128       0.0629        0.117       0.0901       0.0938        0.159        0.126       0.0156      0.00104


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             170 3640.623    0.005     2.18e-05     1.03e-07     2.19e-05       0.0994        0.135        0.069        0.134        0.102       0.0902        0.172        0.131         0.11      0.00735
! Validation        170 3640.623    0.005     2.16e-05     4.73e-09     2.16e-05       0.0916        0.134       0.0635        0.124       0.0936       0.0938        0.169        0.131       0.0191      0.00127
Wall time: 3640.623495725
! Best model      170    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    171    10     2.11e-05      2.1e-05     8.54e-08       0.0982        0.132       0.0713        0.129          0.1       0.0924        0.166        0.129        0.119      0.00792
    171    20     2.13e-05     2.13e-05     2.06e-08       0.0946        0.133       0.0599        0.134        0.097       0.0886         0.17        0.129       0.0469      0.00313
    171    30     1.73e-05     1.73e-05     7.63e-09       0.0876         0.12       0.0604        0.119       0.0896       0.0834        0.151        0.117       0.0344      0.00229
    171    40     2.13e-05     2.13e-05     1.48e-08        0.104        0.133       0.0822         0.13        0.106        0.112        0.154        0.133       0.0562      0.00375
    171    50     2.75e-05     2.75e-05      1.1e-08        0.114        0.151       0.0716        0.162        0.117       0.0926        0.198        0.145       0.0312      0.00208
    171    60     1.35e-05     1.35e-05     3.67e-08       0.0809        0.106       0.0646       0.0997       0.0821       0.0844        0.126        0.105       0.0781      0.00521
    171    70     2.44e-05     2.43e-05      6.8e-08        0.103        0.142       0.0764        0.134        0.105        0.105        0.175         0.14        0.112       0.0075
    171    80     2.06e-05     2.05e-05     7.57e-08        0.097        0.131       0.0644        0.134       0.0994       0.0813         0.17        0.126        0.112       0.0075
    171    90     2.05e-05     2.04e-05     1.53e-08       0.0934         0.13       0.0613         0.13       0.0956       0.0796        0.171        0.125       0.0531      0.00354
    171   100     2.17e-05     2.16e-05     2.12e-08        0.101        0.134       0.0703        0.136        0.103       0.0887        0.172         0.13       0.0625      0.00417
    171   110     1.57e-05     1.57e-05     8.35e-08       0.0867        0.114       0.0559        0.122       0.0889       0.0713        0.149         0.11        0.122      0.00813
    171   120     1.43e-05     1.43e-05     7.21e-09       0.0795        0.109       0.0522        0.111       0.0814        0.069        0.142        0.105       0.0344      0.00229
    171   130     2.52e-05     2.46e-05     6.24e-07        0.109        0.143       0.0814        0.141        0.111          0.1         0.18         0.14        0.341       0.0227
    171   140     2.08e-05     2.08e-05     6.57e-09        0.097        0.131       0.0649        0.134       0.0993       0.0826        0.171        0.127       0.0312      0.00208
    171   150     2.46e-05     2.46e-05     6.78e-09        0.104        0.143       0.0694        0.143        0.106       0.0936        0.184        0.139       0.0188      0.00125
    171   160     2.16e-05     2.16e-05     6.36e-09       0.0958        0.134       0.0594        0.137       0.0984       0.0769        0.178        0.128       0.0219      0.00146
    171   170     3.07e-05     3.07e-05     2.48e-08        0.115         0.16       0.0643        0.172        0.118       0.0859        0.215         0.15       0.0594      0.00396
    171   180     2.55e-05     2.55e-05     3.09e-08        0.106        0.146       0.0671        0.149        0.108       0.0963        0.187        0.141        0.075        0.005
    171   190     3.03e-05     3.02e-05     8.67e-08        0.111        0.158       0.0626        0.166        0.114       0.0785        0.216        0.147        0.128      0.00854

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    171     5     1.97e-05     1.97e-05     1.38e-09       0.0883        0.128       0.0627        0.118       0.0901       0.0933        0.159        0.126       0.0141     0.000938


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             171 3661.806    0.005     2.23e-05     6.57e-08     2.23e-05       0.0998        0.136       0.0683        0.136        0.102       0.0897        0.175        0.132       0.0865      0.00577
! Validation        171 3661.806    0.005     2.14e-05     4.47e-09     2.14e-05       0.0913        0.133       0.0635        0.123       0.0933       0.0936        0.168        0.131       0.0203      0.00135
Wall time: 3661.806374542999
! Best model      171    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    172    10     2.29e-05     2.27e-05     2.74e-07        0.102        0.137        0.077        0.131        0.104        0.102        0.168        0.135        0.228       0.0152
    172    20     1.54e-05     1.53e-05     8.43e-08       0.0843        0.113       0.0585        0.114       0.0862        0.073        0.145        0.109        0.125      0.00833
    172    30      1.8e-05      1.8e-05      3.6e-09       0.0881        0.122       0.0575        0.123       0.0903       0.0787        0.158        0.118       0.0188      0.00125
    172    40     1.94e-05     1.93e-05     1.14e-07       0.0895        0.127       0.0577        0.126       0.0917       0.0716        0.169         0.12        0.144      0.00958
    172    50     2.74e-05     2.69e-05     5.37e-07        0.106        0.149        0.073        0.145        0.109       0.0922        0.195        0.144        0.316        0.021
    172    60        2e-05        2e-05     1.34e-08       0.0947        0.129       0.0591        0.135       0.0972       0.0754        0.171        0.123       0.0406      0.00271
    172    70     1.57e-05     1.56e-05     6.23e-08       0.0849        0.114       0.0602        0.113       0.0867        0.079        0.144        0.111        0.106      0.00708
    172    80     1.85e-05     1.85e-05     5.51e-08       0.0948        0.124       0.0649        0.129        0.097       0.0815        0.159         0.12        0.103      0.00687
    172    90     1.66e-05     1.66e-05     2.33e-09       0.0863        0.117       0.0515        0.126       0.0888       0.0658        0.157        0.111       0.0219      0.00146
    172   100     2.08e-05     2.07e-05     2.86e-08       0.0993        0.131       0.0716        0.131        0.101       0.0926        0.165        0.129       0.0594      0.00396
    172   110     1.54e-05     1.54e-05     1.48e-09       0.0839        0.113       0.0571        0.115       0.0858       0.0747        0.145         0.11       0.0156      0.00104
    172   120     2.21e-05      2.2e-05     1.05e-07       0.0987        0.135        0.074        0.127          0.1          0.1        0.167        0.133        0.138      0.00917
    172   130      1.7e-05     1.69e-05        5e-08       0.0925        0.119       0.0745        0.113       0.0938        0.102        0.135        0.119       0.0938      0.00625
    172   140     2.05e-05     2.04e-05     7.31e-08       0.0957         0.13        0.069        0.126       0.0976        0.086        0.167        0.127        0.112       0.0075
    172   150     2.23e-05     2.23e-05     3.18e-09       0.0961        0.136       0.0626        0.134       0.0985       0.0802         0.18         0.13       0.0219      0.00146
    172   160     1.79e-05     1.79e-05     2.76e-09        0.091        0.122       0.0608        0.126       0.0931       0.0835        0.154        0.119       0.0219      0.00146
    172   170     1.77e-05     1.76e-05     3.77e-08       0.0872        0.121       0.0549        0.124       0.0895       0.0721         0.16        0.116       0.0812      0.00542
    172   180     2.17e-05     2.17e-05     2.99e-08        0.101        0.134       0.0749        0.131        0.103       0.0951        0.168        0.132       0.0656      0.00438
    172   190     2.18e-05     2.18e-05     8.79e-08        0.102        0.134       0.0666        0.142        0.104       0.0858        0.174         0.13        0.128      0.00854

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    172     5     1.94e-05     1.94e-05     5.62e-09       0.0875        0.127       0.0629        0.116       0.0892       0.0919        0.158        0.125        0.025      0.00167


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             172 3683.066    0.005     2.07e-05     7.37e-08     2.07e-05       0.0963        0.131       0.0672         0.13       0.0984       0.0882        0.167        0.128       0.0922      0.00614
! Validation        172 3683.066    0.005     2.12e-05     5.28e-09     2.12e-05        0.091        0.133       0.0633        0.123        0.093        0.093        0.167         0.13       0.0203      0.00135
Wall time: 3683.0667120399994
! Best model      172    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    173    10     1.64e-05     1.63e-05     4.13e-08       0.0821        0.117       0.0577         0.11       0.0838       0.0758         0.15        0.113       0.0844      0.00563
    173    20     1.13e-05     1.12e-05     5.72e-08       0.0708       0.0967       0.0466       0.0985       0.0725       0.0595        0.126        0.093        0.103      0.00687
    173    30      1.7e-05     1.69e-05      3.6e-08       0.0873        0.119       0.0547        0.125       0.0897       0.0736        0.155        0.114       0.0812      0.00542
    173    40     1.57e-05     1.55e-05     2.75e-07       0.0843        0.113       0.0658        0.105       0.0856        0.086        0.138        0.112        0.222       0.0148
    173    50     2.35e-05     2.33e-05     1.59e-07        0.101        0.139       0.0664         0.14        0.103       0.0892         0.18        0.135        0.169       0.0113
    173    60     1.59e-05     1.57e-05     1.96e-07        0.087        0.114       0.0688        0.108       0.0883        0.091        0.136        0.114        0.184       0.0123
    173    70     1.93e-05     1.91e-05     1.48e-07       0.0913        0.126       0.0568        0.131       0.0937       0.0724        0.168         0.12        0.166        0.011
    173    80     1.75e-05     1.73e-05     2.02e-07       0.0929         0.12       0.0708        0.118       0.0945       0.0903        0.147        0.118        0.194       0.0129
    173    90     2.11e-05     2.11e-05     5.49e-08          0.1        0.132       0.0656         0.14        0.103       0.0852        0.171        0.128       0.0969      0.00646
    173   100      2.4e-05     2.39e-05     1.01e-07        0.105        0.141       0.0766        0.138        0.107       0.0981        0.178        0.138        0.131      0.00875
    173   110     2.07e-05     2.07e-05     9.75e-09       0.0962        0.131       0.0637        0.133       0.0986       0.0796        0.172        0.126       0.0344      0.00229
    173   120     2.08e-05     2.08e-05      5.3e-09          0.1        0.132       0.0667        0.138        0.102       0.0864        0.169        0.128       0.0312      0.00208
    173   130      1.9e-05     1.89e-05     5.11e-08       0.0933        0.126       0.0699         0.12        0.095       0.0883        0.158        0.123       0.0906      0.00604
    173   140     1.99e-05     1.96e-05     2.94e-07       0.0975        0.128        0.075        0.123       0.0991       0.0964        0.156        0.126        0.231       0.0154
    173   150     1.96e-05     1.95e-05     1.65e-07       0.0942        0.127       0.0751        0.116       0.0956        0.102        0.151        0.126        0.175       0.0117
    173   160     3.11e-05        3e-05     1.11e-06        0.112        0.158        0.078         0.15        0.114        0.102        0.204        0.153        0.456       0.0304
    173   170     1.76e-05     1.73e-05     2.46e-07       0.0896         0.12       0.0538        0.131       0.0921       0.0704        0.159        0.115        0.213       0.0142
    173   180     1.74e-05     1.69e-05     5.15e-07        0.085        0.119       0.0568        0.117       0.0871       0.0763        0.153        0.115        0.309       0.0206
    173   190     2.25e-05     2.25e-05     6.36e-09       0.0989        0.137       0.0743        0.127        0.101       0.0934        0.174        0.133       0.0281      0.00188

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    173     5     1.97e-05     1.97e-05     3.07e-09       0.0874        0.128       0.0625        0.116       0.0892       0.0941        0.158        0.126       0.0188      0.00125


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             173 3704.352    0.005     2.01e-05     1.55e-07     2.02e-05        0.095        0.129        0.067        0.127       0.0969       0.0879        0.164        0.126        0.141      0.00942
! Validation        173 3704.352    0.005     2.11e-05     4.96e-09     2.11e-05       0.0907        0.133       0.0631        0.122       0.0926       0.0933        0.167         0.13       0.0228      0.00152
Wall time: 3704.352587207999
! Best model      173    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    174    10     2.76e-05     2.76e-05     9.32e-09        0.107        0.151       0.0712        0.149         0.11       0.0916        0.199        0.145       0.0344      0.00229
    174    20     1.94e-05     1.93e-05     8.75e-08       0.0943        0.127        0.065        0.128       0.0964       0.0864        0.161        0.124        0.125      0.00833
    174    30     2.56e-05     2.56e-05     4.45e-08        0.103        0.146       0.0703        0.141        0.106        0.102        0.184        0.143       0.0844      0.00562
    174    40     1.72e-05     1.69e-05     3.15e-07       0.0849        0.119       0.0605        0.113       0.0866       0.0769        0.153        0.115        0.237       0.0158
    174    50     2.95e-05     2.95e-05     2.03e-08        0.119        0.157       0.0878        0.154        0.121        0.114        0.194        0.154       0.0562      0.00375
    174    60     2.87e-05     2.87e-05     1.08e-08         0.12        0.154       0.0923        0.151        0.122        0.114         0.19        0.152       0.0406      0.00271
    174    70     3.04e-05     3.04e-05     3.05e-08        0.119        0.159       0.0751        0.169        0.122       0.0988        0.207        0.153       0.0594      0.00396
    174    80     2.33e-05     2.33e-05     8.05e-09        0.101        0.139       0.0577        0.151        0.104       0.0784        0.186        0.132       0.0344      0.00229
    174    90     2.84e-05     2.84e-05     4.24e-09        0.111        0.154       0.0707        0.157        0.114       0.0959          0.2        0.148       0.0312      0.00208
    174   100     2.54e-05     2.49e-05      4.6e-07        0.107        0.144       0.0666        0.154         0.11       0.0826        0.191        0.137        0.291       0.0194
    174   110     1.72e-05     1.72e-05     1.42e-08       0.0927         0.12       0.0647        0.125       0.0947       0.0832        0.151        0.117       0.0437      0.00292
    174   120     3.08e-05     3.07e-05     1.65e-07        0.119         0.16       0.0707        0.174        0.122       0.0878        0.214        0.151        0.172       0.0115
    174   130     3.12e-05      3.1e-05     2.07e-07        0.114        0.161       0.0712        0.162        0.117       0.0961        0.211        0.154        0.191       0.0127
    174   140     3.39e-05     3.37e-05        2e-07        0.124        0.167       0.0836         0.17        0.127        0.111        0.214        0.163        0.188       0.0125
    174   150     1.86e-05     1.84e-05     2.45e-07         0.09        0.124        0.062        0.122        0.092        0.082        0.158         0.12        0.213       0.0142
    174   160     1.86e-05     1.86e-05     9.11e-09       0.0906        0.124       0.0552        0.131       0.0932       0.0676        0.167        0.117       0.0375       0.0025
    174   170     2.29e-05     2.28e-05     2.08e-08        0.105        0.138       0.0856        0.127        0.106        0.113        0.162        0.137       0.0531      0.00354
    174   180     2.53e-05     2.52e-05     1.03e-07        0.108        0.145       0.0825        0.137         0.11        0.102        0.182        0.142        0.138      0.00917
    174   190     2.59e-05     2.59e-05     3.39e-09        0.109        0.147       0.0827        0.139        0.111        0.104        0.184        0.144        0.025      0.00167

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    174     5     2.02e-05     2.02e-05     1.17e-09       0.0887         0.13       0.0632        0.118       0.0905       0.0955         0.16        0.128       0.0141     0.000938


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             174 3725.604    0.005     2.32e-05     1.37e-07     2.34e-05        0.102        0.139        0.071        0.138        0.104        0.093        0.178        0.135        0.128      0.00852
! Validation        174 3725.604    0.005     2.13e-05     3.48e-09     2.13e-05        0.091        0.133       0.0631        0.123       0.0929       0.0935        0.167         0.13       0.0178      0.00119
Wall time: 3725.604960397999

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    175    10     2.52e-05     2.49e-05     2.96e-07        0.106        0.144       0.0671        0.151        0.109       0.0901        0.187        0.139        0.231       0.0154
    175    20     2.57e-05     2.56e-05     6.93e-08         0.11        0.146       0.0668         0.16        0.114       0.0846        0.194        0.139        0.112       0.0075
    175    30     1.24e-05     1.23e-05     8.05e-09       0.0777        0.101       0.0564        0.102       0.0792       0.0716        0.127       0.0993       0.0344      0.00229
    175    40     2.16e-05     2.15e-05     4.17e-08        0.102        0.134       0.0751        0.132        0.103       0.0909         0.17         0.13       0.0875      0.00583
    175    50     1.47e-05     1.47e-05     2.56e-08       0.0833         0.11        0.059        0.111        0.085       0.0758         0.14        0.108       0.0688      0.00458
    175    60     1.08e-05     1.07e-05     9.03e-08        0.074       0.0942       0.0599       0.0902       0.0751       0.0767        0.111       0.0938        0.128      0.00854
    175    70     1.92e-05     1.91e-05     1.61e-07       0.0932        0.126       0.0628        0.128       0.0954       0.0805        0.163        0.122        0.172       0.0115
    175    80     1.48e-05     1.48e-05     4.73e-08       0.0794        0.111       0.0727       0.0871       0.0799        0.109        0.113        0.111       0.0969      0.00646
    175    90     1.68e-05     1.68e-05     1.57e-08       0.0893        0.118       0.0579        0.125       0.0915       0.0726        0.155        0.114       0.0531      0.00354
    175   100     2.03e-05     2.03e-05     8.69e-09        0.099         0.13       0.0714         0.13        0.101       0.0938        0.162        0.128       0.0344      0.00229
    175   110     2.25e-05     2.25e-05     3.84e-08        0.104        0.137       0.0718         0.14        0.106       0.0879        0.177        0.132       0.0812      0.00542
    175   120     2.65e-05     2.65e-05     1.86e-08        0.107        0.148        0.075        0.143        0.109        0.108        0.184        0.146       0.0437      0.00292
    175   130     1.92e-05      1.9e-05     1.48e-07       0.0894        0.126       0.0682        0.114       0.0909       0.0877        0.158        0.123        0.169       0.0113
    175   140     2.33e-05     2.33e-05      2.5e-08        0.107        0.139       0.0839        0.133        0.109        0.108        0.168        0.138       0.0562      0.00375
    175   150     1.07e-05     1.06e-05     5.81e-08       0.0713        0.094       0.0523        0.093       0.0726        0.066        0.118       0.0921          0.1      0.00667
    175   160     1.32e-05     1.32e-05     4.75e-08       0.0802        0.105       0.0557        0.108       0.0819       0.0691        0.134        0.102       0.0906      0.00604
    175   170     1.77e-05     1.76e-05     8.29e-08       0.0915        0.121       0.0694        0.117       0.0931       0.0938        0.146         0.12        0.122      0.00812
    175   180     2.35e-05     2.35e-05     3.45e-08         0.11         0.14       0.0945        0.127        0.111        0.116        0.163        0.139       0.0719      0.00479
    175   190     1.84e-05     1.82e-05     2.23e-07       0.0957        0.123       0.0788        0.115       0.0969       0.0999        0.145        0.122        0.206       0.0137

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    175     5     2.03e-05     2.03e-05     1.59e-09        0.089         0.13       0.0628        0.119       0.0909       0.0951        0.161        0.128       0.0172      0.00115


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             175 3746.796    0.005     1.91e-05     7.48e-08     1.92e-05       0.0936        0.126       0.0669        0.124       0.0955       0.0877        0.159        0.123       0.0941      0.00627
! Validation        175 3746.796    0.005     2.14e-05     4.37e-09     2.14e-05       0.0911        0.133       0.0629        0.123       0.0931       0.0932        0.168        0.131       0.0175      0.00117
Wall time: 3746.797163772999

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    176    10     1.94e-05     1.94e-05      3.6e-09       0.0941        0.127       0.0576        0.136       0.0967       0.0713        0.169         0.12       0.0188      0.00125
    176    20     2.37e-05     2.34e-05     2.38e-07        0.101         0.14       0.0586         0.15        0.105        0.072        0.189        0.131        0.206       0.0137
    176    30     2.02e-05     1.99e-05     3.48e-07       0.0964        0.129       0.0659        0.131       0.0985       0.0829        0.166        0.124        0.256       0.0171
    176    40     1.24e-05     1.22e-05     2.27e-07       0.0756        0.101       0.0508        0.104       0.0774       0.0647         0.13       0.0975        0.206       0.0137
    176    50     2.56e-05     2.56e-05     8.48e-09        0.108        0.146       0.0862        0.134         0.11         0.12        0.171        0.145       0.0344      0.00229
    176    60     1.84e-05     1.82e-05     1.55e-07       0.0901        0.123       0.0563        0.129       0.0925       0.0739        0.162        0.118        0.166        0.011
    176    70     2.21e-05     2.19e-05     2.41e-07        0.102        0.135       0.0666        0.142        0.104       0.0843        0.176         0.13        0.213       0.0142
    176    80     1.41e-05     1.41e-05     4.26e-08        0.082        0.108       0.0598        0.107       0.0836       0.0779        0.135        0.106       0.0812      0.00542
    176    90     2.49e-05     2.48e-05     1.04e-07        0.101        0.144       0.0604        0.148        0.104       0.0814        0.192        0.136        0.141      0.00938
    176   100     2.26e-05     2.21e-05     4.43e-07        0.093        0.136       0.0594        0.131       0.0954       0.0748        0.182        0.128        0.287       0.0192
    176   110     1.63e-05     1.63e-05     3.81e-09       0.0876        0.116       0.0565        0.123       0.0898       0.0724        0.152        0.112       0.0188      0.00125
    176   120     2.58e-05     2.56e-05      1.9e-07        0.104        0.146       0.0661        0.148        0.107       0.0905        0.191        0.141        0.184       0.0123
    176   130     2.74e-05     2.72e-05     1.87e-07        0.108         0.15        0.069        0.153        0.111       0.0934        0.196        0.145        0.188       0.0125
    176   140     2.13e-05     2.13e-05     4.94e-08       0.0962        0.133        0.066        0.131       0.0984       0.0878        0.171        0.129       0.0969      0.00646
    176   150     1.79e-05     1.77e-05     1.87e-07       0.0891        0.121       0.0622         0.12        0.091       0.0814        0.155        0.118        0.191       0.0127
    176   160     2.39e-05     2.39e-05     4.47e-08        0.113        0.141       0.0913        0.138        0.114        0.114        0.167         0.14       0.0812      0.00542
    176   170     2.21e-05     2.19e-05     1.62e-07        0.108        0.135        0.082        0.137         0.11          0.1        0.166        0.133        0.166        0.011
    176   180     2.53e-05     2.49e-05     4.52e-07        0.114        0.144       0.0791        0.153        0.116       0.0999        0.181        0.141        0.287       0.0192
    176   190      1.6e-05      1.6e-05      4.3e-08       0.0905        0.115       0.0662        0.118       0.0922       0.0837        0.143        0.113       0.0844      0.00563

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    176     5     2.03e-05     2.03e-05     3.18e-09       0.0883         0.13       0.0624        0.118       0.0902       0.0946        0.161        0.128       0.0172      0.00115


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             176 3768.106    0.005     2.17e-05     9.66e-08     2.18e-05       0.0985        0.134       0.0689        0.132        0.101        0.091        0.171        0.131        0.111      0.00739
! Validation        176 3768.106    0.005     2.12e-05     5.17e-09     2.12e-05       0.0906        0.133       0.0628        0.122       0.0926       0.0936        0.167         0.13         0.02      0.00133
Wall time: 3768.1070624509994

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    177    10     1.35e-05     1.35e-05     4.77e-08       0.0766        0.106       0.0476         0.11       0.0786       0.0633        0.139        0.101       0.0906      0.00604
    177    20     2.31e-05      2.3e-05     1.24e-07        0.102        0.138       0.0679         0.14        0.104       0.0918        0.177        0.134        0.153       0.0102
    177    30     1.44e-05     1.44e-05     6.36e-10       0.0808        0.109       0.0555         0.11       0.0826       0.0753        0.139        0.107      0.00938     0.000625
    177    40     1.79e-05     1.78e-05     1.33e-07       0.0891        0.122       0.0582        0.124       0.0913       0.0785        0.157        0.118        0.153       0.0102
    177    50     2.01e-05     2.01e-05     3.24e-08       0.0924        0.129       0.0605        0.129       0.0947       0.0789        0.169        0.124        0.075        0.005
    177    60     1.56e-05     1.55e-05     5.72e-08       0.0821        0.114       0.0571        0.111       0.0839       0.0702        0.148        0.109          0.1      0.00667
    177    70      1.8e-05      1.8e-05     7.31e-08       0.0869        0.122       0.0607        0.117       0.0888       0.0774        0.159        0.118        0.116      0.00771
    177    80     3.36e-05     3.34e-05     2.15e-07        0.128        0.167       0.0874        0.175        0.131        0.103        0.218         0.16        0.203       0.0135
    177    90     1.54e-05     1.51e-05     3.47e-07       0.0852        0.112       0.0565        0.118       0.0873       0.0708        0.145        0.108        0.253       0.0169
    177   100     1.86e-05     1.86e-05     5.13e-08       0.0952        0.124       0.0727        0.121       0.0968       0.0905        0.154        0.122       0.0938      0.00625
    177   110     1.67e-05     1.67e-05     3.81e-09       0.0811        0.118       0.0559         0.11       0.0829       0.0735        0.153        0.113       0.0188      0.00125
    177   120     1.37e-05     1.37e-05     4.24e-10       0.0759        0.107       0.0574        0.097       0.0772       0.0788        0.132        0.105      0.00625     0.000417
    177   130     1.48e-05     1.47e-05     7.76e-08       0.0883         0.11       0.0761        0.102       0.0892       0.0934        0.127         0.11        0.119      0.00792
    177   140     2.19e-05     2.18e-05     2.65e-08       0.0987        0.135       0.0637        0.139        0.101       0.0847        0.175         0.13       0.0594      0.00396
    177   150     2.23e-05     2.22e-05      1.3e-07       0.0963        0.136       0.0582         0.14       0.0991       0.0709        0.184        0.127        0.153       0.0102
    177   160     1.47e-05     1.46e-05     2.59e-08        0.077         0.11       0.0494        0.108        0.079       0.0655        0.146        0.106       0.0656      0.00438
    177   170     1.77e-05     1.76e-05      1.4e-07        0.097        0.121       0.0823        0.114       0.0981        0.101         0.14        0.121        0.159       0.0106
    177   180     2.59e-05     2.58e-05     1.95e-08        0.107        0.147       0.0805        0.138        0.109        0.107        0.182        0.144         0.05      0.00333
    177   190     2.18e-05     2.18e-05     1.48e-09        0.098        0.135       0.0594        0.142        0.101       0.0797        0.178        0.129       0.0156      0.00104

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    177     5     1.97e-05     1.97e-05     2.33e-09       0.0873        0.128       0.0624        0.116       0.0891        0.094        0.158        0.126       0.0141     0.000938


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             177 3789.446    0.005     1.84e-05     8.51e-08     1.85e-05       0.0911        0.124       0.0639        0.122        0.093       0.0839        0.157        0.121        0.104      0.00691
! Validation        177 3789.446    0.005     2.09e-05     4.43e-09     2.09e-05       0.0901        0.132       0.0628        0.121       0.0921       0.0928        0.166        0.129       0.0172      0.00115
Wall time: 3789.447111629999
! Best model      177    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    178    10      1.9e-05      1.9e-05     4.54e-08       0.0955        0.126       0.0749        0.119       0.0969       0.0925        0.155        0.124       0.0906      0.00604
    178    20     2.03e-05     2.03e-05     9.32e-09        0.101         0.13       0.0779        0.126        0.102        0.099        0.158        0.129       0.0312      0.00208
    178    30     2.23e-05     2.23e-05     3.24e-08        0.104        0.136       0.0863        0.124        0.105        0.107        0.163        0.135       0.0719      0.00479
    178    40     2.49e-05     2.49e-05     3.81e-09        0.104        0.144       0.0678        0.145        0.106       0.0896        0.188        0.139       0.0156      0.00104
    178    50     1.96e-05     1.96e-05     5.51e-08       0.0932        0.128        0.059        0.132       0.0956       0.0784        0.167        0.123       0.0938      0.00625
    178    60      1.8e-05      1.8e-05     2.97e-09       0.0879        0.122       0.0578        0.122       0.0901       0.0771        0.159        0.118       0.0188      0.00125
    178    70      1.8e-05     1.79e-05     1.45e-07       0.0899        0.122       0.0586        0.126       0.0922       0.0759        0.159        0.117        0.166        0.011
    178    80     1.84e-05     1.84e-05     7.93e-08        0.089        0.124       0.0632        0.118       0.0908       0.0843        0.157        0.121        0.119      0.00792
    178    90     3.56e-05     3.55e-05     4.17e-08        0.123        0.172       0.0693        0.184        0.127       0.0916        0.232        0.162       0.0812      0.00542
    178   100     4.01e-05     3.99e-05     2.12e-07        0.143        0.182       0.0983        0.193        0.146        0.119        0.234        0.177        0.194       0.0129
    178   110     1.77e-05     1.75e-05     1.58e-07       0.0925        0.121       0.0726        0.115        0.094       0.0906        0.148        0.119        0.166        0.011
    178   120     2.53e-05     2.52e-05     5.34e-08        0.115        0.145        0.101        0.131        0.116        0.121        0.168        0.144          0.1      0.00667
    178   130     1.85e-05     1.83e-05      1.5e-07       0.0918        0.123       0.0696        0.117       0.0933       0.0943         0.15        0.122        0.166        0.011
    178   140     1.87e-05     1.84e-05     2.94e-07       0.0945        0.124       0.0691        0.123       0.0963       0.0875        0.155        0.121        0.241        0.016
    178   150     2.62e-05     2.62e-05     2.27e-08        0.112        0.148       0.0795        0.149        0.114        0.105        0.185        0.145       0.0562      0.00375
    178   160     2.02e-05     1.99e-05     2.66e-07       0.0904        0.129       0.0537        0.132       0.0931       0.0744        0.171        0.123        0.225        0.015
    178   170     5.09e-05     5.01e-05     7.75e-07         0.15        0.204        0.107        0.199        0.153        0.136        0.261        0.199        0.378       0.0252
    178   180     5.15e-05     5.13e-05     1.53e-07         0.15        0.207        0.102        0.206        0.154        0.136        0.265        0.201        0.166        0.011
    178   190     5.28e-05     5.18e-05     9.71e-07        0.155        0.208        0.121        0.193        0.157        0.158        0.253        0.205        0.425       0.0283

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    178     5      2.1e-05      2.1e-05     2.12e-09       0.0894        0.132       0.0628         0.12       0.0913       0.0956        0.164         0.13       0.0156      0.00104


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             178 3810.782    0.005     2.62e-05     1.73e-07     2.64e-05        0.108        0.148       0.0761        0.145         0.11          0.1        0.188        0.144        0.142      0.00946
! Validation        178 3810.782    0.005     2.14e-05     3.86e-09     2.14e-05       0.0907        0.133       0.0627        0.123       0.0927        0.093        0.168         0.13       0.0169      0.00113
Wall time: 3810.78359653

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    179    10     2.47e-05     2.47e-05     4.98e-08        0.102        0.143       0.0649        0.144        0.104        0.084        0.189        0.137       0.0906      0.00604
    179    20     2.08e-05     2.07e-05     9.64e-08       0.0967        0.131       0.0689        0.128       0.0986        0.086        0.168        0.127        0.131      0.00875
    179    30     1.92e-05      1.9e-05     2.14e-07       0.0914        0.126       0.0678        0.118        0.093       0.0863        0.159        0.123          0.2       0.0133
    179    40     1.29e-05     1.28e-05     3.92e-08       0.0803        0.103       0.0539        0.111       0.0822       0.0681        0.133          0.1       0.0844      0.00562
    179    50     2.27e-05     2.26e-05     3.79e-08        0.101        0.137       0.0679        0.138        0.103       0.0929        0.175        0.134       0.0781      0.00521
    179    60     1.48e-05     1.47e-05     1.08e-07       0.0828        0.111       0.0556        0.114       0.0847       0.0721        0.142        0.107        0.138      0.00917
    179    70      2.6e-05     2.58e-05     1.91e-07        0.106        0.146       0.0684        0.148        0.108       0.0948        0.189        0.142        0.184       0.0123
    179    80     2.97e-05     2.95e-05     1.96e-07        0.115        0.157       0.0742        0.162        0.118       0.0947        0.206         0.15        0.188       0.0125
    179    90     1.87e-05     1.86e-05     1.58e-07       0.0944        0.124       0.0697        0.123       0.0962       0.0896        0.155        0.122        0.172       0.0115
    179   100     1.96e-05     1.95e-05     1.44e-08       0.0917        0.127       0.0622        0.125       0.0938       0.0834        0.164        0.124       0.0562      0.00375
    179   110     1.54e-05     1.53e-05     5.13e-08       0.0857        0.113       0.0578        0.117       0.0877       0.0717        0.146        0.109          0.1      0.00667
    179   120     1.87e-05     1.86e-05     5.91e-08       0.0913        0.124       0.0601        0.127       0.0935       0.0819         0.16        0.121        0.103      0.00687
    179   130     1.59e-05     1.59e-05     1.19e-08       0.0879        0.115        0.065        0.114       0.0896       0.0821        0.144        0.113         0.05      0.00333
    179   140     1.97e-05     1.96e-05     3.12e-08        0.097        0.128       0.0707        0.127       0.0989       0.0895        0.161        0.125       0.0688      0.00458
    179   150     2.65e-05     2.63e-05     1.33e-07        0.106        0.148       0.0693        0.148        0.109       0.0985        0.189        0.144         0.15         0.01
    179   160     2.02e-05     1.94e-05     7.81e-07        0.102        0.127       0.0847        0.121        0.103        0.106        0.147        0.127        0.384       0.0256
    179   170     1.79e-05     1.77e-05     1.97e-07        0.092        0.121        0.067        0.121       0.0938        0.083        0.154        0.118        0.194       0.0129
    179   180     1.56e-05     1.56e-05     2.44e-08       0.0897        0.114       0.0736        0.108       0.0909       0.0946        0.132        0.113       0.0656      0.00438
    179   190     2.43e-05     2.42e-05     7.01e-08        0.101        0.142       0.0624        0.145        0.104       0.0905        0.184        0.137        0.112       0.0075

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    179     5     2.08e-05     2.08e-05     2.01e-09       0.0893        0.131       0.0613        0.121       0.0913       0.0929        0.165        0.129       0.0172      0.00115


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             179 3832.151    0.005        2e-05     1.23e-07     2.01e-05       0.0949        0.129       0.0662        0.128       0.0969       0.0872        0.164        0.126        0.123       0.0082
! Validation        179 3832.151    0.005     2.12e-05     4.92e-09     2.13e-05       0.0905        0.133       0.0622        0.123       0.0925       0.0921        0.168         0.13       0.0216      0.00144
Wall time: 3832.152085443

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    180    10     2.03e-05     2.03e-05     2.52e-08       0.0957         0.13       0.0633        0.133        0.098       0.0833        0.168        0.126       0.0656      0.00438
    180    20     1.16e-05     1.16e-05     1.02e-08       0.0723       0.0982       0.0511       0.0965       0.0738       0.0666        0.125       0.0957       0.0406      0.00271
    180    30     1.68e-05     1.68e-05     1.48e-08       0.0876        0.118       0.0642        0.114       0.0893       0.0848        0.147        0.116       0.0406      0.00271
    180    40     2.45e-05     2.44e-05     7.27e-08        0.109        0.143       0.0891        0.131         0.11        0.113         0.17        0.141        0.116      0.00771
    180    50     1.51e-05      1.5e-05     9.47e-08       0.0809        0.112        0.061        0.104       0.0823       0.0847        0.136        0.111        0.134      0.00896
    180    60     1.73e-05     1.71e-05      1.2e-07       0.0881        0.119       0.0628        0.117       0.0899       0.0782        0.153        0.116         0.15         0.01
    180    70     1.57e-05     1.57e-05     6.99e-08       0.0875        0.114       0.0652        0.113       0.0891       0.0838        0.141        0.112        0.116      0.00771
    180    80      1.3e-05      1.3e-05     3.43e-08        0.078        0.104       0.0505        0.109       0.0799       0.0646        0.136          0.1       0.0719      0.00479
    180    90     1.73e-05     1.73e-05     3.37e-08       0.0869         0.12       0.0523        0.127       0.0894       0.0683         0.16        0.114        0.075        0.005
    180   100     1.73e-05     1.71e-05     2.33e-07       0.0867        0.119       0.0598        0.118       0.0886       0.0781        0.153        0.116        0.216       0.0144
    180   110     2.11e-05     2.09e-05     2.95e-07       0.0969        0.132       0.0647        0.134       0.0992       0.0831        0.171        0.127        0.234       0.0156
    180   120     1.67e-05     1.67e-05     1.34e-08       0.0855        0.118       0.0589        0.116       0.0874       0.0805        0.149        0.115       0.0375       0.0025
    180   130     2.06e-05     2.04e-05     2.15e-07       0.0994         0.13        0.077        0.125        0.101          0.1        0.158        0.129        0.203       0.0135
    180   140     1.56e-05     1.55e-05      2.8e-08       0.0872        0.114       0.0533        0.126       0.0896       0.0668         0.15        0.109       0.0656      0.00438
    180   150     1.19e-05     1.18e-05     9.85e-08       0.0736        0.099       0.0489        0.102       0.0753       0.0611        0.129       0.0952        0.131      0.00875
    180   160     1.71e-05     1.71e-05     3.14e-08       0.0879        0.119       0.0657        0.113       0.0895        0.086        0.148        0.117       0.0719      0.00479
    180   170     2.17e-05     2.17e-05     1.84e-08       0.0987        0.134       0.0655        0.137        0.101       0.0848        0.175         0.13         0.05      0.00333
    180   180     2.07e-05     2.07e-05     2.44e-08       0.0976        0.131       0.0719        0.127       0.0994       0.0901        0.166        0.128       0.0594      0.00396
    180   190      1.6e-05      1.6e-05     2.44e-08       0.0868        0.115       0.0624        0.115       0.0885       0.0807        0.145        0.113       0.0688      0.00458

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    180     5     2.09e-05     2.09e-05     2.54e-09       0.0894        0.132       0.0612        0.122       0.0914       0.0922        0.166        0.129       0.0188      0.00125


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             180 3853.597    0.005     1.82e-05     9.16e-08     1.83e-05       0.0909        0.123        0.064        0.122       0.0928       0.0842        0.156         0.12        0.105      0.00703
! Validation        180 3853.597    0.005     2.11e-05     4.47e-09     2.11e-05       0.0904        0.133       0.0619        0.123       0.0924       0.0915        0.168         0.13       0.0178      0.00119
Wall time: 3853.597098537999

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    181    10      1.7e-05     1.67e-05     2.41e-07       0.0874        0.118       0.0626        0.116       0.0892       0.0836        0.148        0.116        0.216       0.0144
    181    20     2.75e-05     2.72e-05     3.17e-07         0.11         0.15        0.103        0.119        0.111        0.146        0.155        0.151        0.247       0.0165
    181    30     1.73e-05     1.73e-05     8.27e-08       0.0869         0.12        0.054        0.124       0.0892       0.0747        0.156        0.115        0.122      0.00813
    181    40     1.19e-05     1.17e-05     1.55e-07       0.0738       0.0987       0.0503        0.101       0.0755       0.0694        0.124       0.0967        0.169       0.0112
    181    50     2.04e-05     2.04e-05     1.55e-08       0.0984         0.13        0.068        0.133        0.101        0.089        0.165        0.127       0.0469      0.00313
    181    60     3.12e-05     3.11e-05     6.04e-08        0.121        0.161        0.102        0.142        0.122        0.125        0.194         0.16       0.0969      0.00646
    181    70     2.39e-05     2.39e-05     5.72e-09        0.102        0.141       0.0726        0.135        0.104       0.0962        0.179        0.137        0.025      0.00167
    181    80     1.39e-05     1.39e-05     6.57e-09       0.0793        0.107       0.0613       0.0999       0.0806       0.0817        0.131        0.106       0.0281      0.00188
    181    90     1.22e-05     1.22e-05     2.31e-08       0.0733        0.101       0.0461        0.105       0.0753       0.0619        0.132       0.0967       0.0625      0.00417
    181   100     1.71e-05     1.71e-05     3.71e-08       0.0901        0.119       0.0667        0.117       0.0917       0.0867        0.148        0.117        0.075        0.005
    181   110     2.63e-05     2.63e-05     1.93e-08        0.106        0.148       0.0774         0.14        0.109        0.107        0.184        0.145         0.05      0.00333
    181   120     3.24e-05     3.23e-05      2.1e-08        0.125        0.164       0.0901        0.164        0.127        0.115        0.206        0.161         0.05      0.00333
    181   130     1.75e-05     1.74e-05     8.48e-09       0.0915         0.12       0.0632        0.124       0.0935        0.086         0.15        0.118       0.0344      0.00229
    181   140     1.72e-05     1.72e-05     1.27e-09       0.0914         0.12       0.0654        0.121       0.0933       0.0834        0.151        0.117      0.00938     0.000625
    181   150     2.09e-05     2.09e-05     5.02e-08       0.0938        0.132       0.0604        0.132       0.0962       0.0763        0.175        0.126       0.0938      0.00625
    181   160     1.93e-05     1.93e-05     2.69e-08       0.0879        0.127       0.0535        0.127       0.0904       0.0661        0.172        0.119       0.0688      0.00458
    181   170     2.02e-05     2.02e-05     3.54e-08       0.0942        0.129       0.0568        0.137       0.0969       0.0711        0.174        0.122       0.0781      0.00521
    181   180     1.76e-05     1.76e-05      3.6e-09       0.0877        0.121       0.0662        0.112       0.0892       0.0901        0.148        0.119       0.0188      0.00125
    181   190     3.19e-05     3.17e-05     1.43e-07         0.11        0.162       0.0552        0.173        0.114       0.0752        0.224        0.149        0.162       0.0108

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    181     5     2.02e-05     2.02e-05     8.48e-10       0.0886         0.13       0.0613         0.12       0.0906       0.0921        0.162        0.127      0.00938     0.000625


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             181 3874.989    0.005     1.91e-05     7.49e-08     1.91e-05       0.0923        0.126       0.0644        0.124       0.0942       0.0851         0.16        0.123       0.0957      0.00638
! Validation        181 3874.989    0.005     2.09e-05     3.69e-09      2.1e-05         0.09        0.132       0.0617        0.122        0.092       0.0914        0.167        0.129       0.0159      0.00106
Wall time: 3874.9897592549987

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    182    10     2.57e-05     2.57e-05     2.27e-08        0.108        0.146       0.0875        0.131        0.109        0.113        0.177        0.145       0.0625      0.00417
    182    20      2.2e-05     2.18e-05     1.36e-07       0.0975        0.135       0.0591        0.141          0.1       0.0786        0.179        0.129        0.156       0.0104
    182    30     1.86e-05     1.79e-05     6.34e-07       0.0889        0.122        0.051        0.132       0.0916       0.0657        0.164        0.115        0.341       0.0227
    182    40     1.97e-05     1.96e-05     1.21e-07       0.0925        0.128       0.0566        0.134       0.0951       0.0722         0.17        0.121         0.15         0.01
    182    50     2.08e-05     2.08e-05     3.16e-08       0.0968        0.132       0.0672        0.131        0.099       0.0849         0.17        0.127       0.0719      0.00479
    182    60     2.08e-05     2.08e-05     2.59e-08       0.0923        0.131       0.0587        0.131       0.0947       0.0778        0.174        0.126       0.0656      0.00438
    182    70     2.02e-05     1.99e-05     3.32e-07       0.0932        0.129       0.0757        0.113       0.0944       0.0988        0.156        0.127        0.247       0.0165
    182    80      1.4e-05      1.4e-05     2.33e-09       0.0825        0.108       0.0601        0.108       0.0841       0.0751        0.136        0.106       0.0125     0.000833
    182    90     1.69e-05     1.67e-05     1.22e-07       0.0865        0.118       0.0584        0.119       0.0885       0.0754        0.153        0.114         0.15         0.01
    182   100     1.37e-05     1.37e-05     1.42e-08       0.0857        0.107       0.0651        0.109       0.0872         0.08        0.131        0.105       0.0469      0.00313
    182   110     3.01e-05     3.01e-05     8.48e-09        0.114        0.158        0.069        0.165        0.117       0.0872        0.212         0.15       0.0437      0.00292
    182   120     1.84e-05     1.84e-05      7.4e-08       0.0916        0.124       0.0669         0.12       0.0934       0.0888        0.154        0.121        0.119      0.00792
    182   130      1.9e-05     1.89e-05     1.25e-07        0.091        0.125       0.0674        0.118       0.0927       0.0881        0.158        0.123        0.153       0.0102
    182   140     1.59e-05     1.59e-05     8.71e-08       0.0884        0.115       0.0574        0.124       0.0906       0.0717         0.15        0.111        0.125      0.00833
    182   150      1.6e-05      1.6e-05      4.2e-08       0.0881        0.115       0.0691         0.11       0.0895       0.0903        0.138        0.114       0.0875      0.00583
    182   160     1.56e-05     1.56e-05     1.91e-08       0.0851        0.114       0.0635         0.11       0.0867        0.083        0.141        0.112         0.05      0.00333
    182   170     2.79e-05     2.77e-05     1.97e-07        0.116        0.152       0.0805        0.156        0.118       0.0986        0.196        0.147        0.191       0.0127
    182   180     1.65e-05     1.65e-05     3.26e-08       0.0898        0.117       0.0576        0.127       0.0921       0.0729        0.152        0.113       0.0719      0.00479
    182   190     2.44e-05     2.41e-05     3.01e-07        0.109        0.142       0.0824        0.138         0.11        0.103        0.176        0.139        0.231       0.0154

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    182     5     1.95e-05     1.95e-05     3.07e-09       0.0878        0.127       0.0614        0.118       0.0897       0.0913        0.159        0.125       0.0188      0.00125


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             182 3896.017    0.005     2.07e-05     1.22e-07     2.08e-05       0.0962        0.131       0.0659        0.131       0.0984       0.0862        0.168        0.127        0.123      0.00819
! Validation        182 3896.017    0.005     2.09e-05     4.22e-09     2.09e-05       0.0904        0.132       0.0621        0.123       0.0924       0.0916        0.166        0.129         0.02      0.00133
Wall time: 3896.017581480999

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    183    10     1.14e-05     1.13e-05     1.16e-07       0.0728       0.0971       0.0524       0.0962       0.0743       0.0692        0.121       0.0953        0.144      0.00958
    183    20     2.09e-05     2.09e-05     1.17e-08       0.0968        0.132       0.0753        0.121       0.0984        0.101         0.16         0.13       0.0344      0.00229
    183    30     2.51e-05     2.51e-05     6.72e-08        0.103        0.144       0.0609        0.151        0.106       0.0803        0.193        0.137        0.109      0.00729
    183    40     2.44e-05     2.44e-05     1.34e-08         0.11        0.142       0.0997        0.122        0.111        0.128        0.157        0.143       0.0437      0.00292
    183    50     1.48e-05     1.48e-05     2.12e-09       0.0831        0.111       0.0626        0.107       0.0846       0.0782        0.139        0.109       0.0156      0.00104
    183    60     2.06e-05     2.02e-05     4.02e-07       0.0964         0.13       0.0754         0.12       0.0979       0.0957         0.16        0.128        0.275       0.0183
    183    70     2.78e-05     2.78e-05     8.27e-09        0.122        0.152        0.107        0.138        0.123        0.128        0.175        0.152       0.0406      0.00271
    183    80      2.3e-05     2.29e-05     1.58e-07       0.0996        0.138       0.0662        0.138        0.102         0.09        0.178        0.134        0.172       0.0115
    183    90     2.94e-05     2.91e-05     3.23e-07        0.111        0.156       0.0613        0.168        0.114         0.08        0.211        0.145        0.244       0.0162
    183   100     2.64e-05     2.61e-05     2.86e-07        0.107        0.147       0.0689         0.15         0.11       0.0903        0.193        0.142        0.237       0.0158
    183   110     2.42e-05      2.4e-05     2.35e-07        0.107        0.141       0.0695         0.15         0.11       0.0906        0.183        0.137        0.203       0.0135
    183   120     2.44e-05     2.43e-05     7.67e-08        0.105        0.142       0.0686        0.146        0.107       0.0922        0.183        0.138        0.122      0.00812
    183   130     1.78e-05     1.78e-05     8.69e-09       0.0935        0.122       0.0759        0.114       0.0948       0.0962        0.146        0.121       0.0281      0.00188
    183   140     1.94e-05     1.92e-05     2.07e-07       0.0964        0.126       0.0753         0.12       0.0979       0.0943        0.155        0.125        0.191       0.0127
    183   150     2.03e-05     2.02e-05     1.11e-07       0.0996         0.13       0.0759        0.127        0.101       0.0948        0.161        0.128        0.141      0.00938
    183   160     1.43e-05     1.43e-05     5.64e-08       0.0807        0.109       0.0584        0.106       0.0823        0.078        0.136        0.107        0.109      0.00729
    183   170     2.12e-05     2.12e-05      3.2e-08        0.104        0.133       0.0695        0.143        0.106       0.0861        0.171        0.129       0.0625      0.00417
    183   180     1.43e-05     1.43e-05     7.21e-09       0.0845        0.109       0.0673        0.104       0.0857       0.0867         0.13        0.108        0.025      0.00167
    183   190        2e-05     1.96e-05     4.44e-07       0.0913        0.128       0.0645        0.122       0.0932       0.0885        0.161        0.125        0.291       0.0194

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    183     5     1.97e-05     1.97e-05     3.07e-09       0.0875        0.128        0.061        0.118       0.0894       0.0903         0.16        0.125       0.0188      0.00125


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             183 3917.543    0.005     2.07e-05     1.95e-07     2.09e-05       0.0965        0.131       0.0681        0.129       0.0985       0.0897        0.167        0.128         0.15         0.01
! Validation        183 3917.543    0.005     2.07e-05     5.02e-09     2.07e-05       0.0899        0.131       0.0617        0.122        0.092       0.0905        0.166        0.128       0.0194      0.00129
Wall time: 3917.543744523
! Best model      183    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    184    10     1.73e-05     1.73e-05     1.86e-08         0.09         0.12       0.0643        0.119       0.0918        0.081        0.153        0.117       0.0562      0.00375
    184    20     1.15e-05     1.15e-05     2.92e-08       0.0802       0.0976       0.0698        0.092       0.0809       0.0827        0.112       0.0975       0.0781      0.00521
    184    30     2.66e-05     2.66e-05     9.11e-09         0.11        0.149       0.0699        0.155        0.112       0.0919        0.194        0.143       0.0312      0.00208
    184    40     2.79e-05     2.78e-05     1.11e-07         0.11        0.152       0.0679        0.158        0.113       0.0832        0.204        0.144        0.134      0.00896
    184    50     2.25e-05     2.24e-05     2.82e-08        0.103        0.137       0.0683        0.143        0.106       0.0839        0.179        0.131        0.075        0.005
    184    60     1.51e-05      1.5e-05     2.52e-08       0.0874        0.112       0.0663        0.111       0.0889       0.0851        0.136        0.111       0.0625      0.00417
    184    70     2.08e-05     2.07e-05      4.7e-08       0.0937        0.131       0.0607        0.131        0.096       0.0792        0.172        0.126       0.0938      0.00625
    184    80     5.11e-05     5.06e-05     5.44e-07        0.147        0.205       0.0971        0.205        0.151        0.135        0.263        0.199        0.312       0.0208
    184    90     2.81e-05     2.81e-05     2.52e-08        0.109        0.153       0.0602        0.164        0.112       0.0806        0.206        0.144       0.0562      0.00375
    184   100     1.54e-05     1.54e-05     2.54e-09       0.0816        0.113       0.0507        0.117       0.0838       0.0647        0.151        0.108       0.0156      0.00104
    184   110     2.05e-05     2.05e-05     3.77e-08        0.098        0.131       0.0572        0.145        0.101       0.0704        0.176        0.123        0.075        0.005
    184   120     2.73e-05     2.73e-05     9.11e-09        0.108        0.151       0.0703        0.151         0.11       0.0962        0.195        0.146       0.0406      0.00271
    184   130     2.66e-05     2.66e-05     6.99e-09         0.11        0.149       0.0745        0.151        0.113       0.0993         0.19        0.145       0.0344      0.00229
    184   140     1.59e-05     1.58e-05     2.29e-08       0.0839        0.115       0.0538        0.118       0.0861       0.0683        0.151         0.11       0.0531      0.00354
    184   150     1.69e-05     1.69e-05     4.87e-09       0.0854        0.118       0.0521        0.124       0.0878       0.0632         0.16        0.111       0.0281      0.00188
    184   160     2.33e-05     2.29e-05     3.62e-07       0.0999        0.138       0.0545        0.152        0.103       0.0683        0.188        0.128        0.259       0.0173
    184   170     2.79e-05     2.76e-05     2.89e-07        0.113        0.152       0.0746        0.158        0.116       0.0939        0.198        0.146        0.237       0.0158
    184   180     2.33e-05     2.33e-05     9.54e-09       0.0974        0.139       0.0622        0.138       0.0999       0.0861        0.182        0.134       0.0344      0.00229
    184   190     1.73e-05     1.73e-05     1.02e-08       0.0902         0.12       0.0698        0.113       0.0917       0.0906        0.146        0.119       0.0437      0.00292

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    184     5     1.93e-05     1.93e-05     1.91e-09       0.0866        0.127         0.06        0.117       0.0885       0.0907        0.158        0.124       0.0156      0.00104


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             184 3938.807    0.005     2.05e-05     1.41e-07     2.06e-05       0.0957         0.13       0.0655         0.13       0.0978       0.0857        0.167        0.127        0.131      0.00874
! Validation        184 3938.807    0.005     2.06e-05     4.09e-09     2.06e-05       0.0893        0.131       0.0614        0.121       0.0913       0.0908        0.165        0.128       0.0188      0.00125
Wall time: 3938.807554371999
! Best model      184    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    185    10     2.24e-05     2.23e-05     9.11e-09          0.1        0.136       0.0785        0.125        0.102       0.0964        0.171        0.134       0.0312      0.00208
    185    20     2.37e-05     2.35e-05     1.96e-07        0.101         0.14       0.0647        0.142        0.103       0.0859        0.183        0.134        0.188       0.0125
    185    30     2.16e-05     2.16e-05     1.59e-08        0.101        0.134       0.0677         0.14        0.104       0.0894        0.171         0.13       0.0437      0.00292
    185    40     1.25e-05     1.25e-05     4.34e-08       0.0742        0.102       0.0481        0.104       0.0761       0.0618        0.134       0.0977       0.0812      0.00542
    185    50     2.05e-05     2.02e-05     2.53e-07       0.0967         0.13       0.0736        0.123       0.0984       0.0947        0.161        0.128        0.209        0.014
    185    60     2.14e-05     2.14e-05     1.12e-08       0.0945        0.133       0.0553        0.139       0.0973       0.0702         0.18        0.125       0.0344      0.00229
    185    70     2.41e-05     2.36e-05     4.98e-07        0.103         0.14       0.0599        0.152        0.106       0.0744        0.189        0.132        0.297       0.0198
    185    80      2.1e-05     2.09e-05     9.88e-08       0.0997        0.132       0.0796        0.123        0.101        0.102        0.159        0.131        0.134      0.00896
    185    90      1.5e-05     1.47e-05     2.55e-07       0.0827        0.111       0.0521        0.118       0.0849       0.0711        0.143        0.107        0.222       0.0148
    185   100     2.32e-05     2.32e-05     1.57e-08        0.104        0.139       0.0752        0.137        0.106        0.098        0.174        0.136       0.0562      0.00375
    185   110     1.96e-05     1.96e-05     1.59e-08       0.0931        0.128       0.0641        0.126       0.0951        0.081        0.166        0.123       0.0437      0.00292
    185   120     2.25e-05     2.24e-05     8.75e-08       0.0994        0.136        0.081         0.12        0.101        0.116        0.157        0.136        0.128      0.00854
    185   130     1.95e-05      1.9e-05     5.54e-07       0.0979        0.126       0.0799        0.119       0.0992        0.104        0.147        0.125        0.322       0.0215
    185   140     1.77e-05     1.75e-05     1.52e-07       0.0918        0.121       0.0692        0.118       0.0934       0.0843        0.152        0.118        0.169       0.0112
    185   150     1.97e-05     1.95e-05     1.99e-07       0.0937        0.127       0.0603        0.132        0.096       0.0779        0.167        0.122        0.197       0.0131
    185   160     1.52e-05      1.5e-05     1.91e-07       0.0881        0.112       0.0729        0.105       0.0892       0.0884        0.133        0.111        0.184       0.0123
    185   170     1.78e-05     1.77e-05     9.37e-08       0.0872        0.121       0.0541        0.125       0.0896       0.0677        0.162        0.115        0.128      0.00854
    185   180     1.98e-05     1.98e-05     8.27e-09        0.103        0.128        0.103        0.104        0.103        0.127        0.129        0.128       0.0406      0.00271
    185   190     1.79e-05     1.78e-05     7.42e-08       0.0853        0.122       0.0599        0.114       0.0872       0.0842        0.154        0.119        0.112       0.0075

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    185     5     1.96e-05     1.96e-05     8.48e-10       0.0869        0.128       0.0609        0.117       0.0888       0.0925        0.158        0.125      0.00938     0.000625


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             185 3960.142    0.005      1.9e-05     1.37e-07     1.91e-05       0.0927        0.126       0.0645        0.125       0.0947       0.0848         0.16        0.122        0.126      0.00842
! Validation        185 3960.142    0.005     2.06e-05     4.22e-09     2.06e-05       0.0894        0.131       0.0615        0.121       0.0914       0.0915        0.165        0.128       0.0181      0.00121
Wall time: 3960.1435874189992

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    186    10     2.35e-05     2.35e-05      1.7e-09        0.101         0.14       0.0655        0.141        0.103       0.0899        0.181        0.135       0.0188      0.00125
    186    20     1.92e-05     1.91e-05     9.73e-08       0.0973        0.126       0.0778         0.12       0.0987          0.1         0.15        0.125        0.131      0.00875
    186    30     1.41e-05     1.41e-05     1.67e-08       0.0826        0.108       0.0614        0.107       0.0841       0.0761        0.136        0.106       0.0469      0.00313
    186    40     1.45e-05     1.43e-05     2.42e-07        0.087        0.109       0.0832       0.0913       0.0873        0.103        0.116        0.109        0.219       0.0146
    186    50     1.37e-05     1.36e-05     4.51e-08       0.0812        0.106       0.0578        0.108       0.0828       0.0729        0.135        0.104       0.0844      0.00563
    186    60     2.23e-05     2.23e-05      5.3e-09        0.104        0.136       0.0757        0.137        0.106       0.0987        0.169        0.134       0.0188      0.00125
    186    70     1.96e-05     1.95e-05      7.9e-08          0.1        0.128       0.0765        0.127        0.102       0.0945        0.157        0.126        0.119      0.00792
    186    80     1.67e-05     1.65e-05     1.52e-07       0.0921        0.117       0.0661        0.122       0.0939        0.084        0.146        0.115        0.166        0.011
    186    90      2.7e-05     2.68e-05     1.95e-07        0.118        0.149       0.0932        0.146        0.119        0.114        0.182        0.148        0.188       0.0125
    186   100     1.49e-05     1.49e-05     6.99e-09       0.0838        0.111       0.0625        0.108       0.0853       0.0893        0.132        0.111       0.0281      0.00188
    186   110     1.78e-05     1.73e-05     5.25e-07       0.0877         0.12       0.0665        0.112       0.0892       0.0892        0.147        0.118        0.312       0.0208
    186   120      8.8e-06     8.44e-06     3.67e-07       0.0637       0.0838       0.0449       0.0853       0.0651       0.0549        0.108       0.0813        0.262       0.0175
    186   130     3.22e-05     3.17e-05     4.98e-07        0.126        0.162       0.0916        0.166        0.129        0.116        0.203        0.159        0.303       0.0202
    186   140      1.6e-05     1.59e-05      1.8e-07       0.0883        0.115       0.0581        0.123       0.0905        0.072        0.149        0.111        0.184       0.0123
    186   150     1.65e-05     1.65e-05     3.12e-08       0.0853        0.117       0.0712        0.101       0.0863       0.0905        0.141        0.116       0.0719      0.00479
    186   160      1.1e-05      1.1e-05     4.17e-08         0.07       0.0955       0.0486       0.0944       0.0715       0.0611        0.124       0.0924       0.0875      0.00583
    186   170     1.37e-05     1.37e-05     3.09e-08       0.0806        0.107       0.0527        0.112       0.0826       0.0663        0.139        0.103       0.0719      0.00479
    186   180     2.33e-05     2.32e-05     1.09e-07       0.0947        0.139        0.055         0.14       0.0976       0.0703        0.189         0.13        0.141      0.00938
    186   190     2.11e-05     2.11e-05     3.18e-08       0.0941        0.132       0.0551        0.139       0.0969       0.0738        0.177        0.125       0.0719      0.00479

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    186     5     1.95e-05     1.95e-05     3.28e-09       0.0863        0.127       0.0611        0.115       0.0881       0.0921        0.158        0.125       0.0188      0.00125


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             186 3981.364    0.005     1.86e-05     1.06e-07     1.88e-05       0.0917        0.125       0.0651        0.122       0.0936       0.0858        0.158        0.122        0.112      0.00745
! Validation        186 3981.364    0.005     2.05e-05     4.77e-09     2.05e-05        0.089        0.131       0.0612        0.121        0.091        0.091        0.165        0.128       0.0194      0.00129
Wall time: 3981.3652528389994
! Best model      186    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    187    10     1.51e-05      1.5e-05     1.58e-07       0.0777        0.112       0.0442        0.116       0.0801       0.0573        0.151        0.104        0.175       0.0117
    187    20     1.53e-05     1.53e-05     5.09e-09       0.0875        0.113        0.065        0.113       0.0892       0.0818         0.14        0.111       0.0312      0.00208
    187    30      1.8e-05     1.79e-05     6.12e-08       0.0884        0.122       0.0574        0.124       0.0906       0.0742         0.16        0.117        0.106      0.00708
    187    40     1.59e-05     1.59e-05     4.22e-08       0.0837        0.115       0.0557        0.116       0.0857       0.0711         0.15        0.111       0.0875      0.00583
    187    50     1.05e-05     1.02e-05     2.87e-07       0.0673       0.0921       0.0494       0.0877       0.0686       0.0654        0.115       0.0904        0.225        0.015
    187    60     1.49e-05     1.49e-05     8.05e-09       0.0873        0.111       0.0774       0.0985        0.088        0.098        0.125        0.111       0.0344      0.00229
    187    70     1.38e-05     1.38e-05     6.85e-08        0.081        0.107       0.0598        0.105       0.0825       0.0763        0.134        0.105        0.112       0.0075
    187    80      1.1e-05      1.1e-05     4.87e-09       0.0686       0.0956       0.0477       0.0924         0.07       0.0605        0.124       0.0923       0.0219      0.00146
    187    90     2.37e-05     2.37e-05     4.66e-09        0.112         0.14        0.106        0.119        0.112         0.13        0.152        0.141       0.0219      0.00146
    187   100     1.62e-05     1.58e-05     4.12e-07       0.0867        0.115       0.0588        0.119       0.0887       0.0747        0.148        0.111        0.269       0.0179
    187   110     1.18e-05     1.18e-05     2.69e-08       0.0693        0.099       0.0421          0.1       0.0712       0.0582        0.131       0.0945       0.0656      0.00438
    187   120     1.17e-05     1.17e-05     4.13e-08       0.0779       0.0986       0.0693       0.0877       0.0785       0.0861        0.111       0.0986       0.0875      0.00583
    187   130     1.83e-05     1.82e-05     1.36e-07       0.0892        0.123        0.059        0.124       0.0913       0.0797        0.159        0.119        0.159       0.0106
    187   140     3.33e-05     3.33e-05     9.32e-09        0.125        0.166       0.0892        0.166        0.128        0.112        0.212        0.162       0.0344      0.00229
    187   150     1.48e-05     1.48e-05     3.62e-08       0.0862        0.111       0.0682        0.107       0.0875       0.0916         0.13        0.111       0.0781      0.00521
    187   160     2.25e-05     2.24e-05     7.31e-08        0.103        0.137        0.076        0.134        0.105        0.105        0.165        0.135        0.116      0.00771
    187   170     1.31e-05      1.3e-05     1.19e-08       0.0753        0.104       0.0514        0.103        0.077       0.0661        0.135        0.101       0.0437      0.00292
    187   180     1.68e-05     1.67e-05     3.79e-08       0.0903        0.118       0.0561        0.129       0.0927       0.0692        0.156        0.113       0.0781      0.00521
    187   190     1.73e-05     1.72e-05     1.36e-07       0.0853         0.12       0.0544        0.121       0.0875       0.0705        0.158        0.114        0.156       0.0104

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    187     5     1.96e-05     1.96e-05     9.54e-10       0.0867        0.128       0.0614        0.116       0.0885       0.0924        0.158        0.125       0.0109     0.000729


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             187 4002.625    0.005     1.92e-05     9.43e-08     1.93e-05       0.0929        0.126       0.0646        0.125       0.0949       0.0852        0.161        0.123         0.11      0.00733
! Validation        187 4002.625    0.005     2.04e-05     4.01e-09     2.04e-05       0.0889         0.13       0.0615         0.12       0.0909       0.0911        0.164        0.128       0.0194      0.00129
Wall time: 4002.6260203459988
! Best model      187    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    188    10      1.3e-05      1.3e-05      7.4e-08       0.0762        0.104       0.0507        0.105        0.078       0.0682        0.133        0.101        0.116      0.00771
    188    20     2.81e-05      2.8e-05     1.25e-07        0.106        0.153       0.0681         0.15        0.109       0.0873        0.203        0.145        0.156       0.0104
    188    30     1.54e-05     1.54e-05     1.48e-08       0.0883        0.113       0.0599        0.121       0.0903       0.0751        0.145         0.11       0.0562      0.00375
    188    40     1.17e-05     1.16e-05     6.36e-08       0.0751       0.0983       0.0666       0.0848       0.0757       0.0862        0.111       0.0984        0.106      0.00708
    188    50     2.26e-05     2.26e-05     1.27e-08        0.106        0.137       0.0787        0.137        0.108       0.0983        0.171        0.135       0.0437      0.00292
    188    60     1.02e-05     9.75e-06     4.59e-07       0.0696         0.09       0.0628       0.0773       0.0701         0.08          0.1       0.0901        0.291       0.0194
    188    70     2.38e-05     2.38e-05     2.18e-08        0.104        0.141       0.0678        0.145        0.106       0.0877        0.183        0.135       0.0562      0.00375
    188    80     2.17e-05     2.17e-05     4.54e-08        0.102        0.134       0.0791        0.129        0.104        0.101        0.164        0.133       0.0812      0.00542
    188    90     1.37e-05     1.37e-05     4.79e-08       0.0801        0.107       0.0655       0.0968       0.0811        0.089        0.124        0.106       0.0906      0.00604
    188   100     1.52e-05      1.5e-05     2.34e-07       0.0819        0.112       0.0543        0.113       0.0838       0.0661        0.147        0.107        0.206       0.0137
    188   110     1.99e-05     1.99e-05     9.54e-09       0.0958        0.129       0.0658         0.13       0.0979       0.0865        0.164        0.125       0.0406      0.00271
    188   120     1.79e-05     1.79e-05     4.03e-09       0.0858        0.122       0.0529        0.123       0.0881       0.0714        0.161        0.116        0.025      0.00167
    188   130      2.5e-05      2.5e-05     6.57e-09        0.104        0.144       0.0716        0.142        0.107        0.105        0.179        0.142       0.0344      0.00229
    188   140     2.29e-05     2.28e-05     9.66e-08       0.0965        0.138       0.0591        0.139       0.0991       0.0797        0.183        0.131        0.134      0.00896
    188   150     1.97e-05     1.97e-05     7.63e-09       0.0943        0.128       0.0619        0.131       0.0966       0.0833        0.165        0.124       0.0281      0.00188
    188   160     2.07e-05     2.06e-05      1.1e-07          0.1        0.131       0.0784        0.126        0.102        0.103        0.157         0.13        0.138      0.00917
    188   170      1.4e-05      1.4e-05     9.96e-09       0.0764        0.108       0.0577       0.0977       0.0777       0.0802        0.133        0.106       0.0344      0.00229
    188   180     2.92e-05     2.92e-05     3.81e-08        0.114        0.156       0.0739         0.16        0.117       0.0938        0.205        0.149       0.0781      0.00521
    188   190     2.86e-05     2.85e-05     1.34e-07        0.113        0.154       0.0708        0.161        0.116       0.0877        0.205        0.146        0.156       0.0104

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    188     5     1.97e-05     1.97e-05     1.17e-09       0.0873        0.128       0.0603        0.118       0.0892       0.0897        0.161        0.125       0.0109     0.000729


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             188 4024.054    0.005     1.88e-05     7.97e-08     1.89e-05       0.0918        0.125       0.0641        0.123       0.0938       0.0844        0.159        0.122        0.097      0.00647
! Validation        188 4024.054    0.005     2.04e-05     4.77e-09     2.04e-05       0.0889         0.13       0.0612         0.12       0.0908       0.0906        0.164        0.127       0.0194      0.00129
Wall time: 4024.054625158
! Best model      188    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    189    10     1.06e-05     1.06e-05     1.29e-08       0.0689       0.0937       0.0504       0.0899       0.0702       0.0673        0.117        0.092       0.0437      0.00292
    189    20     1.67e-05     1.67e-05     9.75e-09       0.0922        0.118       0.0717        0.116       0.0936       0.0915        0.142        0.117       0.0312      0.00208
    189    30     1.78e-05     1.77e-05     5.21e-08       0.0898        0.121       0.0647        0.119       0.0916       0.0859        0.152        0.119       0.0938      0.00625
    189    40     1.62e-05      1.6e-05      1.8e-07       0.0877        0.115       0.0604        0.119       0.0896       0.0767        0.148        0.112        0.181       0.0121
    189    50     1.45e-05     1.45e-05     3.45e-08       0.0812         0.11       0.0583        0.107       0.0828       0.0777        0.138        0.108       0.0781      0.00521
    189    60     2.41e-05      2.4e-05     6.85e-08        0.102        0.141       0.0669        0.142        0.104       0.0886        0.184        0.136        0.109      0.00729
    189    70     2.41e-05     2.41e-05     5.72e-09        0.106        0.142       0.0773        0.139        0.108        0.102        0.176        0.139        0.025      0.00167
    189    80     1.67e-05     1.67e-05     3.88e-08       0.0913        0.118       0.0764        0.108       0.0924       0.0948        0.139        0.117       0.0812      0.00542
    189    90      1.8e-05     1.79e-05     1.46e-08       0.0905        0.122        0.059        0.127       0.0928        0.074         0.16        0.117       0.0437      0.00292
    189   100     3.21e-05     3.16e-05     5.44e-07         0.12        0.162       0.0751        0.171        0.123       0.0916        0.216        0.154        0.316        0.021
    189   110     1.97e-05     1.97e-05     2.97e-09       0.0976        0.128       0.0692         0.13       0.0996       0.0882        0.162        0.125       0.0188      0.00125
    189   120     2.34e-05     2.33e-05     7.65e-08        0.101        0.139       0.0619        0.146        0.104       0.0775        0.186        0.132        0.116      0.00771
    189   130     2.75e-05     2.75e-05     6.08e-08         0.12        0.151        0.104        0.138        0.121        0.131        0.171        0.151        0.103      0.00687
    189   140     2.18e-05     2.18e-05     2.18e-08        0.101        0.135       0.0648        0.143        0.104       0.0808        0.177        0.129       0.0562      0.00375
    189   150     2.64e-05      2.6e-05     3.81e-07        0.109        0.147       0.0593        0.166        0.113       0.0759          0.2        0.138        0.262       0.0175
    189   160     1.19e-05     1.19e-05     4.87e-09       0.0774       0.0994        0.063       0.0938       0.0784       0.0794        0.118       0.0988       0.0219      0.00146
    189   170     1.66e-05     1.65e-05     9.47e-08       0.0856        0.117        0.062        0.113       0.0873       0.0869        0.144        0.116        0.131      0.00875
    189   180      1.6e-05      1.6e-05     5.64e-08       0.0836        0.115        0.056        0.115       0.0856       0.0722         0.15        0.111        0.103      0.00687
    189   190     1.08e-05     1.07e-05     6.15e-08       0.0708       0.0943       0.0486       0.0962       0.0724       0.0623        0.121       0.0916        0.106      0.00708

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    189     5     1.95e-05     1.95e-05     3.07e-09       0.0864        0.127       0.0604        0.116       0.0882       0.0899        0.159        0.125       0.0188      0.00125


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             189 4045.361    0.005     1.95e-05     1.16e-07     1.96e-05       0.0942        0.127       0.0679        0.124       0.0961       0.0895         0.16        0.125        0.114      0.00758
! Validation        189 4045.361    0.005     2.03e-05     4.32e-09     2.03e-05       0.0884         0.13        0.061         0.12       0.0904       0.0906        0.164        0.127       0.0197      0.00131
Wall time: 4045.361618257999
! Best model      189    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    190    10     1.46e-05     1.46e-05     3.52e-08       0.0819         0.11       0.0588        0.108       0.0835       0.0736        0.141        0.107        0.075        0.005
    190    20     1.72e-05     1.72e-05     2.97e-09       0.0925         0.12        0.068        0.121       0.0943       0.0819        0.151        0.117       0.0188      0.00125
    190    30     2.72e-05     2.71e-05      8.9e-09        0.108         0.15       0.0692        0.153        0.111       0.0882        0.199        0.143       0.0312      0.00208
    190    40     2.37e-05     2.35e-05     1.29e-07        0.102         0.14       0.0709        0.139        0.105       0.0855        0.183        0.134        0.147      0.00979
    190    50     2.33e-05     2.33e-05      1.8e-08        0.101        0.139        0.072        0.134        0.103       0.0954        0.176        0.136       0.0469      0.00313
    190    60     3.25e-05     3.24e-05     5.02e-08        0.129        0.164        0.102        0.161        0.131        0.121        0.203        0.162       0.0938      0.00625
    190    70     2.18e-05     2.17e-05     7.71e-08        0.102        0.134       0.0756        0.131        0.104       0.0993        0.166        0.132        0.116      0.00771
    190    80     1.52e-05     1.52e-05     2.69e-08       0.0854        0.112       0.0596        0.115       0.0872       0.0781        0.142         0.11       0.0594      0.00396
    190    90      2.2e-05      2.2e-05     7.63e-09       0.0988        0.135       0.0613        0.142        0.101       0.0907        0.173        0.132       0.0344      0.00229
    190   100     1.53e-05     1.52e-05     1.74e-08       0.0809        0.113       0.0473        0.119       0.0833        0.066        0.149        0.107       0.0594      0.00396
    190   110     8.47e-06     8.46e-06     3.81e-09       0.0608       0.0839       0.0406       0.0838       0.0622       0.0524        0.109       0.0808       0.0156      0.00104
    190   120     1.92e-05     1.91e-05     3.28e-08       0.0943        0.126       0.0716         0.12        0.096        0.091        0.157        0.124        0.075        0.005
    190   130     1.56e-05     1.56e-05     4.03e-09       0.0787        0.114       0.0467        0.115        0.081       0.0594        0.154        0.107        0.025      0.00167
    190   140     2.04e-05        2e-05     3.45e-07       0.0944        0.129       0.0647        0.128       0.0965       0.0829        0.167        0.125        0.253       0.0169
    190   150     1.03e-05     1.02e-05     4.49e-08       0.0724       0.0922       0.0553        0.092       0.0737       0.0699        0.112       0.0912       0.0906      0.00604
    190   160     2.51e-05      2.5e-05     7.25e-08        0.105        0.144       0.0634        0.152        0.107       0.0831        0.191        0.137        0.109      0.00729
    190   170     2.19e-05     2.19e-05     5.17e-08       0.0968        0.135       0.0554        0.144       0.0998        0.068        0.184        0.126       0.0938      0.00625
    190   180     2.41e-05      2.4e-05     8.73e-08        0.109        0.141       0.0708        0.152        0.111       0.0889        0.184        0.136        0.119      0.00792
    190   190     1.24e-05     1.24e-05     2.54e-08       0.0765        0.102       0.0597       0.0957       0.0777       0.0785        0.123        0.101       0.0688      0.00458

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    190     5     1.89e-05     1.89e-05     3.39e-09       0.0857        0.125       0.0595        0.116       0.0876       0.0882        0.157        0.123       0.0203      0.00135


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             190 4066.897    0.005      1.8e-05     7.65e-08     1.81e-05       0.0905        0.122       0.0639        0.121       0.0924       0.0835        0.155        0.119       0.0981      0.00654
! Validation        190 4066.897    0.005     2.01e-05     5.21e-09     2.01e-05       0.0883        0.129       0.0608         0.12       0.0903       0.0904        0.163        0.127       0.0213      0.00142
Wall time: 4066.897139331999
! Best model      190    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    191    10     1.75e-05     1.72e-05     3.14e-07       0.0914         0.12       0.0698        0.116        0.093       0.0891        0.147        0.118        0.237       0.0158
    191    20     1.71e-05     1.71e-05      1.7e-09       0.0909        0.119       0.0667        0.119       0.0927       0.0849        0.149        0.117       0.0188      0.00125
    191    30     2.14e-05     2.13e-05     1.26e-07       0.0998        0.133       0.0777        0.125        0.101       0.0949        0.166         0.13         0.15         0.01
    191    40     1.95e-05     1.95e-05      5.4e-08       0.0899        0.127       0.0566        0.128       0.0922       0.0797        0.166        0.123          0.1      0.00667
    191    50     2.55e-05     2.48e-05     6.62e-07        0.105        0.144       0.0793        0.134        0.107        0.108        0.176        0.142        0.347       0.0231
    191    60     2.44e-05     2.43e-05     4.01e-08        0.103        0.142       0.0518        0.162        0.107       0.0649        0.196        0.131       0.0781      0.00521
    191    70     1.49e-05     1.47e-05     1.45e-07       0.0808        0.111       0.0553         0.11       0.0826       0.0721        0.143        0.107        0.162       0.0108
    191    80     1.57e-05     1.54e-05     2.69e-07       0.0847        0.113       0.0694        0.102       0.0858       0.0878        0.137        0.112        0.228       0.0152
    191    90     1.07e-05     1.07e-05     2.33e-09       0.0693       0.0945       0.0474       0.0945       0.0709       0.0596        0.123       0.0912       0.0188      0.00125
    191   100     1.71e-05     1.71e-05     1.17e-08        0.088        0.119       0.0577        0.123       0.0901       0.0742        0.155        0.115       0.0375       0.0025
    191   110     3.03e-05     3.03e-05     2.92e-08        0.116        0.159       0.0687         0.17        0.119       0.0905        0.211        0.151       0.0656      0.00438
    191   120     1.38e-05     1.36e-05     2.02e-07       0.0788        0.106       0.0534        0.108       0.0806       0.0681        0.138        0.103        0.197       0.0131
    191   130     2.49e-05     2.49e-05     5.51e-09         0.11        0.144       0.0811        0.143        0.112        0.102         0.18        0.141       0.0281      0.00188
    191   140     2.23e-05     2.22e-05     9.62e-08        0.104        0.136       0.0678        0.145        0.106       0.0851        0.177        0.131        0.125      0.00833
    191   150     1.38e-05     1.38e-05     6.63e-08       0.0811        0.107       0.0601        0.105       0.0826       0.0808        0.131        0.106        0.112       0.0075
    191   160     3.26e-05     3.24e-05     2.12e-07         0.12        0.164       0.0752        0.172        0.124       0.0957        0.217        0.157        0.197       0.0131
    191   170     3.62e-05     3.61e-05     8.77e-08        0.129        0.173        0.111         0.15        0.131        0.144        0.201        0.173        0.119      0.00792
    191   180     2.09e-05     2.09e-05     1.91e-09       0.0891        0.132       0.0532         0.13       0.0917       0.0695        0.178        0.124       0.0125     0.000833
    191   190     1.98e-05     1.98e-05     3.94e-08       0.0934        0.128       0.0599        0.132       0.0958       0.0835        0.165        0.124       0.0781      0.00521

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    191     5     1.84e-05     1.84e-05     2.01e-09       0.0848        0.124       0.0596        0.114       0.0866       0.0872        0.155        0.121       0.0172      0.00115


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             191 4088.285    0.005     2.09e-05     1.23e-07      2.1e-05       0.0961        0.132       0.0672        0.129       0.0981       0.0889        0.168        0.128        0.121      0.00809
! Validation        191 4088.285    0.005     2.02e-05      3.9e-09     2.02e-05       0.0886         0.13        0.061         0.12       0.0905         0.09        0.163        0.127       0.0181      0.00121
Wall time: 4088.285938453999

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    192    10     5.49e-05     5.49e-05     8.48e-10        0.152        0.214       0.0826        0.231        0.157        0.104        0.292        0.198       0.0125     0.000833
    192    20      3.3e-05     3.29e-05     9.24e-08        0.114        0.166       0.0769        0.157        0.117       0.0958         0.22        0.158        0.128      0.00854
    192    30     3.07e-05     3.07e-05     1.99e-08        0.122         0.16       0.0794        0.171        0.125        0.104        0.206        0.155       0.0531      0.00354
    192    40     3.12e-05     3.06e-05     6.16e-07        0.111        0.159       0.0625        0.166        0.114       0.0828        0.216        0.149        0.338       0.0225
    192    50     1.65e-05     1.61e-05     4.47e-07       0.0899        0.116       0.0635         0.12       0.0918       0.0791        0.147        0.113        0.281       0.0188
    192    60     1.69e-05     1.69e-05     2.54e-09       0.0882        0.118       0.0533        0.128       0.0907       0.0711        0.156        0.113      0.00938     0.000625
    192    70     1.98e-05     1.98e-05     4.41e-08       0.0943        0.128       0.0666        0.126       0.0963       0.0852        0.164        0.125       0.0938      0.00625
    192    80     2.14e-05     2.14e-05     1.29e-08        0.105        0.133       0.0892        0.122        0.106        0.107        0.158        0.133       0.0469      0.00313
    192    90     2.09e-05     2.06e-05     3.03e-07       0.0921        0.131       0.0555        0.134       0.0947       0.0775        0.173        0.125        0.237       0.0158
    192   100     1.28e-05     1.28e-05     1.74e-08       0.0747        0.103       0.0513        0.101       0.0763       0.0685        0.132          0.1       0.0437      0.00292
    192   110     1.09e-05     1.09e-05     1.02e-08       0.0703       0.0952       0.0566       0.0859       0.0713       0.0708        0.117       0.0939       0.0375       0.0025
    192   120     2.25e-05     2.24e-05      1.4e-07       0.0997        0.136       0.0594        0.146        0.103       0.0765        0.182        0.129        0.159       0.0106
    192   130     1.69e-05     1.69e-05     2.12e-08         0.09        0.119       0.0804        0.101       0.0907        0.101        0.136        0.119       0.0562      0.00375
    192   140     2.11e-05      2.1e-05     4.62e-08        0.102        0.132       0.0763         0.13        0.103       0.0953        0.165         0.13       0.0906      0.00604
    192   150     2.46e-05     2.45e-05     6.32e-08        0.104        0.143       0.0648        0.148        0.106       0.0807         0.19        0.136        0.106      0.00708
    192   160     2.99e-05     2.98e-05      1.2e-07        0.116        0.157       0.0756        0.162        0.119       0.0947        0.207        0.151         0.15         0.01
    192   170     2.18e-05     2.17e-05     8.73e-08       0.0982        0.134       0.0641        0.137        0.101       0.0839        0.175         0.13        0.122      0.00812
    192   180     1.82e-05     1.81e-05     1.13e-07       0.0898        0.123       0.0593        0.125        0.092       0.0765         0.16        0.118        0.138      0.00917
    192   190     1.33e-05     1.33e-05      8.9e-09       0.0732        0.105       0.0517       0.0979       0.0748       0.0718        0.134        0.103       0.0312      0.00208

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    192     5     1.89e-05     1.89e-05     2.86e-09       0.0869        0.125       0.0599        0.118       0.0889       0.0882        0.157        0.123       0.0156      0.00104


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             192 4109.219    0.005     2.33e-05     1.25e-07     2.34e-05        0.101        0.139        0.069        0.137        0.103       0.0907        0.179        0.135        0.118      0.00784
! Validation        192 4109.219    0.005        2e-05     4.26e-09        2e-05       0.0883        0.129       0.0611        0.119       0.0902       0.0905        0.162        0.126       0.0178      0.00119
Wall time: 4109.219365728999
! Best model      192    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    193    10     1.49e-05     1.49e-05     2.97e-09       0.0867        0.111       0.0706        0.105       0.0879       0.0905        0.131        0.111       0.0125     0.000833
    193    20     1.87e-05     1.87e-05     1.65e-08       0.0894        0.125        0.059        0.124       0.0915       0.0782        0.162         0.12       0.0406      0.00271
    193    30     1.78e-05     1.78e-05     2.76e-09       0.0915        0.122       0.0752         0.11       0.0926        0.102        0.141        0.121       0.0188      0.00125
    193    40     1.77e-05     1.73e-05      4.2e-07        0.088         0.12       0.0611        0.119       0.0899       0.0804        0.153        0.117        0.278       0.0185
    193    50        2e-05     1.99e-05      3.2e-08       0.0892        0.129         0.05        0.134        0.092       0.0626        0.176        0.119       0.0656      0.00438
    193    60     1.59e-05     1.59e-05     2.35e-08       0.0835        0.115        0.055        0.116       0.0856       0.0757        0.148        0.112       0.0562      0.00375
    193    70     1.33e-05     1.33e-05     7.42e-09       0.0769        0.105       0.0505        0.107       0.0788       0.0649        0.138        0.101        0.025      0.00167
    193    80     1.85e-05     1.84e-05     8.35e-08       0.0902        0.124       0.0488        0.138       0.0932       0.0631        0.168        0.116        0.122      0.00812
    193    90     1.09e-05     1.08e-05     1.02e-07       0.0709       0.0948       0.0493       0.0956       0.0725       0.0633        0.121       0.0922        0.141      0.00938
    193   100     1.86e-05     1.86e-05     1.17e-08       0.0976        0.124       0.0697        0.129       0.0996       0.0868        0.157        0.122       0.0406      0.00271
    193   110     9.27e-06     9.02e-06      2.5e-07       0.0629       0.0866        0.042       0.0869       0.0644       0.0544        0.113       0.0835        0.213       0.0142
    193   120      1.7e-05      1.7e-05     1.78e-08       0.0801        0.119       0.0474        0.117       0.0824       0.0652        0.159        0.112       0.0594      0.00396
    193   130     2.35e-05     2.35e-05     1.46e-08        0.104         0.14       0.0614        0.152        0.107       0.0779        0.187        0.132         0.05      0.00333
    193   140      1.9e-05     1.88e-05     1.92e-07       0.0934        0.125       0.0658        0.125       0.0953       0.0826         0.16        0.122        0.191       0.0127
    193   150     2.83e-05      2.8e-05     2.91e-07        0.115        0.153       0.0746         0.16        0.117       0.0947        0.199        0.147        0.228       0.0152
    193   160     2.42e-05      2.4e-05     1.88e-07        0.102        0.141       0.0689        0.141        0.105       0.0922        0.182        0.137        0.184       0.0123
    193   170     1.66e-05     1.66e-05     9.96e-09       0.0875        0.117       0.0557        0.124       0.0898       0.0683        0.156        0.112       0.0406      0.00271
    193   180     2.68e-05     2.67e-05     1.11e-07         0.11        0.149         0.07        0.156        0.113       0.0955        0.193        0.144        0.141      0.00938
    193   190     2.98e-05     2.98e-05     3.81e-09        0.119        0.157       0.0849        0.159        0.122        0.112        0.197        0.154        0.025      0.00167

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    193     5     1.87e-05     1.87e-05     1.48e-09       0.0856        0.125       0.0606        0.114       0.0874         0.09        0.155        0.123       0.0125     0.000833


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             193 4130.499    0.005     2.02e-05     1.04e-07     2.03e-05       0.0941         0.13       0.0652        0.127       0.0962        0.086        0.166        0.126         0.11      0.00733
! Validation        193 4130.499    0.005     1.98e-05     4.41e-09     1.98e-05       0.0879        0.128       0.0611        0.119       0.0898       0.0904        0.161        0.126       0.0188      0.00125
Wall time: 4130.499654187999
! Best model      193    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    194    10     2.52e-05     2.52e-05     4.45e-09        0.112        0.145       0.0798        0.149        0.115       0.0987        0.184        0.141       0.0188      0.00125
    194    20     1.66e-05     1.65e-05     6.59e-08       0.0836        0.117        0.052         0.12       0.0858       0.0637        0.158        0.111        0.109      0.00729
    194    30     1.16e-05     1.15e-05     1.25e-07        0.076       0.0977       0.0546          0.1       0.0775       0.0668        0.124       0.0954         0.15         0.01
    194    40     1.62e-05     1.62e-05     5.09e-09       0.0869        0.116       0.0609        0.117       0.0888       0.0781        0.148        0.113       0.0281      0.00188
    194    50      1.9e-05     1.89e-05        1e-07       0.0963        0.125        0.063        0.134       0.0987       0.0779        0.163        0.121        0.138      0.00917
    194    60      2.2e-05      2.2e-05     1.06e-09       0.0928        0.135        0.051        0.141       0.0958         0.07        0.183        0.127      0.00938     0.000625
    194    70     1.43e-05     1.42e-05     9.54e-08       0.0857        0.109       0.0652        0.109       0.0871       0.0807        0.133        0.107        0.128      0.00854
    194    80     2.06e-05     2.06e-05     1.27e-08       0.0991        0.131        0.072         0.13        0.101       0.0924        0.164        0.128       0.0437      0.00292
    194    90     1.63e-05     1.63e-05     3.39e-08       0.0886        0.116       0.0664        0.114       0.0901       0.0837        0.145        0.114       0.0812      0.00542
    194   100     2.73e-05     2.72e-05     1.24e-07        0.107         0.15       0.0662        0.154         0.11       0.0909        0.198        0.144        0.147      0.00979
    194   110     1.31e-05     1.28e-05     2.83e-07       0.0776        0.103       0.0578          0.1        0.079       0.0775        0.126        0.102        0.228       0.0152
    194   120     1.98e-05     1.96e-05     1.98e-07       0.0972        0.128       0.0768        0.121       0.0987        0.102        0.152        0.127        0.191       0.0127
    194   130      1.5e-05     1.48e-05     1.59e-07       0.0846        0.111       0.0543        0.119       0.0868       0.0673        0.146        0.107        0.169       0.0112
    194   140     2.05e-05     2.02e-05     2.77e-07       0.0948         0.13       0.0629        0.131       0.0971       0.0916        0.163        0.127        0.228       0.0152
    194   150     2.39e-05     2.37e-05      1.6e-07        0.103        0.141       0.0657        0.146        0.106       0.0887        0.183        0.136        0.175       0.0117
    194   160     1.94e-05     1.93e-05     4.13e-08       0.0933        0.127       0.0585        0.133       0.0958       0.0767        0.166        0.122       0.0812      0.00542
    194   170     2.29e-05     2.28e-05     6.93e-08        0.101        0.138       0.0644        0.142        0.103       0.0831        0.181        0.132        0.112       0.0075
    194   180     1.15e-05     1.15e-05     7.63e-09       0.0704       0.0978       0.0501       0.0936       0.0718       0.0703        0.122        0.096        0.025      0.00167
    194   190     1.36e-05     1.32e-05     4.25e-07       0.0786        0.105       0.0572        0.103       0.0801       0.0719        0.133        0.102        0.281       0.0188

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    194     5     1.89e-05     1.89e-05     4.24e-09       0.0865        0.126       0.0597        0.117       0.0884       0.0873        0.158        0.123       0.0234      0.00156


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             194 4151.872    0.005     1.94e-05     1.31e-07     1.96e-05       0.0933        0.127       0.0642        0.126       0.0954       0.0842        0.163        0.124        0.127      0.00846
! Validation        194 4151.872    0.005     2.01e-05     4.73e-09     2.01e-05       0.0883        0.129       0.0609         0.12       0.0903       0.0902        0.163        0.126         0.02      0.00133
Wall time: 4151.872483445

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    195    10     1.56e-05     1.48e-05     8.56e-07       0.0806        0.111       0.0511        0.114       0.0827       0.0688        0.145        0.107        0.397       0.0265
    195    20     1.42e-05     1.42e-05     2.12e-09       0.0833        0.109       0.0566        0.114       0.0852        0.071         0.14        0.106       0.0156      0.00104
    195    30     1.68e-05     1.67e-05     7.99e-08       0.0921        0.118       0.0729        0.114       0.0934       0.0957        0.139        0.117        0.122      0.00812
    195    40     2.61e-05      2.6e-05     5.21e-08        0.113        0.147       0.0859        0.144        0.115        0.109        0.181        0.145       0.0969      0.00646
    195    50     1.49e-05     1.49e-05     6.57e-09       0.0816        0.111       0.0556        0.111       0.0835       0.0712        0.144        0.108       0.0281      0.00188
    195    60     2.57e-05     2.57e-05     3.75e-08         0.11        0.146       0.0744        0.151        0.113       0.0903        0.191        0.141       0.0812      0.00542
    195    70     1.32e-05     1.32e-05     9.75e-09       0.0795        0.105       0.0515        0.111       0.0815       0.0654        0.136        0.101       0.0312      0.00208
    195    80     2.24e-05     2.24e-05     1.46e-08        0.101        0.136       0.0647        0.143        0.104       0.0862        0.177        0.132       0.0406      0.00271
    195    90     1.52e-05      1.5e-05     1.84e-07       0.0873        0.112       0.0737        0.103       0.0882       0.0948        0.128        0.112        0.181       0.0121
    195   100     1.59e-05     1.59e-05     2.12e-09       0.0856        0.115       0.0545        0.121       0.0878       0.0696        0.151         0.11       0.0156      0.00104
    195   110     2.15e-05     2.15e-05     5.89e-08       0.0981        0.134       0.0623        0.139        0.101       0.0794        0.176        0.128          0.1      0.00667
    195   120     2.66e-05      2.6e-05     6.01e-07       0.0986        0.147         0.07        0.131        0.101        0.102        0.185        0.144        0.331       0.0221
    195   130     2.39e-05     2.39e-05     5.04e-08        0.101        0.141       0.0652        0.142        0.104       0.0835        0.186        0.135       0.0906      0.00604
    195   140     1.41e-05      1.4e-05     2.33e-09       0.0808        0.108       0.0548         0.11       0.0826        0.068        0.141        0.104      0.00938     0.000625
    195   150     1.84e-05     1.83e-05     8.07e-08       0.0908        0.123       0.0664        0.119       0.0926       0.0848        0.156         0.12        0.125      0.00833
    195   160      1.1e-05     1.09e-05     1.86e-07       0.0744        0.095       0.0596       0.0913       0.0754       0.0711        0.117       0.0938        0.188       0.0125
    195   170     1.46e-05     1.45e-05     1.07e-07       0.0823         0.11       0.0621        0.105       0.0838       0.0793        0.136        0.108        0.134      0.00896
    195   180      1.5e-05     1.49e-05     1.49e-07       0.0835        0.111         0.06         0.11       0.0852       0.0758        0.141        0.109        0.162       0.0108
    195   190     1.36e-05     1.36e-05     5.51e-09       0.0791        0.106       0.0524         0.11        0.081       0.0686        0.137        0.103       0.0281      0.00188

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    195     5     1.75e-05     1.75e-05     1.06e-09        0.084        0.121       0.0592        0.112       0.0857       0.0881        0.149        0.119       0.0125     0.000833


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             195 4173.303    0.005     1.77e-05     1.21e-07     1.78e-05       0.0893        0.121       0.0633        0.119       0.0912       0.0831        0.154        0.118        0.123      0.00817
! Validation        195 4173.303    0.005     1.97e-05     4.01e-09     1.97e-05       0.0875        0.128       0.0606        0.118       0.0895       0.0898        0.161        0.125       0.0191      0.00127
Wall time: 4173.304237332999
! Best model      195    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    196    10     1.44e-05     1.43e-05     3.14e-08       0.0847        0.109       0.0704        0.101       0.0857       0.0906        0.127        0.109       0.0625      0.00417
    196    20     9.76e-06     9.71e-06     4.81e-08       0.0653       0.0899       0.0463        0.087       0.0666       0.0601        0.115       0.0874       0.0969      0.00646
    196    30     1.56e-05     1.55e-05     5.34e-08       0.0865        0.114       0.0663        0.109       0.0879       0.0845         0.14        0.112       0.0969      0.00646
    196    40      2.9e-05     2.89e-05     6.06e-08        0.122        0.155       0.0902        0.158        0.124        0.111        0.194        0.152          0.1      0.00667
    196    50     1.84e-05     1.83e-05     1.26e-07       0.0922        0.123       0.0645        0.124       0.0942       0.0898        0.153        0.121         0.15         0.01
    196    60     1.56e-05     1.54e-05     2.41e-07        0.084        0.113       0.0582        0.113       0.0858       0.0727        0.146        0.109        0.209        0.014
    196    70     1.61e-05     1.58e-05     3.92e-07       0.0847        0.114       0.0556        0.118       0.0868       0.0679        0.151        0.109        0.275       0.0183
    196    80     2.05e-05     2.05e-05     3.39e-09       0.0991        0.131       0.0608        0.143        0.102       0.0772        0.172        0.125        0.025      0.00167
    196    90     1.69e-05     1.68e-05     9.73e-08       0.0903        0.118        0.068        0.116       0.0919       0.0837        0.148        0.116        0.134      0.00896
    196   100     1.04e-05     1.04e-05     2.97e-09       0.0691        0.093       0.0486       0.0926       0.0706       0.0639        0.118       0.0908       0.0156      0.00104
    196   110     2.11e-05      2.1e-05     7.12e-08       0.0947        0.132       0.0637         0.13       0.0969       0.0855         0.17        0.128        0.112       0.0075
    196   120     2.49e-05     2.49e-05     1.95e-08        0.101        0.144       0.0633        0.143        0.103       0.0802        0.192        0.136       0.0531      0.00354
    196   130     1.17e-05     1.17e-05      1.1e-08       0.0718       0.0986       0.0537       0.0926       0.0731       0.0703        0.123       0.0967       0.0437      0.00292
    196   140     1.29e-05     1.29e-05     2.54e-09       0.0772        0.104       0.0474        0.111       0.0793       0.0597        0.138       0.0987       0.0156      0.00104
    196   150     1.87e-05     1.86e-05     1.11e-07       0.0867        0.124       0.0544        0.124        0.089       0.0721        0.165        0.119        0.144      0.00958
    196   160      2.1e-05     2.09e-05      9.6e-08        0.101        0.132       0.0672        0.139        0.103       0.0855         0.17        0.128        0.138      0.00917
    196   170     1.28e-05     1.27e-05     2.95e-08       0.0806        0.103        0.072       0.0904       0.0812       0.0881        0.118        0.103       0.0719      0.00479
    196   180     1.58e-05     1.58e-05     1.91e-09       0.0872        0.115       0.0626        0.115        0.089       0.0778        0.146        0.112       0.0125     0.000833
    196   190     1.56e-05     1.56e-05     1.48e-08       0.0912        0.114       0.0833          0.1       0.0917        0.105        0.123        0.114       0.0469      0.00313

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    196     5     1.92e-05     1.92e-05     1.27e-09       0.0863        0.126       0.0593        0.117       0.0882       0.0891        0.158        0.124       0.0125     0.000833


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             196 4194.767    0.005     1.83e-05     7.25e-08     1.83e-05       0.0912        0.123       0.0649        0.121       0.0931        0.085        0.156         0.12       0.0925      0.00617
! Validation        196 4194.767    0.005     1.99e-05     3.94e-09     1.99e-05       0.0878        0.129       0.0607        0.119       0.0897       0.0897        0.162        0.126       0.0178      0.00119
Wall time: 4194.767866692999

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    197    10     1.99e-05     1.98e-05     6.17e-08        0.105        0.128       0.0935        0.118        0.106        0.113        0.144        0.128        0.103      0.00687
    197    20     1.52e-05     1.51e-05     9.83e-08       0.0862        0.112       0.0539        0.123       0.0885       0.0693        0.147        0.108        0.134      0.00896
    197    30     1.19e-05     1.18e-05     1.12e-07       0.0715        0.099       0.0481       0.0982       0.0732       0.0638        0.128       0.0958        0.144      0.00958
    197    40     2.13e-05     2.12e-05     1.55e-08       0.0998        0.133       0.0614        0.144        0.103       0.0771        0.176        0.127       0.0469      0.00313
    197    50     1.77e-05     1.71e-05     6.53e-07       0.0886        0.119       0.0606        0.121       0.0906       0.0782        0.153        0.116         0.35       0.0233
    197    60      1.5e-05     1.49e-05     7.12e-08        0.084        0.111       0.0672        0.103       0.0852       0.0829        0.137         0.11        0.119      0.00792
    197    70     1.46e-05     1.46e-05     6.57e-09       0.0811         0.11       0.0552        0.111       0.0829       0.0713        0.142        0.107       0.0312      0.00208
    197    80     8.24e-06      8.2e-06     4.81e-08       0.0629       0.0826       0.0452       0.0832       0.0642       0.0586        0.103        0.081       0.0938      0.00625
    197    90     1.78e-05     1.76e-05     1.54e-07       0.0884        0.121       0.0741        0.105       0.0894       0.0999        0.141        0.121        0.169       0.0113
    197   100     2.43e-05     2.42e-05     1.27e-08        0.106        0.142       0.0685        0.148        0.108        0.089        0.185        0.137       0.0469      0.00313
    197   110     1.82e-05     1.82e-05     2.33e-09       0.0931        0.123       0.0652        0.125       0.0951        0.084        0.156         0.12       0.0156      0.00104
    197   120     1.93e-05     1.93e-05     1.44e-08       0.0914        0.127       0.0616        0.126       0.0936       0.0826        0.163        0.123         0.05      0.00333
    197   130     1.67e-05     1.67e-05     2.39e-08       0.0856        0.118        0.059        0.116       0.0875       0.0767        0.152        0.114       0.0594      0.00396
    197   140     2.31e-05     2.27e-05     4.09e-07        0.108        0.137       0.0933        0.126        0.109        0.117        0.158        0.137        0.275       0.0183
    197   150     1.72e-05      1.7e-05      1.2e-07       0.0794        0.119       0.0425        0.121        0.082       0.0577        0.163         0.11        0.153       0.0102
    197   160     1.71e-05      1.7e-05     5.93e-08       0.0899        0.119       0.0735        0.109       0.0911       0.0919        0.144        0.118        0.103      0.00687
    197   170     1.77e-05     1.77e-05     3.18e-09       0.0871        0.121       0.0521        0.127       0.0896       0.0692        0.161        0.115       0.0188      0.00125
    197   180     2.62e-05     2.62e-05     5.91e-08        0.107        0.148       0.0617        0.158         0.11       0.0769          0.2        0.138          0.1      0.00667
    197   190     1.98e-05     1.97e-05     8.22e-08       0.0986        0.128       0.0784        0.122          0.1       0.0991        0.154        0.127        0.122      0.00812

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    197     5     1.82e-05     1.82e-05     1.48e-09       0.0841        0.123       0.0582        0.114        0.086       0.0859        0.155         0.12       0.0156      0.00104


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             197 4216.355    0.005     1.74e-05     9.13e-08     1.75e-05       0.0889         0.12       0.0627        0.119       0.0907       0.0821        0.153        0.117        0.106      0.00707
! Validation        197 4216.355    0.005     1.98e-05     4.28e-09     1.98e-05       0.0872        0.128       0.0603        0.118       0.0891       0.0893        0.162        0.125       0.0197      0.00131
Wall time: 4216.355700030999

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    198    10     1.14e-05     1.08e-05     6.75e-07        0.074       0.0946       0.0556       0.0951       0.0753       0.0698        0.117       0.0933        0.356       0.0237
    198    20     2.26e-05     2.24e-05     1.87e-07       0.0975        0.137       0.0615        0.139          0.1       0.0775        0.182         0.13        0.184       0.0123
    198    30     2.72e-05     2.53e-05     1.84e-06         0.11        0.145        0.082        0.142        0.112        0.104        0.181        0.143        0.587       0.0392
    198    40     2.21e-05     2.18e-05     2.82e-07       0.0997        0.135       0.0703        0.133        0.102       0.0884        0.173        0.131        0.225        0.015
    198    50     2.89e-05     2.86e-05     3.25e-07        0.115        0.154       0.0863        0.149        0.117        0.109        0.193        0.151        0.247       0.0165
    198    60     2.79e-05     2.79e-05     9.32e-09        0.119        0.152       0.0979        0.143         0.12        0.121        0.182        0.151       0.0375       0.0025
    198    70     2.05e-05     2.04e-05     1.19e-08       0.0981         0.13       0.0638        0.137        0.101       0.0841        0.168        0.126       0.0437      0.00292
    198    80     1.72e-05     1.71e-05     4.81e-08        0.088        0.119       0.0629        0.117       0.0898       0.0786        0.153        0.116       0.0969      0.00646
    198    90     1.92e-05     1.91e-05     9.49e-08       0.0944        0.126       0.0614        0.132       0.0968       0.0771        0.165        0.121        0.131      0.00875
    198   100     1.56e-05     1.56e-05     1.31e-08       0.0849        0.114       0.0601        0.113       0.0867       0.0767        0.145        0.111       0.0437      0.00292
    198   110      2.6e-05     2.59e-05     1.74e-07        0.115        0.147       0.0926        0.141        0.117        0.117        0.174        0.146        0.175       0.0117
    198   120     1.97e-05     1.88e-05     8.32e-07       0.0937        0.125       0.0651        0.126       0.0957       0.0856        0.159        0.122        0.397       0.0265
    198   130     1.46e-05     1.43e-05     2.72e-07       0.0761        0.109       0.0518        0.104       0.0778       0.0702        0.141        0.106        0.219       0.0146
    198   140     1.37e-05     1.36e-05     1.43e-07       0.0785        0.106       0.0547        0.106       0.0802       0.0744        0.134        0.104        0.166        0.011
    198   150     1.46e-05     1.44e-05     2.16e-07       0.0854        0.109        0.064         0.11       0.0869       0.0798        0.136        0.108          0.2       0.0133
    198   160     8.75e-06     8.68e-06     6.19e-08       0.0635        0.085       0.0451       0.0845       0.0648       0.0583        0.108        0.083        0.109      0.00729
    198   170     1.48e-05     1.48e-05     2.39e-08         0.08        0.111       0.0494        0.115       0.0822       0.0601        0.149        0.104       0.0625      0.00417
    198   180     1.23e-05     1.23e-05      4.3e-08       0.0746        0.101       0.0464        0.107       0.0766       0.0578        0.134       0.0961       0.0844      0.00562
    198   190     1.71e-05     1.71e-05     2.27e-08       0.0933        0.119       0.0733        0.116       0.0948        0.092        0.144        0.118       0.0594      0.00396

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    198     5     1.85e-05     1.85e-05     1.91e-09       0.0845        0.124       0.0585        0.114       0.0864       0.0864        0.156        0.121       0.0156      0.00104


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             198 4237.631    0.005     1.83e-05     2.13e-07     1.85e-05       0.0908        0.123       0.0635        0.122       0.0927       0.0835        0.157         0.12        0.158       0.0105
! Validation        198 4237.631    0.005     1.95e-05      4.2e-09     1.95e-05        0.087        0.127       0.0601        0.118       0.0889       0.0889        0.161        0.125       0.0175      0.00117
Wall time: 4237.631527825999
! Best model      198    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    199    10     1.82e-05     1.81e-05     4.75e-08       0.0885        0.123       0.0546        0.127       0.0909       0.0754        0.161        0.118       0.0906      0.00604
    199    20     1.93e-05     1.93e-05     5.34e-08       0.0917        0.127       0.0613        0.126       0.0939       0.0917        0.157        0.124       0.0969      0.00646
    199    30     2.56e-05     2.55e-05      9.2e-08        0.111        0.146       0.0761        0.152        0.114       0.0941        0.188        0.141        0.125      0.00833
    199    40     1.36e-05     1.36e-05     5.72e-09       0.0805        0.106       0.0603        0.104       0.0819       0.0798         0.13        0.105        0.025      0.00167
    199    50      2.1e-05     2.07e-05     2.89e-07       0.0998        0.131       0.0801        0.122        0.101       0.0992         0.16         0.13        0.234       0.0156
    199    60     2.19e-05     2.18e-05     1.84e-07          0.1        0.135       0.0686        0.136        0.103       0.0869        0.174         0.13        0.181       0.0121
    199    70     1.72e-05      1.7e-05     2.65e-07       0.0877        0.119       0.0624        0.117       0.0895         0.08        0.151        0.116        0.222       0.0148
    199    80     2.16e-05     2.16e-05     7.67e-08       0.0971        0.134       0.0577        0.142          0.1       0.0714        0.181        0.126        0.119      0.00792
    199    90     1.97e-05     1.97e-05     8.48e-09       0.0982        0.128       0.0728        0.127          0.1       0.0945        0.158        0.126       0.0344      0.00229
    199   100     1.71e-05      1.7e-05     8.52e-08       0.0876        0.119       0.0551        0.125       0.0899       0.0691        0.157        0.113        0.125      0.00833
    199   110     2.29e-05     2.29e-05     4.28e-08        0.102        0.138        0.064        0.145        0.104       0.0852         0.18        0.133       0.0844      0.00563
    199   120     1.79e-05     1.79e-05      8.9e-09         0.09        0.122       0.0543        0.131       0.0925       0.0692        0.162        0.116       0.0375       0.0025
    199   130     1.17e-05     1.17e-05     4.87e-09       0.0732       0.0987       0.0489        0.101        0.075       0.0617        0.129       0.0951       0.0281      0.00188
    199   140     1.41e-05     1.38e-05     3.55e-07       0.0797        0.107       0.0565        0.106       0.0813        0.071        0.137        0.104        0.256       0.0171
    199   150     1.64e-05     1.62e-05     2.38e-07       0.0852        0.116       0.0559        0.119       0.0873       0.0751        0.149        0.112        0.203       0.0135
    199   160      9.4e-06     8.81e-06      5.9e-07       0.0642       0.0856       0.0486        0.082       0.0653       0.0644        0.105       0.0845        0.334       0.0223
    199   170     1.42e-05     1.39e-05     3.22e-07        0.076        0.108       0.0443        0.112       0.0783        0.058        0.145        0.101        0.247       0.0165
    199   180      1.8e-05     1.77e-05     3.26e-07       0.0896        0.121       0.0521        0.132       0.0922       0.0651        0.163        0.114        0.247       0.0165
    199   190     1.38e-05     1.38e-05     6.57e-09       0.0819        0.107       0.0521        0.116        0.084       0.0667         0.14        0.103       0.0281      0.00188

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    199     5     1.84e-05     1.84e-05     3.28e-09       0.0842        0.124       0.0587        0.113        0.086       0.0884        0.154        0.121       0.0188      0.00125


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             199 4258.973    0.005     1.78e-05     1.12e-07     1.79e-05       0.0897        0.122       0.0629         0.12       0.0916       0.0826        0.154        0.119        0.117      0.00779
! Validation        199 4258.973    0.005     1.95e-05     4.51e-09     1.95e-05       0.0868        0.127       0.0602        0.117       0.0887       0.0893         0.16        0.125       0.0197      0.00131
Wall time: 4258.974219676
! Best model      199    0.000

training
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    200    10     1.25e-05     1.24e-05     1.23e-08       0.0763        0.102       0.0495        0.107       0.0782       0.0622        0.133       0.0977       0.0437      0.00292
    200    20     1.11e-05     1.11e-05     1.23e-08       0.0728       0.0962       0.0542       0.0939       0.0741       0.0713        0.118       0.0949       0.0469      0.00313
    200    30     1.86e-05     1.86e-05     1.82e-08       0.0941        0.124       0.0565        0.137       0.0968        0.073        0.165        0.119       0.0562      0.00375
    200    40     2.31e-05     2.31e-05      8.9e-09        0.102        0.138       0.0655        0.143        0.104       0.0867         0.18        0.133       0.0281      0.00188
    200    50     2.79e-05     2.78e-05     1.07e-07        0.118        0.152       0.0826        0.158         0.12        0.104        0.193        0.148        0.141      0.00938
    200    60     1.19e-05     1.19e-05     7.42e-09       0.0779       0.0996       0.0731       0.0835       0.0783       0.0887        0.111       0.0998       0.0281      0.00188
    200    70     1.78e-05     1.78e-05     6.93e-08       0.0922        0.122       0.0669        0.121        0.094       0.0885        0.151         0.12        0.109      0.00729
    200    80     1.49e-05     1.47e-05     2.23e-07       0.0812        0.111       0.0487        0.118       0.0836       0.0632        0.147        0.105        0.203       0.0135
    200    90      1.7e-05      1.7e-05     3.39e-09       0.0889        0.119       0.0572        0.125       0.0912       0.0715        0.156        0.114        0.025      0.00167
    200   100     1.83e-05     1.83e-05     4.87e-09       0.0875        0.123       0.0637        0.115       0.0892       0.0886        0.154        0.121       0.0281      0.00188
    200   110     2.57e-05     2.55e-05     2.11e-07        0.106        0.146       0.0683        0.149        0.109       0.0852        0.193        0.139        0.203       0.0135
    200   120     2.09e-05     2.09e-05     4.03e-09          0.1        0.132       0.0693        0.136        0.103       0.0926        0.165        0.129       0.0188      0.00125
    200   130     2.68e-05     2.67e-05     1.24e-07        0.113        0.149       0.0806         0.15        0.115        0.106        0.187        0.146        0.153       0.0102
    200   140      3.7e-05      3.7e-05     2.99e-08         0.13        0.175       0.0922        0.174        0.133        0.125         0.22        0.172       0.0656      0.00438
    200   150     1.59e-05     1.59e-05     2.25e-08        0.088        0.115        0.063        0.117       0.0898       0.0775        0.146        0.112       0.0562      0.00375
    200   160     1.62e-05     1.62e-05     5.51e-09       0.0868        0.116       0.0642        0.113       0.0884        0.081        0.146        0.114       0.0281      0.00188
    200   170     1.97e-05     1.96e-05     2.54e-08       0.0942        0.128       0.0654        0.127       0.0962       0.0889        0.161        0.125       0.0625      0.00417
    200   180     1.99e-05     1.98e-05     1.28e-07       0.0909        0.128       0.0542        0.133       0.0935       0.0722        0.171        0.122         0.15         0.01
    200   190      1.9e-05     1.89e-05     2.27e-08       0.0897        0.126       0.0587        0.125       0.0919         0.08        0.163        0.121       0.0531      0.00354

validation
# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
    200     5     1.82e-05     1.82e-05     3.07e-09       0.0842        0.123       0.0586        0.113        0.086       0.0882        0.153        0.121       0.0188      0.00125


  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae
! Train             200 4280.225    0.005     1.95e-05     6.03e-08     1.96e-05       0.0935        0.127       0.0646        0.127       0.0956       0.0848        0.163        0.124       0.0825       0.0055
! Validation        200 4280.225    0.005     1.94e-05     4.77e-09     1.94e-05       0.0868        0.127         0.06        0.117       0.0888       0.0895        0.159        0.124         0.02      0.00133
Wall time: 4280.225874275
! Best model      200    0.000
! Stop training: max epochs
Wall time: 4280.437213101
Cumulative wall time: 4280.437213101
